{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2><center>Programa Nanodegree Engenheiro de Machine Learning</center></h2>\n",
    "<h3><center>Relatório do projeto de conclusão de machine learning - Capstone</center></h3>\n",
    "<br>\n",
    "<center>  \n",
    "Robson Azevedo Rung<br>\n",
    "    <i>30/07/2019</i>\n",
    "</center> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visão geral do projeto\n",
    "\n",
    "Esse projeto busca desenvolver uma solução baseada em técnicas de machine learning para prever preços de imóveis.\n",
    "\n",
    "Imóveis são bens de grande relevância para qualquer sociedade, e têm seus preços formados não de forma única, mas a partir das características que possuem. [A]\n",
    "\n",
    "Assim sendo, os consumidores potenciais têm a percepção de diferenciaras diversas possibilidades de características em função do que é tido como prioritário. Desta maneira, um determinado consumidor pode escolher seu \"pacote\" de características disponíveis para cada bem ou serviço em função da percepção de utilidade.\n",
    "\n",
    "Muitos estudos buscam determinar os atributos intrínsecos e extrínsecos pertencentes a cada residência, a fim de verificar quais deles apresentam maior representatividade para a composição dos instrumentos de demanda e oferta, utilizando-se modelos de preços hedônicos, por meio dos quais é possível analisar a importância relativa de cada atributo em função dos diferentes perfis sociodemográficos. [B]\n",
    "\n",
    "Uma das atividades de empresas e profissionais do ramo imobiliário é a analisar o valor de imóveis, com objetivo de vendê-los em tempo razoável e maximizar seus lucros.\n",
    "\n",
    "O conjunto de dados deste trabalho será aquele disponibilizado na competição intitulada *\"House Prices: Advanced Regression Techniques\"* da plataforma Kaggle. [C]\n",
    "\n",
    "Constam dos dados diversos atributos, por exemplo:\n",
    "\n",
    "- Tipo da propriedade;\n",
    "- Tamanho do lote;\n",
    "- Recursos públicos disponíveis (eletricidade, gás, água e saneamento);\n",
    "- Condições de acesso;\n",
    "- Acabamento (materiais);\n",
    "- Estado de conservação;\n",
    "- Tipo da fundação;\n",
    "- Tipo de aquecimento;\n",
    "- Sistema elétrico;\n",
    "- Características da garagem;\n",
    "- Idade do imóvel;\n",
    "- etc.\n",
    "\n",
    "Os dados são fornecidos em dois grupos, um de treinamento e outro de teste (esse não contém o preço de venda, e deve ser usada para envio à competição).\n",
    "\n",
    "### Declaração do problema\n",
    "\n",
    "Entender quais características são as mais relevantes e como impactam os preços é tarefa complexa por si só. Além disso, tais fatores podem mudar ao longo do tempo e variam entre regiões geográficas. Podem, ainda, ser afetadas por diferenças culturais e climáticas.\n",
    "\n",
    "Inicialmente serão usadas técnicas de análise de dados para buscar obter uma compreensão dos tipos de atributos existentes na base de dados, considerando seus tipos de dados e suas possíveis correlações. \n",
    "\n",
    "Como auxílio à análise, estatísticas como média, mediana, desvio padrão, valores máximos e mínimos serão calculadas.\n",
    "\n",
    "Os atributos que precisarem de tratamento especial, como a aplicação de normalização ou *one-hot enconde* serão devidamente tratados. Dados ordinais textuais serão convertidos em numéricos.\n",
    "\n",
    "Buscar-se-á, também, a aplicação da técnica de seleção de atributos (*feature selection*) conhecida como PCA (*Principal Component Analysis*), de modo a evitar-se o problema da dimensionalidade (*curse of dimensionality*).\n",
    "\n",
    "Será conduzida uma uma busca por *outliers* e dados faltantes, de modo a evitar distorções nos modelos durante o treinamento.\n",
    "\n",
    "Agora será realizado o treinamento dos modelos. Para o caso da aprendizagem supervisionada, será conduzida uma otimização dos hiperparâmetros usando a técnica de *grid search*, validação com *cross-validation* e regularizção (*regularization*).\n",
    "    \n",
    "Agora será realizado o treinamento dos modelos. Para o caso da aprendizagem supervisionada, será conduzida uma otimização dos hiperparâmetros usando a técnica de *grid search*.\n",
    "\n",
    "Além disso, a mesma tarefa será realizada usando técnicas de deep learning. Será criada e treinada uma rede neural com os dados fornecidos.\n",
    "\n",
    "For fim, o coeficiente de determinação será calculado para avaliar a performance dos modelos.\n",
    "\n",
    "### Métricas\n",
    "\n",
    "Para avaliar a performance dos modelos, será calculado o coeficiente de determinação (R2), um modelo bastante usado para analisar regressões.\n",
    "\n",
    "O valor de R2 indica o percentual de correlação quadrática entre os valores previstos e os valores reais. Quando o resultado é igual a 0, o modelo de regressão se equivale a um modelo que sempre tem como resultado a média amostral (dados de treinamento). Por outro lado, quando R2 é igual a 1, significa que o modelo foi capaz de prever com precisão os valores da variável alvo.\n",
    "\n",
    "É possível que R2 tenha como resultado um valor negativo, o que significa que o modelo de regressão é pior do que um modelo que sempre prevê a média.\n",
    "\n",
    "A competição no Kaggle utiliza-se, para comparar as soluções que são submetidas, a métrica Root Mean Squared Logarithmic Error - RMSLE. Essa métrica calcula a raiz quadrada da média do quadrado das diferenças entre o valor original e o valor previsto. O uso de logs tem como objetivo evitar que erros nos valores previstos de imóveis caros afete mais o resultado do que erros em imóveis baratos. Essa métrica também será calculada neste projeto.\n",
    "\n",
    "Além disso, com o objetivo de comparação entre as soluções propostas e uma métrica inicial, do tipo ingênua (*naive*), serão calculadas as métricas acima para um conjunto de dados que tenha como preços estimados exatamente a média dos preços de venda existentes. O mesmo procedimento será feito para a mediana."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importação das bibliotecas usadas no projeto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import datetime\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import locale\n",
    "import math\n",
    "from math import sqrt\n",
    "from sklearn.linear_model import ElasticNet\n",
    "from sklearn.linear_model import LassoLars\n",
    "from sklearn.linear_model import LassoCV\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn import preprocessing\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Carregamento da Base de Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cálculo das estatísticas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Valor mínimo do conjunto de treinamento ------>  $34,900.00\n",
      "Valor máximo do conjunto de treinamento ------> $755,000.00\n",
      "Valor da média do conjunto de treinamento ----> $180,921.20\n",
      "Valor da mediana do conjunto de treinamento --> $163,000.00\n",
      "Valor do desvio padrão ----------------------->  $79,415.29\n"
     ]
    }
   ],
   "source": [
    "locale.setlocale(locale.LC_ALL, 'en_US.utf8') \n",
    "\n",
    "Y_train_full = train[\"SalePrice\"]\n",
    "X_train_full = train.drop([\"SalePrice\"], axis=1)\n",
    "\n",
    "print(\"Valor mínimo do conjunto de treinamento ------>  {}\".format(locale.currency(np.min(Y_train_full), grouping=True)))\n",
    "print(\"Valor máximo do conjunto de treinamento ------> {}\".format(locale.currency(np.max(Y_train_full), grouping=True)))\n",
    "print(\"Valor da média do conjunto de treinamento ----> {}\".format(locale.currency(np.mean(Y_train_full), grouping=True)))\n",
    "print(\"Valor da mediana do conjunto de treinamento --> {}\".format(locale.currency(np.median(Y_train_full), grouping=True)))\n",
    "print(\"Valor do desvio padrão ----------------------->  {}\".format(locale.currency(np.std(Y_train_full), grouping=True)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cálculo das métricas a serem usadas como base"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inicialmente é necessário definir a função para cálculo da média quadrática entre o logaritmo do valor previsto e o logaritmo do valor estimado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmsle(y, y_pred):\n",
    "    soma = 0.0\n",
    "    for i,pred in enumerate(y_pred):\n",
    "        if (pred > 0) & (y[i] > 0):\n",
    "            soma += (np.log(pred + 1) - np.log(y[i] + 1)) ** 2.0\n",
    "        elif pred <= 0:  \n",
    "            print(\"Erro na linha {}. Valor previsto menor ou igual a zero: {}.\".format(i, pred))\n",
    "        elif y[i] <= 0:  \n",
    "            print(\"Erro na linha {}. Valor original menor ou igual a zero: {}.\".format(i, y[i]))\n",
    "    return (soma * (1.0/len(y))) ** 0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agora iremos calcular as métricas para um conjunto de dados que tem como valores previstos a média dos valores originais (aqui, conforme dito acima, o resultado será igual a zero). Na sequência, o mesmo procedimento será feito usando a mediana."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score para a previsão usando a média:      0.000\n",
      "RMSLE para a previsão usando a média:         0.408\n"
     ]
    }
   ],
   "source": [
    "Y_media = np.full((len(Y_train_full)), np.mean(Y_train_full))\n",
    "print(\"R2 Score para a previsão usando a média: {:10.3f}\".format(r2_score(Y_train_full, Y_media)))\n",
    "print(\"RMSLE para a previsão usando a média:    {:10.3f}\".format(rmsle(Y_train_full, Y_media)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score para a previsão usando a mediana:     -0.051\n",
      "RMSLE para a previsão usando a mediana:         0.400\n"
     ]
    }
   ],
   "source": [
    "Y_median = np.full((len(Y_train_full)), np.median(Y_train_full))\n",
    "print(\"R2 Score para a previsão usando a mediana: {:10.3f}\".format(r2_score(Y_train_full, Y_median)))\n",
    "print(\"RMSLE para a previsão usando a mediana:    {:10.3f}\".format(rmsle(Y_train_full, Y_median)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Com base nos cálculos acima, nosso objetivo será buscar projeções que apresentem, pelo menos, R2 Score maior do que 0.0 e RMSLE menor do que 0.4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análise de correlação"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Iniciaremos com uma visualização da matriz de correlação."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x648 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#correlation matrix\n",
    "corrmat = train.corr()\n",
    "f, ax = plt.subplots(figsize=(20, 9))\n",
    "sns.heatmap(corrmat, vmax=.8, annot=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listagem de atributos com graus de correlação maior do que 50% com o preço de venda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlação de OverallQual com SalePrice: 0.791\n",
      "Correlação de YearBuilt com SalePrice: 0.523\n",
      "Correlação de YearRemodAdd com SalePrice: 0.507\n",
      "Correlação de TotalBsmtSF com SalePrice: 0.614\n",
      "Correlação de 1stFlrSF com SalePrice: 0.606\n",
      "Correlação de GrLivArea com SalePrice: 0.709\n",
      "Correlação de FullBath com SalePrice: 0.561\n",
      "Correlação de TotRmsAbvGrd com SalePrice: 0.534\n",
      "Correlação de GarageCars com SalePrice: 0.640\n",
      "Correlação de GarageArea com SalePrice: 0.623\n"
     ]
    }
   ],
   "source": [
    "atributos_correlacao_preco_maior_50 = []\n",
    "for id in corrmat.index:\n",
    "    achouDiagonal = False\n",
    "    if (id != \"SalePrice\") & (corrmat.loc[id][\"SalePrice\"] > 0.5):\n",
    "        atributos_correlacao_preco_maior_50.append(id)\n",
    "        print(\"Correlação de {} com SalePrice: {:1.3f}\".format(id, corrmat.loc[id][\"SalePrice\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Listagem de atributos com graus de correlação entre 10% e 50% com o preço de venda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Correlação de LotFrontage com SalePrice: 0.352\n",
      "Correlação de LotArea com SalePrice: 0.264\n",
      "Correlação de MasVnrArea com SalePrice: 0.477\n",
      "Correlação de BsmtFinSF1 com SalePrice: 0.386\n",
      "Correlação de BsmtUnfSF com SalePrice: 0.214\n",
      "Correlação de 2ndFlrSF com SalePrice: 0.319\n",
      "Correlação de BsmtFullBath com SalePrice: 0.227\n",
      "Correlação de HalfBath com SalePrice: 0.284\n",
      "Correlação de BedroomAbvGr com SalePrice: 0.168\n",
      "Correlação de Fireplaces com SalePrice: 0.467\n",
      "Correlação de GarageYrBlt com SalePrice: 0.486\n",
      "Correlação de WoodDeckSF com SalePrice: 0.324\n",
      "Correlação de OpenPorchSF com SalePrice: 0.316\n",
      "Correlação de ScreenPorch com SalePrice: 0.111\n"
     ]
    }
   ],
   "source": [
    "atributos_correlacao_preco_entre_10_e_50 = []\n",
    "for id in corrmat.index:\n",
    "    achouDiagonal = False\n",
    "    if (id != \"SalePrice\") & (0.1 < corrmat.loc[id][\"SalePrice\"] <= 0.5):\n",
    "        atributos_correlacao_preco_entre_10_e_50.append(id)\n",
    "        print(\"Correlação de {} com SalePrice: {:1.3f}\".format(id, corrmat.loc[id][\"SalePrice\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Visualização gráfica dos 3 atributos com os maiores graus de correlação com o preço de venda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe15b76ad30>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(train[\"OverallQual\"],train.SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe15b717940>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.scatterplot(train[\"GrLivArea\"],train.SalePrice)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fe15b57e6d8>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.barplot(train[\"GarageCars\"],train.SalePrice)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Criação e exibição de um novo DataFrame apenas com os atributos que possuem correlação maior do que 50% com o preço de venda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>OverallQual</th>\n",
       "      <th>YearBuilt</th>\n",
       "      <th>YearRemodAdd</th>\n",
       "      <th>TotalBsmtSF</th>\n",
       "      <th>1stFlrSF</th>\n",
       "      <th>GrLivArea</th>\n",
       "      <th>FullBath</th>\n",
       "      <th>TotRmsAbvGrd</th>\n",
       "      <th>GarageCars</th>\n",
       "      <th>GarageArea</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7</td>\n",
       "      <td>2003</td>\n",
       "      <td>2003</td>\n",
       "      <td>856</td>\n",
       "      <td>856</td>\n",
       "      <td>1710</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>548</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>1976</td>\n",
       "      <td>1976</td>\n",
       "      <td>1262</td>\n",
       "      <td>1262</td>\n",
       "      <td>1262</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>460</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7</td>\n",
       "      <td>2001</td>\n",
       "      <td>2002</td>\n",
       "      <td>920</td>\n",
       "      <td>920</td>\n",
       "      <td>1786</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7</td>\n",
       "      <td>1915</td>\n",
       "      <td>1970</td>\n",
       "      <td>756</td>\n",
       "      <td>961</td>\n",
       "      <td>1717</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>642</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>8</td>\n",
       "      <td>2000</td>\n",
       "      <td>2000</td>\n",
       "      <td>1145</td>\n",
       "      <td>1145</td>\n",
       "      <td>2198</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>836</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   OverallQual  YearBuilt  YearRemodAdd  TotalBsmtSF  1stFlrSF  GrLivArea  \\\n",
       "0            7       2003          2003          856       856       1710   \n",
       "1            6       1976          1976         1262      1262       1262   \n",
       "2            7       2001          2002          920       920       1786   \n",
       "3            7       1915          1970          756       961       1717   \n",
       "4            8       2000          2000         1145      1145       2198   \n",
       "\n",
       "   FullBath  TotRmsAbvGrd  GarageCars  GarageArea  \n",
       "0         2             8           2         548  \n",
       "1         2             6           2         460  \n",
       "2         2             6           2         608  \n",
       "3         1             7           3         642  \n",
       "4         2             9           3         836  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_atributos_correlacao_preco_maior_50 = X_train_full[atributos_correlacao_preco_maior_50]\n",
    "\n",
    "X_atributos_correlacao_preco_maior_50.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Regressões com atributos que possuem correlação maior do que 50% com o preço de venda"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Serão realizadas agora regressões com base nos atributos que possuem correlação maior do que 50% com o preço de venda. \n",
    "\n",
    "Não será realizado nenhum tipo de otimização.\n",
    "\n",
    "Os melhores índices alcançados, se melhores do que os obtidos anteriormente com a média e a mediana, serão usados como benchmark para as futuras tentativas de melhorar os resultados."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Preparação dos dados*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X_atributos_correlacao_preco_maior_50)\n",
    "\n",
    "X_train, X_test, Y_train, Y_test = train_test_split(X_scale, Y_train_full, test_size=0.3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Função genérica*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def regressao(model):\n",
    "    reg = model.fit(X_train, Y_train.values)\n",
    "\n",
    "    Y_predicted = reg.predict(X_test)\n",
    "\n",
    "    df_Y_predicted = pd.Series(Y_predicted)\n",
    "\n",
    "    df_Y_predicted = pd.DataFrame(Y_predicted)\n",
    "    df_Y_predicted.columns = [\"previsto\"]\n",
    "    df_Y_predicted[df_Y_predicted[\"previsto\"] <= 0] = np.mean(Y_train_full)\n",
    "\n",
    "    print(\"R2 Score: {:10.3f}\".format(r2_score(Y_test.values, df_Y_predicted.round(0).values)))\n",
    "    print(\"RMSLE:    {:10.3f}\".format(rmsle(Y_test.values, df_Y_predicted.values)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Linear Regression*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score:      0.759\n",
      "RMSLE:         0.208\n"
     ]
    }
   ],
   "source": [
    "regressao(LinearRegression())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Decision Tree*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score:      0.659\n",
      "RMSLE:         0.223\n"
     ]
    }
   ],
   "source": [
    "regressao(DecisionTreeClassifier())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*LassoCV*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score:      0.726\n",
      "RMSLE:         0.209\n"
     ]
    }
   ],
   "source": [
    "X, y = make_regression(noise=4, random_state=0)\n",
    "\n",
    "regressao(LassoCV(cv=5, random_state=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*ElasticNet*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 Score:      0.258\n",
      "RMSLE:         0.339\n"
     ]
    }
   ],
   "source": [
    "regressao(ElasticNet(random_state=0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*Neural Network*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-31 15:07:59.776303\n",
      "Train on 1022 samples, validate on 438 samples\n",
      "Epoch 1/15000\n",
      "1022/1022 [==============================] - 1s 654us/step - loss: 38871402015.0607 - val_loss: 39430800790.7945\n",
      "Epoch 2/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 38871300789.3542 - val_loss: 39430646685.8082\n",
      "Epoch 3/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 38871073192.8297 - val_loss: 39430311056.9498\n",
      "Epoch 4/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 38870598902.4814 - val_loss: 39429639247.4886\n",
      "Epoch 5/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 38869680256.2505 - val_loss: 39428392660.7489\n",
      "Epoch 6/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 38868083489.5656 - val_loss: 39426368011.6895\n",
      "Epoch 7/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 38865606163.0372 - val_loss: 39423354851.9452\n",
      "Epoch 8/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 38862060020.9785 - val_loss: 39419144004.9680\n",
      "Epoch 9/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 38857257665.3777 - val_loss: 39413574370.7763\n",
      "Epoch 10/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 38850981912.0470 - val_loss: 39406494388.0183\n",
      "Epoch 11/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 38843127944.2661 - val_loss: 39397603384.1096\n",
      "Epoch 12/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 38833304902.6380 - val_loss: 39386589296.2192\n",
      "Epoch 13/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 38821247324.6810 - val_loss: 39373004603.6164\n",
      "Epoch 14/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 38806568751.5930 - val_loss: 39357008900.6758\n",
      "Epoch 15/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 38789360381.4951 - val_loss: 39338239597.8813\n",
      "Epoch 16/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 38769262575.9687 - val_loss: 39316687296.8767\n",
      "Epoch 17/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 38746342450.0978 - val_loss: 39291791182.3196\n",
      "Epoch 18/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 38720221135.9061 - val_loss: 39263893045.7717\n",
      "Epoch 19/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 38690828460.3366 - val_loss: 39232778417.6804\n",
      "Epoch 20/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 38658284357.6360 - val_loss: 39197903483.9087\n",
      "Epoch 21/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 38622078779.6164 - val_loss: 39159866092.1279\n",
      "Epoch 22/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 38582414814.9354 - val_loss: 39117798890.9589\n",
      "Epoch 23/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 38538881789.4951 - val_loss: 39072152356.2374\n",
      "Epoch 24/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 38491479591.0763 - val_loss: 39022752061.9543\n",
      "Epoch 25/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 38440311705.8004 - val_loss: 38968855594.0822\n",
      "Epoch 26/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 38384858029.8395 - val_loss: 38911013855.2694\n",
      "Epoch 27/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 38325357425.7221 - val_loss: 38848976372.3105\n",
      "Epoch 28/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 38261844420.8845 - val_loss: 38782245312.8767\n",
      "Epoch 29/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 38193625204.2270 - val_loss: 38711762345.4977\n",
      "Epoch 30/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 38121525532.5558 - val_loss: 38636092682.5205\n",
      "Epoch 31/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 38044380093.8708 - val_loss: 38556869861.1142\n",
      "Epoch 32/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 37963160573.9961 - val_loss: 38472667182.7580\n",
      "Epoch 33/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 37876949116.2427 - val_loss: 38384112410.8858\n",
      "Epoch 34/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 37786403713.7534 - val_loss: 38290467218.1187\n",
      "Epoch 35/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 37691171577.4873 - val_loss: 38191602384.0731\n",
      "Epoch 36/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 37591163360.9393 - val_loss: 38087805545.2055\n",
      "Epoch 37/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 37485834801.0959 - val_loss: 37980554768.3653\n",
      "Epoch 38/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 37376663527.9530 - val_loss: 37867017753.7169\n",
      "Epoch 39/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 37261687268.9472 - val_loss: 37750151794.5571\n",
      "Epoch 40/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 37142681475.7573 - val_loss: 37626903725.0046\n",
      "Epoch 41/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 37017937731.6321 - val_loss: 37500211807.8539\n",
      "Epoch 42/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 36889303156.2270 - val_loss: 37366653900.5662\n",
      "Epoch 43/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 36754965758.4971 - val_loss: 37228818862.1735\n",
      "Epoch 44/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 36615731340.2740 - val_loss: 37086493373.3699\n",
      "Epoch 45/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 36471408179.0998 - val_loss: 36939738247.5982\n",
      "Epoch 46/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 36323101613.8395 - val_loss: 36785414518.0639\n",
      "Epoch 47/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 36168140908.2114 - val_loss: 36629299321.5708\n",
      "Epoch 48/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 36009450798.5910 - val_loss: 36466920480.7306\n",
      "Epoch 49/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 35845299558.7006 - val_loss: 36299692948.4566\n",
      "Epoch 50/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 35676112186.6145 - val_loss: 36128072961.1690\n",
      "Epoch 51/15000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 35503254221.4012 - val_loss: 35948410917.4064\n",
      "Epoch 52/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 35323880530.1605 - val_loss: 35765757596.6393\n",
      "Epoch 53/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 35140060234.1448 - val_loss: 35579002253.4429\n",
      "Epoch 54/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 34952130187.2720 - val_loss: 35385617047.9635\n",
      "Epoch 55/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 34758337970.8493 - val_loss: 35189646948.5297\n",
      "Epoch 56/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 34560476418.5049 - val_loss: 34987863858.2648\n",
      "Epoch 57/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 34357335763.4129 - val_loss: 34782064434.2648\n",
      "Epoch 58/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 34150718069.2290 - val_loss: 34569066000.3653\n",
      "Epoch 59/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 33938513499.1781 - val_loss: 34351276032.0000\n",
      "Epoch 60/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 33720119195.8043 - val_loss: 34133325206.7945\n",
      "Epoch 61/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 33500027541.2916 - val_loss: 33906580400.5114\n",
      "Epoch 62/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 33273430224.4070 - val_loss: 33677231445.3333\n",
      "Epoch 63/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 33042000910.0274 - val_loss: 33446330555.0320\n",
      "Epoch 64/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 32809716557.6517 - val_loss: 33203527006.6849\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 65/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 32569371822.3405 - val_loss: 32960599119.4886\n",
      "Epoch 66/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 32325053506.1292 - val_loss: 32716539277.4429\n",
      "Epoch 67/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 32079051112.7045 - val_loss: 32463215386.8858\n",
      "Epoch 68/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 31826577107.4129 - val_loss: 32208412989.9543\n",
      "Epoch 69/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 31570087398.9511 - val_loss: 31950532832.4384\n",
      "Epoch 70/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 31310613758.4971 - val_loss: 31687149717.6256\n",
      "Epoch 71/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 31046931806.6849 - val_loss: 31419006817.0228\n",
      "Epoch 72/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 30778390183.3268 - val_loss: 31149546238.8311\n",
      "Epoch 73/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 30508026493.2446 - val_loss: 30872704612.5297\n",
      "Epoch 74/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 30231476015.5930 - val_loss: 30595984248.4018\n",
      "Epoch 75/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 29954106478.2153 - val_loss: 30311404614.1370\n",
      "Epoch 76/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 29670617596.9941 - val_loss: 30027047145.7900\n",
      "Epoch 77/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 29385321550.1526 - val_loss: 29738195617.3151\n",
      "Epoch 78/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 29095913972.9785 - val_loss: 29446563980.2740\n",
      "Epoch 79/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 28804716544.0000 - val_loss: 29149230458.7397\n",
      "Epoch 80/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 28509328506.2388 - val_loss: 28849624349.2237\n",
      "Epoch 81/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 28209767726.5910 - val_loss: 28550957261.7352\n",
      "Epoch 82/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 27907923438.9667 - val_loss: 28251419708.7854\n",
      "Epoch 83/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 27607520378.2388 - val_loss: 27937187129.2785\n",
      "Epoch 84/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 27298831345.9726 - val_loss: 27627716925.9543\n",
      "Epoch 85/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 26989064761.1115 - val_loss: 27317698541.2968\n",
      "Epoch 86/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 26680083610.3014 - val_loss: 26998010108.4931\n",
      "Epoch 87/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 26362941548.2113 - val_loss: 26685979559.1598\n",
      "Epoch 88/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 26047868254.6849 - val_loss: 26367202121.6438\n",
      "Epoch 89/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 25729140279.1076 - val_loss: 26046773865.2055\n",
      "Epoch 90/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 25409794869.6047 - val_loss: 25720489104.9498\n",
      "Epoch 91/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 25086892116.1644 - val_loss: 25394962665.7900\n",
      "Epoch 92/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 24761791185.4090 - val_loss: 25070552461.4429\n",
      "Epoch 93/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 24436590850.5049 - val_loss: 24742505401.8630\n",
      "Epoch 94/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 24109219507.3503 - val_loss: 24412952585.3516\n",
      "Epoch 95/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 23781638632.9550 - val_loss: 24078895197.5160\n",
      "Epoch 96/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 23450137602.0039 - val_loss: 23747595133.0776\n",
      "Epoch 97/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 23118218999.4834 - val_loss: 23417833429.9178\n",
      "Epoch 98/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 22788245239.4834 - val_loss: 23079867452.7854\n",
      "Epoch 99/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 22454192123.9922 - val_loss: 22744815316.7489\n",
      "Epoch 100/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 22120484114.5362 - val_loss: 22408974336.0000\n",
      "Epoch 101/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 21785157796.3209 - val_loss: 22075815879.8904\n",
      "Epoch 102/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 21451746895.1546 - val_loss: 21737492802.6301\n",
      "Epoch 103/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 21116493759.8748 - val_loss: 21399616628.8950\n",
      "Epoch 104/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 20780697604.0078 - val_loss: 21062701303.8173\n",
      "Epoch 105/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 20445552980.6654 - val_loss: 20724572711.7443\n",
      "Epoch 106/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 20109868725.3542 - val_loss: 20387798577.0959\n",
      "Epoch 107/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 19774591476.9785 - val_loss: 20051758818.7763\n",
      "Epoch 108/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 19439807626.2701 - val_loss: 19715754484.3105\n",
      "Epoch 109/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 19104049837.3386 - val_loss: 19383557503.4155\n",
      "Epoch 110/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 18771295662.8415 - val_loss: 19047439813.5525\n",
      "Epoch 111/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 18439465166.4031 - val_loss: 18708387522.0457\n",
      "Epoch 112/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 18104203512.4853 - val_loss: 18380261520.9498\n",
      "Epoch 113/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 17775571669.4168 - val_loss: 18045094294.7945\n",
      "Epoch 114/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 17443262936.9237 - val_loss: 17718094932.1644\n",
      "Epoch 115/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 17116753188.5714 - val_loss: 17384305972.6027\n",
      "Epoch 116/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 16787741112.8611 - val_loss: 17057689296.0731\n",
      "Epoch 117/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 16462673136.4697 - val_loss: 16730468244.4566\n",
      "Epoch 118/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 16136916142.3405 - val_loss: 16410637643.9817\n",
      "Epoch 119/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 15817325746.3483 - val_loss: 16083709414.2831\n",
      "Epoch 120/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 15495603783.1389 - val_loss: 15763497357.4429\n",
      "Epoch 121/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 15177613075.5382 - val_loss: 15444343995.0320\n",
      "Epoch 122/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 14860057569.9413 - val_loss: 15132163216.9498\n",
      "Epoch 123/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 14548557866.0822 - val_loss: 14815034812.2009\n",
      "Epoch 124/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 14237120413.8082 - val_loss: 14500857084.4932\n",
      "Epoch 125/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 13926620739.1311 - val_loss: 14195350892.7123\n",
      "Epoch 126/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 13622406785.2524 - val_loss: 13886923794.7032\n",
      "Epoch 127/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 13318067987.5382 - val_loss: 13584805214.6849\n",
      "Epoch 128/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 13016705863.6399 - val_loss: 13288886800.3653\n",
      "Epoch 129/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 38us/step - loss: 12721037388.1487 - val_loss: 12990310633.7900\n",
      "Epoch 130/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 12426644834.6928 - val_loss: 12695935745.1689\n",
      "Epoch 131/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 12135116329.0802 - val_loss: 12406920540.3470\n",
      "Epoch 132/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 11846663418.4892 - val_loss: 12124298934.3562\n",
      "Epoch 133/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 11564412731.6164 - val_loss: 11838751888.9498\n",
      "Epoch 134/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 11283001195.7104 - val_loss: 11561009965.5890\n",
      "Epoch 135/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 11007311385.0489 - val_loss: 11283757719.9635\n",
      "Epoch 136/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 10734844062.3092 - val_loss: 11010227740.0548\n",
      "Epoch 137/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 10465858395.6791 - val_loss: 10741729672.7671\n",
      "Epoch 138/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 10199313056.3131 - val_loss: 10483769603.5068\n",
      "Epoch 139/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 9940278338.1292 - val_loss: 10224966452.6027\n",
      "Epoch 140/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 9683262344.7671 - val_loss: 9971689609.9361\n",
      "Epoch 141/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 9431712978.4110 - val_loss: 9720440086.2100\n",
      "Epoch 142/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 9184158557.6830 - val_loss: 9473136490.3744\n",
      "Epoch 143/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 8940429217.8160 - val_loss: 9232101549.0046\n",
      "Epoch 144/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 8702240659.7887 - val_loss: 8993872608.4384\n",
      "Epoch 145/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 8467109179.6164 - val_loss: 8763497981.6621\n",
      "Epoch 146/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 8238971154.5362 - val_loss: 8533609799.3059\n",
      "Epoch 147/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 8013453114.6145 - val_loss: 8311097993.9361\n",
      "Epoch 148/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 7792999292.7436 - val_loss: 8094856357.9909\n",
      "Epoch 149/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 7578361887.0607 - val_loss: 7881529063.4521\n",
      "Epoch 150/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 7367281969.5969 - val_loss: 7675376675.0685\n",
      "Epoch 151/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 7164182131.7260 - val_loss: 7467566136.1096\n",
      "Epoch 152/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 6960072977.5342 - val_loss: 7275485112.6941\n",
      "Epoch 153/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 6766388204.9628 - val_loss: 7081369622.2100\n",
      "Epoch 154/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 6576183753.8943 - val_loss: 6890740491.6895\n",
      "Epoch 155/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 6389380892.5558 - val_loss: 6708661353.2055\n",
      "Epoch 156/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 6209543047.7652 - val_loss: 6529405431.8174\n",
      "Epoch 157/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 6032902475.1468 - val_loss: 6358537685.9178\n",
      "Epoch 158/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 5861812831.1859 - val_loss: 6195217226.8128\n",
      "Epoch 159/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 5698532640.0626 - val_loss: 6029198255.3425\n",
      "Epoch 160/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 5538192856.9237 - val_loss: 5869040053.1872\n",
      "Epoch 161/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 5381102941.6830 - val_loss: 5719037159.4521\n",
      "Epoch 162/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 5231292348.3679 - val_loss: 5571940643.0685\n",
      "Epoch 163/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 5086296289.4403 - val_loss: 5429079687.5982\n",
      "Epoch 164/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 4945405843.7886 - val_loss: 5292324560.0731\n",
      "Epoch 165/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 4810163375.3425 - val_loss: 5160088311.8174\n",
      "Epoch 166/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 4680343874.6301 - val_loss: 5030696422.2831\n",
      "Epoch 167/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 4553853534.1840 - val_loss: 4908373082.0091\n",
      "Epoch 168/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 4433110693.3229 - val_loss: 4790341584.0731\n",
      "Epoch 169/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 4316297770.0822 - val_loss: 4679040812.4201\n",
      "Epoch 170/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 4205849364.0391 - val_loss: 4569176507.0320\n",
      "Epoch 171/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 4097847426.2544 - val_loss: 4467406676.1644\n",
      "Epoch 172/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 3997109198.7789 - val_loss: 4365282932.3105\n",
      "Epoch 173/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 3898092418.7554 - val_loss: 4271706027.8356\n",
      "Epoch 174/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 3805280336.1566 - val_loss: 4181153841.0959\n",
      "Epoch 175/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 3716590085.5108 - val_loss: 4093896193.1689\n",
      "Epoch 176/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 3631280094.9354 - val_loss: 4012407992.6941\n",
      "Epoch 177/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 3549746223.5930 - val_loss: 3936945187.0685\n",
      "Epoch 178/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 3473485793.9413 - val_loss: 3863631630.6119\n",
      "Epoch 179/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 3401142796.0235 - val_loss: 3792374659.5068\n",
      "Epoch 180/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 3332126928.6575 - val_loss: 3724853572.3836\n",
      "Epoch 181/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 3265998331.2407 - val_loss: 3663850269.8082\n",
      "Epoch 182/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 3204531551.6869 - val_loss: 3605605070.9041\n",
      "Epoch 183/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 3146962061.2759 - val_loss: 3548650563.2146\n",
      "Epoch 184/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 3091983765.7926 - val_loss: 3496003002.4475\n",
      "Epoch 185/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 3040512516.5088 - val_loss: 3446599072.7306\n",
      "Epoch 186/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2991948967.3268 - val_loss: 3401127072.1461\n",
      "Epoch 187/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2946172925.9961 - val_loss: 3360292581.1142\n",
      "Epoch 188/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2904770700.7750 - val_loss: 3318333396.7489\n",
      "Epoch 189/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2864416290.5675 - val_loss: 3281391361.1689\n",
      "Epoch 190/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2827634963.5382 - val_loss: 3246430997.6256\n",
      "Epoch 191/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2793024580.1331 - val_loss: 3214852683.3973\n",
      "Epoch 192/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2761374487.0450 - val_loss: 3184630138.1553\n",
      "Epoch 193/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 2731714957.7769 - val_loss: 3156789955.7991\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 194/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 2704437273.2994 - val_loss: 3130552878.1735\n",
      "Epoch 195/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 2678374946.5675 - val_loss: 3108898218.0822\n",
      "Epoch 196/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2656061947.4912 - val_loss: 3085744654.0274\n",
      "Epoch 197/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2634585045.6673 - val_loss: 3065006174.6849\n",
      "Epoch 198/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2613736414.4344 - val_loss: 3048726647.8174\n",
      "Epoch 199/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2596618213.1977 - val_loss: 3030915509.1872\n",
      "Epoch 200/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2579117996.9628 - val_loss: 3016735352.4018\n",
      "Epoch 201/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2564433006.4658 - val_loss: 3002227419.1781\n",
      "Epoch 202/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2550252152.2348 - val_loss: 2989902531.2146\n",
      "Epoch 203/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2537693624.8611 - val_loss: 2978763088.0731\n",
      "Epoch 204/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2526196083.6008 - val_loss: 2968129976.6941\n",
      "Epoch 205/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2515520734.9354 - val_loss: 2959386112.5845\n",
      "Epoch 206/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2506424616.5793 - val_loss: 2949988406.9406\n",
      "Epoch 207/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2498011369.2055 - val_loss: 2941724239.4886\n",
      "Epoch 208/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2489765984.1879 - val_loss: 2935586519.0868\n",
      "Epoch 209/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 2482990862.2779 - val_loss: 2929640488.9132\n",
      "Epoch 210/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2476634940.6184 - val_loss: 2924044369.8265\n",
      "Epoch 211/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2471276923.7417 - val_loss: 2918860692.4566\n",
      "Epoch 212/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 2465927289.7378 - val_loss: 2915018994.5571\n",
      "Epoch 213/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2461395578.2387 - val_loss: 2910688231.4521\n",
      "Epoch 214/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2457267459.5068 - val_loss: 2907306214.2831\n",
      "Epoch 215/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2453436539.7417 - val_loss: 2904445897.0594\n",
      "Epoch 216/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2450250818.3796 - val_loss: 2901530763.1050\n",
      "Epoch 217/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2447147985.1585 - val_loss: 2898951805.6621\n",
      "Epoch 218/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2444546039.6086 - val_loss: 2896595586.3379\n",
      "Epoch 219/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2442143519.0607 - val_loss: 2894355405.7352\n",
      "Epoch 220/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2439815801.9883 - val_loss: 2892881444.8219\n",
      "Epoch 221/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2437982989.2759 - val_loss: 2891175741.9543\n",
      "Epoch 222/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 2436255132.8063 - val_loss: 2889804638.1005\n",
      "Epoch 223/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2434557339.3033 - val_loss: 2888229671.7443\n",
      "Epoch 224/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 2433048404.1644 - val_loss: 2887002844.3470\n",
      "Epoch 225/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2431750883.4442 - val_loss: 2885929833.2055\n",
      "Epoch 226/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2430363789.7769 - val_loss: 2884771828.8950\n",
      "Epoch 227/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2429213991.3268 - val_loss: 2883745584.5114\n",
      "Epoch 228/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2428353192.0783 - val_loss: 2882697089.7534\n",
      "Epoch 229/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2427174499.6947 - val_loss: 2881920614.2831\n",
      "Epoch 230/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2426178625.1272 - val_loss: 2881091143.3059\n",
      "Epoch 231/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2425542619.1781 - val_loss: 2880164385.8995\n",
      "Epoch 232/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2424419538.9119 - val_loss: 2879412831.8539\n",
      "Epoch 233/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 2423659887.9687 - val_loss: 2878724985.5708\n",
      "Epoch 234/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2422833726.1213 - val_loss: 2877959672.9863\n",
      "Epoch 235/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2422205775.5303 - val_loss: 2877156895.5616\n",
      "Epoch 236/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2421345235.1624 - val_loss: 2876416611.3607\n",
      "Epoch 237/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2420565415.3268 - val_loss: 2875655412.8950\n",
      "Epoch 238/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 2419864006.6380 - val_loss: 2874965326.3196\n",
      "Epoch 239/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2419340160.2505 - val_loss: 2874163287.6712\n",
      "Epoch 240/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2418643580.9941 - val_loss: 2873461813.7717\n",
      "Epoch 241/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2417721269.8552 - val_loss: 2872706920.6210\n",
      "Epoch 242/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 2417049062.9511 - val_loss: 2871953970.8493\n",
      "Epoch 243/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2416200423.9530 - val_loss: 2871163197.9543\n",
      "Epoch 244/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2415866072.4227 - val_loss: 2870447337.2055\n",
      "Epoch 245/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 2415304540.6810 - val_loss: 2869601985.4612\n",
      "Epoch 246/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2414072170.2074 - val_loss: 2868858497.7534\n",
      "Epoch 247/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 2413484015.9687 - val_loss: 2868068361.9361\n",
      "Epoch 248/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2412817953.5656 - val_loss: 2867236824.8402\n",
      "Epoch 249/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 2412220973.0881 - val_loss: 2866493981.8082\n",
      "Epoch 250/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 2411114849.6908 - val_loss: 2865625268.6027\n",
      "Epoch 251/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2410505513.3307 - val_loss: 2864757025.3151\n",
      "Epoch 252/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 2409834295.4834 - val_loss: 2863952842.8128\n",
      "Epoch 253/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 2408990477.0254 - val_loss: 2863119652.8219\n",
      "Epoch 254/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 2408144389.0098 - val_loss: 2862210919.4521\n",
      "Epoch 255/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 2407437004.0235 - val_loss: 2861376963.7991\n",
      "Epoch 256/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 2407020642.1918 - val_loss: 2860449066.6667\n",
      "Epoch 257/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 2405976441.2368 - val_loss: 2859582596.6758\n",
      "Epoch 258/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2405342236.8063 - val_loss: 2858791737.8630\n",
      "Epoch 259/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 31us/step - loss: 2404661393.2838 - val_loss: 2857738009.1324\n",
      "Epoch 260/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2403792912.4070 - val_loss: 2856954818.6301\n",
      "Epoch 261/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2402771908.8845 - val_loss: 2855997832.7671\n",
      "Epoch 262/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2401874181.0098 - val_loss: 2855083466.2283\n",
      "Epoch 263/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2401098605.2133 - val_loss: 2854150700.4201\n",
      "Epoch 264/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2400528529.9100 - val_loss: 2853231343.6347\n",
      "Epoch 265/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2399575352.6106 - val_loss: 2852291595.1050\n",
      "Epoch 266/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2398677330.9119 - val_loss: 2851333373.0776\n",
      "Epoch 267/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2397868433.5342 - val_loss: 2850380105.0594\n",
      "Epoch 268/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 2396956096.8767 - val_loss: 2849428200.6210\n",
      "Epoch 269/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 2396174886.3249 - val_loss: 2848361474.9224\n",
      "Epoch 270/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2395455213.9648 - val_loss: 2847363837.0776\n",
      "Epoch 271/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2394450601.3307 - val_loss: 2846469542.5753\n",
      "Epoch 272/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 2393856777.7691 - val_loss: 2845581884.2009\n",
      "Epoch 273/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2392680098.8180 - val_loss: 2844501130.5205\n",
      "Epoch 274/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2391832960.5010 - val_loss: 2843474617.2785\n",
      "Epoch 275/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2390929171.0372 - val_loss: 2842476354.0457\n",
      "Epoch 276/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2390494197.9804 - val_loss: 2841335702.2100\n",
      "Epoch 277/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2389447782.1996 - val_loss: 2840536885.7717\n",
      "Epoch 278/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2388245825.8787 - val_loss: 2839427678.6849\n",
      "Epoch 279/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 2387406352.7828 - val_loss: 2838306869.1872\n",
      "Epoch 280/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2386577909.4795 - val_loss: 2837356988.7854\n",
      "Epoch 281/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2385522887.3894 - val_loss: 2836250233.5708\n",
      "Epoch 282/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2384500755.7887 - val_loss: 2835163020.8584\n",
      "Epoch 283/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2383759526.3249 - val_loss: 2834029681.9726\n",
      "Epoch 284/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 2382867977.0176 - val_loss: 2833014941.2237\n",
      "Epoch 285/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2382133585.6595 - val_loss: 2832021538.4840\n",
      "Epoch 286/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 2380854142.1213 - val_loss: 2830934305.8995\n",
      "Epoch 287/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 2380153074.9746 - val_loss: 2829763693.8813\n",
      "Epoch 288/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2379243814.4501 - val_loss: 2828876092.2009\n",
      "Epoch 289/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2378231836.5558 - val_loss: 2827755168.7306\n",
      "Epoch 290/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2377047754.3953 - val_loss: 2826568125.3699\n",
      "Epoch 291/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2376394763.0215 - val_loss: 2825416859.4703\n",
      "Epoch 292/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 2375181020.9315 - val_loss: 2824311679.4155\n",
      "Epoch 293/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2374560033.3151 - val_loss: 2823288687.0502\n",
      "Epoch 294/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 2373769218.5049 - val_loss: 2822079723.5434\n",
      "Epoch 295/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2372629733.8239 - val_loss: 2821138238.5388\n",
      "Epoch 296/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 2371253731.9452 - val_loss: 2819898529.3151\n",
      "Epoch 297/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2370820894.0587 - val_loss: 2818812978.8493\n",
      "Epoch 298/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2369321676.3992 - val_loss: 2817644912.8037\n",
      "Epoch 299/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2368516046.1526 - val_loss: 2816555082.8128\n",
      "Epoch 300/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 2367414151.2642 - val_loss: 2815277407.2694\n",
      "Epoch 301/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 2366848798.5597 - val_loss: 2814215295.4155\n",
      "Epoch 302/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2365930117.2603 - val_loss: 2813044686.9041\n",
      "Epoch 303/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 2364437081.1742 - val_loss: 2811873057.8995\n",
      "Epoch 304/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2363338952.3914 - val_loss: 2810748158.8311\n",
      "Epoch 305/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2362401155.2564 - val_loss: 2809549646.9041\n",
      "Epoch 306/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2361517266.4110 - val_loss: 2808422897.3881\n",
      "Epoch 307/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 2360235074.6301 - val_loss: 2807178588.3470\n",
      "Epoch 308/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2359833680.4070 - val_loss: 2805855758.6119\n",
      "Epoch 309/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 2358300171.5225 - val_loss: 2804765853.2237\n",
      "Epoch 310/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2357767759.1546 - val_loss: 2803566172.3470\n",
      "Epoch 311/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 2357001077.7299 - val_loss: 2802601652.6027\n",
      "Epoch 312/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2355276784.9706 - val_loss: 2801223971.6530\n",
      "Epoch 313/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2354295620.8845 - val_loss: 2800010742.0639\n",
      "Epoch 314/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 2352980075.4599 - val_loss: 2798881790.2466\n",
      "Epoch 315/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 2352025453.2133 - val_loss: 2797713357.7352\n",
      "Epoch 316/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2351246441.2055 - val_loss: 2796493912.2557\n",
      "Epoch 317/15000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 2350668530.9746 - val_loss: 2795200988.3470\n",
      "Epoch 318/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2349140027.6164 - val_loss: 2793954739.4338\n",
      "Epoch 319/15000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 2348619691.3346 - val_loss: 2792914296.9863\n",
      "Epoch 320/15000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 2347441814.7945 - val_loss: 2791492128.1461\n",
      "Epoch 321/15000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 2345672623.0920 - val_loss: 2790411504.2192\n",
      "Epoch 322/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 2344670895.3425 - val_loss: 2789272348.6393\n",
      "Epoch 323/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 2343956048.4070 - val_loss: 2787969956.2374\n",
      "Epoch 324/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 32us/step - loss: 2343172554.3953 - val_loss: 2786732136.6210\n",
      "Epoch 325/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2341412005.3229 - val_loss: 2785492085.4795\n",
      "Epoch 326/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2340378395.0528 - val_loss: 2784322922.3744\n",
      "Epoch 327/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2339294370.5675 - val_loss: 2783049450.3744\n",
      "Epoch 328/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2338331776.2505 - val_loss: 2781768107.2511\n",
      "Epoch 329/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 2337260277.7299 - val_loss: 2780528955.0320\n",
      "Epoch 330/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2336669211.3033 - val_loss: 2779340559.7808\n",
      "Epoch 331/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2335189131.7730 - val_loss: 2777996371.5799\n",
      "Epoch 332/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2333987550.4344 - val_loss: 2776880405.6256\n",
      "Epoch 333/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2333043260.3679 - val_loss: 2775688522.8128\n",
      "Epoch 334/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2331907629.0881 - val_loss: 2774401798.4292\n",
      "Epoch 335/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2330759672.9863 - val_loss: 2773170831.7808\n",
      "Epoch 336/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 2329887186.4110 - val_loss: 2771857918.8311\n",
      "Epoch 337/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2330414871.0450 - val_loss: 2770846714.1553\n",
      "Epoch 338/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2328140865.1272 - val_loss: 2769500524.1279\n",
      "Epoch 339/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2326543690.6458 - val_loss: 2768136858.3014\n",
      "Epoch 340/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2325565876.8532 - val_loss: 2766927569.8265\n",
      "Epoch 341/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2324490663.5773 - val_loss: 2765628141.8813\n",
      "Epoch 342/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2323408896.5010 - val_loss: 2764388333.8813\n",
      "Epoch 343/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 2322451577.4873 - val_loss: 2763221393.5342\n",
      "Epoch 344/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2321177838.4658 - val_loss: 2761956545.4612\n",
      "Epoch 345/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2320762424.6106 - val_loss: 2760906811.0320\n",
      "Epoch 346/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 2319048686.9667 - val_loss: 2759483708.2009\n",
      "Epoch 347/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2318090128.0313 - val_loss: 2758129834.0822\n",
      "Epoch 348/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 2317394585.6751 - val_loss: 2757071284.6027\n",
      "Epoch 349/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2316232395.8982 - val_loss: 2755734311.7443\n",
      "Epoch 350/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2314816796.8063 - val_loss: 2754482609.0959\n",
      "Epoch 351/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2313847761.1585 - val_loss: 2753191381.3333\n",
      "Epoch 352/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 2313533853.8082 - val_loss: 2751866833.8265\n",
      "Epoch 353/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 2311349383.0137 - val_loss: 2750602977.0228\n",
      "Epoch 354/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2310495468.7123 - val_loss: 2749466786.4840\n",
      "Epoch 355/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2309670884.1957 - val_loss: 2748280238.1735\n",
      "Epoch 356/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2308247328.5636 - val_loss: 2747035407.7808\n",
      "Epoch 357/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2307421339.3033 - val_loss: 2745823005.2237\n",
      "Epoch 358/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2306527958.7945 - val_loss: 2744560311.5251\n",
      "Epoch 359/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2305359712.1879 - val_loss: 2743264345.4247\n",
      "Epoch 360/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2303982524.1174 - val_loss: 2741964593.6804\n",
      "Epoch 361/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2303283304.9550 - val_loss: 2740669577.9361\n",
      "Epoch 362/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 2301721082.9902 - val_loss: 2739399799.2329\n",
      "Epoch 363/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2300664645.6360 - val_loss: 2738231381.3333\n",
      "Epoch 364/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2299611835.8669 - val_loss: 2736992048.5114\n",
      "Epoch 365/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2298692064.9393 - val_loss: 2735619322.1553\n",
      "Epoch 366/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 2297768995.8200 - val_loss: 2734436037.5525\n",
      "Epoch 367/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2296457837.2133 - val_loss: 2733184975.4886\n",
      "Epoch 368/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2295253583.9061 - val_loss: 2731973937.0959\n",
      "Epoch 369/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2294536988.5558 - val_loss: 2730707231.5616\n",
      "Epoch 370/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2293220875.5225 - val_loss: 2729490720.1461\n",
      "Epoch 371/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 2292486504.9550 - val_loss: 2728158227.2877\n",
      "Epoch 372/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 2290977141.2290 - val_loss: 2726977781.4795\n",
      "Epoch 373/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2290139372.3366 - val_loss: 2725826924.1279\n",
      "Epoch 374/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2289343798.1057 - val_loss: 2724435769.2785\n",
      "Epoch 375/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2287914998.9824 - val_loss: 2723282558.8311\n",
      "Epoch 376/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 2286839319.5460 - val_loss: 2722030478.0274\n",
      "Epoch 377/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2285733844.9159 - val_loss: 2720756088.4018\n",
      "Epoch 378/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2285054600.5166 - val_loss: 2719446098.4110\n",
      "Epoch 379/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2283972029.8708 - val_loss: 2718254196.8950\n",
      "Epoch 380/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2282815515.5538 - val_loss: 2716999798.6484\n",
      "Epoch 381/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2281555550.9354 - val_loss: 2715723785.9361\n",
      "Epoch 382/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 2280908461.2133 - val_loss: 2714613699.2146\n",
      "Epoch 383/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2279844554.6458 - val_loss: 2713233969.0959\n",
      "Epoch 384/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2278180110.5284 - val_loss: 2712028857.8630\n",
      "Epoch 385/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2277329379.4442 - val_loss: 2710759377.2420\n",
      "Epoch 386/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2276195683.6947 - val_loss: 2709594198.5023\n",
      "Epoch 387/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2275589332.4149 - val_loss: 2708250787.0685\n",
      "Epoch 388/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2274250403.8200 - val_loss: 2707139328.0000\n",
      "Epoch 389/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 40us/step - loss: 2273125532.3053 - val_loss: 2705864332.8584\n",
      "Epoch 390/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 2271730826.7710 - val_loss: 2704669323.1050\n",
      "Epoch 391/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2270799581.9335 - val_loss: 2703422221.4429\n",
      "Epoch 392/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2270116804.8845 - val_loss: 2702220636.3470\n",
      "Epoch 393/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2268899108.5714 - val_loss: 2701022818.7763\n",
      "Epoch 394/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2268128031.5616 - val_loss: 2699712066.6301\n",
      "Epoch 395/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2266764007.9530 - val_loss: 2698544685.0046\n",
      "Epoch 396/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2265611319.3581 - val_loss: 2697277612.4201\n",
      "Epoch 397/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 2264502972.7436 - val_loss: 2695982844.4932\n",
      "Epoch 398/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2263711532.8376 - val_loss: 2694845114.4475\n",
      "Epoch 399/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 2262554584.9237 - val_loss: 2693546356.3105\n",
      "Epoch 400/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2261315135.1233 - val_loss: 2692314643.8721\n",
      "Epoch 401/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2260349544.7045 - val_loss: 2691126221.7352\n",
      "Epoch 402/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 2259678057.4560 - val_loss: 2689925496.9863\n",
      "Epoch 403/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2258078527.1233 - val_loss: 2688687795.4338\n",
      "Epoch 404/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2257156649.3307 - val_loss: 2687413848.8402\n",
      "Epoch 405/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2256142077.8708 - val_loss: 2686153276.2009\n",
      "Epoch 406/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2255235459.6321 - val_loss: 2684930288.2192\n",
      "Epoch 407/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 2253915091.4129 - val_loss: 2683739449.8630\n",
      "Epoch 408/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2253659893.7299 - val_loss: 2682633204.8950\n",
      "Epoch 409/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2251935976.9550 - val_loss: 2681285391.1963\n",
      "Epoch 410/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2251150916.1331 - val_loss: 2679939723.1050\n",
      "Epoch 411/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 2249981596.0548 - val_loss: 2678785681.5342\n",
      "Epoch 412/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2248718024.8924 - val_loss: 2677557835.3973\n",
      "Epoch 413/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2247680436.8532 - val_loss: 2676290713.7169\n",
      "Epoch 414/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2247305391.8434 - val_loss: 2675212282.1553\n",
      "Epoch 415/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2245543248.5323 - val_loss: 2673883471.4886\n",
      "Epoch 416/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2244630123.7104 - val_loss: 2672643347.8721\n",
      "Epoch 417/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2243799831.7965 - val_loss: 2671435178.6667\n",
      "Epoch 418/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 2242935179.5225 - val_loss: 2670192309.7717\n",
      "Epoch 419/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 2241412279.8591 - val_loss: 2668941930.9589\n",
      "Epoch 420/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2240643008.1252 - val_loss: 2667668155.0320\n",
      "Epoch 421/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2239681185.8160 - val_loss: 2666498011.7626\n",
      "Epoch 422/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2238312291.9452 - val_loss: 2665215264.1461\n",
      "Epoch 423/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2237314061.7769 - val_loss: 2664032269.4429\n",
      "Epoch 424/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2236422976.1252 - val_loss: 2662802821.2603\n",
      "Epoch 425/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2235251391.3738 - val_loss: 2661661078.7945\n",
      "Epoch 426/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2234101964.9002 - val_loss: 2660308443.1781\n",
      "Epoch 427/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2233026436.5088 - val_loss: 2659106640.0731\n",
      "Epoch 428/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2232413349.8239 - val_loss: 2657899368.0365\n",
      "Epoch 429/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 2231058068.7906 - val_loss: 2656653098.0822\n",
      "Epoch 430/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2229826375.6399 - val_loss: 2655406340.0913\n",
      "Epoch 431/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 2229338859.7104 - val_loss: 2654196780.4201\n",
      "Epoch 432/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 2227769810.1605 - val_loss: 2653049400.6941\n",
      "Epoch 433/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 2227072935.8278 - val_loss: 2651806081.7534\n",
      "Epoch 434/15000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 2226209452.0861 - val_loss: 2650586375.5982\n",
      "Epoch 435/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 2225022041.6751 - val_loss: 2649387815.1598\n",
      "Epoch 436/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 2224333657.6751 - val_loss: 2648185274.4475\n",
      "Epoch 437/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2222817296.5323 - val_loss: 2646927992.4018\n",
      "Epoch 438/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 2221955068.9941 - val_loss: 2645766745.4247\n",
      "Epoch 439/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 2221007809.5029 - val_loss: 2644545730.6301\n",
      "Epoch 440/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 2220069706.1448 - val_loss: 2643275334.7215\n",
      "Epoch 441/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2218548191.1859 - val_loss: 2642203446.9406\n",
      "Epoch 442/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2217643168.0626 - val_loss: 2640998571.8356\n",
      "Epoch 443/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 2216805480.9550 - val_loss: 2639770558.5388\n",
      "Epoch 444/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 2215665080.8611 - val_loss: 2638558570.3744\n",
      "Epoch 445/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 2214668275.3503 - val_loss: 2637383896.2557\n",
      "Epoch 446/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2213775401.4560 - val_loss: 2636239869.0776\n",
      "Epoch 447/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2212739224.2975 - val_loss: 2635043602.1187\n",
      "Epoch 448/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 2212130304.5010 - val_loss: 2633787131.9087\n",
      "Epoch 449/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2210991608.9863 - val_loss: 2632645311.1233\n",
      "Epoch 450/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 2210038198.3562 - val_loss: 2631438856.7671\n",
      "Epoch 451/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 2208684480.7515 - val_loss: 2630268355.7991\n",
      "Epoch 452/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 2208265740.7750 - val_loss: 2629041292.8584\n",
      "Epoch 453/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 2206838134.2309 - val_loss: 2627876973.2968\n",
      "Epoch 454/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 37us/step - loss: 2205650908.4305 - val_loss: 2626688417.8995\n",
      "Epoch 455/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2204793401.3620 - val_loss: 2625512122.4475\n",
      "Epoch 456/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2204136141.9022 - val_loss: 2624289076.0183\n",
      "Epoch 457/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2202857722.4892 - val_loss: 2623210494.2466\n",
      "Epoch 458/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2203387734.4188 - val_loss: 2622074496.0000\n",
      "Epoch 459/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2200721597.1194 - val_loss: 2620848129.7534\n",
      "Epoch 460/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2199879123.9139 - val_loss: 2619725157.1142\n",
      "Epoch 461/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2198665890.8180 - val_loss: 2618552240.5114\n",
      "Epoch 462/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 2197655109.3855 - val_loss: 2617368414.1005\n",
      "Epoch 463/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2197294430.4344 - val_loss: 2616192562.2648\n",
      "Epoch 464/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2196234827.6477 - val_loss: 2614916197.1142\n",
      "Epoch 465/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 2194784233.4560 - val_loss: 2613745429.6256\n",
      "Epoch 466/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2194135203.5695 - val_loss: 2612685112.6941\n",
      "Epoch 467/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2193128164.4462 - val_loss: 2611336081.5342\n",
      "Epoch 468/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 2191926585.8630 - val_loss: 2610219795.8721\n",
      "Epoch 469/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2190870213.6360 - val_loss: 2609082024.3288\n",
      "Epoch 470/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 2189816597.0411 - val_loss: 2607896990.9772\n",
      "Epoch 471/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2188836345.9883 - val_loss: 2606679326.9772\n",
      "Epoch 472/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2187784926.4344 - val_loss: 2605605403.4703\n",
      "Epoch 473/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 2186700439.7965 - val_loss: 2604386761.0594\n",
      "Epoch 474/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2185879628.6497 - val_loss: 2603203106.4840\n",
      "Epoch 475/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 2184829425.3464 - val_loss: 2602001341.9543\n",
      "Epoch 476/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2183817715.4755 - val_loss: 2600843051.8356\n",
      "Epoch 477/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 2182791257.6751 - val_loss: 2599599862.0639\n",
      "Epoch 478/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2182228779.5851 - val_loss: 2598512304.5114\n",
      "Epoch 479/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2180731603.0372 - val_loss: 2597285283.0685\n",
      "Epoch 480/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2180107110.1996 - val_loss: 2596053381.8447\n",
      "Epoch 481/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 2179071135.5616 - val_loss: 2594943819.9817\n",
      "Epoch 482/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2178025885.3072 - val_loss: 2593808957.3699\n",
      "Epoch 483/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 2176976077.0254 - val_loss: 2592565409.8995\n",
      "Epoch 484/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 2176109458.2857 - val_loss: 2591397707.3973\n",
      "Epoch 485/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 2175142651.9922 - val_loss: 2590196606.8311\n",
      "Epoch 486/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2174072018.6614 - val_loss: 2588941891.2146\n",
      "Epoch 487/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 2173158192.3444 - val_loss: 2587789382.7215\n",
      "Epoch 488/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2172020543.3738 - val_loss: 2586632566.6484\n",
      "Epoch 489/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 2171638199.8591 - val_loss: 2585466524.6393\n",
      "Epoch 490/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 2170132892.8063 - val_loss: 2584350198.6484\n",
      "Epoch 491/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 2169024427.8356 - val_loss: 2583119064.8402\n",
      "Epoch 492/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2168126915.3816 - val_loss: 2581959733.1872\n",
      "Epoch 493/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2167172309.4168 - val_loss: 2580776184.9863\n",
      "Epoch 494/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 2166060605.6204 - val_loss: 2579584628.3105\n",
      "Epoch 495/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 2165173060.8845 - val_loss: 2578463998.8311\n",
      "Epoch 496/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 2164282048.1252 - val_loss: 2577259099.7626\n",
      "Epoch 497/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2163352080.0313 - val_loss: 2576044997.5525\n",
      "Epoch 498/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2162478502.8258 - val_loss: 2574941579.6895\n",
      "Epoch 499/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2161224922.9276 - val_loss: 2573787729.8265\n",
      "Epoch 500/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2160266788.3209 - val_loss: 2572581271.3790\n",
      "Epoch 501/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2159374821.6986 - val_loss: 2571411965.0776\n",
      "Epoch 502/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 2158437149.5577 - val_loss: 2570232014.9041\n",
      "Epoch 503/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 2157360466.1605 - val_loss: 2568993592.1096\n",
      "Epoch 504/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 2156265057.1898 - val_loss: 2567874745.2785\n",
      "Epoch 505/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 2155325416.9550 - val_loss: 2566760840.7671\n",
      "Epoch 506/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2154534846.8728 - val_loss: 2565545490.1187\n",
      "Epoch 507/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 2153678340.5088 - val_loss: 2564428049.5342\n",
      "Epoch 508/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 2152655879.7652 - val_loss: 2563252103.5982\n",
      "Epoch 509/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2151708737.6282 - val_loss: 2562107967.7078\n",
      "Epoch 510/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2150513503.4364 - val_loss: 2560982675.2877\n",
      "Epoch 511/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2150026609.9726 - val_loss: 2559771601.2420\n",
      "Epoch 512/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 2148517495.7339 - val_loss: 2558558488.5479\n",
      "Epoch 513/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 2149061444.1331 - val_loss: 2557436320.7306\n",
      "Epoch 514/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2146971223.9217 - val_loss: 2556214390.0639\n",
      "Epoch 515/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 2145797554.8493 - val_loss: 2555067006.8311\n",
      "Epoch 516/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2145231616.7515 - val_loss: 2553942907.9087\n",
      "Epoch 517/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 2143870570.5832 - val_loss: 2552748333.5890\n",
      "Epoch 518/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2142826019.3190 - val_loss: 2551605712.6575\n",
      "Epoch 519/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 43us/step - loss: 2142083370.5832 - val_loss: 2550380567.9635\n",
      "Epoch 520/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 2141506784.9393 - val_loss: 2549230047.8539\n",
      "Epoch 521/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2139936920.7984 - val_loss: 2548091552.7306\n",
      "Epoch 522/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 2139183677.6204 - val_loss: 2546938721.0228\n",
      "Epoch 523/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2137943464.3288 - val_loss: 2545772391.4521\n",
      "Epoch 524/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 2137528199.5147 - val_loss: 2544655348.8950\n",
      "Epoch 525/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2136274886.8885 - val_loss: 2543522248.4749\n",
      "Epoch 526/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 2135032245.1037 - val_loss: 2542339593.9361\n",
      "Epoch 527/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 2134174876.0548 - val_loss: 2541157317.5525\n",
      "Epoch 528/15000\n",
      "1022/1022 [==============================] - 0s 68us/step - loss: 2133190769.7221 - val_loss: 2539942788.6758\n",
      "Epoch 529/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2132543019.0841 - val_loss: 2538736762.7397\n",
      "Epoch 530/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2131131660.7750 - val_loss: 2537621945.8630\n",
      "Epoch 531/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2130677575.6399 - val_loss: 2536532806.1370\n",
      "Epoch 532/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2129294505.0802 - val_loss: 2535310760.9132\n",
      "Epoch 533/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2128275628.8376 - val_loss: 2534103265.6073\n",
      "Epoch 534/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2127707279.5303 - val_loss: 2532935265.0228\n",
      "Epoch 535/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2127264554.5832 - val_loss: 2531827401.0594\n",
      "Epoch 536/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2125729355.3973 - val_loss: 2530673647.6347\n",
      "Epoch 537/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2125105963.3346 - val_loss: 2529519330.1918\n",
      "Epoch 538/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2123698105.6125 - val_loss: 2528319523.6530\n",
      "Epoch 539/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2122553462.2309 - val_loss: 2527184047.9269\n",
      "Epoch 540/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2121885342.0587 - val_loss: 2525936441.8630\n",
      "Epoch 541/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 2120835685.6986 - val_loss: 2524835791.4886\n",
      "Epoch 542/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2119788082.0978 - val_loss: 2523702255.0502\n",
      "Epoch 543/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 2118982728.8924 - val_loss: 2522538256.9498\n",
      "Epoch 544/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2117719069.8082 - val_loss: 2521344800.7306\n",
      "Epoch 545/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2116873340.2427 - val_loss: 2520248747.8356\n",
      "Epoch 546/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 2116538473.4560 - val_loss: 2519122977.8995\n",
      "Epoch 547/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 2114983807.2485 - val_loss: 2517987669.3333\n",
      "Epoch 548/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 2114151395.9452 - val_loss: 2516729251.0685\n",
      "Epoch 549/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2113189594.9276 - val_loss: 2515651221.6256\n",
      "Epoch 550/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 2112050678.4814 - val_loss: 2514479709.5160\n",
      "Epoch 551/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 2111178877.2446 - val_loss: 2513329022.8311\n",
      "Epoch 552/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2110250203.3033 - val_loss: 2512160222.1005\n",
      "Epoch 553/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 2109403352.4227 - val_loss: 2510971401.9361\n",
      "Epoch 554/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2108282272.0626 - val_loss: 2509831880.4749\n",
      "Epoch 555/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2107342249.7065 - val_loss: 2508705306.3014\n",
      "Epoch 556/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 2106382978.7554 - val_loss: 2507599078.8676\n",
      "Epoch 557/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 2105433272.8611 - val_loss: 2506361872.9498\n",
      "Epoch 558/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 2104634552.8611 - val_loss: 2505237004.2740\n",
      "Epoch 559/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2104405355.9609 - val_loss: 2504079222.0639\n",
      "Epoch 560/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 2102569525.3542 - val_loss: 2502998262.0639\n",
      "Epoch 561/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 2101704068.5088 - val_loss: 2501851722.8128\n",
      "Epoch 562/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 2100861184.0000 - val_loss: 2500679266.7763\n",
      "Epoch 563/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2100133909.5421 - val_loss: 2499607752.4749\n",
      "Epoch 564/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 2098982861.4012 - val_loss: 2498470013.0776\n",
      "Epoch 565/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 2098652778.7084 - val_loss: 2497295884.2740\n",
      "Epoch 566/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2096911123.5382 - val_loss: 2496230753.0228\n",
      "Epoch 567/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2096141589.2916 - val_loss: 2495047645.5160\n",
      "Epoch 568/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 2095379320.2348 - val_loss: 2493961188.5297\n",
      "Epoch 569/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2094445632.1252 - val_loss: 2492848635.9087\n",
      "Epoch 570/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2093693442.7554 - val_loss: 2491614864.9498\n",
      "Epoch 571/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2092373172.3523 - val_loss: 2490535469.0046\n",
      "Epoch 572/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2091843321.4873 - val_loss: 2489393715.4338\n",
      "Epoch 573/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2090861747.3503 - val_loss: 2488346669.5890\n",
      "Epoch 574/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 2089668540.9941 - val_loss: 2487193021.9543\n",
      "Epoch 575/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2088654461.7456 - val_loss: 2486082430.8311\n",
      "Epoch 576/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2087861067.1468 - val_loss: 2484986313.0594\n",
      "Epoch 577/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2086889256.9550 - val_loss: 2483909695.7078\n",
      "Epoch 578/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2086044958.8102 - val_loss: 2482786258.9954\n",
      "Epoch 579/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2085027707.9922 - val_loss: 2481697590.9406\n",
      "Epoch 580/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2084144194.0039 - val_loss: 2480535746.6301\n",
      "Epoch 581/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 2083445351.2016 - val_loss: 2479428622.0274\n",
      "Epoch 582/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2082252941.7769 - val_loss: 2478211515.6164\n",
      "Epoch 583/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 2081598395.3659 - val_loss: 2477127795.1416\n",
      "Epoch 584/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 32us/step - loss: 2080514020.4462 - val_loss: 2476026458.0091\n",
      "Epoch 585/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 2079781358.2153 - val_loss: 2474926538.2283\n",
      "Epoch 586/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 2078947561.9569 - val_loss: 2473775208.0365\n",
      "Epoch 587/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 2077643569.0959 - val_loss: 2472691541.3333\n",
      "Epoch 588/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2077842429.2446 - val_loss: 2471617675.6895\n",
      "Epoch 589/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2076012402.7241 - val_loss: 2470550313.4977\n",
      "Epoch 590/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2075454133.3542 - val_loss: 2469396713.2055\n",
      "Epoch 591/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 2074395947.5851 - val_loss: 2468364570.8858\n",
      "Epoch 592/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 2074184906.6458 - val_loss: 2467300418.6301\n",
      "Epoch 593/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2073578910.0587 - val_loss: 2466074208.4384\n",
      "Epoch 594/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 2071522434.2544 - val_loss: 2464981338.5936\n",
      "Epoch 595/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2070769274.2387 - val_loss: 2463935219.1416\n",
      "Epoch 596/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2069794253.6517 - val_loss: 2462894446.4658\n",
      "Epoch 597/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2069302113.1898 - val_loss: 2461708846.1735\n",
      "Epoch 598/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2068479832.5479 - val_loss: 2460681153.4612\n",
      "Epoch 599/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2067222980.5714 - val_loss: 2459583546.4475\n",
      "Epoch 600/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2066283849.6438 - val_loss: 2458507794.7032\n",
      "Epoch 601/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 2066241704.7045 - val_loss: 2457369767.1598\n",
      "Epoch 602/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2064680146.1605 - val_loss: 2456393730.3379\n",
      "Epoch 603/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2063690062.1526 - val_loss: 2455292190.9772\n",
      "Epoch 604/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2062781808.7202 - val_loss: 2454240488.0365\n",
      "Epoch 605/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 2061929307.9295 - val_loss: 2453159717.9909\n",
      "Epoch 606/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2061119329.9413 - val_loss: 2452024898.6301\n",
      "Epoch 607/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2060090187.6477 - val_loss: 2450984600.5479\n",
      "Epoch 608/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2059309718.5440 - val_loss: 2449982418.9954\n",
      "Epoch 609/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2058609535.7495 - val_loss: 2448926474.5205\n",
      "Epoch 610/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2057631564.3992 - val_loss: 2447769117.2237\n",
      "Epoch 611/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2056968143.4051 - val_loss: 2446671636.4566\n",
      "Epoch 612/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2055948358.1370 - val_loss: 2445607118.9041\n",
      "Epoch 613/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2055262640.9706 - val_loss: 2444518835.4338\n",
      "Epoch 614/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2054113431.5460 - val_loss: 2443459813.6986\n",
      "Epoch 615/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 2053225750.0431 - val_loss: 2442467064.4018\n",
      "Epoch 616/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2052873199.5930 - val_loss: 2441323594.2283\n",
      "Epoch 617/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2051767393.3151 - val_loss: 2440319909.4064\n",
      "Epoch 618/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 2050518740.4149 - val_loss: 2439287842.4840\n",
      "Epoch 619/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 2049916684.2740 - val_loss: 2438162125.7352\n",
      "Epoch 620/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 2049429146.8023 - val_loss: 2437167036.2009\n",
      "Epoch 621/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2047996443.0528 - val_loss: 2436093061.8447\n",
      "Epoch 622/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2047425367.1703 - val_loss: 2434991518.9772\n",
      "Epoch 623/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 2046363498.8337 - val_loss: 2433953448.9132\n",
      "Epoch 624/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 2045534096.7828 - val_loss: 2432901492.3105\n",
      "Epoch 625/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 2044953123.0685 - val_loss: 2431836798.2466\n",
      "Epoch 626/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 2043969390.3405 - val_loss: 2430796871.3059\n",
      "Epoch 627/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2043488965.3855 - val_loss: 2429802041.8630\n",
      "Epoch 628/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2041938847.8121 - val_loss: 2428666659.6530\n",
      "Epoch 629/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2041331496.0783 - val_loss: 2427555225.1324\n",
      "Epoch 630/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 2040175402.8337 - val_loss: 2426474652.6393\n",
      "Epoch 631/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 2039733839.6556 - val_loss: 2425461659.4703\n",
      "Epoch 632/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 2038640457.1429 - val_loss: 2424408173.2968\n",
      "Epoch 633/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2037902941.6830 - val_loss: 2423272681.7900\n",
      "Epoch 634/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 2036826053.8865 - val_loss: 2422231991.5251\n",
      "Epoch 635/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 2036347600.9080 - val_loss: 2421165501.9543\n",
      "Epoch 636/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2035420580.8219 - val_loss: 2420216422.2831\n",
      "Epoch 637/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2034440956.7436 - val_loss: 2419196556.8584\n",
      "Epoch 638/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2033537793.5029 - val_loss: 2418037716.1644\n",
      "Epoch 639/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2032602070.9198 - val_loss: 2416952335.7808\n",
      "Epoch 640/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2031784196.2583 - val_loss: 2415836092.2009\n",
      "Epoch 641/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 2031789144.5479 - val_loss: 2414898593.8995\n",
      "Epoch 642/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2030157225.0802 - val_loss: 2413812065.6073\n",
      "Epoch 643/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2029559282.0978 - val_loss: 2412719676.2009\n",
      "Epoch 644/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2028448970.3953 - val_loss: 2411714754.0457\n",
      "Epoch 645/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2027507183.2172 - val_loss: 2410700082.8493\n",
      "Epoch 646/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 2026699106.6928 - val_loss: 2409613319.5982\n",
      "Epoch 647/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 2026068086.9824 - val_loss: 2408567061.6256\n",
      "Epoch 648/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 2025080972.0235 - val_loss: 2407486088.1826\n",
      "Epoch 649/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 34us/step - loss: 2024152710.2622 - val_loss: 2406459979.9817\n",
      "Epoch 650/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 2024139005.9961 - val_loss: 2405511806.2466\n",
      "Epoch 651/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2022839603.6008 - val_loss: 2404331249.9726\n",
      "Epoch 652/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2021784097.0646 - val_loss: 2403341744.5114\n",
      "Epoch 653/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2021002712.4227 - val_loss: 2402266909.8082\n",
      "Epoch 654/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 2020262144.5010 - val_loss: 2401174462.5388\n",
      "Epoch 655/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 2019146973.4325 - val_loss: 2400176730.5936\n",
      "Epoch 656/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 2018404723.4755 - val_loss: 2399257069.8813\n",
      "Epoch 657/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 2017565505.1272 - val_loss: 2398102056.3288\n",
      "Epoch 658/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 2016736359.2016 - val_loss: 2397132584.9132\n",
      "Epoch 659/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2015854275.1311 - val_loss: 2396044938.5205\n",
      "Epoch 660/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2015169092.3836 - val_loss: 2395081116.0548\n",
      "Epoch 661/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 2014502194.0978 - val_loss: 2393951509.0411\n",
      "Epoch 662/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 2013530227.0998 - val_loss: 2392894812.9315\n",
      "Epoch 663/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 2013105983.1233 - val_loss: 2392039625.6438\n",
      "Epoch 664/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2012495879.0137 - val_loss: 2390777768.3288\n",
      "Epoch 665/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2010887910.4501 - val_loss: 2389847242.8128\n",
      "Epoch 666/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 2010171797.7926 - val_loss: 2388916590.4658\n",
      "Epoch 667/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2009228232.5166 - val_loss: 2387787224.2557\n",
      "Epoch 668/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 2008570862.2153 - val_loss: 2386730964.1644\n",
      "Epoch 669/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 2007816851.0372 - val_loss: 2385586202.3014\n",
      "Epoch 670/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 2006805612.4618 - val_loss: 2384647920.2192\n",
      "Epoch 671/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2006197576.3914 - val_loss: 2383710172.3470\n",
      "Epoch 672/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2005292831.5616 - val_loss: 2382573907.5799\n",
      "Epoch 673/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 2004487714.0665 - val_loss: 2381628548.6758\n",
      "Epoch 674/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 2003406020.8845 - val_loss: 2380561590.3562\n",
      "Epoch 675/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2003957780.7906 - val_loss: 2379651630.7580\n",
      "Epoch 676/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2001992912.6575 - val_loss: 2378471931.3242\n",
      "Epoch 677/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2001099341.6517 - val_loss: 2377398934.2100\n",
      "Epoch 678/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 2000140332.2114 - val_loss: 2376459406.0274\n",
      "Epoch 679/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1999391493.2603 - val_loss: 2375400325.8447\n",
      "Epoch 680/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1998553397.8552 - val_loss: 2374412545.1689\n",
      "Epoch 681/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1997815200.5636 - val_loss: 2373350631.4521\n",
      "Epoch 682/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1996925248.2505 - val_loss: 2372348242.4110\n",
      "Epoch 683/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1996488885.8552 - val_loss: 2371434146.4840\n",
      "Epoch 684/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1996085127.2642 - val_loss: 2370171856.6575\n",
      "Epoch 685/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1994575847.2016 - val_loss: 2369224446.8311\n",
      "Epoch 686/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1993921111.6712 - val_loss: 2368274707.8721\n",
      "Epoch 687/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1993442029.2133 - val_loss: 2367325608.3288\n",
      "Epoch 688/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1992225848.2348 - val_loss: 2366201366.7945\n",
      "Epoch 689/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1991395118.8415 - val_loss: 2365226355.1416\n",
      "Epoch 690/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1990660269.2133 - val_loss: 2364147966.2466\n",
      "Epoch 691/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1990033631.1859 - val_loss: 2363165086.3927\n",
      "Epoch 692/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1989131092.1644 - val_loss: 2362139031.9635\n",
      "Epoch 693/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1988125670.7006 - val_loss: 2361125056.2922\n",
      "Epoch 694/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1988030485.5421 - val_loss: 2360278087.8904\n",
      "Epoch 695/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1986975115.5225 - val_loss: 2359090435.5068\n",
      "Epoch 696/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1985869654.4188 - val_loss: 2358196339.1416\n",
      "Epoch 697/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1985108167.8904 - val_loss: 2357288118.3562\n",
      "Epoch 698/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1984161996.9002 - val_loss: 2356292896.7306\n",
      "Epoch 699/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1983620602.4892 - val_loss: 2355137244.9315\n",
      "Epoch 700/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1982533361.9726 - val_loss: 2354153377.8995\n",
      "Epoch 701/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1981707513.4873 - val_loss: 2353271547.9087\n",
      "Epoch 702/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1981119477.4795 - val_loss: 2352129620.7489\n",
      "Epoch 703/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1980201451.4599 - val_loss: 2351154865.6804\n",
      "Epoch 704/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1979380624.0313 - val_loss: 2350166571.2511\n",
      "Epoch 705/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1978645413.3229 - val_loss: 2349129160.4749\n",
      "Epoch 706/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1977965070.2779 - val_loss: 2348078603.6895\n",
      "Epoch 707/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1978457806.2779 - val_loss: 2346965246.2466\n",
      "Epoch 708/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1975952169.0802 - val_loss: 2346126845.6621\n",
      "Epoch 709/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1975371323.6164 - val_loss: 2345181473.3151\n",
      "Epoch 710/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1975278687.9374 - val_loss: 2343975038.8311\n",
      "Epoch 711/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1973889496.1722 - val_loss: 2342974261.1872\n",
      "Epoch 712/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1973487009.8160 - val_loss: 2342224827.6164\n",
      "Epoch 713/15000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1972204238.5284 - val_loss: 2340988789.4795\n",
      "Epoch 714/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 37us/step - loss: 1971436313.9256 - val_loss: 2340020757.6256\n",
      "Epoch 715/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1970629096.9550 - val_loss: 2338982212.9680\n",
      "Epoch 716/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1969741416.7045 - val_loss: 2337962439.3059\n",
      "Epoch 717/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1968939739.6791 - val_loss: 2336929232.0731\n",
      "Epoch 718/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1968423753.3933 - val_loss: 2335843811.9452\n",
      "Epoch 719/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1968067193.1115 - val_loss: 2334957466.8858\n",
      "Epoch 720/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1966582208.1879 - val_loss: 2333958761.7900\n",
      "Epoch 721/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1966053137.5342 - val_loss: 2332883171.3607\n",
      "Epoch 722/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1965033474.1292 - val_loss: 2331893417.4977\n",
      "Epoch 723/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1964468292.6341 - val_loss: 2331029975.6712\n",
      "Epoch 724/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1964334843.4912 - val_loss: 2330193514.3744\n",
      "Epoch 725/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1963323515.9922 - val_loss: 2328869833.6438\n",
      "Epoch 726/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1961910653.7456 - val_loss: 2327826005.3333\n",
      "Epoch 727/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1961097361.5342 - val_loss: 2326955012.0913\n",
      "Epoch 728/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1960497594.6145 - val_loss: 2325886562.7763\n",
      "Epoch 729/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1959626400.6888 - val_loss: 2324946338.4840\n",
      "Epoch 730/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1959168392.0157 - val_loss: 2323793128.6210\n",
      "Epoch 731/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1958035587.2564 - val_loss: 2322954366.2466\n",
      "Epoch 732/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1957378808.2348 - val_loss: 2322106799.9269\n",
      "Epoch 733/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1957266409.4560 - val_loss: 2320870522.7397\n",
      "Epoch 734/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1955848413.6830 - val_loss: 2319877877.4795\n",
      "Epoch 735/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1954978044.9941 - val_loss: 2318852919.5251\n",
      "Epoch 736/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1954322974.3092 - val_loss: 2318169171.5799\n",
      "Epoch 737/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1953807373.0254 - val_loss: 2316979614.9772\n",
      "Epoch 738/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1952667654.0117 - val_loss: 2316007709.8082\n",
      "Epoch 739/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1952341548.5871 - val_loss: 2315273333.4795\n",
      "Epoch 740/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1951016310.6067 - val_loss: 2314138554.4475\n",
      "Epoch 741/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1950684738.1292 - val_loss: 2313211953.6804\n",
      "Epoch 742/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1950063014.3249 - val_loss: 2312132869.2603\n",
      "Epoch 743/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1948677319.3894 - val_loss: 2311191680.0000\n",
      "Epoch 744/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1948002409.4560 - val_loss: 2310226220.4201\n",
      "Epoch 745/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1947419640.4853 - val_loss: 2309266588.0548\n",
      "Epoch 746/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1946583579.5538 - val_loss: 2308254492.0548\n",
      "Epoch 747/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1946116836.5714 - val_loss: 2307162399.5616\n",
      "Epoch 748/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1945027238.8258 - val_loss: 2306172122.0091\n",
      "Epoch 749/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1945114735.7182 - val_loss: 2305158504.6210\n",
      "Epoch 750/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1943633716.1018 - val_loss: 2304476340.6027\n",
      "Epoch 751/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1942729817.6751 - val_loss: 2303460456.6210\n",
      "Epoch 752/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1941844168.1409 - val_loss: 2302391633.8265\n",
      "Epoch 753/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1941293808.7202 - val_loss: 2301261272.2557\n",
      "Epoch 754/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1940287392.0626 - val_loss: 2300426269.8082\n",
      "Epoch 755/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1939703906.0665 - val_loss: 2299410977.3151\n",
      "Epoch 756/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1939888494.4658 - val_loss: 2298541698.3379\n",
      "Epoch 757/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1938164053.6673 - val_loss: 2297596509.5160\n",
      "Epoch 758/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1937307493.6986 - val_loss: 2296433430.7945\n",
      "Epoch 759/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1936617277.8708 - val_loss: 2295517032.0365\n",
      "Epoch 760/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1936420349.6204 - val_loss: 2294544706.6301\n",
      "Epoch 761/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1935229701.7613 - val_loss: 2293534274.6301\n",
      "Epoch 762/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1934849088.8767 - val_loss: 2292575113.3516\n",
      "Epoch 763/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1933742475.2720 - val_loss: 2291658517.0411\n",
      "Epoch 764/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1933148852.8532 - val_loss: 2290637508.9680\n",
      "Epoch 765/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1932311173.7613 - val_loss: 2289828807.3059\n",
      "Epoch 766/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1931396603.9922 - val_loss: 2288867555.9452\n",
      "Epoch 767/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1930667582.7476 - val_loss: 2287902508.4201\n",
      "Epoch 768/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1930472901.8865 - val_loss: 2286713391.9269\n",
      "Epoch 769/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1929150362.5519 - val_loss: 2285840374.6484\n",
      "Epoch 770/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1928927655.5773 - val_loss: 2285051845.5525\n",
      "Epoch 771/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1927621714.5362 - val_loss: 2283973049.2785\n",
      "Epoch 772/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1927351382.9198 - val_loss: 2282963750.5753\n",
      "Epoch 773/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1926323250.0978 - val_loss: 2282216797.5160\n",
      "Epoch 774/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1925374546.1605 - val_loss: 2281311061.9178\n",
      "Epoch 775/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1924650713.4247 - val_loss: 2280194101.7717\n",
      "Epoch 776/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1924305340.3679 - val_loss: 2279074850.4840\n",
      "Epoch 777/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1923580192.3131 - val_loss: 2278311306.5205\n",
      "Epoch 778/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1922854014.9980 - val_loss: 2277248316.2009\n",
      "Epoch 779/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 39us/step - loss: 1922071224.1096 - val_loss: 2276512730.0091\n",
      "Epoch 780/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1921479024.7202 - val_loss: 2275330561.1689\n",
      "Epoch 781/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1921012074.4579 - val_loss: 2274568277.9178\n",
      "Epoch 782/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1919772019.2250 - val_loss: 2273462431.5616\n",
      "Epoch 783/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1918818391.1703 - val_loss: 2272557456.9498\n",
      "Epoch 784/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1918305693.8082 - val_loss: 2271656233.4977\n",
      "Epoch 785/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1918033751.4207 - val_loss: 2270456802.1918\n",
      "Epoch 786/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1917237462.1683 - val_loss: 2269750478.3196\n",
      "Epoch 787/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1916014856.7671 - val_loss: 2268666936.6941\n",
      "Epoch 788/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1915521682.7867 - val_loss: 2267647887.1963\n",
      "Epoch 789/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1914682466.1918 - val_loss: 2266621707.6895\n",
      "Epoch 790/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1913882811.4286 - val_loss: 2265928362.0822\n",
      "Epoch 791/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1913572314.9276 - val_loss: 2264790460.7854\n",
      "Epoch 792/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1912449937.2838 - val_loss: 2264015558.1370\n",
      "Epoch 793/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1911667292.6810 - val_loss: 2263216822.9406\n",
      "Epoch 794/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1910882381.4012 - val_loss: 2262226410.9589\n",
      "Epoch 795/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1910173599.3112 - val_loss: 2261202141.5160\n",
      "Epoch 796/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1909409016.2348 - val_loss: 2260233675.3973\n",
      "Epoch 797/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1908866697.6438 - val_loss: 2259289090.3379\n",
      "Epoch 798/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1908024738.8180 - val_loss: 2258432728.2557\n",
      "Epoch 799/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1907365695.3738 - val_loss: 2257586690.9224\n",
      "Epoch 800/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1906597839.7808 - val_loss: 2256667047.7443\n",
      "Epoch 801/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1906441629.8082 - val_loss: 2255434133.0411\n",
      "Epoch 802/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1905041918.9980 - val_loss: 2254494907.6164\n",
      "Epoch 803/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1904580997.2603 - val_loss: 2253783135.2694\n",
      "Epoch 804/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1903950818.1918 - val_loss: 2252639361.1689\n",
      "Epoch 805/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1903006663.8904 - val_loss: 2251953168.9498\n",
      "Epoch 806/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1902913847.8591 - val_loss: 2250829517.7352\n",
      "Epoch 807/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1902145848.8611 - val_loss: 2249880007.8904\n",
      "Epoch 808/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1901280997.4481 - val_loss: 2248982076.2009\n",
      "Epoch 809/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1900283142.5127 - val_loss: 2247884311.9635\n",
      "Epoch 810/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1899617391.7182 - val_loss: 2247143065.1324\n",
      "Epoch 811/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1899365255.7652 - val_loss: 2246131673.7169\n",
      "Epoch 812/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1898125906.1605 - val_loss: 2245540724.0183\n",
      "Epoch 813/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1897675492.3209 - val_loss: 2244251724.2740\n",
      "Epoch 814/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1896670331.2407 - val_loss: 2243601140.3105\n",
      "Epoch 815/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1895945603.2564 - val_loss: 2242547736.8402\n",
      "Epoch 816/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1895327836.4305 - val_loss: 2241562272.1461\n",
      "Epoch 817/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1894417849.4873 - val_loss: 2240653535.8539\n",
      "Epoch 818/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1894176951.3581 - val_loss: 2239946568.1826\n",
      "Epoch 819/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1893587570.9746 - val_loss: 2238720935.4521\n",
      "Epoch 820/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1892474015.3112 - val_loss: 2237960655.7808\n",
      "Epoch 821/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1891879784.2035 - val_loss: 2236996999.3059\n",
      "Epoch 822/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1890941673.4560 - val_loss: 2235944855.9635\n",
      "Epoch 823/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1890269162.3327 - val_loss: 2234934572.7123\n",
      "Epoch 824/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1889528729.4247 - val_loss: 2234167492.9680\n",
      "Epoch 825/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1889459954.7241 - val_loss: 2233305910.0639\n",
      "Epoch 826/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1888146708.9159 - val_loss: 2232351514.0091\n",
      "Epoch 827/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1887688995.5695 - val_loss: 2231405735.7443\n",
      "Epoch 828/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1886945386.3327 - val_loss: 2230562760.4749\n",
      "Epoch 829/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1886064938.0822 - val_loss: 2229686018.9224\n",
      "Epoch 830/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1885407323.0528 - val_loss: 2228628265.2055\n",
      "Epoch 831/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1885141861.6986 - val_loss: 2228043741.8082\n",
      "Epoch 832/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1884098204.0548 - val_loss: 2226902478.3196\n",
      "Epoch 833/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1883703096.1096 - val_loss: 2225881154.6301\n",
      "Epoch 834/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1882866199.2955 - val_loss: 2225165179.9087\n",
      "Epoch 835/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1883010790.0744 - val_loss: 2224097429.0411\n",
      "Epoch 836/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1881491673.4247 - val_loss: 2223406228.4566\n",
      "Epoch 837/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1880739609.5499 - val_loss: 2222501836.2740\n",
      "Epoch 838/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1879971809.4403 - val_loss: 2221552514.6301\n",
      "Epoch 839/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1879290858.4579 - val_loss: 2220524026.4475\n",
      "Epoch 840/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1878541306.4892 - val_loss: 2219624518.1370\n",
      "Epoch 841/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1877957380.0078 - val_loss: 2218827523.7991\n",
      "Epoch 842/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1877571259.8669 - val_loss: 2218047713.8995\n",
      "Epoch 843/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1876639561.5186 - val_loss: 2216820225.4612\n",
      "Epoch 844/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 37us/step - loss: 1876076958.3718 - val_loss: 2216123082.8128\n",
      "Epoch 845/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1875850256.7828 - val_loss: 2215380536.9863\n",
      "Epoch 846/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1874566598.3875 - val_loss: 2214339509.1872\n",
      "Epoch 847/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1874521276.3679 - val_loss: 2213353509.6986\n",
      "Epoch 848/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1873276931.0059 - val_loss: 2212426676.3105\n",
      "Epoch 849/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1872732038.0117 - val_loss: 2211640648.7671\n",
      "Epoch 850/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1871806757.8239 - val_loss: 2210723438.7580\n",
      "Epoch 851/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1871603524.6341 - val_loss: 2210113853.9543\n",
      "Epoch 852/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1870544806.7006 - val_loss: 2209102865.8265\n",
      "Epoch 853/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1870055046.7632 - val_loss: 2208287430.7215\n",
      "Epoch 854/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1869361817.9256 - val_loss: 2207202751.7078\n",
      "Epoch 855/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1868686029.9022 - val_loss: 2206208221.2237\n",
      "Epoch 856/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1868284236.1487 - val_loss: 2205562861.2968\n",
      "Epoch 857/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1867240836.7593 - val_loss: 2204591988.0183\n",
      "Epoch 858/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1867847349.1037 - val_loss: 2203324509.2237\n",
      "Epoch 859/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1866807262.4344 - val_loss: 2203045134.0274\n",
      "Epoch 860/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1865341099.3346 - val_loss: 2202121141.4795\n",
      "Epoch 861/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1865308431.4051 - val_loss: 2200809823.5616\n",
      "Epoch 862/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1863997804.2114 - val_loss: 2200134132.6027\n",
      "Epoch 863/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1863946247.0137 - val_loss: 2199283890.8493\n",
      "Epoch 864/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1862790856.3914 - val_loss: 2198478876.0548\n",
      "Epoch 865/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1861917390.1526 - val_loss: 2197517175.8174\n",
      "Epoch 866/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1861261842.0352 - val_loss: 2196497168.9498\n",
      "Epoch 867/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1860670397.8708 - val_loss: 2195690873.2785\n",
      "Epoch 868/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1859978885.7613 - val_loss: 2194806634.0822\n",
      "Epoch 869/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1859281501.5577 - val_loss: 2193815501.4429\n",
      "Epoch 870/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1859003273.7691 - val_loss: 2193279117.4429\n",
      "Epoch 871/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1858202227.2250 - val_loss: 2191969636.5297\n",
      "Epoch 872/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1857412102.7632 - val_loss: 2191348997.2603\n",
      "Epoch 873/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1856780334.5910 - val_loss: 2190240151.9635\n",
      "Epoch 874/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1856000141.2759 - val_loss: 2189382539.9817\n",
      "Epoch 875/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1855443782.6380 - val_loss: 2188356935.3059\n",
      "Epoch 876/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1855716210.0978 - val_loss: 2187872923.4703\n",
      "Epoch 877/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1854137824.6888 - val_loss: 2186892680.4749\n",
      "Epoch 878/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1853921504.8767 - val_loss: 2185823978.9589\n",
      "Epoch 879/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1852778069.1663 - val_loss: 2185194973.2237\n",
      "Epoch 880/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1853515932.3053 - val_loss: 2184516772.2374\n",
      "Epoch 881/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1851285851.1781 - val_loss: 2183222792.1826\n",
      "Epoch 882/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1851143369.8943 - val_loss: 2182333246.8311\n",
      "Epoch 883/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1850069551.7182 - val_loss: 2181328593.2420\n",
      "Epoch 884/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1849437062.5127 - val_loss: 2180531882.0822\n",
      "Epoch 885/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1848732140.8376 - val_loss: 2179710471.8904\n",
      "Epoch 886/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1848123161.0489 - val_loss: 2178851946.6667\n",
      "Epoch 887/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1847665125.1977 - val_loss: 2178070702.4658\n",
      "Epoch 888/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1847026913.4403 - val_loss: 2177031789.8813\n",
      "Epoch 889/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1846042896.0313 - val_loss: 2176282043.0320\n",
      "Epoch 890/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1845874106.8650 - val_loss: 2175262374.8676\n",
      "Epoch 891/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1844814378.7084 - val_loss: 2174507961.2785\n",
      "Epoch 892/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1844339055.4677 - val_loss: 2173414003.4338\n",
      "Epoch 893/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1843407827.5382 - val_loss: 2172782976.8767\n",
      "Epoch 894/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1843022062.0900 - val_loss: 2171801416.1826\n",
      "Epoch 895/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1842162145.9413 - val_loss: 2171036148.0183\n",
      "Epoch 896/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1842103858.3483 - val_loss: 2170360719.4886\n",
      "Epoch 897/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1841267592.5166 - val_loss: 2169645108.0183\n",
      "Epoch 898/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1840752049.3464 - val_loss: 2168436539.0320\n",
      "Epoch 899/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1839752850.0352 - val_loss: 2167470070.0639\n",
      "Epoch 900/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1840179386.2387 - val_loss: 2167087645.5160\n",
      "Epoch 901/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1838648730.8023 - val_loss: 2166008836.0913\n",
      "Epoch 902/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1837980612.8845 - val_loss: 2165080514.0457\n",
      "Epoch 903/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1837257130.8337 - val_loss: 2164196264.6210\n",
      "Epoch 904/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1837234592.5636 - val_loss: 2163132968.0365\n",
      "Epoch 905/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1835957893.7613 - val_loss: 2162409391.6347\n",
      "Epoch 906/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1835182491.0528 - val_loss: 2161616583.5982\n",
      "Epoch 907/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1834731516.9941 - val_loss: 2160520391.5982\n",
      "Epoch 908/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1834127697.4090 - val_loss: 2159645710.3196\n",
      "Epoch 909/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 33us/step - loss: 1833400617.2055 - val_loss: 2158984478.3927\n",
      "Epoch 910/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1832648120.6106 - val_loss: 2158214645.1872\n",
      "Epoch 911/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1832582605.9022 - val_loss: 2157083378.2648\n",
      "Epoch 912/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1831795373.3386 - val_loss: 2156741127.0137\n",
      "Epoch 913/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1830869748.9785 - val_loss: 2155662056.0365\n",
      "Epoch 914/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1830231228.1174 - val_loss: 2154690279.7443\n",
      "Epoch 915/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1829753521.0959 - val_loss: 2153980498.1187\n",
      "Epoch 916/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1829757830.2622 - val_loss: 2152941068.5662\n",
      "Epoch 917/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1828325116.3679 - val_loss: 2152036805.2603\n",
      "Epoch 918/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1827788079.8434 - val_loss: 2151483276.5662\n",
      "Epoch 919/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1827026816.5010 - val_loss: 2150400509.0776\n",
      "Epoch 920/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1826581108.2270 - val_loss: 2149713629.5160\n",
      "Epoch 921/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1826202009.0489 - val_loss: 2148511751.8904\n",
      "Epoch 922/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1825352300.4618 - val_loss: 2147882366.5388\n",
      "Epoch 923/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1824706482.4736 - val_loss: 2147126640.8037\n",
      "Epoch 924/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1824100482.5049 - val_loss: 2146010565.5525\n",
      "Epoch 925/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1824033358.6536 - val_loss: 2145616593.2420\n",
      "Epoch 926/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1822919316.5401 - val_loss: 2144285070.9041\n",
      "Epoch 927/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1822337085.1194 - val_loss: 2143359044.6758\n",
      "Epoch 928/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1821909242.1135 - val_loss: 2142842175.1233\n",
      "Epoch 929/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1820979092.7906 - val_loss: 2142079683.2146\n",
      "Epoch 930/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1820500582.7006 - val_loss: 2140955868.6393\n",
      "Epoch 931/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1819684658.5988 - val_loss: 2140219161.7169\n",
      "Epoch 932/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1819830449.8474 - val_loss: 2138932910.4658\n",
      "Epoch 933/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1818628881.2838 - val_loss: 2138651263.7078\n",
      "Epoch 934/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1817783032.4853 - val_loss: 2137607172.9680\n",
      "Epoch 935/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1817497228.0235 - val_loss: 2136813745.6804\n",
      "Epoch 936/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1817188777.4560 - val_loss: 2135537281.7534\n",
      "Epoch 937/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1816175164.3679 - val_loss: 2135148857.8630\n",
      "Epoch 938/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1815844342.1057 - val_loss: 2134432362.0822\n",
      "Epoch 939/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1814935783.9530 - val_loss: 2133666230.6484\n",
      "Epoch 940/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1814312426.7084 - val_loss: 2132550044.9315\n",
      "Epoch 941/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1813666817.0020 - val_loss: 2131800436.6027\n",
      "Epoch 942/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1813067873.9413 - val_loss: 2130773605.6986\n",
      "Epoch 943/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1812191971.9452 - val_loss: 2130052470.3562\n",
      "Epoch 944/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1811737549.2759 - val_loss: 2129037265.5342\n",
      "Epoch 945/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1810970739.4755 - val_loss: 2128417180.3470\n",
      "Epoch 946/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1810431988.9785 - val_loss: 2127526702.7580\n",
      "Epoch 947/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1810006426.5519 - val_loss: 2126575316.1644\n",
      "Epoch 948/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1809445787.5538 - val_loss: 2125715478.2100\n",
      "Epoch 949/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1808969113.2994 - val_loss: 2124705286.4292\n",
      "Epoch 950/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1808213327.2798 - val_loss: 2124326573.8813\n",
      "Epoch 951/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1807391664.9706 - val_loss: 2123580166.7215\n",
      "Epoch 952/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1806906609.2211 - val_loss: 2122406734.6119\n",
      "Epoch 953/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1806675617.8160 - val_loss: 2121716623.1963\n",
      "Epoch 954/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1805624800.4384 - val_loss: 2120877368.1096\n",
      "Epoch 955/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1805097618.2857 - val_loss: 2119840731.4703\n",
      "Epoch 956/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1804755566.7162 - val_loss: 2119251176.6210\n",
      "Epoch 957/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1804000113.9726 - val_loss: 2118237482.6667\n",
      "Epoch 958/15000\n",
      "1022/1022 [==============================] - 0s 66us/step - loss: 1803473049.4247 - val_loss: 2117447810.3379\n",
      "Epoch 959/15000\n",
      "1022/1022 [==============================] - 0s 66us/step - loss: 1802599459.0685 - val_loss: 2116720485.6986\n",
      "Epoch 960/15000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1802313001.2055 - val_loss: 2116005075.2877\n",
      "Epoch 961/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1801646470.7632 - val_loss: 2114872142.3196\n",
      "Epoch 962/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1801059566.7162 - val_loss: 2114006087.3059\n",
      "Epoch 963/15000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1800926121.5812 - val_loss: 2113241027.5068\n",
      "Epoch 964/15000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1799557940.6027 - val_loss: 2112662290.4110\n",
      "Epoch 965/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1798995323.8669 - val_loss: 2111802371.7991\n",
      "Epoch 966/15000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1798663303.7652 - val_loss: 2111253620.3105\n",
      "Epoch 967/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1797860521.5812 - val_loss: 2110287489.4612\n",
      "Epoch 968/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1797455157.3542 - val_loss: 2109293293.5890\n",
      "Epoch 969/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1796951066.0509 - val_loss: 2108378379.9817\n",
      "Epoch 970/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1796103009.5656 - val_loss: 2107689946.5936\n",
      "Epoch 971/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1795623220.6027 - val_loss: 2106841760.1461\n",
      "Epoch 972/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1795076106.0196 - val_loss: 2106206003.4338\n",
      "Epoch 973/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1794643427.0685 - val_loss: 2105647805.9543\n",
      "Epoch 974/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 37us/step - loss: 1794051599.0294 - val_loss: 2104565980.9315\n",
      "Epoch 975/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1793276207.0920 - val_loss: 2103625713.6804\n",
      "Epoch 976/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1793021462.7945 - val_loss: 2103069762.6301\n",
      "Epoch 977/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1792182221.1507 - val_loss: 2101976336.6575\n",
      "Epoch 978/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1791522669.9648 - val_loss: 2101414645.1872\n",
      "Epoch 979/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1791409292.5245 - val_loss: 2100297316.8219\n",
      "Epoch 980/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1791087956.2896 - val_loss: 2099879397.6986\n",
      "Epoch 981/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1790272540.6810 - val_loss: 2098605022.1005\n",
      "Epoch 982/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1789910901.7299 - val_loss: 2097693369.8630\n",
      "Epoch 983/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1789092068.8219 - val_loss: 2097586403.6530\n",
      "Epoch 984/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1788281703.5773 - val_loss: 2096591731.4338\n",
      "Epoch 985/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1788218818.3796 - val_loss: 2095514745.5708\n",
      "Epoch 986/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1787118843.9922 - val_loss: 2094984600.2557\n",
      "Epoch 987/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1786398956.8376 - val_loss: 2094209691.1781\n",
      "Epoch 988/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1786990137.7378 - val_loss: 2093996783.6347\n",
      "Epoch 989/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1785406952.9550 - val_loss: 2092587091.5799\n",
      "Epoch 990/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1784868314.9276 - val_loss: 2091730050.9224\n",
      "Epoch 991/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1784513457.5969 - val_loss: 2091310028.8584\n",
      "Epoch 992/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1783859010.1292 - val_loss: 2090163313.6804\n",
      "Epoch 993/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1783240594.5362 - val_loss: 2089618012.0548\n",
      "Epoch 994/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1782789990.7006 - val_loss: 2088678867.2877\n",
      "Epoch 995/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1782072799.6869 - val_loss: 2087957411.6530\n",
      "Epoch 996/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1781580783.7182 - val_loss: 2087062676.7489\n",
      "Epoch 997/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1781053229.0881 - val_loss: 2086543131.7626\n",
      "Epoch 998/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1781094792.0157 - val_loss: 2085562621.6621\n",
      "Epoch 999/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1780317902.1526 - val_loss: 2084941529.7169\n",
      "Epoch 1000/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1779530386.2857 - val_loss: 2084113515.8356\n",
      "Epoch 1001/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1778919007.8121 - val_loss: 2083239441.5342\n",
      "Epoch 1002/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1778278904.2348 - val_loss: 2082638077.0776\n",
      "Epoch 1003/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1778010089.9569 - val_loss: 2081821293.8813\n",
      "Epoch 1004/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1777284911.7182 - val_loss: 2081277845.6256\n",
      "Epoch 1005/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1776575422.3718 - val_loss: 2080407808.2922\n",
      "Epoch 1006/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1776326322.8493 - val_loss: 2079299200.2922\n",
      "Epoch 1007/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1775753703.2016 - val_loss: 2078781099.8356\n",
      "Epoch 1008/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1775085187.7573 - val_loss: 2078076516.5297\n",
      "Epoch 1009/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1774577520.4697 - val_loss: 2077046539.3973\n",
      "Epoch 1010/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1774067138.1292 - val_loss: 2076261386.2283\n",
      "Epoch 1011/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1773336110.8415 - val_loss: 2075595280.0731\n",
      "Epoch 1012/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1772841533.4951 - val_loss: 2074907064.6941\n",
      "Epoch 1013/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1772509686.7319 - val_loss: 2074096453.2603\n",
      "Epoch 1014/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1772106303.6243 - val_loss: 2073333082.3014\n",
      "Epoch 1015/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1771292705.8160 - val_loss: 2072769587.4338\n",
      "Epoch 1016/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1770722375.5147 - val_loss: 2071811245.2968\n",
      "Epoch 1017/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1770160112.9706 - val_loss: 2071149362.5571\n",
      "Epoch 1018/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1769660926.4971 - val_loss: 2070422897.6804\n",
      "Epoch 1019/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1769175221.6047 - val_loss: 2069872588.2740\n",
      "Epoch 1020/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1768803373.0881 - val_loss: 2068738876.4932\n",
      "Epoch 1021/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1768211237.8239 - val_loss: 2068069488.8037\n",
      "Epoch 1022/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1767734995.5382 - val_loss: 2067585088.5845\n",
      "Epoch 1023/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1767216874.4579 - val_loss: 2066481216.0000\n",
      "Epoch 1024/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1766582936.2975 - val_loss: 2066123714.9224\n",
      "Epoch 1025/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1765821651.9139 - val_loss: 2065275646.8311\n",
      "Epoch 1026/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1765706506.5205 - val_loss: 2064073167.4886\n",
      "Epoch 1027/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1765042634.3953 - val_loss: 2063856164.2374\n",
      "Epoch 1028/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1765169579.7104 - val_loss: 2062500897.3151\n",
      "Epoch 1029/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1764172347.6164 - val_loss: 2062410304.5845\n",
      "Epoch 1030/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1763497924.8845 - val_loss: 2061089531.0320\n",
      "Epoch 1031/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1762940495.1546 - val_loss: 2060691188.0183\n",
      "Epoch 1032/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1762304170.0822 - val_loss: 2059826455.9635\n",
      "Epoch 1033/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1761949160.4540 - val_loss: 2059125216.7306\n",
      "Epoch 1034/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1761125602.9432 - val_loss: 2058156200.6210\n",
      "Epoch 1035/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1760912347.4286 - val_loss: 2057572997.5525\n",
      "Epoch 1036/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1760349443.0059 - val_loss: 2056590061.0046\n",
      "Epoch 1037/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1760639144.8297 - val_loss: 2056354735.0502\n",
      "Epoch 1038/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1759824958.6223 - val_loss: 2055375829.3333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1039/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1758650482.3483 - val_loss: 2054675188.8950\n",
      "Epoch 1040/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1758274566.0117 - val_loss: 2054093314.0457\n",
      "Epoch 1041/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1757551277.3386 - val_loss: 2052958525.3699\n",
      "Epoch 1042/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1757162092.9628 - val_loss: 2052172547.5068\n",
      "Epoch 1043/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1757141451.3973 - val_loss: 2051994573.4429\n",
      "Epoch 1044/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1756324844.9628 - val_loss: 2050732191.8539\n",
      "Epoch 1045/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1755873776.4697 - val_loss: 2050332371.8721\n",
      "Epoch 1046/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1755179941.9491 - val_loss: 2049309789.2237\n",
      "Epoch 1047/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1754751067.6791 - val_loss: 2048902538.2283\n",
      "Epoch 1048/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1754034344.3288 - val_loss: 2048031557.5525\n",
      "Epoch 1049/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1754007895.1703 - val_loss: 2046998744.2557\n",
      "Epoch 1050/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1753955640.1096 - val_loss: 2046922709.3333\n",
      "Epoch 1051/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1753962340.6967 - val_loss: 2045312543.5616\n",
      "Epoch 1052/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1752257904.4697 - val_loss: 2045235589.5525\n",
      "Epoch 1053/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1751491118.8415 - val_loss: 2044572312.2557\n",
      "Epoch 1054/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1750981378.1292 - val_loss: 2043818698.2283\n",
      "Epoch 1055/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1750672642.7554 - val_loss: 2042795939.3607\n",
      "Epoch 1056/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1750419841.7534 - val_loss: 2042592365.0046\n",
      "Epoch 1057/15000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1749460544.3757 - val_loss: 2041528379.9087\n",
      "Epoch 1058/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1749199676.6184 - val_loss: 2041081809.5342\n",
      "Epoch 1059/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1748392320.0000 - val_loss: 2040135856.8037\n",
      "Epoch 1060/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1748396873.1429 - val_loss: 2039639502.9041\n",
      "Epoch 1061/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1747718028.0235 - val_loss: 2038346820.9680\n",
      "Epoch 1062/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1747300566.4188 - val_loss: 2038000551.4521\n",
      "Epoch 1063/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1746558653.8708 - val_loss: 2036996085.7717\n",
      "Epoch 1064/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1746674212.9472 - val_loss: 2036123967.1233\n",
      "Epoch 1065/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1745686397.4951 - val_loss: 2036045074.7032\n",
      "Epoch 1066/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1745034086.1996 - val_loss: 2035117556.6027\n",
      "Epoch 1067/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1745753806.0274 - val_loss: 2033835952.5114\n",
      "Epoch 1068/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1744466468.0705 - val_loss: 2034106387.2877\n",
      "Epoch 1069/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1743603111.0763 - val_loss: 2033364795.9087\n",
      "Epoch 1070/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1743372553.0176 - val_loss: 2032168697.5708\n",
      "Epoch 1071/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1742623171.3816 - val_loss: 2031465541.2603\n",
      "Epoch 1072/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1743695669.6047 - val_loss: 2030275088.6575\n",
      "Epoch 1073/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1742583170.5049 - val_loss: 2030450927.3425\n",
      "Epoch 1074/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1741716355.0059 - val_loss: 2029235434.6667\n",
      "Epoch 1075/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1740714917.3229 - val_loss: 2028708223.1233\n",
      "Epoch 1076/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1740185567.9374 - val_loss: 2028102603.6895\n",
      "Epoch 1077/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1739873825.1898 - val_loss: 2027372828.6393\n",
      "Epoch 1078/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1739330438.5127 - val_loss: 2026467128.4018\n",
      "Epoch 1079/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1738846090.7710 - val_loss: 2026000291.3607\n",
      "Epoch 1080/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1738636615.6399 - val_loss: 2025125365.4795\n",
      "Epoch 1081/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1737854516.1018 - val_loss: 2024195189.1872\n",
      "Epoch 1082/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1737399488.3757 - val_loss: 2024209015.8174\n",
      "Epoch 1083/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1737257223.2642 - val_loss: 2022981133.1507\n",
      "Epoch 1084/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1736411658.0196 - val_loss: 2022438113.8995\n",
      "Epoch 1085/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1736058067.6634 - val_loss: 2021856062.8311\n",
      "Epoch 1086/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1735739418.0509 - val_loss: 2021191933.9543\n",
      "Epoch 1087/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1735076992.7515 - val_loss: 2020148494.3196\n",
      "Epoch 1088/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1734457985.5029 - val_loss: 2019515923.8721\n",
      "Epoch 1089/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1734753992.3914 - val_loss: 2019547780.6758\n",
      "Epoch 1090/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1733937803.5225 - val_loss: 2017937668.9680\n",
      "Epoch 1091/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1733502524.6184 - val_loss: 2017515899.9087\n",
      "Epoch 1092/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1732632618.4579 - val_loss: 2016883729.5342\n",
      "Epoch 1093/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1732222288.1566 - val_loss: 2016344699.0320\n",
      "Epoch 1094/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1731858742.2309 - val_loss: 2015321878.2100\n",
      "Epoch 1095/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1731603942.8258 - val_loss: 2015052547.2146\n",
      "Epoch 1096/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1732767233.5029 - val_loss: 2013671133.5160\n",
      "Epoch 1097/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1730201771.5851 - val_loss: 2013515430.2831\n",
      "Epoch 1098/15000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1729826591.5616 - val_loss: 2012675566.7580\n",
      "Epoch 1099/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1729362891.5851 - val_loss: 2012300195.3607\n",
      "Epoch 1100/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1728906189.4012 - val_loss: 2011506247.0137\n",
      "Epoch 1101/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1728720874.7084 - val_loss: 2010625070.4658\n",
      "Epoch 1102/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1727978506.3953 - val_loss: 2010215417.8630\n",
      "Epoch 1103/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 31us/step - loss: 1728182083.8826 - val_loss: 2009603248.2192\n",
      "Epoch 1104/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1727279722.9589 - val_loss: 2008778550.6484\n",
      "Epoch 1105/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1726540259.9452 - val_loss: 2008076679.3059\n",
      "Epoch 1106/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1726169480.5166 - val_loss: 2007331151.7808\n",
      "Epoch 1107/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1725720302.9667 - val_loss: 2006855702.5023\n",
      "Epoch 1108/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1725639770.6771 - val_loss: 2005806459.0320\n",
      "Epoch 1109/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1724998102.4188 - val_loss: 2005470333.3699\n",
      "Epoch 1110/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1725175065.5499 - val_loss: 2004686779.0320\n",
      "Epoch 1111/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1724149022.3092 - val_loss: 2004339058.5571\n",
      "Epoch 1112/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1724174611.1624 - val_loss: 2003616810.9589\n",
      "Epoch 1113/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1723013479.7025 - val_loss: 2002797319.5982\n",
      "Epoch 1114/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1722600684.8376 - val_loss: 2002186212.2374\n",
      "Epoch 1115/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1722076509.1820 - val_loss: 2001359614.8311\n",
      "Epoch 1116/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1721559082.3327 - val_loss: 2000773300.8950\n",
      "Epoch 1117/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1721162151.0763 - val_loss: 1999987179.8356\n",
      "Epoch 1118/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1720855622.3875 - val_loss: 1999243952.2192\n",
      "Epoch 1119/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1720763554.6928 - val_loss: 1998846765.2968\n",
      "Epoch 1120/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1720311866.9902 - val_loss: 1997690488.4018\n",
      "Epoch 1121/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1719406785.5029 - val_loss: 1997401311.8539\n",
      "Epoch 1122/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1718837971.4129 - val_loss: 1996670128.5114\n",
      "Epoch 1123/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1718803138.6301 - val_loss: 1996207591.7443\n",
      "Epoch 1124/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1719973869.8395 - val_loss: 1994620756.1644\n",
      "Epoch 1125/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1717586697.0176 - val_loss: 1994569864.4749\n",
      "Epoch 1126/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1717183328.6888 - val_loss: 1994276563.8721\n",
      "Epoch 1127/15000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1716801034.0196 - val_loss: 1993215874.9224\n",
      "Epoch 1128/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1716241474.2544 - val_loss: 1992584597.6256\n",
      "Epoch 1129/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1716028169.5186 - val_loss: 1992459503.3425\n",
      "Epoch 1130/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1715893941.8552 - val_loss: 1991505692.0548\n",
      "Epoch 1131/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1714986801.9726 - val_loss: 1990451740.9315\n",
      "Epoch 1132/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1714568014.0274 - val_loss: 1989793668.9680\n",
      "Epoch 1133/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1714050317.5264 - val_loss: 1989330014.6849\n",
      "Epoch 1134/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1713573775.0294 - val_loss: 1988665302.2100\n",
      "Epoch 1135/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1713351554.2544 - val_loss: 1987897035.3973\n",
      "Epoch 1136/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1712638918.8885 - val_loss: 1987348710.5753\n",
      "Epoch 1137/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1712224023.0450 - val_loss: 1986754612.6027\n",
      "Epoch 1138/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1711967762.7867 - val_loss: 1986382183.4521\n",
      "Epoch 1139/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1711372740.8845 - val_loss: 1985640279.3790\n",
      "Epoch 1140/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1710862584.2348 - val_loss: 1984462044.6393\n",
      "Epoch 1141/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1710401895.9530 - val_loss: 1984125572.3836\n",
      "Epoch 1142/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1710647806.9980 - val_loss: 1982844310.5023\n",
      "Epoch 1143/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1709335998.7476 - val_loss: 1982663005.8082\n",
      "Epoch 1144/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1709246512.8454 - val_loss: 1981727800.1096\n",
      "Epoch 1145/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1708605497.2368 - val_loss: 1981436221.3699\n",
      "Epoch 1146/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1708110766.8415 - val_loss: 1980696417.6073\n",
      "Epoch 1147/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1707728434.0978 - val_loss: 1980246727.5982\n",
      "Epoch 1148/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1707379275.2720 - val_loss: 1979220731.0320\n",
      "Epoch 1149/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1707078154.7710 - val_loss: 1978554022.5753\n",
      "Epoch 1150/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1706481755.1781 - val_loss: 1977893733.1142\n",
      "Epoch 1151/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1705911038.9980 - val_loss: 1977437572.6758\n",
      "Epoch 1152/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1705769312.1879 - val_loss: 1977026302.5388\n",
      "Epoch 1153/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1705795569.9726 - val_loss: 1975664320.8767\n",
      "Epoch 1154/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1705009699.0685 - val_loss: 1975262264.6941\n",
      "Epoch 1155/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1704190744.4227 - val_loss: 1974810951.5982\n",
      "Epoch 1156/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1703786267.8043 - val_loss: 1973953979.0320\n",
      "Epoch 1157/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1703511351.2329 - val_loss: 1973216747.8356\n",
      "Epoch 1158/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1702995769.3620 - val_loss: 1972825153.4612\n",
      "Epoch 1159/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1702822623.1859 - val_loss: 1971855122.4110\n",
      "Epoch 1160/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1702121057.3151 - val_loss: 1971419201.4612\n",
      "Epoch 1161/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1701621512.2661 - val_loss: 1970756560.0731\n",
      "Epoch 1162/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1701293973.2916 - val_loss: 1969928158.9772\n",
      "Epoch 1163/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1701421390.4031 - val_loss: 1969534993.8265\n",
      "Epoch 1164/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1700318600.0157 - val_loss: 1968950299.1781\n",
      "Epoch 1165/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1700155567.0920 - val_loss: 1968445876.0183\n",
      "Epoch 1166/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1700323020.1487 - val_loss: 1967399434.2283\n",
      "Epoch 1167/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 32us/step - loss: 1699115350.7945 - val_loss: 1966868999.3059\n",
      "Epoch 1168/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1698632128.1252 - val_loss: 1966359341.5890\n",
      "Epoch 1169/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1698205865.2055 - val_loss: 1965668911.6347\n",
      "Epoch 1170/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1697875386.8650 - val_loss: 1964991923.7260\n",
      "Epoch 1171/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1697568377.4873 - val_loss: 1964105687.0868\n",
      "Epoch 1172/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1697112008.8924 - val_loss: 1963370163.1416\n",
      "Epoch 1173/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1696536093.5577 - val_loss: 1962873090.6301\n",
      "Epoch 1174/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1696281579.2094 - val_loss: 1961861653.3333\n",
      "Epoch 1175/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1695912579.5068 - val_loss: 1961480365.2968\n",
      "Epoch 1176/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1695349477.4481 - val_loss: 1961029481.2055\n",
      "Epoch 1177/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1694962380.9002 - val_loss: 1960774333.0776\n",
      "Epoch 1178/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1694509353.5812 - val_loss: 1959756679.0137\n",
      "Epoch 1179/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1693968140.9002 - val_loss: 1959280912.6575\n",
      "Epoch 1180/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1694806707.8513 - val_loss: 1959179067.3242\n",
      "Epoch 1181/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1693072087.6712 - val_loss: 1957537113.1324\n",
      "Epoch 1182/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1692830168.2975 - val_loss: 1956912890.7397\n",
      "Epoch 1183/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1692444490.6458 - val_loss: 1956312695.5251\n",
      "Epoch 1184/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1692056532.4149 - val_loss: 1955884242.4110\n",
      "Epoch 1185/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1691544604.0548 - val_loss: 1955032390.1370\n",
      "Epoch 1186/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1691387241.4560 - val_loss: 1954235579.6164\n",
      "Epoch 1187/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1690939785.6438 - val_loss: 1953498664.9132\n",
      "Epoch 1188/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1690742339.6321 - val_loss: 1953294551.6712\n",
      "Epoch 1189/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1690151547.9922 - val_loss: 1952487344.8037\n",
      "Epoch 1190/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1689548868.7593 - val_loss: 1951791034.4475\n",
      "Epoch 1191/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1689117136.4070 - val_loss: 1951553670.4292\n",
      "Epoch 1192/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1688599929.7378 - val_loss: 1950746554.7397\n",
      "Epoch 1193/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1688259679.1859 - val_loss: 1949958265.5708\n",
      "Epoch 1194/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1688003770.1135 - val_loss: 1949509235.7260\n",
      "Epoch 1195/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1687358508.3366 - val_loss: 1948855309.4429\n",
      "Epoch 1196/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1687236922.1135 - val_loss: 1947809343.1233\n",
      "Epoch 1197/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1686889290.2701 - val_loss: 1947526937.4247\n",
      "Epoch 1198/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1686231676.4932 - val_loss: 1947088605.2237\n",
      "Epoch 1199/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1685847549.4951 - val_loss: 1946355678.3927\n",
      "Epoch 1200/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1685909493.9804 - val_loss: 1945638857.0594\n",
      "Epoch 1201/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1685135038.6223 - val_loss: 1944954434.6301\n",
      "Epoch 1202/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1684891623.4521 - val_loss: 1944544879.3425\n",
      "Epoch 1203/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1684301774.4031 - val_loss: 1943949203.8721\n",
      "Epoch 1204/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1684043099.1781 - val_loss: 1943275791.1963\n",
      "Epoch 1205/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1683470113.5656 - val_loss: 1942764290.0457\n",
      "Epoch 1206/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1683011857.2838 - val_loss: 1941699210.8128\n",
      "Epoch 1207/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1682586482.4736 - val_loss: 1941041834.0822\n",
      "Epoch 1208/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1682308002.3170 - val_loss: 1940321204.3105\n",
      "Epoch 1209/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1682020928.1252 - val_loss: 1940149908.1644\n",
      "Epoch 1210/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1681420061.6830 - val_loss: 1939550332.7854\n",
      "Epoch 1211/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1681430557.8082 - val_loss: 1939152149.0411\n",
      "Epoch 1212/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1680937368.0470 - val_loss: 1937909618.2648\n",
      "Epoch 1213/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1680361876.7906 - val_loss: 1937381717.3333\n",
      "Epoch 1214/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1679932734.1213 - val_loss: 1936968331.1050\n",
      "Epoch 1215/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1679554438.2622 - val_loss: 1936240577.7534\n",
      "Epoch 1216/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1679522787.6947 - val_loss: 1935528338.4110\n",
      "Epoch 1217/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1679319383.9217 - val_loss: 1934690732.7123\n",
      "Epoch 1218/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1678224288.8141 - val_loss: 1934637920.4384\n",
      "Epoch 1219/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1678069737.0802 - val_loss: 1933805192.7671\n",
      "Epoch 1220/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1677554668.7123 - val_loss: 1933382515.7260\n",
      "Epoch 1221/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1677242428.8689 - val_loss: 1932765404.0548\n",
      "Epoch 1222/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1676870267.7417 - val_loss: 1931993091.5068\n",
      "Epoch 1223/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1677139154.9119 - val_loss: 1931762570.2283\n",
      "Epoch 1224/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1676444064.3131 - val_loss: 1930825100.2740\n",
      "Epoch 1225/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1675766043.8043 - val_loss: 1930203370.0822\n",
      "Epoch 1226/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1675778107.8669 - val_loss: 1929839885.7352\n",
      "Epoch 1227/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1675415901.1820 - val_loss: 1929131623.7443\n",
      "Epoch 1228/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1674547628.0861 - val_loss: 1928517046.6484\n",
      "Epoch 1229/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1674959826.9119 - val_loss: 1928159702.7945\n",
      "Epoch 1230/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1674286926.4031 - val_loss: 1926755234.7763\n",
      "Epoch 1231/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 32us/step - loss: 1673365107.8513 - val_loss: 1926558760.6210\n",
      "Epoch 1232/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1673251931.4286 - val_loss: 1926413570.3379\n",
      "Epoch 1233/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1672848123.4912 - val_loss: 1925185460.8950\n",
      "Epoch 1234/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1672355838.7476 - val_loss: 1924702681.1324\n",
      "Epoch 1235/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1672153839.9687 - val_loss: 1924578819.7991\n",
      "Epoch 1236/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1671648620.7123 - val_loss: 1923710461.6621\n",
      "Epoch 1237/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1671239065.4247 - val_loss: 1923099797.3333\n",
      "Epoch 1238/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1671077329.9100 - val_loss: 1922618699.9817\n",
      "Epoch 1239/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1670538979.6947 - val_loss: 1921913749.6256\n",
      "Epoch 1240/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1670387935.1859 - val_loss: 1921607512.2557\n",
      "Epoch 1241/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1670879981.2133 - val_loss: 1920036331.8356\n",
      "Epoch 1242/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1669499283.4129 - val_loss: 1919682680.6941\n",
      "Epoch 1243/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1668994572.0235 - val_loss: 1919763008.5845\n",
      "Epoch 1244/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1668709218.3170 - val_loss: 1919124400.5114\n",
      "Epoch 1245/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1668449948.8063 - val_loss: 1918645155.6530\n",
      "Epoch 1246/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1667877512.2661 - val_loss: 1917776188.4932\n",
      "Epoch 1247/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1667736560.2192 - val_loss: 1916722802.2648\n",
      "Epoch 1248/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1667341912.6732 - val_loss: 1916322288.5114\n",
      "Epoch 1249/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1666955563.5851 - val_loss: 1915951020.7123\n",
      "Epoch 1250/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1666461266.1605 - val_loss: 1915510452.6027\n",
      "Epoch 1251/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1666400976.6575 - val_loss: 1914727956.7489\n",
      "Epoch 1252/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1665778325.7926 - val_loss: 1913947130.7397\n",
      "Epoch 1253/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1665879382.9198 - val_loss: 1913971705.8630\n",
      "Epoch 1254/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1665085429.9804 - val_loss: 1913572744.1826\n",
      "Epoch 1255/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1664604504.6732 - val_loss: 1912571543.9635\n",
      "Epoch 1256/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1664331844.6341 - val_loss: 1912033097.0594\n",
      "Epoch 1257/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1664551294.4971 - val_loss: 1910840795.7626\n",
      "Epoch 1258/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1664046573.7143 - val_loss: 1911132328.3288\n",
      "Epoch 1259/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1663753199.7182 - val_loss: 1909840073.0594\n",
      "Epoch 1260/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1663206761.3307 - val_loss: 1909223586.4840\n",
      "Epoch 1261/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1663397603.6947 - val_loss: 1909267758.4658\n",
      "Epoch 1262/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1662432457.8943 - val_loss: 1908197800.6210\n",
      "Epoch 1263/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1661807133.5577 - val_loss: 1907999127.3790\n",
      "Epoch 1264/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1661563186.8493 - val_loss: 1907298221.2968\n",
      "Epoch 1265/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1661222695.5773 - val_loss: 1906414214.4292\n",
      "Epoch 1266/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1660985783.7339 - val_loss: 1905854986.5205\n",
      "Epoch 1267/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1660484096.2505 - val_loss: 1905920424.0365\n",
      "Epoch 1268/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1660055653.9491 - val_loss: 1905294461.3699\n",
      "Epoch 1269/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1660074543.2172 - val_loss: 1904795901.3699\n",
      "Epoch 1270/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1660350640.0939 - val_loss: 1903346337.0228\n",
      "Epoch 1271/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1658898851.3190 - val_loss: 1903345600.0000\n",
      "Epoch 1272/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1658923290.6771 - val_loss: 1903319525.4064\n",
      "Epoch 1273/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1658396500.6654 - val_loss: 1902706015.5616\n",
      "Epoch 1274/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1658230751.4364 - val_loss: 1901974494.6849\n",
      "Epoch 1275/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1658124020.4775 - val_loss: 1901897799.0137\n",
      "Epoch 1276/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1657676148.9785 - val_loss: 1901048120.6941\n",
      "Epoch 1277/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1657016330.2701 - val_loss: 1899989074.7032\n",
      "Epoch 1278/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1656783500.7750 - val_loss: 1899350795.6895\n",
      "Epoch 1279/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1656302036.9159 - val_loss: 1899174692.2374\n",
      "Epoch 1280/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1656090126.7789 - val_loss: 1898643576.9863\n",
      "Epoch 1281/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1655677358.2153 - val_loss: 1897724786.8493\n",
      "Epoch 1282/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1655470351.5303 - val_loss: 1897640502.3562\n",
      "Epoch 1283/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1655088929.0646 - val_loss: 1896483976.7671\n",
      "Epoch 1284/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1654608524.2740 - val_loss: 1896089617.8265\n",
      "Epoch 1285/15000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1654481386.4579 - val_loss: 1896189194.8128\n",
      "Epoch 1286/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1654255560.2661 - val_loss: 1894873672.1826\n",
      "Epoch 1287/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1653569577.0802 - val_loss: 1894569456.8037\n",
      "Epoch 1288/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1653533006.1526 - val_loss: 1894086937.7169\n",
      "Epoch 1289/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1653106522.0509 - val_loss: 1893392838.7215\n",
      "Epoch 1290/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1652641885.8082 - val_loss: 1893043418.5936\n",
      "Epoch 1291/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1652893159.7025 - val_loss: 1893169272.6941\n",
      "Epoch 1292/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1652119433.6438 - val_loss: 1892218959.4886\n",
      "Epoch 1293/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1651584508.4932 - val_loss: 1891508835.9452\n",
      "Epoch 1294/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1651475280.5323 - val_loss: 1890647843.6530\n",
      "Epoch 1295/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 31us/step - loss: 1651019503.2172 - val_loss: 1890185590.9406\n",
      "Epoch 1296/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1650793506.0665 - val_loss: 1889649887.8539\n",
      "Epoch 1297/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1650860113.4090 - val_loss: 1889196031.7078\n",
      "Epoch 1298/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1650033110.6693 - val_loss: 1889013763.5068\n",
      "Epoch 1299/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1650075111.0763 - val_loss: 1888422141.9543\n",
      "Epoch 1300/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1649894550.6693 - val_loss: 1887442896.3653\n",
      "Epoch 1301/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1649077906.1605 - val_loss: 1887078319.0502\n",
      "Epoch 1302/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1648795288.7984 - val_loss: 1887143016.3288\n",
      "Epoch 1303/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1648497630.1840 - val_loss: 1886597010.9954\n",
      "Epoch 1304/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1648373286.3249 - val_loss: 1885759384.5479\n",
      "Epoch 1305/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1647759870.2466 - val_loss: 1885181293.8813\n",
      "Epoch 1306/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1647994730.2074 - val_loss: 1884057870.9041\n",
      "Epoch 1307/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1646976091.1781 - val_loss: 1884032874.3744\n",
      "Epoch 1308/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1646925513.8943 - val_loss: 1883561683.2877\n",
      "Epoch 1309/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1646627328.7515 - val_loss: 1882932653.0046\n",
      "Epoch 1310/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1646310482.6614 - val_loss: 1882401351.8904\n",
      "Epoch 1311/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1646409740.0235 - val_loss: 1882662256.8037\n",
      "Epoch 1312/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1646049883.4286 - val_loss: 1881022818.1918\n",
      "Epoch 1313/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1645410503.8904 - val_loss: 1880491981.7352\n",
      "Epoch 1314/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1644927369.7691 - val_loss: 1880178289.0959\n",
      "Epoch 1315/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1644521121.5656 - val_loss: 1879653123.7991\n",
      "Epoch 1316/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1644657031.2642 - val_loss: 1879300283.3242\n",
      "Epoch 1317/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1643931550.3092 - val_loss: 1879050413.5890\n",
      "Epoch 1318/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1643662571.4599 - val_loss: 1878331180.4201\n",
      "Epoch 1319/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1643457679.4051 - val_loss: 1877506575.4886\n",
      "Epoch 1320/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1643306387.5382 - val_loss: 1876830975.4155\n",
      "Epoch 1321/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1642747801.6751 - val_loss: 1876341424.8037\n",
      "Epoch 1322/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1642929390.5910 - val_loss: 1876535818.8128\n",
      "Epoch 1323/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1642464263.2642 - val_loss: 1875097741.4429\n",
      "Epoch 1324/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1641635319.6086 - val_loss: 1875241080.1096\n",
      "Epoch 1325/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1641639249.6595 - val_loss: 1875114488.1096\n",
      "Epoch 1326/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1641189614.3405 - val_loss: 1874391850.0822\n",
      "Epoch 1327/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1640862656.3757 - val_loss: 1873174096.3653\n",
      "Epoch 1328/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1640437841.1585 - val_loss: 1872795572.3105\n",
      "Epoch 1329/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1640444413.4951 - val_loss: 1872105220.6758\n",
      "Epoch 1330/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1639849549.4012 - val_loss: 1871665263.9269\n",
      "Epoch 1331/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1639635146.8963 - val_loss: 1871483451.9087\n",
      "Epoch 1332/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1639792595.9139 - val_loss: 1871673588.6027\n",
      "Epoch 1333/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1639732312.6732 - val_loss: 1870790365.8082\n",
      "Epoch 1334/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1639057163.5225 - val_loss: 1869292431.4886\n",
      "Epoch 1335/15000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1638248015.5303 - val_loss: 1869434841.7169\n",
      "Epoch 1336/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1638274039.4834 - val_loss: 1869132617.6438\n",
      "Epoch 1337/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1637949081.5499 - val_loss: 1868348303.4886\n",
      "Epoch 1338/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1637412776.8297 - val_loss: 1868254848.8767\n",
      "Epoch 1339/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1637435175.3268 - val_loss: 1867331466.2283\n",
      "Epoch 1340/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1636709864.0783 - val_loss: 1866911744.0000\n",
      "Epoch 1341/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1636648728.7984 - val_loss: 1866581846.5023\n",
      "Epoch 1342/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1637216124.9941 - val_loss: 1866160404.7489\n",
      "Epoch 1343/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1635927417.2368 - val_loss: 1865137549.7352\n",
      "Epoch 1344/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1636339492.8219 - val_loss: 1865143416.9863\n",
      "Epoch 1345/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1635192129.1272 - val_loss: 1864198919.8904\n",
      "Epoch 1346/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1635277573.0098 - val_loss: 1863679783.7443\n",
      "Epoch 1347/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1635069288.7045 - val_loss: 1863705587.4338\n",
      "Epoch 1348/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1634512110.8415 - val_loss: 1862928051.1416\n",
      "Epoch 1349/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1634220272.2192 - val_loss: 1861994593.8995\n",
      "Epoch 1350/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1634198257.4716 - val_loss: 1861767191.0868\n",
      "Epoch 1351/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1633563955.0998 - val_loss: 1861467160.5479\n",
      "Epoch 1352/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1633377311.5616 - val_loss: 1860431587.6530\n",
      "Epoch 1353/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1633203812.6967 - val_loss: 1860026756.6758\n",
      "Epoch 1354/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1632792949.7299 - val_loss: 1860241281.7534\n",
      "Epoch 1355/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1632740332.2114 - val_loss: 1858988631.9635\n",
      "Epoch 1356/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1633031980.7123 - val_loss: 1858756510.9772\n",
      "Epoch 1357/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1631829530.5519 - val_loss: 1858540486.7215\n",
      "Epoch 1358/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1631594001.7847 - val_loss: 1857960932.5297\n",
      "Epoch 1359/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 41us/step - loss: 1631465995.7730 - val_loss: 1857737751.0868\n",
      "Epoch 1360/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1631096873.4560 - val_loss: 1856955984.6575\n",
      "Epoch 1361/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1630606856.5166 - val_loss: 1856442606.4658\n",
      "Epoch 1362/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1630843085.4012 - val_loss: 1856328905.3516\n",
      "Epoch 1363/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1630020819.4129 - val_loss: 1855617182.3927\n",
      "Epoch 1364/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1629884093.1194 - val_loss: 1854933932.4201\n",
      "Epoch 1365/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1630322154.7084 - val_loss: 1855040137.0594\n",
      "Epoch 1366/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1629272816.3444 - val_loss: 1853656446.5388\n",
      "Epoch 1367/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1629119325.0568 - val_loss: 1853681065.7900\n",
      "Epoch 1368/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1628775444.2896 - val_loss: 1852917129.0594\n",
      "Epoch 1369/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1628430718.9980 - val_loss: 1852511707.4703\n",
      "Epoch 1370/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1628271163.7417 - val_loss: 1852365107.7260\n",
      "Epoch 1371/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1627948759.9217 - val_loss: 1851331854.6119\n",
      "Epoch 1372/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1627635213.2759 - val_loss: 1851214586.1553\n",
      "Epoch 1373/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1627348388.3209 - val_loss: 1850777638.5753\n",
      "Epoch 1374/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1627066554.3640 - val_loss: 1849831299.2146\n",
      "Epoch 1375/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1626917428.6027 - val_loss: 1849931000.4018\n",
      "Epoch 1376/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1626372194.0665 - val_loss: 1849162734.1735\n",
      "Epoch 1377/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1626271416.6106 - val_loss: 1848869593.7169\n",
      "Epoch 1378/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1626159455.4364 - val_loss: 1848625547.9817\n",
      "Epoch 1379/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1625872692.4775 - val_loss: 1847547693.8813\n",
      "Epoch 1380/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1625371901.1194 - val_loss: 1847261164.4201\n",
      "Epoch 1381/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1625865639.8278 - val_loss: 1846534297.7169\n",
      "Epoch 1382/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1625165021.1820 - val_loss: 1846921314.1918\n",
      "Epoch 1383/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1624457421.9022 - val_loss: 1846166682.5936\n",
      "Epoch 1384/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1624439522.1918 - val_loss: 1845569424.6575\n",
      "Epoch 1385/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1624531709.4951 - val_loss: 1844595560.9132\n",
      "Epoch 1386/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1623728621.9648 - val_loss: 1844737427.2877\n",
      "Epoch 1387/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1623469501.6204 - val_loss: 1844429370.4475\n",
      "Epoch 1388/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1623121024.7515 - val_loss: 1844041815.3790\n",
      "Epoch 1389/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1623314759.6399 - val_loss: 1842807332.2374\n",
      "Epoch 1390/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1622597931.8356 - val_loss: 1842722026.9589\n",
      "Epoch 1391/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1622363840.3757 - val_loss: 1842274510.0274\n",
      "Epoch 1392/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1621989634.8806 - val_loss: 1841837681.3881\n",
      "Epoch 1393/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1621676626.6614 - val_loss: 1841135137.6073\n",
      "Epoch 1394/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1621659570.5988 - val_loss: 1840648109.2968\n",
      "Epoch 1395/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1621085292.5871 - val_loss: 1840318791.0137\n",
      "Epoch 1396/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1621106762.1448 - val_loss: 1840026969.1324\n",
      "Epoch 1397/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1621231202.1918 - val_loss: 1839099598.9041\n",
      "Epoch 1398/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1620433993.6438 - val_loss: 1839101162.9589\n",
      "Epoch 1399/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1620538418.0978 - val_loss: 1838555444.6027\n",
      "Epoch 1400/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1620338574.2779 - val_loss: 1838797487.9269\n",
      "Epoch 1401/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1620165638.0117 - val_loss: 1838450524.0548\n",
      "Epoch 1402/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1619500598.1057 - val_loss: 1837144282.5936\n",
      "Epoch 1403/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1619437516.1487 - val_loss: 1836629370.7397\n",
      "Epoch 1404/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1618687662.8415 - val_loss: 1836347715.7991\n",
      "Epoch 1405/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1618742703.3425 - val_loss: 1835389702.7215\n",
      "Epoch 1406/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1618804210.3483 - val_loss: 1835777394.2648\n",
      "Epoch 1407/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1618800564.9785 - val_loss: 1834507849.9361\n",
      "Epoch 1408/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1617888563.4755 - val_loss: 1834433624.2557\n",
      "Epoch 1409/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1617417266.2231 - val_loss: 1833718689.0228\n",
      "Epoch 1410/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1617321164.7750 - val_loss: 1833388954.5936\n",
      "Epoch 1411/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1616953072.4697 - val_loss: 1833449219.5068\n",
      "Epoch 1412/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1617293135.4051 - val_loss: 1832068029.3699\n",
      "Epoch 1413/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1616437335.6712 - val_loss: 1832615239.8904\n",
      "Epoch 1414/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1616270221.2759 - val_loss: 1832147317.7717\n",
      "Epoch 1415/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1616475482.1761 - val_loss: 1831638393.8630\n",
      "Epoch 1416/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1615897487.2798 - val_loss: 1831015367.8904\n",
      "Epoch 1417/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1616334782.8728 - val_loss: 1830518266.4475\n",
      "Epoch 1418/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1615299016.2661 - val_loss: 1829693598.6849\n",
      "Epoch 1419/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1614823225.6125 - val_loss: 1829086380.1279\n",
      "Epoch 1420/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1615242335.1859 - val_loss: 1830068040.7671\n",
      "Epoch 1421/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1614113899.4599 - val_loss: 1829003136.5845\n",
      "Epoch 1422/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1614935641.4247 - val_loss: 1828989207.3790\n",
      "Epoch 1423/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 40us/step - loss: 1614182121.7065 - val_loss: 1827466423.2329\n",
      "Epoch 1424/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1613789805.0881 - val_loss: 1827502943.5616\n",
      "Epoch 1425/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1613304157.4325 - val_loss: 1826553115.7626\n",
      "Epoch 1426/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1613318132.9785 - val_loss: 1825745667.5068\n",
      "Epoch 1427/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1612702525.1194 - val_loss: 1825756978.8493\n",
      "Epoch 1428/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1613282709.5421 - val_loss: 1825864751.0502\n",
      "Epoch 1429/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1612246187.8356 - val_loss: 1825102151.5982\n",
      "Epoch 1430/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1612154943.3738 - val_loss: 1825227645.3699\n",
      "Epoch 1431/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1611879758.4031 - val_loss: 1824205914.0091\n",
      "Epoch 1432/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1611694370.3170 - val_loss: 1824218658.4840\n",
      "Epoch 1433/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1611573630.6223 - val_loss: 1823176932.8219\n",
      "Epoch 1434/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1611199334.1996 - val_loss: 1822960654.0274\n",
      "Epoch 1435/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1610961408.5010 - val_loss: 1822464749.5890\n",
      "Epoch 1436/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1611021681.5969 - val_loss: 1822009964.4201\n",
      "Epoch 1437/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1610868180.9159 - val_loss: 1821197844.1644\n",
      "Epoch 1438/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1610517123.1311 - val_loss: 1821188985.8630\n",
      "Epoch 1439/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1610048312.4853 - val_loss: 1820663689.9361\n",
      "Epoch 1440/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1609571522.8806 - val_loss: 1820588285.3699\n",
      "Epoch 1441/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1609959721.8317 - val_loss: 1819704054.3562\n",
      "Epoch 1442/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1609141087.5616 - val_loss: 1819702158.9041\n",
      "Epoch 1443/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1608773784.2975 - val_loss: 1819455388.3470\n",
      "Epoch 1444/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1609326586.9902 - val_loss: 1818296595.8721\n",
      "Epoch 1445/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1608923516.9941 - val_loss: 1818067283.8721\n",
      "Epoch 1446/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1608160556.4618 - val_loss: 1818198941.5160\n",
      "Epoch 1447/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1608112015.5303 - val_loss: 1817390641.9726\n",
      "Epoch 1448/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1607670685.3072 - val_loss: 1816791273.7900\n",
      "Epoch 1449/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1607232197.3855 - val_loss: 1816542634.3744\n",
      "Epoch 1450/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1607098508.0235 - val_loss: 1816202763.9817\n",
      "Epoch 1451/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1607061342.1840 - val_loss: 1815893328.6575\n",
      "Epoch 1452/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1606794241.7534 - val_loss: 1815326241.8995\n",
      "Epoch 1453/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1606609578.8337 - val_loss: 1815347765.4795\n",
      "Epoch 1454/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1606359352.9863 - val_loss: 1814089936.9498\n",
      "Epoch 1455/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1605954524.4305 - val_loss: 1813971698.2648\n",
      "Epoch 1456/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1605642509.0254 - val_loss: 1813700655.6347\n",
      "Epoch 1457/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1605556934.3875 - val_loss: 1812819388.4932\n",
      "Epoch 1458/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1605237478.9511 - val_loss: 1812798079.7078\n",
      "Epoch 1459/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1605149204.4149 - val_loss: 1812291842.3379\n",
      "Epoch 1460/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1604867758.0900 - val_loss: 1812241932.2740\n",
      "Epoch 1461/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1605692270.8415 - val_loss: 1812097527.8174\n",
      "Epoch 1462/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1604652635.0528 - val_loss: 1810800954.1553\n",
      "Epoch 1463/15000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1604174066.4736 - val_loss: 1810719408.2192\n",
      "Epoch 1464/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1603980160.5010 - val_loss: 1809951669.4795\n",
      "Epoch 1465/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1603497890.9432 - val_loss: 1810030354.7032\n",
      "Epoch 1466/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1603518172.6810 - val_loss: 1809561409.1689\n",
      "Epoch 1467/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1603082128.0313 - val_loss: 1808878509.2968\n",
      "Epoch 1468/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1602865516.2114 - val_loss: 1809028923.0320\n",
      "Epoch 1469/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1603039798.3562 - val_loss: 1807799687.3059\n",
      "Epoch 1470/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1602773716.5401 - val_loss: 1807638594.9224\n",
      "Epoch 1471/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1602076851.7260 - val_loss: 1807471836.0548\n",
      "Epoch 1472/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1601876958.4344 - val_loss: 1807169258.9589\n",
      "Epoch 1473/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1602108078.9667 - val_loss: 1806887567.1963\n",
      "Epoch 1474/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1601650924.4618 - val_loss: 1806376763.3242\n",
      "Epoch 1475/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1601204628.0391 - val_loss: 1805892613.8447\n",
      "Epoch 1476/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1600997895.5147 - val_loss: 1805247993.5708\n",
      "Epoch 1477/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1600785541.7613 - val_loss: 1804749281.6073\n",
      "Epoch 1478/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1600579294.3092 - val_loss: 1804987703.8174\n",
      "Epoch 1479/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1600186175.6243 - val_loss: 1804429406.3927\n",
      "Epoch 1480/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1600134915.7573 - val_loss: 1804064202.5205\n",
      "Epoch 1481/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1599901623.1076 - val_loss: 1803201791.7078\n",
      "Epoch 1482/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1599924182.4188 - val_loss: 1802672381.9543\n",
      "Epoch 1483/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1599367767.6712 - val_loss: 1802900254.9772\n",
      "Epoch 1484/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1599165724.9315 - val_loss: 1802493048.4018\n",
      "Epoch 1485/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1599510862.7789 - val_loss: 1801673798.7215\n",
      "Epoch 1486/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1598820276.6027 - val_loss: 1801680997.6986\n",
      "Epoch 1487/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 39us/step - loss: 1598393072.7202 - val_loss: 1800763467.1050\n",
      "Epoch 1488/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1598492616.1409 - val_loss: 1800104084.7489\n",
      "Epoch 1489/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1598366550.6693 - val_loss: 1800293036.1279\n",
      "Epoch 1490/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1597765309.6204 - val_loss: 1799704230.5753\n",
      "Epoch 1491/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1597677798.5753 - val_loss: 1799055466.6667\n",
      "Epoch 1492/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1597930779.8043 - val_loss: 1799190096.9498\n",
      "Epoch 1493/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1597081498.5519 - val_loss: 1798635378.5571\n",
      "Epoch 1494/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1596928111.9687 - val_loss: 1798213122.3379\n",
      "Epoch 1495/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1597041520.2192 - val_loss: 1798220795.0320\n",
      "Epoch 1496/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1596447589.6986 - val_loss: 1796866674.5571\n",
      "Epoch 1497/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1596023282.9119 - val_loss: 1796574980.9680\n",
      "Epoch 1498/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1595777643.9609 - val_loss: 1796234720.1461\n",
      "Epoch 1499/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1595576212.0391 - val_loss: 1795814409.9361\n",
      "Epoch 1500/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1596015878.1370 - val_loss: 1796074148.8219\n",
      "Epoch 1501/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1595251506.0978 - val_loss: 1795269510.7215\n",
      "Epoch 1502/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1595268504.7984 - val_loss: 1794319509.0411\n",
      "Epoch 1503/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1594690381.1507 - val_loss: 1794468649.4977\n",
      "Epoch 1504/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1595646606.7789 - val_loss: 1794995636.3105\n",
      "Epoch 1505/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1594046216.2661 - val_loss: 1793843210.5205\n",
      "Epoch 1506/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1594072313.4873 - val_loss: 1793556180.1644\n",
      "Epoch 1507/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1593989751.9843 - val_loss: 1792510755.3607\n",
      "Epoch 1508/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1594856759.3581 - val_loss: 1793396968.9132\n",
      "Epoch 1509/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1593354536.5793 - val_loss: 1791826674.2648\n",
      "Epoch 1510/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1593290674.8493 - val_loss: 1791209361.2420\n",
      "Epoch 1511/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1593757195.5225 - val_loss: 1791881329.3881\n",
      "Epoch 1512/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1593298825.7691 - val_loss: 1790278617.7169\n",
      "Epoch 1513/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1592439247.5303 - val_loss: 1789924329.4977\n",
      "Epoch 1514/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1592557552.4697 - val_loss: 1790447563.9817\n",
      "Epoch 1515/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1592268657.2211 - val_loss: 1790137138.2648\n",
      "Epoch 1516/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1591883892.9785 - val_loss: 1789136943.0502\n",
      "Epoch 1517/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1591735893.1663 - val_loss: 1789140660.6027\n",
      "Epoch 1518/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1592024530.1605 - val_loss: 1787935183.1963\n",
      "Epoch 1519/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1591154095.7182 - val_loss: 1787858447.1963\n",
      "Epoch 1520/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1590993344.1252 - val_loss: 1787634235.0320\n",
      "Epoch 1521/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1591214797.5264 - val_loss: 1787409538.0457\n",
      "Epoch 1522/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1590659153.1585 - val_loss: 1786677158.8676\n",
      "Epoch 1523/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1590298414.3405 - val_loss: 1786494811.7626\n",
      "Epoch 1524/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1590072544.3757 - val_loss: 1786280669.5160\n",
      "Epoch 1525/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1589890384.6575 - val_loss: 1785999869.6621\n",
      "Epoch 1526/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1589711289.1115 - val_loss: 1785568737.8995\n",
      "Epoch 1527/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1589791243.5225 - val_loss: 1785268814.6119\n",
      "Epoch 1528/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1589497720.2348 - val_loss: 1784963146.5205\n",
      "Epoch 1529/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1589363744.0626 - val_loss: 1784815282.5571\n",
      "Epoch 1530/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1589180603.1155 - val_loss: 1783887503.1963\n",
      "Epoch 1531/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1588862050.9432 - val_loss: 1783243797.9178\n",
      "Epoch 1532/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1588383744.5010 - val_loss: 1783251907.2146\n",
      "Epoch 1533/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1588415355.9295 - val_loss: 1782736423.4521\n",
      "Epoch 1534/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1588227315.7260 - val_loss: 1781942613.6256\n",
      "Epoch 1535/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1587850888.0157 - val_loss: 1782322761.3516\n",
      "Epoch 1536/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1587850127.3425 - val_loss: 1781452351.4155\n",
      "Epoch 1537/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1587516437.7926 - val_loss: 1781669989.4064\n",
      "Epoch 1538/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1587093665.5656 - val_loss: 1781145500.3470\n",
      "Epoch 1539/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1587679873.7534 - val_loss: 1780078012.2009\n",
      "Epoch 1540/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1588033260.4618 - val_loss: 1781072069.2603\n",
      "Epoch 1541/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1586692069.1977 - val_loss: 1780134623.2694\n",
      "Epoch 1542/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1587012899.8200 - val_loss: 1779593356.2740\n",
      "Epoch 1543/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1586208759.6086 - val_loss: 1779048284.3470\n",
      "Epoch 1544/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1586320339.4129 - val_loss: 1778654343.3059\n",
      "Epoch 1545/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1585794260.9159 - val_loss: 1778319584.7306\n",
      "Epoch 1546/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1585897545.2681 - val_loss: 1778728965.5525\n",
      "Epoch 1547/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1585346356.3523 - val_loss: 1778011514.4475\n",
      "Epoch 1548/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1585121880.6732 - val_loss: 1777021356.7123\n",
      "Epoch 1549/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1584839692.1487 - val_loss: 1776742125.5890\n",
      "Epoch 1550/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1584570915.8200 - val_loss: 1776832555.2511\n",
      "Epoch 1551/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 41us/step - loss: 1584896221.1820 - val_loss: 1776323229.2237\n",
      "Epoch 1552/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1585000098.5675 - val_loss: 1776469137.8265\n",
      "Epoch 1553/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1584353703.5773 - val_loss: 1775445857.6073\n",
      "Epoch 1554/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1583876924.7436 - val_loss: 1775406710.6484\n",
      "Epoch 1555/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1583822466.7554 - val_loss: 1775087018.9589\n",
      "Epoch 1556/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1584098028.9628 - val_loss: 1774600871.4521\n",
      "Epoch 1557/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1583412220.6184 - val_loss: 1773895146.9589\n",
      "Epoch 1558/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1583210680.6106 - val_loss: 1773650546.2648\n",
      "Epoch 1559/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1582924468.8532 - val_loss: 1773566612.1644\n",
      "Epoch 1560/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1582604064.8141 - val_loss: 1773371531.6895\n",
      "Epoch 1561/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1582473710.0900 - val_loss: 1772788221.9543\n",
      "Epoch 1562/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1582474678.9824 - val_loss: 1772076364.5662\n",
      "Epoch 1563/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1582144969.6438 - val_loss: 1772522865.3881\n",
      "Epoch 1564/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1581956113.2838 - val_loss: 1771404689.2420\n",
      "Epoch 1565/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1581849806.9041 - val_loss: 1771147389.3699\n",
      "Epoch 1566/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1581976066.8806 - val_loss: 1771164195.0685\n",
      "Epoch 1567/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1582029595.5538 - val_loss: 1771364062.1005\n",
      "Epoch 1568/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1581115215.9061 - val_loss: 1769808699.9087\n",
      "Epoch 1569/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1581065889.9413 - val_loss: 1770158443.2511\n",
      "Epoch 1570/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1580795281.5342 - val_loss: 1769300301.4429\n",
      "Epoch 1571/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1580728020.6654 - val_loss: 1768685686.0639\n",
      "Epoch 1572/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1580434724.0705 - val_loss: 1768369971.7260\n",
      "Epoch 1573/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1580178826.0196 - val_loss: 1768489893.9909\n",
      "Epoch 1574/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1580004075.2094 - val_loss: 1768665554.4110\n",
      "Epoch 1575/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1579825648.2192 - val_loss: 1767962792.3288\n",
      "Epoch 1576/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1579647164.1174 - val_loss: 1767387631.0502\n",
      "Epoch 1577/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1579977135.9687 - val_loss: 1767000092.3470\n",
      "Epoch 1578/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1579196964.6967 - val_loss: 1766627946.0822\n",
      "Epoch 1579/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1579050756.5088 - val_loss: 1766818747.0320\n",
      "Epoch 1580/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1579492910.5910 - val_loss: 1765495841.6073\n",
      "Epoch 1581/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1578747541.7926 - val_loss: 1765998961.3881\n",
      "Epoch 1582/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1578357428.6027 - val_loss: 1765515245.8813\n",
      "Epoch 1583/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1579228378.1761 - val_loss: 1764365556.6027\n",
      "Epoch 1584/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1577952638.6223 - val_loss: 1764817301.6256\n",
      "Epoch 1585/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1578145038.5284 - val_loss: 1763550250.9589\n",
      "Epoch 1586/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1577578665.8317 - val_loss: 1764026920.3288\n",
      "Epoch 1587/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1577401986.3170 - val_loss: 1763656960.5845\n",
      "Epoch 1588/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1577435659.2094 - val_loss: 1763922111.4155\n",
      "Epoch 1589/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1577039076.4462 - val_loss: 1763260615.5982\n",
      "Epoch 1590/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1577124915.0998 - val_loss: 1762598770.8493\n",
      "Epoch 1591/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1577098962.1605 - val_loss: 1761456045.2968\n",
      "Epoch 1592/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1576308119.5460 - val_loss: 1762146364.7854\n",
      "Epoch 1593/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1576403405.1507 - val_loss: 1761452222.2466\n",
      "Epoch 1594/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1576403854.0274 - val_loss: 1761038070.0639\n",
      "Epoch 1595/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1575769748.7906 - val_loss: 1760787487.2694\n",
      "Epoch 1596/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1575901521.1585 - val_loss: 1760693598.1005\n",
      "Epoch 1597/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1575605238.6067 - val_loss: 1760432454.4292\n",
      "Epoch 1598/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1575535005.8082 - val_loss: 1760340122.3014\n",
      "Epoch 1599/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1575234001.7847 - val_loss: 1759573907.8721\n",
      "Epoch 1600/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1575081541.1350 - val_loss: 1759011311.9269\n",
      "Epoch 1601/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1574980731.7417 - val_loss: 1758690873.8630\n",
      "Epoch 1602/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1574637127.6399 - val_loss: 1758231177.9361\n",
      "Epoch 1603/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1574890407.5773 - val_loss: 1757526231.9635\n",
      "Epoch 1604/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1574471006.6849 - val_loss: 1758119235.5068\n",
      "Epoch 1605/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1574380728.3601 - val_loss: 1757719745.1689\n",
      "Epoch 1606/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1573987543.1703 - val_loss: 1757346268.6393\n",
      "Epoch 1607/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1573676742.8885 - val_loss: 1757417822.6849\n",
      "Epoch 1608/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1573511689.5186 - val_loss: 1756886963.7260\n",
      "Epoch 1609/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1573317663.0607 - val_loss: 1756160906.2283\n",
      "Epoch 1610/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1574198999.9217 - val_loss: 1756589054.5388\n",
      "Epoch 1611/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1572854031.5303 - val_loss: 1755706320.9498\n",
      "Epoch 1612/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1573124957.4325 - val_loss: 1755299338.2283\n",
      "Epoch 1613/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1572503995.4912 - val_loss: 1755281880.8402\n",
      "Epoch 1614/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1572410566.3875 - val_loss: 1754728250.1553\n",
      "Epoch 1615/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 43us/step - loss: 1572327727.4677 - val_loss: 1754078357.0411\n",
      "Epoch 1616/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1572269516.7750 - val_loss: 1754379039.5616\n",
      "Epoch 1617/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1571984961.3777 - val_loss: 1754049715.1416\n",
      "Epoch 1618/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1572129264.0939 - val_loss: 1753254981.5525\n",
      "Epoch 1619/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1571563186.9746 - val_loss: 1753286450.5571\n",
      "Epoch 1620/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1571688386.8806 - val_loss: 1752492196.8219\n",
      "Epoch 1621/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1571050888.7671 - val_loss: 1752472126.2466\n",
      "Epoch 1622/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1571120864.5010 - val_loss: 1752584374.6484\n",
      "Epoch 1623/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1570860676.6341 - val_loss: 1752099637.4795\n",
      "Epoch 1624/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1570722623.7495 - val_loss: 1751594665.2055\n",
      "Epoch 1625/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1570940934.0117 - val_loss: 1751980631.3790\n",
      "Epoch 1626/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1570338395.6791 - val_loss: 1750820222.5388\n",
      "Epoch 1627/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1570398433.6908 - val_loss: 1750624734.1005\n",
      "Epoch 1628/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1570623916.5871 - val_loss: 1749779618.1918\n",
      "Epoch 1629/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1569671693.0254 - val_loss: 1749858443.1050\n",
      "Epoch 1630/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1569568052.1018 - val_loss: 1749747638.3562\n",
      "Epoch 1631/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1569477770.7710 - val_loss: 1749717369.2785\n",
      "Epoch 1632/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1569509150.5597 - val_loss: 1749622723.5068\n",
      "Epoch 1633/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1569988742.2622 - val_loss: 1748810732.4201\n",
      "Epoch 1634/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1569153675.6477 - val_loss: 1748420351.7078\n",
      "Epoch 1635/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1568603386.7397 - val_loss: 1748036955.4703\n",
      "Epoch 1636/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1568582346.6458 - val_loss: 1747775810.9224\n",
      "Epoch 1637/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1568842314.1448 - val_loss: 1747577622.5023\n",
      "Epoch 1638/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1568162634.5205 - val_loss: 1747527576.8402\n",
      "Epoch 1639/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1568080602.9276 - val_loss: 1746978709.3333\n",
      "Epoch 1640/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1568289720.6106 - val_loss: 1746241357.4429\n",
      "Epoch 1641/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1567671350.8571 - val_loss: 1746373604.2374\n",
      "Epoch 1642/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1567511325.4325 - val_loss: 1746249717.7717\n",
      "Epoch 1643/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1567289116.8063 - val_loss: 1745651290.0091\n",
      "Epoch 1644/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1567119704.4227 - val_loss: 1745428162.3379\n",
      "Epoch 1645/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1567079908.4462 - val_loss: 1745451373.0046\n",
      "Epoch 1646/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1566864855.1703 - val_loss: 1744333155.9452\n",
      "Epoch 1647/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1566759220.1018 - val_loss: 1744516211.4338\n",
      "Epoch 1648/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1566629083.9295 - val_loss: 1744058648.8402\n",
      "Epoch 1649/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1566901618.4736 - val_loss: 1743214451.4338\n",
      "Epoch 1650/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1566438093.5264 - val_loss: 1742693890.3379\n",
      "Epoch 1651/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1565908257.1272 - val_loss: 1742856502.0639\n",
      "Epoch 1652/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1565845217.9413 - val_loss: 1742507998.9772\n",
      "Epoch 1653/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1566030000.3444 - val_loss: 1742004164.0913\n",
      "Epoch 1654/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1565536010.0196 - val_loss: 1742761736.4749\n",
      "Epoch 1655/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1565394700.0235 - val_loss: 1741960536.8402\n",
      "Epoch 1656/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1564996959.5616 - val_loss: 1741808687.6347\n",
      "Epoch 1657/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1564902270.4971 - val_loss: 1741215944.4749\n",
      "Epoch 1658/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1564888847.5303 - val_loss: 1740430849.1689\n",
      "Epoch 1659/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1564921594.7397 - val_loss: 1741092630.2100\n",
      "Epoch 1660/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1565117597.8082 - val_loss: 1739916620.8584\n",
      "Epoch 1661/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1564405294.5910 - val_loss: 1740408271.7808\n",
      "Epoch 1662/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1564101884.9941 - val_loss: 1740460566.2100\n",
      "Epoch 1663/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1564188666.9902 - val_loss: 1739697515.5434\n",
      "Epoch 1664/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1563798307.0685 - val_loss: 1739336941.0046\n",
      "Epoch 1665/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1563704747.3346 - val_loss: 1739230810.5936\n",
      "Epoch 1666/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1564300596.9785 - val_loss: 1739100654.7580\n",
      "Epoch 1667/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1563367850.3327 - val_loss: 1738328302.4658\n",
      "Epoch 1668/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1563015320.5479 - val_loss: 1737803870.1005\n",
      "Epoch 1669/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1562853408.4384 - val_loss: 1737738460.3470\n",
      "Epoch 1670/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1562695911.2016 - val_loss: 1737177335.5251\n",
      "Epoch 1671/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1562499579.9922 - val_loss: 1737257650.8493\n",
      "Epoch 1672/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1562473967.0920 - val_loss: 1736774482.1187\n",
      "Epoch 1673/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1562556411.4912 - val_loss: 1736639389.8082\n",
      "Epoch 1674/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1561991088.8454 - val_loss: 1736387182.7580\n",
      "Epoch 1675/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1561868737.0020 - val_loss: 1736017334.3562\n",
      "Epoch 1676/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1561871265.8160 - val_loss: 1735236873.0594\n",
      "Epoch 1677/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1561726936.7984 - val_loss: 1735764939.3973\n",
      "Epoch 1678/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1561729343.2485 - val_loss: 1735273410.0457\n",
      "Epoch 1679/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1561802636.0235 - val_loss: 1734172740.6758\n",
      "Epoch 1680/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1561188575.9374 - val_loss: 1733943530.9589\n",
      "Epoch 1681/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1561063482.6145 - val_loss: 1734681412.3836\n",
      "Epoch 1682/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1560780110.0274 - val_loss: 1734404638.3927\n",
      "Epoch 1683/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1560443324.3679 - val_loss: 1733919018.9589\n",
      "Epoch 1684/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1560652230.8885 - val_loss: 1733591199.2694\n",
      "Epoch 1685/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1560496162.8180 - val_loss: 1732816153.1324\n",
      "Epoch 1686/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1560244836.6967 - val_loss: 1732406889.2055\n",
      "Epoch 1687/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1560030585.2368 - val_loss: 1732459481.7169\n",
      "Epoch 1688/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1559619343.5303 - val_loss: 1732012694.5023\n",
      "Epoch 1689/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1559582897.3464 - val_loss: 1731881188.2374\n",
      "Epoch 1690/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1559646848.2505 - val_loss: 1732042640.0731\n",
      "Epoch 1691/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1559233169.7847 - val_loss: 1731376301.0046\n",
      "Epoch 1692/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1559426522.9276 - val_loss: 1731076548.3836\n",
      "Epoch 1693/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1559289593.9883 - val_loss: 1730644650.9589\n",
      "Epoch 1694/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1558820163.3816 - val_loss: 1729749094.2831\n",
      "Epoch 1695/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1558918322.4736 - val_loss: 1729963152.3653\n",
      "Epoch 1696/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1558550064.4697 - val_loss: 1729846804.1644\n",
      "Epoch 1697/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1558194449.2838 - val_loss: 1729246895.3425\n",
      "Epoch 1698/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1558228024.7358 - val_loss: 1729141157.4064\n",
      "Epoch 1699/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1557923123.8513 - val_loss: 1728691831.8174\n",
      "Epoch 1700/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1557840302.5910 - val_loss: 1728137842.5571\n",
      "Epoch 1701/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1557822689.0646 - val_loss: 1728243834.4475\n",
      "Epoch 1702/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1557493055.8748 - val_loss: 1727879978.3744\n",
      "Epoch 1703/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1557248306.3483 - val_loss: 1727342136.9863\n",
      "Epoch 1704/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1557360469.4168 - val_loss: 1727402362.1553\n",
      "Epoch 1705/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1557129663.3738 - val_loss: 1726991800.4018\n",
      "Epoch 1706/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1556863026.8493 - val_loss: 1726918283.3973\n",
      "Epoch 1707/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1556752194.1292 - val_loss: 1726957946.7397\n",
      "Epoch 1708/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1557035151.4677 - val_loss: 1726388659.1416\n",
      "Epoch 1709/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1556572332.3366 - val_loss: 1725564487.0137\n",
      "Epoch 1710/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1556369327.2172 - val_loss: 1725774255.3425\n",
      "Epoch 1711/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1556581356.7123 - val_loss: 1724948771.0685\n",
      "Epoch 1712/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1555870052.4462 - val_loss: 1725160317.3699\n",
      "Epoch 1713/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1555846548.7906 - val_loss: 1725175409.3881\n",
      "Epoch 1714/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1555847698.5362 - val_loss: 1725402465.8995\n",
      "Epoch 1715/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1555477740.2114 - val_loss: 1724456263.3059\n",
      "Epoch 1716/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1555507754.8337 - val_loss: 1723624064.8767\n",
      "Epoch 1717/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1555461008.6575 - val_loss: 1723853628.7854\n",
      "Epoch 1718/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1555015843.9452 - val_loss: 1723668138.6667\n",
      "Epoch 1719/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1554888706.6301 - val_loss: 1723537678.0274\n",
      "Epoch 1720/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1555160527.0294 - val_loss: 1723105682.1187\n",
      "Epoch 1721/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1554711122.6614 - val_loss: 1722807736.1096\n",
      "Epoch 1722/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1554423986.1605 - val_loss: 1722323004.2009\n",
      "Epoch 1723/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1554651930.5519 - val_loss: 1721707147.3973\n",
      "Epoch 1724/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1554933341.4325 - val_loss: 1721003366.8676\n",
      "Epoch 1725/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1553824138.5205 - val_loss: 1721806814.6849\n",
      "Epoch 1726/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1553918311.7025 - val_loss: 1721981326.0274\n",
      "Epoch 1727/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1553834263.0450 - val_loss: 1721867040.4384\n",
      "Epoch 1728/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1553587531.0215 - val_loss: 1720823774.1005\n",
      "Epoch 1729/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1553213356.3366 - val_loss: 1720398370.4840\n",
      "Epoch 1730/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1553548472.8611 - val_loss: 1719895288.9863\n",
      "Epoch 1731/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1553710971.9922 - val_loss: 1720393391.6347\n",
      "Epoch 1732/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1552821356.5871 - val_loss: 1720017649.6804\n",
      "Epoch 1733/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1552562322.7867 - val_loss: 1719487633.2420\n",
      "Epoch 1734/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1552689986.2544 - val_loss: 1719059469.4429\n",
      "Epoch 1735/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1552604760.5479 - val_loss: 1718445181.3699\n",
      "Epoch 1736/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1552574260.2270 - val_loss: 1719069166.7580\n",
      "Epoch 1737/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1552523451.1155 - val_loss: 1718222222.3196\n",
      "Epoch 1738/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1552014527.3738 - val_loss: 1717947392.8767\n",
      "Epoch 1739/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1552246812.5558 - val_loss: 1718314240.5845\n",
      "Epoch 1740/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1551677241.3620 - val_loss: 1717376872.9132\n",
      "Epoch 1741/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1551505460.3523 - val_loss: 1716977576.0365\n",
      "Epoch 1742/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1551700872.7671 - val_loss: 1717598492.6393\n",
      "Epoch 1743/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 40us/step - loss: 1551417529.3620 - val_loss: 1716893549.5890\n",
      "Epoch 1744/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1551109032.3288 - val_loss: 1716612878.0274\n",
      "Epoch 1745/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1551119339.7104 - val_loss: 1715869867.5434\n",
      "Epoch 1746/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1550888526.0274 - val_loss: 1715453966.3196\n",
      "Epoch 1747/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1550743878.8885 - val_loss: 1715988165.2603\n",
      "Epoch 1748/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1550527901.4325 - val_loss: 1715321358.9041\n",
      "Epoch 1749/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1550383268.1957 - val_loss: 1715280277.9178\n",
      "Epoch 1750/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1550190050.4423 - val_loss: 1715018299.3242\n",
      "Epoch 1751/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1550203309.8395 - val_loss: 1715211262.8311\n",
      "Epoch 1752/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1549911460.0705 - val_loss: 1714763410.7032\n",
      "Epoch 1753/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1549745505.8160 - val_loss: 1714418551.8174\n",
      "Epoch 1754/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1549818486.1057 - val_loss: 1713847604.0183\n",
      "Epoch 1755/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1550101965.6517 - val_loss: 1713775860.3105\n",
      "Epoch 1756/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1549361544.7671 - val_loss: 1712975300.9680\n",
      "Epoch 1757/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1549510109.9335 - val_loss: 1712483988.4566\n",
      "Epoch 1758/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1548929111.2955 - val_loss: 1712971943.1598\n",
      "Epoch 1759/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1549244751.1546 - val_loss: 1713426494.2466\n",
      "Epoch 1760/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1548695897.2994 - val_loss: 1712700638.9772\n",
      "Epoch 1761/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1548663000.7358 - val_loss: 1712239995.9087\n",
      "Epoch 1762/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1548617792.6262 - val_loss: 1712232326.1370\n",
      "Epoch 1763/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1548584895.3738 - val_loss: 1712286139.3242\n",
      "Epoch 1764/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1548533950.6223 - val_loss: 1711041399.2329\n",
      "Epoch 1765/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1549256353.1898 - val_loss: 1711630419.8721\n",
      "Epoch 1766/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1548026007.2955 - val_loss: 1710471082.3744\n",
      "Epoch 1767/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1548289448.8297 - val_loss: 1710637247.4155\n",
      "Epoch 1768/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1547866385.5342 - val_loss: 1710682789.9909\n",
      "Epoch 1769/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1547539289.6751 - val_loss: 1710480294.5753\n",
      "Epoch 1770/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1547324328.0783 - val_loss: 1709543139.0685\n",
      "Epoch 1771/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1547526006.2309 - val_loss: 1709696935.1598\n",
      "Epoch 1772/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1547044088.2348 - val_loss: 1709199943.5982\n",
      "Epoch 1773/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1547181737.9569 - val_loss: 1709085917.2237\n",
      "Epoch 1774/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1546668957.3072 - val_loss: 1708772393.4977\n",
      "Epoch 1775/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1546950604.7750 - val_loss: 1708200300.4201\n",
      "Epoch 1776/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1546532858.6145 - val_loss: 1708556200.6210\n",
      "Epoch 1777/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1546471311.0294 - val_loss: 1708412375.6712\n",
      "Epoch 1778/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1546173609.0802 - val_loss: 1707833141.7717\n",
      "Epoch 1779/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1546069007.5303 - val_loss: 1707308811.3973\n",
      "Epoch 1780/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1546115383.3581 - val_loss: 1707663701.3333\n",
      "Epoch 1781/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1546852419.1311 - val_loss: 1706039751.0137\n",
      "Epoch 1782/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1545441765.9491 - val_loss: 1706711485.6621\n",
      "Epoch 1783/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1545529261.3386 - val_loss: 1706979723.9817\n",
      "Epoch 1784/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1545333105.4716 - val_loss: 1706423979.5434\n",
      "Epoch 1785/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1545335425.1272 - val_loss: 1706237718.2100\n",
      "Epoch 1786/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1545076403.7260 - val_loss: 1706159576.8402\n",
      "Epoch 1787/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1545034737.0959 - val_loss: 1705511969.6073\n",
      "Epoch 1788/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1545094631.2642 - val_loss: 1705276532.8950\n",
      "Epoch 1789/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1545006938.1761 - val_loss: 1705446373.1142\n",
      "Epoch 1790/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1544762726.1996 - val_loss: 1704981910.7945\n",
      "Epoch 1791/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1545005075.0372 - val_loss: 1703739770.7397\n",
      "Epoch 1792/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1544111261.6830 - val_loss: 1704260098.3379\n",
      "Epoch 1793/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1544548206.9667 - val_loss: 1704573773.4429\n",
      "Epoch 1794/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1544256766.2466 - val_loss: 1704542312.0365\n",
      "Epoch 1795/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1543885057.3777 - val_loss: 1703628314.3014\n",
      "Epoch 1796/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1543962349.7143 - val_loss: 1703286020.6758\n",
      "Epoch 1797/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1543676270.9667 - val_loss: 1703545674.2283\n",
      "Epoch 1798/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1543948445.0568 - val_loss: 1703766174.6849\n",
      "Epoch 1799/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1543690021.1350 - val_loss: 1702165184.5845\n",
      "Epoch 1800/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1543058223.0920 - val_loss: 1702410843.4703\n",
      "Epoch 1801/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1543057825.3151 - val_loss: 1702173411.6530\n",
      "Epoch 1802/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1543104570.7397 - val_loss: 1702318295.0868\n",
      "Epoch 1803/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1542785924.5088 - val_loss: 1702208488.9132\n",
      "Epoch 1804/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1542541364.6027 - val_loss: 1701738817.7534\n",
      "Epoch 1805/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1542822614.6693 - val_loss: 1700746584.5479\n",
      "Epoch 1806/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1542441220.0078 - val_loss: 1700832293.4064\n",
      "Epoch 1807/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 40us/step - loss: 1542439119.6556 - val_loss: 1700705463.2329\n",
      "Epoch 1808/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1542306786.1918 - val_loss: 1700246481.2420\n",
      "Epoch 1809/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1541935870.3718 - val_loss: 1700303357.9543\n",
      "Epoch 1810/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1541797264.7828 - val_loss: 1699883327.1233\n",
      "Epoch 1811/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1541819123.6008 - val_loss: 1699985451.2511\n",
      "Epoch 1812/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1542178515.6634 - val_loss: 1699387159.0868\n",
      "Epoch 1813/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1541931806.9354 - val_loss: 1699295630.6119\n",
      "Epoch 1814/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1541880335.7808 - val_loss: 1698488637.9543\n",
      "Epoch 1815/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1541193059.5695 - val_loss: 1699689440.7306\n",
      "Epoch 1816/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1541730204.4305 - val_loss: 1699653128.1826\n",
      "Epoch 1817/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1540978007.6712 - val_loss: 1698789479.1598\n",
      "Epoch 1818/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1541163560.3288 - val_loss: 1697694255.6347\n",
      "Epoch 1819/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1540565577.7691 - val_loss: 1697927910.2831\n",
      "Epoch 1820/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1540757226.9589 - val_loss: 1697529917.0776\n",
      "Epoch 1821/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1540447105.2524 - val_loss: 1697370473.2055\n",
      "Epoch 1822/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1540123758.2153 - val_loss: 1697760676.2374\n",
      "Epoch 1823/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1540377135.5930 - val_loss: 1696662113.0228\n",
      "Epoch 1824/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1540630510.8415 - val_loss: 1697379805.5160\n",
      "Epoch 1825/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1539896492.3366 - val_loss: 1697088842.8128\n",
      "Epoch 1826/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1540159094.2309 - val_loss: 1695768212.4566\n",
      "Epoch 1827/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1539803107.9452 - val_loss: 1696142222.9041\n",
      "Epoch 1828/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1539799310.2153 - val_loss: 1695754454.5023\n",
      "Epoch 1829/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1539335833.8004 - val_loss: 1695976854.2100\n",
      "Epoch 1830/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1539363276.3992 - val_loss: 1695319919.0502\n",
      "Epoch 1831/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1539347753.7065 - val_loss: 1695164908.1279\n",
      "Epoch 1832/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1539556172.6497 - val_loss: 1695368999.4521\n",
      "Epoch 1833/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1539613654.9198 - val_loss: 1693683664.3653\n",
      "Epoch 1834/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1538697420.1487 - val_loss: 1694514485.1872\n",
      "Epoch 1835/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1539476077.6517 - val_loss: 1693285861.4064\n",
      "Epoch 1836/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1538807700.2896 - val_loss: 1694276290.3379\n",
      "Epoch 1837/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1538467613.0568 - val_loss: 1694551254.2100\n",
      "Epoch 1838/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1538199337.5812 - val_loss: 1693651066.4475\n",
      "Epoch 1839/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1537935084.4618 - val_loss: 1693545159.5982\n",
      "Epoch 1840/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1538175433.9569 - val_loss: 1693377034.8128\n",
      "Epoch 1841/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1537893872.9706 - val_loss: 1692836924.4932\n",
      "Epoch 1842/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1537589430.2309 - val_loss: 1692727074.7763\n",
      "Epoch 1843/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1537908922.3640 - val_loss: 1692686269.6621\n",
      "Epoch 1844/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1537332228.0078 - val_loss: 1691991962.5936\n",
      "Epoch 1845/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1537330355.8513 - val_loss: 1691847938.3379\n",
      "Epoch 1846/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1537418892.5245 - val_loss: 1691619870.9772\n",
      "Epoch 1847/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1537615755.2720 - val_loss: 1690501923.6530\n",
      "Epoch 1848/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1536658735.9687 - val_loss: 1691305797.2603\n",
      "Epoch 1849/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1537183764.5401 - val_loss: 1691193999.4886\n",
      "Epoch 1850/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1536995554.4423 - val_loss: 1690663226.4475\n",
      "Epoch 1851/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1537270547.0372 - val_loss: 1692028058.5936\n",
      "Epoch 1852/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1536597837.6517 - val_loss: 1690759172.9680\n",
      "Epoch 1853/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1536421390.5284 - val_loss: 1690738828.2740\n",
      "Epoch 1854/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1536551940.0078 - val_loss: 1690819495.1598\n",
      "Epoch 1855/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1535962413.7143 - val_loss: 1689315019.9817\n",
      "Epoch 1856/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1536049129.4560 - val_loss: 1689533758.2466\n",
      "Epoch 1857/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1535906058.7710 - val_loss: 1689260321.3151\n",
      "Epoch 1858/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1535742849.7534 - val_loss: 1689500813.4429\n",
      "Epoch 1859/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1536739760.5949 - val_loss: 1688071757.1507\n",
      "Epoch 1860/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1535674389.6673 - val_loss: 1688970309.8447\n",
      "Epoch 1861/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1535202099.0998 - val_loss: 1688580929.1689\n",
      "Epoch 1862/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1535070545.6595 - val_loss: 1687891585.7534\n",
      "Epoch 1863/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1535486161.0333 - val_loss: 1688189956.3836\n",
      "Epoch 1864/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1534853593.1742 - val_loss: 1687893823.1233\n",
      "Epoch 1865/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1534792300.8376 - val_loss: 1687729279.1233\n",
      "Epoch 1866/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1534666649.6751 - val_loss: 1686834268.3470\n",
      "Epoch 1867/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1535198604.7750 - val_loss: 1686396923.9087\n",
      "Epoch 1868/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1535649636.4462 - val_loss: 1685927239.8904\n",
      "Epoch 1869/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1534925031.2016 - val_loss: 1685889118.3927\n",
      "Epoch 1870/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1533861475.9452 - val_loss: 1686495279.9269\n",
      "Epoch 1871/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 37us/step - loss: 1534436542.9980 - val_loss: 1685932302.6119\n",
      "Epoch 1872/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1533661919.5616 - val_loss: 1686267235.3607\n",
      "Epoch 1873/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1534098190.7162 - val_loss: 1685835230.1005\n",
      "Epoch 1874/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1533966345.3933 - val_loss: 1685615694.3196\n",
      "Epoch 1875/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1534146592.9393 - val_loss: 1684756282.1553\n",
      "Epoch 1876/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1533437451.6477 - val_loss: 1685583866.7397\n",
      "Epoch 1877/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1533318644.4775 - val_loss: 1685070395.6164\n",
      "Epoch 1878/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1533088832.1252 - val_loss: 1684594986.6667\n",
      "Epoch 1879/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1532894642.5988 - val_loss: 1684961199.3425\n",
      "Epoch 1880/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1532839070.5597 - val_loss: 1684050496.2922\n",
      "Epoch 1881/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1532622075.8669 - val_loss: 1684126533.8447\n",
      "Epoch 1882/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1532504763.1155 - val_loss: 1683810043.0320\n",
      "Epoch 1883/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1532627277.6517 - val_loss: 1683640527.1963\n",
      "Epoch 1884/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1532620034.5049 - val_loss: 1683131527.3059\n",
      "Epoch 1885/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1532267550.0587 - val_loss: 1682736353.0228\n",
      "Epoch 1886/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1532206507.4599 - val_loss: 1682955950.4658\n",
      "Epoch 1887/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1532260324.4462 - val_loss: 1683399067.7626\n",
      "Epoch 1888/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1532153633.8160 - val_loss: 1683401883.1781\n",
      "Epoch 1889/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1531643266.7554 - val_loss: 1682967832.8402\n",
      "Epoch 1890/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1532027967.7495 - val_loss: 1681939372.7123\n",
      "Epoch 1891/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1531825899.2094 - val_loss: 1682648078.6119\n",
      "Epoch 1892/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1531699173.4481 - val_loss: 1681494513.0959\n",
      "Epoch 1893/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1531065491.5382 - val_loss: 1681514964.4566\n",
      "Epoch 1894/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1531293340.6810 - val_loss: 1681256091.1781\n",
      "Epoch 1895/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1531032758.8571 - val_loss: 1680777571.0685\n",
      "Epoch 1896/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1530766080.8767 - val_loss: 1680949378.0457\n",
      "Epoch 1897/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1532461077.6673 - val_loss: 1679563238.8676\n",
      "Epoch 1898/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1531524344.6106 - val_loss: 1681290816.2922\n",
      "Epoch 1899/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1530470236.0548 - val_loss: 1680536165.6986\n",
      "Epoch 1900/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1530306222.7162 - val_loss: 1680225289.6438\n",
      "Epoch 1901/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1530186066.0352 - val_loss: 1680093019.7626\n",
      "Epoch 1902/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1530270713.2368 - val_loss: 1679309029.9909\n",
      "Epoch 1903/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1530011765.2290 - val_loss: 1679011030.7945\n",
      "Epoch 1904/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1530150481.7221 - val_loss: 1679211046.5753\n",
      "Epoch 1905/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1529852667.2407 - val_loss: 1679064350.3927\n",
      "Epoch 1906/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1529914133.9178 - val_loss: 1679305353.3516\n",
      "Epoch 1907/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1529461042.4736 - val_loss: 1678855125.3333\n",
      "Epoch 1908/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1529670281.0176 - val_loss: 1677914113.1689\n",
      "Epoch 1909/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1530387458.5049 - val_loss: 1678065445.1142\n",
      "Epoch 1910/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1529189890.7554 - val_loss: 1677973481.4977\n",
      "Epoch 1911/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1529024598.4188 - val_loss: 1677829433.5708\n",
      "Epoch 1912/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1528937798.8885 - val_loss: 1677572138.9589\n",
      "Epoch 1913/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1529041745.1585 - val_loss: 1677056786.1187\n",
      "Epoch 1914/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1528837631.4990 - val_loss: 1677101106.5571\n",
      "Epoch 1915/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1528606833.0959 - val_loss: 1677488072.7671\n",
      "Epoch 1916/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1528371858.1605 - val_loss: 1676734325.1872\n",
      "Epoch 1917/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1529008770.0039 - val_loss: 1677124379.1781\n",
      "Epoch 1918/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1529071756.7750 - val_loss: 1675460618.5205\n",
      "Epoch 1919/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1527975604.1018 - val_loss: 1676187854.9041\n",
      "Epoch 1920/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1528257455.2172 - val_loss: 1675474630.7215\n",
      "Epoch 1921/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1527895093.9178 - val_loss: 1676054051.6530\n",
      "Epoch 1922/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1527871381.6673 - val_loss: 1675409861.2603\n",
      "Epoch 1923/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1527641457.4716 - val_loss: 1675632996.8219\n",
      "Epoch 1924/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1527857938.5362 - val_loss: 1674586500.9680\n",
      "Epoch 1925/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1527376132.2583 - val_loss: 1674960208.3653\n",
      "Epoch 1926/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1527544489.5812 - val_loss: 1675244888.5479\n",
      "Epoch 1927/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1527129599.1233 - val_loss: 1674127349.1872\n",
      "Epoch 1928/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1527164113.9100 - val_loss: 1674628968.9132\n",
      "Epoch 1929/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1526940547.1311 - val_loss: 1674214062.4658\n",
      "Epoch 1930/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1526900844.2114 - val_loss: 1673430489.7169\n",
      "Epoch 1931/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1526816763.9922 - val_loss: 1673197094.2831\n",
      "Epoch 1932/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1527304279.2955 - val_loss: 1674006120.3288\n",
      "Epoch 1933/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1526491407.9061 - val_loss: 1672928199.8904\n",
      "Epoch 1934/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1526375896.1722 - val_loss: 1672724680.4749\n",
      "Epoch 1935/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 40us/step - loss: 1526381764.4462 - val_loss: 1673142011.6164\n",
      "Epoch 1936/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1526191687.6399 - val_loss: 1673289681.2420\n",
      "Epoch 1937/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1526481822.3092 - val_loss: 1671816005.5525\n",
      "Epoch 1938/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1526079174.7632 - val_loss: 1672650312.7671\n",
      "Epoch 1939/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1525637809.0959 - val_loss: 1672185421.4429\n",
      "Epoch 1940/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1526398119.8278 - val_loss: 1671546427.3242\n",
      "Epoch 1941/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1525608290.4423 - val_loss: 1671413928.0365\n",
      "Epoch 1942/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1525611698.5988 - val_loss: 1671700196.2374\n",
      "Epoch 1943/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1525312749.4638 - val_loss: 1671778256.0731\n",
      "Epoch 1944/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1525152561.7221 - val_loss: 1671157942.6484\n",
      "Epoch 1945/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1525518217.7691 - val_loss: 1671457716.6027\n",
      "Epoch 1946/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1525315042.3170 - val_loss: 1671371682.1918\n",
      "Epoch 1947/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1524648230.0744 - val_loss: 1670051882.9589\n",
      "Epoch 1948/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1524746898.0352 - val_loss: 1670479146.0822\n",
      "Epoch 1949/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1524504312.9863 - val_loss: 1669946597.9909\n",
      "Epoch 1950/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1524722038.4814 - val_loss: 1669461416.6210\n",
      "Epoch 1951/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1524859961.3620 - val_loss: 1668716983.5251\n",
      "Epoch 1952/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1524114262.4188 - val_loss: 1669372277.1872\n",
      "Epoch 1953/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1524060068.9472 - val_loss: 1669423577.4247\n",
      "Epoch 1954/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1523954520.9237 - val_loss: 1669217860.0913\n",
      "Epoch 1955/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1524030280.3914 - val_loss: 1668991229.0776\n",
      "Epoch 1956/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1523736692.8532 - val_loss: 1668774892.1279\n",
      "Epoch 1957/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1523552682.0822 - val_loss: 1668479555.7991\n",
      "Epoch 1958/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1523801718.7319 - val_loss: 1667494524.2009\n",
      "Epoch 1959/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1523629571.5068 - val_loss: 1668689863.5982\n",
      "Epoch 1960/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1523240394.7710 - val_loss: 1667822614.2100\n",
      "Epoch 1961/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1523465706.9589 - val_loss: 1667463110.7215\n",
      "Epoch 1962/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1523326187.4599 - val_loss: 1667117003.1050\n",
      "Epoch 1963/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1524483362.9432 - val_loss: 1667678468.3836\n",
      "Epoch 1964/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1523298422.8571 - val_loss: 1667256207.7808\n",
      "Epoch 1965/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1522852965.3229 - val_loss: 1666822598.4292\n",
      "Epoch 1966/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1522802096.0939 - val_loss: 1667097000.0365\n",
      "Epoch 1967/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1522488752.8454 - val_loss: 1665819915.3973\n",
      "Epoch 1968/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1522453621.7299 - val_loss: 1666218969.1324\n",
      "Epoch 1969/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1522337517.7143 - val_loss: 1666200099.3607\n",
      "Epoch 1970/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1523000649.8943 - val_loss: 1664992278.5023\n",
      "Epoch 1971/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1522777141.5421 - val_loss: 1665675190.0639\n",
      "Epoch 1972/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1521948239.7808 - val_loss: 1665760446.2466\n",
      "Epoch 1973/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1522022872.2348 - val_loss: 1664853500.4932\n",
      "Epoch 1974/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1521864077.0254 - val_loss: 1664549473.0228\n",
      "Epoch 1975/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1521803077.8865 - val_loss: 1665686272.2922\n",
      "Epoch 1976/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1522137054.3718 - val_loss: 1663816020.7489\n",
      "Epoch 1977/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1521195316.1018 - val_loss: 1664313766.2831\n",
      "Epoch 1978/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1521147805.5577 - val_loss: 1664580857.2785\n",
      "Epoch 1979/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1521210226.9746 - val_loss: 1664686874.0091\n",
      "Epoch 1980/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1521510541.5264 - val_loss: 1664475719.0137\n",
      "Epoch 1981/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1521407580.6810 - val_loss: 1663173543.7443\n",
      "Epoch 1982/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1520829647.6556 - val_loss: 1663965494.0639\n",
      "Epoch 1983/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1521467840.2505 - val_loss: 1663106441.9361\n",
      "Epoch 1984/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1520584874.8337 - val_loss: 1663705091.7991\n",
      "Epoch 1985/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1520543506.7867 - val_loss: 1663355084.2740\n",
      "Epoch 1986/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1520274811.9922 - val_loss: 1662670347.3973\n",
      "Epoch 1987/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1520730561.3777 - val_loss: 1661912250.7397\n",
      "Epoch 1988/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1520363787.8982 - val_loss: 1662686464.0000\n",
      "Epoch 1989/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1520279892.2896 - val_loss: 1662369296.3653\n",
      "Epoch 1990/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1519934296.2975 - val_loss: 1662361998.6119\n",
      "Epoch 1991/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1520118892.9628 - val_loss: 1662634992.5114\n",
      "Epoch 1992/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1520019859.9139 - val_loss: 1662605055.7078\n",
      "Epoch 1993/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1519591828.1644 - val_loss: 1661733625.2785\n",
      "Epoch 1994/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1519495845.5734 - val_loss: 1661169486.9041\n",
      "Epoch 1995/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1519533239.9843 - val_loss: 1660414161.2420\n",
      "Epoch 1996/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1519356783.4677 - val_loss: 1661152915.2877\n",
      "Epoch 1997/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1518988008.4540 - val_loss: 1660667519.1233\n",
      "Epoch 1998/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1519844845.5890 - val_loss: 1660804539.9087\n",
      "Epoch 1999/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 41us/step - loss: 1519143339.0841 - val_loss: 1659799973.4064\n",
      "Epoch 2000/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1519006010.1135 - val_loss: 1659998615.3790\n",
      "Epoch 2001/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1518810173.6204 - val_loss: 1659504168.3288\n",
      "Epoch 2002/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1518933607.0763 - val_loss: 1660209003.8356\n",
      "Epoch 2003/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1518609031.7025 - val_loss: 1659994770.1187\n",
      "Epoch 2004/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1518882114.1292 - val_loss: 1659608651.6895\n",
      "Epoch 2005/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1518794831.2798 - val_loss: 1658952410.0091\n",
      "Epoch 2006/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1518127312.1566 - val_loss: 1659125202.9954\n",
      "Epoch 2007/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1518159916.5871 - val_loss: 1659237782.7945\n",
      "Epoch 2008/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1518318598.5127 - val_loss: 1659264318.5388\n",
      "Epoch 2009/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1518111692.3992 - val_loss: 1658969556.4566\n",
      "Epoch 2010/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1518069469.8082 - val_loss: 1657708123.4703\n",
      "Epoch 2011/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1518239957.6673 - val_loss: 1657305322.6667\n",
      "Epoch 2012/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1517545786.8650 - val_loss: 1657707137.1689\n",
      "Epoch 2013/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1517525558.2309 - val_loss: 1658308037.8447\n",
      "Epoch 2014/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1517865336.9863 - val_loss: 1658918351.4886\n",
      "Epoch 2015/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1517243468.6497 - val_loss: 1657905511.4521\n",
      "Epoch 2016/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1517252495.2798 - val_loss: 1657764628.7489\n",
      "Epoch 2017/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1517030599.8904 - val_loss: 1656826795.5434\n",
      "Epoch 2018/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1517191307.0215 - val_loss: 1656469045.7717\n",
      "Epoch 2019/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1516914449.2838 - val_loss: 1656676977.6804\n",
      "Epoch 2020/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1517477512.0157 - val_loss: 1657746159.9269\n",
      "Epoch 2021/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1516770337.3151 - val_loss: 1656076974.1735\n",
      "Epoch 2022/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1516760901.2603 - val_loss: 1656312199.3059\n",
      "Epoch 2023/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1516359622.3875 - val_loss: 1656250932.6027\n",
      "Epoch 2024/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1516718521.3620 - val_loss: 1655922341.9909\n",
      "Epoch 2025/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1516654791.1389 - val_loss: 1656294099.2877\n",
      "Epoch 2026/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1516287802.6145 - val_loss: 1655219392.8767\n",
      "Epoch 2027/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1516342491.9295 - val_loss: 1655626145.3151\n",
      "Epoch 2028/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1516012634.6771 - val_loss: 1654630531.2146\n",
      "Epoch 2029/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1515574922.5205 - val_loss: 1654991830.7945\n",
      "Epoch 2030/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1515752685.2133 - val_loss: 1654545576.9132\n",
      "Epoch 2031/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1515436056.5479 - val_loss: 1654709987.3607\n",
      "Epoch 2032/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1515939813.4481 - val_loss: 1654850415.3425\n",
      "Epoch 2033/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1515558936.3601 - val_loss: 1654078916.3836\n",
      "Epoch 2034/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1515330464.4384 - val_loss: 1654002683.0320\n",
      "Epoch 2035/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1515102802.9119 - val_loss: 1654098321.8265\n",
      "Epoch 2036/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1515170012.6810 - val_loss: 1654574322.5571\n",
      "Epoch 2037/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1514993681.4716 - val_loss: 1653121168.6575\n",
      "Epoch 2038/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1515160160.8141 - val_loss: 1653591494.7215\n",
      "Epoch 2039/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1514929456.9706 - val_loss: 1653419999.5616\n",
      "Epoch 2040/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1515069949.4951 - val_loss: 1653944039.4521\n",
      "Epoch 2041/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1514420084.2270 - val_loss: 1652901437.6621\n",
      "Epoch 2042/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1515016640.8767 - val_loss: 1652368191.7078\n",
      "Epoch 2043/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1514603146.7710 - val_loss: 1652874721.8995\n",
      "Epoch 2044/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1514697957.9491 - val_loss: 1652477479.1598\n",
      "Epoch 2045/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1514376705.5029 - val_loss: 1652180801.7534\n",
      "Epoch 2046/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1514369491.6634 - val_loss: 1652754007.3790\n",
      "Epoch 2047/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1513889754.8023 - val_loss: 1651948872.4749\n",
      "Epoch 2048/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1514162626.5049 - val_loss: 1652127721.7900\n",
      "Epoch 2049/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1514870957.3386 - val_loss: 1650709364.8950\n",
      "Epoch 2050/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1513930700.3992 - val_loss: 1651187735.6712\n",
      "Epoch 2051/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1513763136.0000 - val_loss: 1650583833.1324\n",
      "Epoch 2052/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1513242642.0352 - val_loss: 1650720095.2694\n",
      "Epoch 2053/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1513409085.4951 - val_loss: 1651319260.6393\n",
      "Epoch 2054/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1513198493.5577 - val_loss: 1651184552.6210\n",
      "Epoch 2055/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1513229473.1898 - val_loss: 1651178988.4201\n",
      "Epoch 2056/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1513345254.7006 - val_loss: 1650684385.3151\n",
      "Epoch 2057/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1512792069.7613 - val_loss: 1650176331.1050\n",
      "Epoch 2058/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1512937693.4325 - val_loss: 1649317004.2740\n",
      "Epoch 2059/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1512701060.0078 - val_loss: 1650058814.8311\n",
      "Epoch 2060/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1512752771.5068 - val_loss: 1649837407.5616\n",
      "Epoch 2061/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1512699431.0763 - val_loss: 1649146139.7626\n",
      "Epoch 2062/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1512304187.8669 - val_loss: 1649668900.5297\n",
      "Epoch 2063/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 32us/step - loss: 1512257984.5010 - val_loss: 1649396407.8174\n",
      "Epoch 2064/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1512456545.2524 - val_loss: 1649628065.0228\n",
      "Epoch 2065/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1512012712.3288 - val_loss: 1649007434.2283\n",
      "Epoch 2066/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1512035190.2309 - val_loss: 1648323396.0913\n",
      "Epoch 2067/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1512450945.7534 - val_loss: 1648519471.9269\n",
      "Epoch 2068/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1511804183.3581 - val_loss: 1648686904.1096\n",
      "Epoch 2069/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1512205088.3131 - val_loss: 1648166290.1187\n",
      "Epoch 2070/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1512116798.3718 - val_loss: 1648846515.4338\n",
      "Epoch 2071/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1511564639.4364 - val_loss: 1648080418.7763\n",
      "Epoch 2072/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1511434356.9785 - val_loss: 1648098786.7763\n",
      "Epoch 2073/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1511560268.9002 - val_loss: 1647400580.0913\n",
      "Epoch 2074/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1511305966.9667 - val_loss: 1647643593.3516\n",
      "Epoch 2075/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1511197168.2192 - val_loss: 1647097761.0228\n",
      "Epoch 2076/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1511124966.7006 - val_loss: 1646986955.9817\n",
      "Epoch 2077/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1510806699.2094 - val_loss: 1646848295.4521\n",
      "Epoch 2078/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1510964709.9491 - val_loss: 1646069443.5068\n",
      "Epoch 2079/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1510720192.1252 - val_loss: 1646667421.5160\n",
      "Epoch 2080/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1511002816.3757 - val_loss: 1646486680.8402\n",
      "Epoch 2081/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1510790381.3386 - val_loss: 1645926110.3927\n",
      "Epoch 2082/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1510277179.1155 - val_loss: 1646384493.0046\n",
      "Epoch 2083/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1510209629.4325 - val_loss: 1646144895.1233\n",
      "Epoch 2084/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1510424616.5793 - val_loss: 1645771784.1826\n",
      "Epoch 2085/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1510114981.3229 - val_loss: 1646224062.8311\n",
      "Epoch 2086/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1510019247.0920 - val_loss: 1645518755.0685\n",
      "Epoch 2087/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1509987361.8160 - val_loss: 1645596577.6073\n",
      "Epoch 2088/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1509941654.2935 - val_loss: 1645773838.9041\n",
      "Epoch 2089/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1510543357.4951 - val_loss: 1644753984.2922\n",
      "Epoch 2090/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1509739645.2446 - val_loss: 1644957172.3105\n",
      "Epoch 2091/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1509636610.2544 - val_loss: 1645057971.7260\n",
      "Epoch 2092/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1509390720.2505 - val_loss: 1644408601.7169\n",
      "Epoch 2093/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1509482738.4736 - val_loss: 1644360877.0046\n",
      "Epoch 2094/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1509284384.5636 - val_loss: 1644427352.8402\n",
      "Epoch 2095/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1509422854.8885 - val_loss: 1643596855.8174\n",
      "Epoch 2096/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1509184898.2544 - val_loss: 1644311248.6575\n",
      "Epoch 2097/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1508916779.5851 - val_loss: 1643799205.1142\n",
      "Epoch 2098/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1508803631.2172 - val_loss: 1643626756.9680\n",
      "Epoch 2099/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1508728382.1213 - val_loss: 1643645254.1370\n",
      "Epoch 2100/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1509173963.1468 - val_loss: 1642661682.8493\n",
      "Epoch 2101/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1508657188.8219 - val_loss: 1642333866.9589\n",
      "Epoch 2102/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1508431913.8317 - val_loss: 1643137640.9132\n",
      "Epoch 2103/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1508354701.9022 - val_loss: 1642402015.8539\n",
      "Epoch 2104/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1508660390.3249 - val_loss: 1643134340.0913\n",
      "Epoch 2105/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1508276823.1703 - val_loss: 1642572015.6347\n",
      "Epoch 2106/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1508289469.6204 - val_loss: 1642536647.5982\n",
      "Epoch 2107/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1508013603.5695 - val_loss: 1642111575.0868\n",
      "Epoch 2108/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1508596255.8121 - val_loss: 1642909056.8767\n",
      "Epoch 2109/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1507949977.9256 - val_loss: 1641429074.9954\n",
      "Epoch 2110/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1507678819.8200 - val_loss: 1641355712.8767\n",
      "Epoch 2111/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1507878505.0802 - val_loss: 1641162531.3607\n",
      "Epoch 2112/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1507428908.8376 - val_loss: 1641120366.4658\n",
      "Epoch 2113/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1507690526.0587 - val_loss: 1641036663.5251\n",
      "Epoch 2114/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1507323736.1722 - val_loss: 1641030880.4384\n",
      "Epoch 2115/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1507146775.1703 - val_loss: 1640727583.5616\n",
      "Epoch 2116/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1507551615.2485 - val_loss: 1639951660.4201\n",
      "Epoch 2117/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1506896561.8474 - val_loss: 1640779220.4566\n",
      "Epoch 2118/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1507262511.0920 - val_loss: 1640052840.0365\n",
      "Epoch 2119/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1506743229.3699 - val_loss: 1640118303.2694\n",
      "Epoch 2120/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1506935567.5303 - val_loss: 1640417266.2648\n",
      "Epoch 2121/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1507168620.4618 - val_loss: 1640605219.3607\n",
      "Epoch 2122/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1506610645.4168 - val_loss: 1640307198.8311\n",
      "Epoch 2123/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1506468485.2603 - val_loss: 1639554434.9224\n",
      "Epoch 2124/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1506880896.0000 - val_loss: 1639994219.5434\n",
      "Epoch 2125/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1506244685.6517 - val_loss: 1639264139.9817\n",
      "Epoch 2126/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1506345687.1703 - val_loss: 1638791302.4292\n",
      "Epoch 2127/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 29us/step - loss: 1506195688.9550 - val_loss: 1639293170.8493\n",
      "Epoch 2128/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1506165812.1018 - val_loss: 1639558860.8584\n",
      "Epoch 2129/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1506470598.2622 - val_loss: 1638908599.2329\n",
      "Epoch 2130/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1505814258.9746 - val_loss: 1638396763.7626\n",
      "Epoch 2131/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1506119128.9237 - val_loss: 1638783429.2603\n",
      "Epoch 2132/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1506008424.5793 - val_loss: 1638008344.8402\n",
      "Epoch 2133/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1506083826.0978 - val_loss: 1637532788.3105\n",
      "Epoch 2134/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1505559915.9609 - val_loss: 1638053336.2557\n",
      "Epoch 2135/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1505662752.8141 - val_loss: 1638275970.9224\n",
      "Epoch 2136/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1505370299.1155 - val_loss: 1637862750.3927\n",
      "Epoch 2137/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1505377033.5186 - val_loss: 1637889851.9087\n",
      "Epoch 2138/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1505292436.0391 - val_loss: 1636812174.6119\n",
      "Epoch 2139/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1505844482.1292 - val_loss: 1638078579.4338\n",
      "Epoch 2140/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1504763195.6164 - val_loss: 1637417184.1461\n",
      "Epoch 2141/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1505120623.2798 - val_loss: 1636199621.5525\n",
      "Epoch 2142/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1505013207.7965 - val_loss: 1637318689.0228\n",
      "Epoch 2143/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1505087725.5890 - val_loss: 1636058235.0320\n",
      "Epoch 2144/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1504692474.3640 - val_loss: 1636627287.3790\n",
      "Epoch 2145/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1504907910.8885 - val_loss: 1635972747.1050\n",
      "Epoch 2146/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1504523945.5812 - val_loss: 1636427274.2283\n",
      "Epoch 2147/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1504452123.4286 - val_loss: 1635791374.9041\n",
      "Epoch 2148/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1504255940.1331 - val_loss: 1635960232.3288\n",
      "Epoch 2149/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1504131858.7867 - val_loss: 1635574939.7626\n",
      "Epoch 2150/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1504335716.8219 - val_loss: 1635245346.7763\n",
      "Epoch 2151/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1504451338.5205 - val_loss: 1636269412.5297\n",
      "Epoch 2152/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1503753605.7613 - val_loss: 1635921696.7306\n",
      "Epoch 2153/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1505030347.3973 - val_loss: 1634713986.9224\n",
      "Epoch 2154/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1504357226.5832 - val_loss: 1635762713.4247\n",
      "Epoch 2155/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1504590132.8532 - val_loss: 1634419488.4384\n",
      "Epoch 2156/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1503960955.9922 - val_loss: 1634379028.7489\n",
      "Epoch 2157/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1503268390.5753 - val_loss: 1634811043.0685\n",
      "Epoch 2158/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1503428545.3777 - val_loss: 1635302905.5708\n",
      "Epoch 2159/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1504272173.0881 - val_loss: 1635898289.3881\n",
      "Epoch 2160/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1503392874.7084 - val_loss: 1634392979.5799\n",
      "Epoch 2161/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1503268217.7378 - val_loss: 1634088116.8950\n",
      "Epoch 2162/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1503680813.3386 - val_loss: 1634523368.3288\n",
      "Epoch 2163/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1503033781.1037 - val_loss: 1633864890.1553\n",
      "Epoch 2164/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1503034916.8219 - val_loss: 1633951477.4795\n",
      "Epoch 2165/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1502833027.2564 - val_loss: 1632978620.4932\n",
      "Epoch 2166/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1502462340.0078 - val_loss: 1632916372.1644\n",
      "Epoch 2167/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1502481558.7945 - val_loss: 1632814906.1553\n",
      "Epoch 2168/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1502425858.0039 - val_loss: 1632514890.8128\n",
      "Epoch 2169/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1502231970.3170 - val_loss: 1632571154.1187\n",
      "Epoch 2170/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1502155015.8904 - val_loss: 1632561826.7763\n",
      "Epoch 2171/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1501970093.5890 - val_loss: 1632567801.5708\n",
      "Epoch 2172/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1501919716.3209 - val_loss: 1632471892.4566\n",
      "Epoch 2173/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1501946901.5421 - val_loss: 1632333560.6941\n",
      "Epoch 2174/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1502126595.7573 - val_loss: 1632012086.9406\n",
      "Epoch 2175/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1501624017.1585 - val_loss: 1631983808.0000\n",
      "Epoch 2176/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1501702765.2133 - val_loss: 1631630456.1096\n",
      "Epoch 2177/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1501599931.8669 - val_loss: 1632015452.3470\n",
      "Epoch 2178/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1501415431.5147 - val_loss: 1631902781.3699\n",
      "Epoch 2179/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1501667153.4090 - val_loss: 1631061465.1324\n",
      "Epoch 2180/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1501665756.6810 - val_loss: 1631251609.7169\n",
      "Epoch 2181/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1501151944.8924 - val_loss: 1631135226.4475\n",
      "Epoch 2182/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1501542923.8982 - val_loss: 1630392493.0046\n",
      "Epoch 2183/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1501363353.2994 - val_loss: 1630735803.9087\n",
      "Epoch 2184/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1501201548.3992 - val_loss: 1630112913.5342\n",
      "Epoch 2185/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1500681346.3796 - val_loss: 1630653725.2237\n",
      "Epoch 2186/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1500842806.1057 - val_loss: 1630301852.9315\n",
      "Epoch 2187/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1500585117.8082 - val_loss: 1630436231.8904\n",
      "Epoch 2188/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1500708855.9843 - val_loss: 1630688906.8128\n",
      "Epoch 2189/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1500554293.3542 - val_loss: 1629669042.5571\n",
      "Epoch 2190/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1500388327.9530 - val_loss: 1629310288.9498\n",
      "Epoch 2191/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 29us/step - loss: 1500254614.9198 - val_loss: 1629938392.5479\n",
      "Epoch 2192/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1500176400.5323 - val_loss: 1629867657.9361\n",
      "Epoch 2193/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1500554833.5342 - val_loss: 1629256978.4110\n",
      "Epoch 2194/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1500381702.1996 - val_loss: 1628925868.7123\n",
      "Epoch 2195/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1500363215.9061 - val_loss: 1630033438.1005\n",
      "Epoch 2196/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1500062626.5675 - val_loss: 1629091343.4886\n",
      "Epoch 2197/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1499833378.3170 - val_loss: 1629028694.5023\n",
      "Epoch 2198/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1499579607.0450 - val_loss: 1628522735.3425\n",
      "Epoch 2199/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1499533331.2877 - val_loss: 1628807925.1872\n",
      "Epoch 2200/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1499494244.3209 - val_loss: 1628748258.7763\n",
      "Epoch 2201/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1499638710.6067 - val_loss: 1628069872.8037\n",
      "Epoch 2202/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1499407789.2133 - val_loss: 1628180302.9041\n",
      "Epoch 2203/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1499215533.3386 - val_loss: 1627443616.1461\n",
      "Epoch 2204/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1499005950.1213 - val_loss: 1627639060.1644\n",
      "Epoch 2205/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1499509771.0215 - val_loss: 1627235650.0457\n",
      "Epoch 2206/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1499283658.3953 - val_loss: 1627803391.1233\n",
      "Epoch 2207/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1499578137.2994 - val_loss: 1627788366.3196\n",
      "Epoch 2208/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1499025247.9374 - val_loss: 1627055871.4155\n",
      "Epoch 2209/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1498674366.6223 - val_loss: 1627356679.5982\n",
      "Epoch 2210/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1498598443.5851 - val_loss: 1627313097.3516\n",
      "Epoch 2211/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1498534274.0039 - val_loss: 1626854751.5616\n",
      "Epoch 2212/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1498337123.1937 - val_loss: 1626961381.4064\n",
      "Epoch 2213/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1498389836.3992 - val_loss: 1626278944.1461\n",
      "Epoch 2214/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1498550319.3425 - val_loss: 1626456788.4566\n",
      "Epoch 2215/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1498195957.9804 - val_loss: 1625697153.1689\n",
      "Epoch 2216/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1497989029.3229 - val_loss: 1625774831.3425\n",
      "Epoch 2217/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1498145017.2368 - val_loss: 1625315460.0913\n",
      "Epoch 2218/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1497779554.1918 - val_loss: 1626132370.9954\n",
      "Epoch 2219/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1497773078.1683 - val_loss: 1625475603.8721\n",
      "Epoch 2220/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1497901177.7378 - val_loss: 1625140416.2922\n",
      "Epoch 2221/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1497615222.6067 - val_loss: 1625563314.2648\n",
      "Epoch 2222/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1497882406.0744 - val_loss: 1626138786.1918\n",
      "Epoch 2223/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1497601002.9589 - val_loss: 1625093340.9315\n",
      "Epoch 2224/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1497420257.6908 - val_loss: 1624540156.4932\n",
      "Epoch 2225/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1497368303.2172 - val_loss: 1625195384.4018\n",
      "Epoch 2226/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1497103083.7104 - val_loss: 1625084604.2009\n",
      "Epoch 2227/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1497102626.1918 - val_loss: 1624340060.0548\n",
      "Epoch 2228/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1497688413.3072 - val_loss: 1623407458.4840\n",
      "Epoch 2229/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1497824727.3581 - val_loss: 1625335293.0776\n",
      "Epoch 2230/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1497675458.5049 - val_loss: 1623627482.3014\n",
      "Epoch 2231/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1497320457.6438 - val_loss: 1623382660.3836\n",
      "Epoch 2232/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1496923631.9687 - val_loss: 1623916290.0457\n",
      "Epoch 2233/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1496731767.4834 - val_loss: 1623577184.4384\n",
      "Epoch 2234/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1496927398.1996 - val_loss: 1623912779.6895\n",
      "Epoch 2235/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1496339376.0939 - val_loss: 1624004903.1598\n",
      "Epoch 2236/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1496242881.6282 - val_loss: 1623671883.9817\n",
      "Epoch 2237/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1496525563.7417 - val_loss: 1623336937.4977\n",
      "Epoch 2238/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1496051525.1350 - val_loss: 1623433665.4612\n",
      "Epoch 2239/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1496413628.8689 - val_loss: 1623063888.3653\n",
      "Epoch 2240/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1496330508.2740 - val_loss: 1622445003.3973\n",
      "Epoch 2241/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1495906122.3953 - val_loss: 1623147048.3288\n",
      "Epoch 2242/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1495869941.7299 - val_loss: 1622730849.0228\n",
      "Epoch 2243/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1495873185.3151 - val_loss: 1623030054.2831\n",
      "Epoch 2244/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1495934310.7006 - val_loss: 1622908606.2466\n",
      "Epoch 2245/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1495392923.3033 - val_loss: 1621746366.2466\n",
      "Epoch 2246/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1495658773.7926 - val_loss: 1621786429.0776\n",
      "Epoch 2247/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1495584564.1018 - val_loss: 1621508922.4475\n",
      "Epoch 2248/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1495264586.1448 - val_loss: 1621517476.2374\n",
      "Epoch 2249/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1495336561.3464 - val_loss: 1620858960.3653\n",
      "Epoch 2250/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1495116352.6262 - val_loss: 1621279719.7443\n",
      "Epoch 2251/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1495103109.5108 - val_loss: 1621410142.6849\n",
      "Epoch 2252/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1494940195.0685 - val_loss: 1621142592.5845\n",
      "Epoch 2253/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1495327015.5773 - val_loss: 1619897423.1963\n",
      "Epoch 2254/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1494959240.2661 - val_loss: 1621230563.3607\n",
      "Epoch 2255/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 32us/step - loss: 1494637891.1311 - val_loss: 1620959984.5114\n",
      "Epoch 2256/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1494613396.1644 - val_loss: 1620409885.5160\n",
      "Epoch 2257/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1494539484.6810 - val_loss: 1620168114.8493\n",
      "Epoch 2258/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1494456768.3757 - val_loss: 1620479634.1187\n",
      "Epoch 2259/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1494460574.5597 - val_loss: 1620523593.6438\n",
      "Epoch 2260/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1494942931.6634 - val_loss: 1619347922.1187\n",
      "Epoch 2261/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1494327624.6419 - val_loss: 1619357596.3470\n",
      "Epoch 2262/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1494890186.7710 - val_loss: 1619993507.6530\n",
      "Epoch 2263/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1494258743.9217 - val_loss: 1619978325.3333\n",
      "Epoch 2264/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1494060790.9824 - val_loss: 1619020181.9178\n",
      "Epoch 2265/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1493811239.3268 - val_loss: 1619545315.9452\n",
      "Epoch 2266/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1493767719.1389 - val_loss: 1619016567.5251\n",
      "Epoch 2267/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1493673244.8063 - val_loss: 1618739728.3653\n",
      "Epoch 2268/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1493744280.0470 - val_loss: 1619114048.5845\n",
      "Epoch 2269/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1493717914.6771 - val_loss: 1618957129.0594\n",
      "Epoch 2270/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1493545444.1957 - val_loss: 1619063222.6484\n",
      "Epoch 2271/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1493716900.3209 - val_loss: 1618372382.6849\n",
      "Epoch 2272/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1493294587.2407 - val_loss: 1619035936.1461\n",
      "Epoch 2273/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1493117582.2779 - val_loss: 1618668861.0776\n",
      "Epoch 2274/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1493166403.6321 - val_loss: 1617902445.8813\n",
      "Epoch 2275/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1494193853.7456 - val_loss: 1618011576.1096\n",
      "Epoch 2276/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1493035497.9569 - val_loss: 1618421286.2831\n",
      "Epoch 2277/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1492979277.7769 - val_loss: 1617651248.8037\n",
      "Epoch 2278/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1492700652.9628 - val_loss: 1617470561.3151\n",
      "Epoch 2279/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1493321981.9961 - val_loss: 1617923963.9087\n",
      "Epoch 2280/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1492579762.2231 - val_loss: 1617737689.1324\n",
      "Epoch 2281/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1492898339.6947 - val_loss: 1617605051.3242\n",
      "Epoch 2282/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1492462985.6438 - val_loss: 1616843445.1872\n",
      "Epoch 2283/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1492726604.1487 - val_loss: 1616315098.8858\n",
      "Epoch 2284/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1492500337.7221 - val_loss: 1616701564.7854\n",
      "Epoch 2285/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1492737549.9022 - val_loss: 1616472149.3333\n",
      "Epoch 2286/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1491984833.3777 - val_loss: 1616696942.4658\n",
      "Epoch 2287/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1492124119.9217 - val_loss: 1616406869.3333\n",
      "Epoch 2288/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1492104256.1252 - val_loss: 1616329775.0502\n",
      "Epoch 2289/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1492066699.3973 - val_loss: 1616779906.0457\n",
      "Epoch 2290/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1491831599.5930 - val_loss: 1616202017.3151\n",
      "Epoch 2291/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1491863602.2231 - val_loss: 1615910668.2740\n",
      "Epoch 2292/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1491687156.6027 - val_loss: 1616149086.9772\n",
      "Epoch 2293/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1492035334.3875 - val_loss: 1615946330.3014\n",
      "Epoch 2294/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1491519240.0157 - val_loss: 1615853976.2557\n",
      "Epoch 2295/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1491759159.8591 - val_loss: 1614767623.3059\n",
      "Epoch 2296/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1491547126.3562 - val_loss: 1615353000.0365\n",
      "Epoch 2297/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1491323399.2642 - val_loss: 1615511494.4292\n",
      "Epoch 2298/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1491778439.0137 - val_loss: 1615885850.8858\n",
      "Epoch 2299/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1491477550.3405 - val_loss: 1614176455.5982\n",
      "Epoch 2300/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1491430166.3562 - val_loss: 1614641900.1279\n",
      "Epoch 2301/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1491175135.3112 - val_loss: 1614317677.0046\n",
      "Epoch 2302/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1491162897.5342 - val_loss: 1615459602.9954\n",
      "Epoch 2303/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1490943248.0313 - val_loss: 1614846035.5799\n",
      "Epoch 2304/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1490831406.9667 - val_loss: 1614255479.5251\n",
      "Epoch 2305/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1490809554.5362 - val_loss: 1614499390.5388\n",
      "Epoch 2306/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1490761667.7573 - val_loss: 1614767656.9132\n",
      "Epoch 2307/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1490495157.3542 - val_loss: 1614167985.6804\n",
      "Epoch 2308/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1490335053.1507 - val_loss: 1614209341.9543\n",
      "Epoch 2309/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1490269336.2975 - val_loss: 1613818402.4840\n",
      "Epoch 2310/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1490247307.7730 - val_loss: 1613590083.2146\n",
      "Epoch 2311/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1490254929.1585 - val_loss: 1613081669.2603\n",
      "Epoch 2312/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1490266910.9354 - val_loss: 1613030871.6712\n",
      "Epoch 2313/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1490178079.1859 - val_loss: 1612552731.1781\n",
      "Epoch 2314/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1489776556.5245 - val_loss: 1613067283.8721\n",
      "Epoch 2315/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1490772231.7652 - val_loss: 1614545500.6393\n",
      "Epoch 2316/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1489980628.4149 - val_loss: 1612764698.5936\n",
      "Epoch 2317/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1489870854.0117 - val_loss: 1612910600.1826\n",
      "Epoch 2318/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1489683554.1918 - val_loss: 1612803296.1461\n",
      "Epoch 2319/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 34us/step - loss: 1489483820.5871 - val_loss: 1612618645.3333\n",
      "Epoch 2320/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1489899502.9667 - val_loss: 1613111751.0137\n",
      "Epoch 2321/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1489638642.9746 - val_loss: 1611634173.9543\n",
      "Epoch 2322/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1489233445.1977 - val_loss: 1611942417.5342\n",
      "Epoch 2323/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1489631063.6712 - val_loss: 1612594722.1918\n",
      "Epoch 2324/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1489130586.9276 - val_loss: 1611591188.1644\n",
      "Epoch 2325/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1489009087.2485 - val_loss: 1611520599.9635\n",
      "Epoch 2326/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1488913884.6810 - val_loss: 1612164181.3333\n",
      "Epoch 2327/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1488736620.2114 - val_loss: 1611611506.5571\n",
      "Epoch 2328/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1489465463.8591 - val_loss: 1611978393.4247\n",
      "Epoch 2329/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1488588707.1937 - val_loss: 1611613877.1872\n",
      "Epoch 2330/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1488701496.4853 - val_loss: 1611531904.8767\n",
      "Epoch 2331/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1488581614.2153 - val_loss: 1610776184.4018\n",
      "Epoch 2332/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1488686993.7847 - val_loss: 1610046072.4018\n",
      "Epoch 2333/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1488943899.0528 - val_loss: 1611698093.0046\n",
      "Epoch 2334/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1488416798.5597 - val_loss: 1610904869.9909\n",
      "Epoch 2335/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1488476972.5871 - val_loss: 1610627252.8950\n",
      "Epoch 2336/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1488498407.2016 - val_loss: 1609926115.0685\n",
      "Epoch 2337/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1488464201.3933 - val_loss: 1611036293.2603\n",
      "Epoch 2338/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1488137973.7299 - val_loss: 1610940339.7260\n",
      "Epoch 2339/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1488621029.5734 - val_loss: 1609591909.4064\n",
      "Epoch 2340/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1488111430.1370 - val_loss: 1610262075.3242\n",
      "Epoch 2341/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1489007058.4110 - val_loss: 1611323404.8584\n",
      "Epoch 2342/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1487650898.1605 - val_loss: 1609838195.1416\n",
      "Epoch 2343/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1488395969.6282 - val_loss: 1609168812.1279\n",
      "Epoch 2344/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1487863421.6204 - val_loss: 1609375537.6804\n",
      "Epoch 2345/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1487556860.2427 - val_loss: 1609517752.1096\n",
      "Epoch 2346/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1488204131.3190 - val_loss: 1610359784.6210\n",
      "Epoch 2347/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1487446504.5793 - val_loss: 1608950956.4201\n",
      "Epoch 2348/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1487544616.3288 - val_loss: 1608538164.0183\n",
      "Epoch 2349/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1487756055.2955 - val_loss: 1609174915.2146\n",
      "Epoch 2350/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1487333187.6321 - val_loss: 1608863871.4155\n",
      "Epoch 2351/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1486939255.9843 - val_loss: 1608652436.7489\n",
      "Epoch 2352/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1486934477.9022 - val_loss: 1608593833.4977\n",
      "Epoch 2353/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1486988109.9022 - val_loss: 1609189454.9041\n",
      "Epoch 2354/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1487348864.7515 - val_loss: 1607779783.0137\n",
      "Epoch 2355/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1486744805.9491 - val_loss: 1608787903.7078\n",
      "Epoch 2356/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1486528854.6693 - val_loss: 1608242845.2237\n",
      "Epoch 2357/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1486729676.0235 - val_loss: 1607838272.0000\n",
      "Epoch 2358/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1486893994.8337 - val_loss: 1607230114.7763\n",
      "Epoch 2359/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1486272351.0607 - val_loss: 1607709253.2603\n",
      "Epoch 2360/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1486565822.1213 - val_loss: 1607341808.2192\n",
      "Epoch 2361/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1486650828.1487 - val_loss: 1608330376.7671\n",
      "Epoch 2362/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1486375387.4286 - val_loss: 1607736501.7717\n",
      "Epoch 2363/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1486392627.6008 - val_loss: 1607439314.7032\n",
      "Epoch 2364/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1486294045.0568 - val_loss: 1607626503.8904\n",
      "Epoch 2365/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1485924351.0607 - val_loss: 1607398034.9954\n",
      "Epoch 2366/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1486039446.9198 - val_loss: 1606565154.7763\n",
      "Epoch 2367/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1486773010.0352 - val_loss: 1606242517.6256\n",
      "Epoch 2368/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1485774543.7808 - val_loss: 1606612408.6941\n",
      "Epoch 2369/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1485526187.5851 - val_loss: 1606938016.4384\n",
      "Epoch 2370/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1486145364.9159 - val_loss: 1607427320.4018\n",
      "Epoch 2371/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1485567305.6438 - val_loss: 1606918667.3973\n",
      "Epoch 2372/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1485559019.4599 - val_loss: 1606944768.0000\n",
      "Epoch 2373/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1485361199.3425 - val_loss: 1606020133.1142\n",
      "Epoch 2374/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1485364218.4892 - val_loss: 1606057777.0959\n",
      "Epoch 2375/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1485329896.9550 - val_loss: 1606377196.7123\n",
      "Epoch 2376/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1485173457.2838 - val_loss: 1606045682.5571\n",
      "Epoch 2377/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1486066842.1761 - val_loss: 1606584949.7717\n",
      "Epoch 2378/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1484932541.6204 - val_loss: 1605598549.3333\n",
      "Epoch 2379/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1485021697.0020 - val_loss: 1605465060.8219\n",
      "Epoch 2380/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1485000465.5342 - val_loss: 1604608758.9406\n",
      "Epoch 2381/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1484770183.8904 - val_loss: 1605515571.7260\n",
      "Epoch 2382/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1485648985.9256 - val_loss: 1606341351.7443\n",
      "Epoch 2383/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 40us/step - loss: 1484881443.3190 - val_loss: 1604768420.8219\n",
      "Epoch 2384/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1484987709.1194 - val_loss: 1605345190.2831\n",
      "Epoch 2385/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1485177274.2387 - val_loss: 1605443443.1416\n",
      "Epoch 2386/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1484549611.9609 - val_loss: 1604255122.7032\n",
      "Epoch 2387/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1484641647.3425 - val_loss: 1604227851.3973\n",
      "Epoch 2388/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1485025849.9883 - val_loss: 1603882801.0959\n",
      "Epoch 2389/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1484364933.2603 - val_loss: 1604975495.5982\n",
      "Epoch 2390/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1484617895.3268 - val_loss: 1605646242.7763\n",
      "Epoch 2391/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1484451549.1820 - val_loss: 1604346090.6667\n",
      "Epoch 2392/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1484241283.2564 - val_loss: 1603668828.6393\n",
      "Epoch 2393/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1483897506.9432 - val_loss: 1604212531.1416\n",
      "Epoch 2394/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1483779221.4795 - val_loss: 1603928163.6530\n",
      "Epoch 2395/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1483751555.0059 - val_loss: 1603795776.0000\n",
      "Epoch 2396/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1485153824.8141 - val_loss: 1605123178.3744\n",
      "Epoch 2397/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1483914229.1037 - val_loss: 1603126276.6758\n",
      "Epoch 2398/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1483838501.0724 - val_loss: 1603884566.2100\n",
      "Epoch 2399/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1483522557.9961 - val_loss: 1603510100.4566\n",
      "Epoch 2400/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1483520278.2935 - val_loss: 1603563145.9361\n",
      "Epoch 2401/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1483284869.5108 - val_loss: 1602970330.0091\n",
      "Epoch 2402/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1483420403.9765 - val_loss: 1603338292.3105\n",
      "Epoch 2403/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1483412355.3816 - val_loss: 1602421007.1963\n",
      "Epoch 2404/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1483355380.9785 - val_loss: 1603619282.4110\n",
      "Epoch 2405/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1483023823.1546 - val_loss: 1603004242.7032\n",
      "Epoch 2406/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1482946816.5010 - val_loss: 1602800607.5616\n",
      "Epoch 2407/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1483670734.4031 - val_loss: 1603696739.0685\n",
      "Epoch 2408/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1482735181.0254 - val_loss: 1602173626.1553\n",
      "Epoch 2409/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1484198695.3268 - val_loss: 1603325535.2694\n",
      "Epoch 2410/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1482526655.1233 - val_loss: 1602056931.0685\n",
      "Epoch 2411/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1482873041.9100 - val_loss: 1602367239.3059\n",
      "Epoch 2412/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1482499847.6399 - val_loss: 1601580257.0228\n",
      "Epoch 2413/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1482549847.4207 - val_loss: 1602119178.2283\n",
      "Epoch 2414/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1482621792.6888 - val_loss: 1601959631.4886\n",
      "Epoch 2415/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1482461614.4658 - val_loss: 1601597033.4977\n",
      "Epoch 2416/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1482219415.2955 - val_loss: 1601628576.7306\n",
      "Epoch 2417/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1482361469.4951 - val_loss: 1601785139.7260\n",
      "Epoch 2418/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1482254693.4481 - val_loss: 1601043769.8630\n",
      "Epoch 2419/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1482330518.0431 - val_loss: 1601220967.7443\n",
      "Epoch 2420/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1482097384.7045 - val_loss: 1600651847.5982\n",
      "Epoch 2421/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1481858995.9765 - val_loss: 1601200498.5571\n",
      "Epoch 2422/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1482539718.8885 - val_loss: 1601942185.7900\n",
      "Epoch 2423/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1481647814.6380 - val_loss: 1600882169.2785\n",
      "Epoch 2424/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1481937776.8454 - val_loss: 1601089554.9954\n",
      "Epoch 2425/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1481677107.0998 - val_loss: 1600892968.6210\n",
      "Epoch 2426/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1481903596.5871 - val_loss: 1600092412.7854\n",
      "Epoch 2427/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1481441034.2701 - val_loss: 1600177812.7489\n",
      "Epoch 2428/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1481734973.4951 - val_loss: 1600021975.6712\n",
      "Epoch 2429/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1481814138.9902 - val_loss: 1600749110.3562\n",
      "Epoch 2430/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1481383976.5793 - val_loss: 1600029148.0548\n",
      "Epoch 2431/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1481700358.7632 - val_loss: 1600517210.3014\n",
      "Epoch 2432/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1481355280.7828 - val_loss: 1600051131.3242\n",
      "Epoch 2433/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1481528597.5421 - val_loss: 1598826803.4338\n",
      "Epoch 2434/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1481256914.6614 - val_loss: 1600059708.7854\n",
      "Epoch 2435/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1480913716.3523 - val_loss: 1599838136.9863\n",
      "Epoch 2436/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1481202113.0020 - val_loss: 1600004544.5845\n",
      "Epoch 2437/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1480724634.4266 - val_loss: 1599163156.7489\n",
      "Epoch 2438/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1481149333.1663 - val_loss: 1599699457.7534\n",
      "Epoch 2439/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1480673654.7319 - val_loss: 1598884849.3881\n",
      "Epoch 2440/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1480616210.6614 - val_loss: 1599125882.1553\n",
      "Epoch 2441/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1480449415.1389 - val_loss: 1599215348.0183\n",
      "Epoch 2442/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1480856682.9589 - val_loss: 1599584914.9954\n",
      "Epoch 2443/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1480929897.4560 - val_loss: 1598744912.3653\n",
      "Epoch 2444/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1480291110.3249 - val_loss: 1598744142.0274\n",
      "Epoch 2445/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1481228471.3581 - val_loss: 1597249227.9817\n",
      "Epoch 2446/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1480815702.1683 - val_loss: 1599091791.1963\n",
      "Epoch 2447/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 33us/step - loss: 1480254118.3249 - val_loss: 1598971837.6621\n",
      "Epoch 2448/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1480193663.3738 - val_loss: 1598062475.1050\n",
      "Epoch 2449/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1479920872.4540 - val_loss: 1598314574.3196\n",
      "Epoch 2450/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1480169449.8317 - val_loss: 1598142932.1644\n",
      "Epoch 2451/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1480043328.3757 - val_loss: 1598366594.3379\n",
      "Epoch 2452/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1479753551.2798 - val_loss: 1598069878.3562\n",
      "Epoch 2453/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1480201616.0313 - val_loss: 1598789659.7626\n",
      "Epoch 2454/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1479934107.3033 - val_loss: 1597203291.7626\n",
      "Epoch 2455/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1479822971.7417 - val_loss: 1598285417.7900\n",
      "Epoch 2456/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1479330025.9569 - val_loss: 1597755895.5251\n",
      "Epoch 2457/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1479527340.3366 - val_loss: 1597818272.1461\n",
      "Epoch 2458/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1479583462.5753 - val_loss: 1597116728.1096\n",
      "Epoch 2459/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1479391848.7045 - val_loss: 1596590262.6484\n",
      "Epoch 2460/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1479356646.3249 - val_loss: 1597182218.5205\n",
      "Epoch 2461/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1479227842.5049 - val_loss: 1596765839.4886\n",
      "Epoch 2462/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1479269942.2309 - val_loss: 1596677343.5616\n",
      "Epoch 2463/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1479132980.8532 - val_loss: 1597098437.8447\n",
      "Epoch 2464/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1478920392.7671 - val_loss: 1596642561.4612\n",
      "Epoch 2465/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1479074508.6497 - val_loss: 1597152411.7626\n",
      "Epoch 2466/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1479154725.9491 - val_loss: 1596319237.8447\n",
      "Epoch 2467/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1478656885.2290 - val_loss: 1596349908.4566\n",
      "Epoch 2468/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1478878163.4129 - val_loss: 1595947186.5571\n",
      "Epoch 2469/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1479485227.5851 - val_loss: 1597757586.1187\n",
      "Epoch 2470/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1478783266.0665 - val_loss: 1596022742.2100\n",
      "Epoch 2471/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1478449568.0626 - val_loss: 1595809184.4384\n",
      "Epoch 2472/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1478644292.1331 - val_loss: 1596682908.6393\n",
      "Epoch 2473/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1478286383.3425 - val_loss: 1596370996.8950\n",
      "Epoch 2474/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1478360785.9100 - val_loss: 1595529862.1370\n",
      "Epoch 2475/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1478298459.1781 - val_loss: 1595173405.5160\n",
      "Epoch 2476/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1478357558.9824 - val_loss: 1595379674.3014\n",
      "Epoch 2477/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1478301969.0333 - val_loss: 1596113037.7352\n",
      "Epoch 2478/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1478068120.2348 - val_loss: 1595147249.6804\n",
      "Epoch 2479/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1478144975.1546 - val_loss: 1595523576.6941\n",
      "Epoch 2480/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1478271669.6047 - val_loss: 1595558042.0091\n",
      "Epoch 2481/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1478097560.2975 - val_loss: 1595115874.7763\n",
      "Epoch 2482/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1478590853.2603 - val_loss: 1595916757.0411\n",
      "Epoch 2483/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1477654032.0313 - val_loss: 1594683056.5114\n",
      "Epoch 2484/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1478089871.7808 - val_loss: 1593943975.4521\n",
      "Epoch 2485/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1477574201.3620 - val_loss: 1594325872.5114\n",
      "Epoch 2486/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1477431052.6497 - val_loss: 1594546742.9406\n",
      "Epoch 2487/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1477866358.8571 - val_loss: 1595007252.7489\n",
      "Epoch 2488/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1477889477.3855 - val_loss: 1594178864.5114\n",
      "Epoch 2489/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1477467154.0352 - val_loss: 1593865590.6484\n",
      "Epoch 2490/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1477272592.5323 - val_loss: 1594029767.0137\n",
      "Epoch 2491/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1477166369.0646 - val_loss: 1594683708.4932\n",
      "Epoch 2492/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1477133006.1526 - val_loss: 1594354047.7078\n",
      "Epoch 2493/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1477161897.3307 - val_loss: 1593936919.0868\n",
      "Epoch 2494/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1477106112.8767 - val_loss: 1594323826.5571\n",
      "Epoch 2495/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1477415479.6086 - val_loss: 1593682353.9726\n",
      "Epoch 2496/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1476689668.7593 - val_loss: 1593406273.1689\n",
      "Epoch 2497/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1476934838.1057 - val_loss: 1593787761.9726\n",
      "Epoch 2498/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1476789792.3131 - val_loss: 1593915551.2694\n",
      "Epoch 2499/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1476542680.5479 - val_loss: 1593792096.7306\n",
      "Epoch 2500/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1476563959.4834 - val_loss: 1593355151.1963\n",
      "Epoch 2501/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1476630940.6810 - val_loss: 1592691754.6667\n",
      "Epoch 2502/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1476382044.4305 - val_loss: 1593368814.1735\n",
      "Epoch 2503/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1476501696.1252 - val_loss: 1593678030.3196\n",
      "Epoch 2504/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1476586105.2368 - val_loss: 1592066865.3881\n",
      "Epoch 2505/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1476136272.1566 - val_loss: 1593099534.9041\n",
      "Epoch 2506/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1476477065.3933 - val_loss: 1593063256.8402\n",
      "Epoch 2507/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1476096450.8806 - val_loss: 1593138564.6758\n",
      "Epoch 2508/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1476247324.5558 - val_loss: 1591784900.3836\n",
      "Epoch 2509/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1475895945.5186 - val_loss: 1592694376.3288\n",
      "Epoch 2510/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1476488713.8943 - val_loss: 1591710070.3562\n",
      "Epoch 2511/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 42us/step - loss: 1476224568.1096 - val_loss: 1592930088.6210\n",
      "Epoch 2512/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1475898928.3444 - val_loss: 1591794828.5662\n",
      "Epoch 2513/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1475675242.3953 - val_loss: 1591758952.3288\n",
      "Epoch 2514/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1475946128.1566 - val_loss: 1592535932.2009\n",
      "Epoch 2515/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1475848553.8317 - val_loss: 1591444883.2877\n",
      "Epoch 2516/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1475290394.6145 - val_loss: 1591903562.8128\n",
      "Epoch 2517/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1475331507.3503 - val_loss: 1592139218.1187\n",
      "Epoch 2518/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1475631189.4168 - val_loss: 1592511168.5845\n",
      "Epoch 2519/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1475518051.9452 - val_loss: 1591785697.3151\n",
      "Epoch 2520/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1475475945.4560 - val_loss: 1592021235.4338\n",
      "Epoch 2521/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1475241882.3014 - val_loss: 1591373644.8584\n",
      "Epoch 2522/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1475395136.3757 - val_loss: 1591012329.7900\n",
      "Epoch 2523/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1475095869.6204 - val_loss: 1591729815.9635\n",
      "Epoch 2524/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1475296958.1213 - val_loss: 1590485633.1689\n",
      "Epoch 2525/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1474875473.6595 - val_loss: 1590788750.9041\n",
      "Epoch 2526/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1474992422.0744 - val_loss: 1591324013.8813\n",
      "Epoch 2527/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1474846344.8924 - val_loss: 1590820784.2192\n",
      "Epoch 2528/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1474777873.1585 - val_loss: 1590819979.1050\n",
      "Epoch 2529/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1474992393.3933 - val_loss: 1590206168.2557\n",
      "Epoch 2530/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1474949129.7691 - val_loss: 1590712746.0822\n",
      "Epoch 2531/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1474731851.8982 - val_loss: 1590657899.2511\n",
      "Epoch 2532/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1474507425.1898 - val_loss: 1590365961.3516\n",
      "Epoch 2533/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1474756885.5421 - val_loss: 1589973557.4795\n",
      "Epoch 2534/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1474502651.9922 - val_loss: 1590272369.3881\n",
      "Epoch 2535/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1474747776.7515 - val_loss: 1591150013.0776\n",
      "Epoch 2536/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1474897498.3014 - val_loss: 1589446098.4110\n",
      "Epoch 2537/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1474302736.5323 - val_loss: 1589345672.7671\n",
      "Epoch 2538/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1474286899.2250 - val_loss: 1590144448.0000\n",
      "Epoch 2539/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1474718171.8043 - val_loss: 1590734127.0502\n",
      "Epoch 2540/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1474074000.2818 - val_loss: 1590139173.1142\n",
      "Epoch 2541/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1473787364.3209 - val_loss: 1589601751.0868\n",
      "Epoch 2542/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1473839997.4951 - val_loss: 1589591350.0639\n",
      "Epoch 2543/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1473915777.7534 - val_loss: 1588432793.1324\n",
      "Epoch 2544/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1473658348.5871 - val_loss: 1589262569.7900\n",
      "Epoch 2545/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1474063609.4873 - val_loss: 1589499809.3151\n",
      "Epoch 2546/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1473578737.7847 - val_loss: 1589148686.3196\n",
      "Epoch 2547/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1473593566.4344 - val_loss: 1588952208.9498\n",
      "Epoch 2548/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1473708382.4344 - val_loss: 1588898417.6804\n",
      "Epoch 2549/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1473966012.9941 - val_loss: 1589390046.3927\n",
      "Epoch 2550/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1473319144.4540 - val_loss: 1588959364.3836\n",
      "Epoch 2551/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1473398313.0802 - val_loss: 1587703958.5023\n",
      "Epoch 2552/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1474116417.1272 - val_loss: 1589157307.6164\n",
      "Epoch 2553/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1473238969.7378 - val_loss: 1588208719.4886\n",
      "Epoch 2554/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1473456252.8689 - val_loss: 1588883671.0868\n",
      "Epoch 2555/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1473226460.4305 - val_loss: 1588224456.7671\n",
      "Epoch 2556/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1473250024.8297 - val_loss: 1587488758.9406\n",
      "Epoch 2557/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1473147664.5323 - val_loss: 1587594229.7717\n",
      "Epoch 2558/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1472916377.5499 - val_loss: 1588030678.7945\n",
      "Epoch 2559/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1472949862.0744 - val_loss: 1588065627.4703\n",
      "Epoch 2560/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1472747166.8102 - val_loss: 1588273912.9863\n",
      "Epoch 2561/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1472776042.7084 - val_loss: 1587433639.1598\n",
      "Epoch 2562/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1472578550.6067 - val_loss: 1588113790.2466\n",
      "Epoch 2563/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1473259919.2798 - val_loss: 1586864103.1598\n",
      "Epoch 2564/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1472531982.4031 - val_loss: 1587662881.6073\n",
      "Epoch 2565/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1472510138.8650 - val_loss: 1588297144.6941\n",
      "Epoch 2566/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1473004451.9452 - val_loss: 1586959967.8539\n",
      "Epoch 2567/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1472538314.1448 - val_loss: 1586562768.3653\n",
      "Epoch 2568/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1472281298.5362 - val_loss: 1587831554.6301\n",
      "Epoch 2569/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1472540248.6732 - val_loss: 1587529409.1689\n",
      "Epoch 2570/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1472950241.3151 - val_loss: 1586532323.3607\n",
      "Epoch 2571/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1473303216.1566 - val_loss: 1588168398.6119\n",
      "Epoch 2572/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1472874060.1487 - val_loss: 1586105705.4977\n",
      "Epoch 2573/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1472170022.5753 - val_loss: 1587530727.4521\n",
      "Epoch 2574/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1472014551.6712 - val_loss: 1587437015.9635\n",
      "Epoch 2575/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 33us/step - loss: 1472655557.3855 - val_loss: 1587732268.4201\n",
      "Epoch 2576/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1471655172.5088 - val_loss: 1586793851.9087\n",
      "Epoch 2577/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1471993149.7456 - val_loss: 1585594635.3973\n",
      "Epoch 2578/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1471709598.0587 - val_loss: 1585600511.1233\n",
      "Epoch 2579/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1471724815.0294 - val_loss: 1586727001.7169\n",
      "Epoch 2580/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1471848213.2916 - val_loss: 1586425854.8311\n",
      "Epoch 2581/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1471577122.5675 - val_loss: 1586526885.9909\n",
      "Epoch 2582/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1471849915.1155 - val_loss: 1585538329.1324\n",
      "Epoch 2583/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1471509976.1722 - val_loss: 1585367642.5936\n",
      "Epoch 2584/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1471277945.7378 - val_loss: 1585613147.4703\n",
      "Epoch 2585/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1471354557.9961 - val_loss: 1586318924.2740\n",
      "Epoch 2586/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1471562906.7397 - val_loss: 1586805120.5845\n",
      "Epoch 2587/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1470969806.2779 - val_loss: 1586101006.3196\n",
      "Epoch 2588/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1471150799.0294 - val_loss: 1585771188.8950\n",
      "Epoch 2589/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1471072173.9648 - val_loss: 1585112941.5890\n",
      "Epoch 2590/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1470948628.5401 - val_loss: 1585795678.3927\n",
      "Epoch 2591/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1470814105.2994 - val_loss: 1585626213.4064\n",
      "Epoch 2592/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1471624762.3640 - val_loss: 1585915296.1461\n",
      "Epoch 2593/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1471117307.9922 - val_loss: 1584398719.7078\n",
      "Epoch 2594/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1470551285.7299 - val_loss: 1584608938.3744\n",
      "Epoch 2595/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1470783349.2290 - val_loss: 1585802105.5708\n",
      "Epoch 2596/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1470533534.4344 - val_loss: 1584741263.7808\n",
      "Epoch 2597/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1470532739.7573 - val_loss: 1584896228.5297\n",
      "Epoch 2598/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1470388168.1409 - val_loss: 1584502824.9132\n",
      "Epoch 2599/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1470521639.0763 - val_loss: 1584431871.7078\n",
      "Epoch 2600/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1471628179.0372 - val_loss: 1584026297.2785\n",
      "Epoch 2601/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1470542692.9472 - val_loss: 1584175808.5845\n",
      "Epoch 2602/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1470264735.8121 - val_loss: 1585188610.6301\n",
      "Epoch 2603/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1471224482.3170 - val_loss: 1583358839.8174\n",
      "Epoch 2604/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1470595093.2916 - val_loss: 1584681695.5616\n",
      "Epoch 2605/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1470119399.4521 - val_loss: 1584987123.1416\n",
      "Epoch 2606/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1469949820.0548 - val_loss: 1584508049.2420\n",
      "Epoch 2607/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1470907241.2055 - val_loss: 1583015790.4658\n",
      "Epoch 2608/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1470426534.7006 - val_loss: 1583825976.6941\n",
      "Epoch 2609/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1469751386.8023 - val_loss: 1584219472.9498\n",
      "Epoch 2610/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1469796705.6908 - val_loss: 1583768552.9132\n",
      "Epoch 2611/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1469817248.5636 - val_loss: 1583742506.9589\n",
      "Epoch 2612/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1470015427.1311 - val_loss: 1584312497.3881\n",
      "Epoch 2613/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1469705986.0039 - val_loss: 1583220380.9315\n",
      "Epoch 2614/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1469512752.2192 - val_loss: 1583311815.5982\n",
      "Epoch 2615/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1469512659.6634 - val_loss: 1583579650.9224\n",
      "Epoch 2616/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1469728253.9961 - val_loss: 1582558207.7078\n",
      "Epoch 2617/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1469460801.1272 - val_loss: 1583160762.7397\n",
      "Epoch 2618/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1469482218.2074 - val_loss: 1583512490.3744\n",
      "Epoch 2619/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1469627897.7378 - val_loss: 1583404475.0320\n",
      "Epoch 2620/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1469174564.8219 - val_loss: 1583500049.8265\n",
      "Epoch 2621/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1469209000.8297 - val_loss: 1582714257.2420\n",
      "Epoch 2622/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1469014991.1546 - val_loss: 1582817592.9863\n",
      "Epoch 2623/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1469025777.4716 - val_loss: 1583292266.0822\n",
      "Epoch 2624/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1468967471.5930 - val_loss: 1582711181.7352\n",
      "Epoch 2625/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1469103113.0176 - val_loss: 1582391794.8493\n",
      "Epoch 2626/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1469703103.8748 - val_loss: 1582833688.5479\n",
      "Epoch 2627/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1468982479.0294 - val_loss: 1582470196.0183\n",
      "Epoch 2628/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1468639445.7926 - val_loss: 1582280670.3927\n",
      "Epoch 2629/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1468696586.3953 - val_loss: 1582612115.5799\n",
      "Epoch 2630/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1468850349.5890 - val_loss: 1582048720.0731\n",
      "Epoch 2631/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1468520706.5049 - val_loss: 1582340091.6164\n",
      "Epoch 2632/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1468592333.1507 - val_loss: 1581652576.4384\n",
      "Epoch 2633/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1468520377.6751 - val_loss: 1581710013.9543\n",
      "Epoch 2634/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1468421042.3483 - val_loss: 1582361814.5023\n",
      "Epoch 2635/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1468486806.2935 - val_loss: 1582208457.3516\n",
      "Epoch 2636/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1468839487.1233 - val_loss: 1581733247.4155\n",
      "Epoch 2637/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1468231514.0509 - val_loss: 1581798330.1553\n",
      "Epoch 2638/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1468349036.4618 - val_loss: 1581973016.8402\n",
      "Epoch 2639/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 41us/step - loss: 1468025748.7906 - val_loss: 1581141170.8493\n",
      "Epoch 2640/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1469480312.1096 - val_loss: 1582304222.6849\n",
      "Epoch 2641/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1469110308.4462 - val_loss: 1579933830.4292\n",
      "Epoch 2642/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1469030234.0509 - val_loss: 1581513736.7671\n",
      "Epoch 2643/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1467896388.3836 - val_loss: 1581476826.0091\n",
      "Epoch 2644/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1468082184.0157 - val_loss: 1580373922.4840\n",
      "Epoch 2645/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1467647540.7906 - val_loss: 1580556498.4110\n",
      "Epoch 2646/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1467547952.5949 - val_loss: 1580319635.2877\n",
      "Epoch 2647/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1467619405.4012 - val_loss: 1580953149.9543\n",
      "Epoch 2648/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1467512768.1252 - val_loss: 1580877671.1598\n",
      "Epoch 2649/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1467636608.2505 - val_loss: 1580248172.4201\n",
      "Epoch 2650/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1467594997.4795 - val_loss: 1581383914.9589\n",
      "Epoch 2651/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1467400495.3425 - val_loss: 1580856582.1370\n",
      "Epoch 2652/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1467291695.2172 - val_loss: 1580407262.3927\n",
      "Epoch 2653/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1467332919.6086 - val_loss: 1580127798.3562\n",
      "Epoch 2654/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1467542513.0959 - val_loss: 1579407228.2009\n",
      "Epoch 2655/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1467321655.6086 - val_loss: 1579677390.9041\n",
      "Epoch 2656/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1467105207.3581 - val_loss: 1580338816.8767\n",
      "Epoch 2657/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1466964013.2133 - val_loss: 1580524779.2511\n",
      "Epoch 2658/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1467042562.0039 - val_loss: 1580482910.1005\n",
      "Epoch 2659/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1466960835.0059 - val_loss: 1579815223.8174\n",
      "Epoch 2660/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1467336408.4227 - val_loss: 1580703050.5205\n",
      "Epoch 2661/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1467245526.9198 - val_loss: 1580831955.8721\n",
      "Epoch 2662/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1467261626.4892 - val_loss: 1579540395.5434\n",
      "Epoch 2663/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1467101210.3014 - val_loss: 1578798305.3151\n",
      "Epoch 2664/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1466684876.3992 - val_loss: 1579408686.4658\n",
      "Epoch 2665/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1467086870.0431 - val_loss: 1580045367.5251\n",
      "Epoch 2666/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1467364962.4423 - val_loss: 1579281071.0502\n",
      "Epoch 2667/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1466662523.7417 - val_loss: 1579333041.6804\n",
      "Epoch 2668/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1466723277.9022 - val_loss: 1578271109.2603\n",
      "Epoch 2669/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1468385465.6125 - val_loss: 1580741343.2694\n",
      "Epoch 2670/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1466026429.8708 - val_loss: 1579207527.1598\n",
      "Epoch 2671/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1466336001.2524 - val_loss: 1579402495.7078\n",
      "Epoch 2672/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1466342711.8591 - val_loss: 1579110234.8858\n",
      "Epoch 2673/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1466675721.0176 - val_loss: 1577817204.0183\n",
      "Epoch 2674/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1466094909.1194 - val_loss: 1578655796.8950\n",
      "Epoch 2675/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1466271286.3562 - val_loss: 1578946320.0731\n",
      "Epoch 2676/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1466361802.3953 - val_loss: 1578299769.5708\n",
      "Epoch 2677/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1466054582.3562 - val_loss: 1578510805.0411\n",
      "Epoch 2678/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1465898290.2231 - val_loss: 1578207549.3699\n",
      "Epoch 2679/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1465920239.8434 - val_loss: 1578791591.1598\n",
      "Epoch 2680/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1465978119.8904 - val_loss: 1578107858.7032\n",
      "Epoch 2681/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1465923832.2348 - val_loss: 1578122375.0137\n",
      "Epoch 2682/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1466218502.5127 - val_loss: 1579377449.2055\n",
      "Epoch 2683/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1465734254.4658 - val_loss: 1578537975.2329\n",
      "Epoch 2684/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1465918686.4344 - val_loss: 1578033342.5388\n",
      "Epoch 2685/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1465339832.8611 - val_loss: 1577910579.7260\n",
      "Epoch 2686/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1466214004.4775 - val_loss: 1577010750.5388\n",
      "Epoch 2687/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1465552950.3562 - val_loss: 1577989055.4155\n",
      "Epoch 2688/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1465547992.4227 - val_loss: 1577488724.7489\n",
      "Epoch 2689/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1466299324.4932 - val_loss: 1578393736.4749\n",
      "Epoch 2690/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1465068610.3796 - val_loss: 1577368838.1370\n",
      "Epoch 2691/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1465725690.9902 - val_loss: 1577210016.4384\n",
      "Epoch 2692/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1466051711.8748 - val_loss: 1576714712.8402\n",
      "Epoch 2693/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1464980153.9883 - val_loss: 1576854990.0274\n",
      "Epoch 2694/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1464969272.8611 - val_loss: 1577506970.5936\n",
      "Epoch 2695/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1464889622.2935 - val_loss: 1576850631.5982\n",
      "Epoch 2696/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1465355213.9022 - val_loss: 1577184813.8813\n",
      "Epoch 2697/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1464983341.5890 - val_loss: 1576188965.9909\n",
      "Epoch 2698/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1464573333.2916 - val_loss: 1576721788.2009\n",
      "Epoch 2699/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1464831807.8748 - val_loss: 1577174520.9863\n",
      "Epoch 2700/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1465064475.0528 - val_loss: 1577250867.4338\n",
      "Epoch 2701/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1465303447.1703 - val_loss: 1575717868.4201\n",
      "Epoch 2702/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1464597473.4403 - val_loss: 1577073370.3014\n",
      "Epoch 2703/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 47us/step - loss: 1464551140.5714 - val_loss: 1576329467.6164\n",
      "Epoch 2704/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1465060578.8180 - val_loss: 1577185673.9361\n",
      "Epoch 2705/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1464755380.1018 - val_loss: 1575879343.6347\n",
      "Epoch 2706/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1464334667.6477 - val_loss: 1576379935.8539\n",
      "Epoch 2707/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1464318499.8200 - val_loss: 1576734122.3744\n",
      "Epoch 2708/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1464526384.5949 - val_loss: 1575666394.5936\n",
      "Epoch 2709/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1464610088.3288 - val_loss: 1576870864.0731\n",
      "Epoch 2710/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1464017963.8356 - val_loss: 1576243259.9087\n",
      "Epoch 2711/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1464379796.0391 - val_loss: 1575260107.1050\n",
      "Epoch 2712/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1464020301.5264 - val_loss: 1575915787.9817\n",
      "Epoch 2713/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1463996237.4012 - val_loss: 1575959978.6667\n",
      "Epoch 2714/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1464062413.1507 - val_loss: 1575354233.5708\n",
      "Epoch 2715/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1464625414.7632 - val_loss: 1576356451.6530\n",
      "Epoch 2716/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1463957211.9295 - val_loss: 1575788816.3653\n",
      "Epoch 2717/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1464008150.1683 - val_loss: 1575689411.2146\n",
      "Epoch 2718/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1463884493.9022 - val_loss: 1575760788.7489\n",
      "Epoch 2719/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1463691968.6262 - val_loss: 1575570833.5342\n",
      "Epoch 2720/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1464191331.6947 - val_loss: 1574704266.8128\n",
      "Epoch 2721/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1463895208.3288 - val_loss: 1575375628.5662\n",
      "Epoch 2722/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1463883689.4560 - val_loss: 1575995026.9954\n",
      "Epoch 2723/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1463427680.0626 - val_loss: 1575403721.6438\n",
      "Epoch 2724/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1463784761.8630 - val_loss: 1575140707.9452\n",
      "Epoch 2725/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1464027256.7358 - val_loss: 1576064611.3607\n",
      "Epoch 2726/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1463234221.5890 - val_loss: 1575123459.2146\n",
      "Epoch 2727/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1463254783.6243 - val_loss: 1574377934.0274\n",
      "Epoch 2728/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1463255626.5205 - val_loss: 1574805638.4292\n",
      "Epoch 2729/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1463068052.0391 - val_loss: 1574864883.1416\n",
      "Epoch 2730/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1463121720.6106 - val_loss: 1574485594.5936\n",
      "Epoch 2731/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1463192802.5675 - val_loss: 1575119265.0228\n",
      "Epoch 2732/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1462915279.9061 - val_loss: 1574240041.4977\n",
      "Epoch 2733/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1462960388.5088 - val_loss: 1573616007.3059\n",
      "Epoch 2734/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1463224234.9589 - val_loss: 1573767658.9589\n",
      "Epoch 2735/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1463177397.8552 - val_loss: 1575132506.0091\n",
      "Epoch 2736/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1462924081.5969 - val_loss: 1574203620.5297\n",
      "Epoch 2737/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1462851428.1957 - val_loss: 1574437440.0000\n",
      "Epoch 2738/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1462644156.1174 - val_loss: 1573815291.6164\n",
      "Epoch 2739/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1463129421.1507 - val_loss: 1573379023.7808\n",
      "Epoch 2740/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1462488728.1722 - val_loss: 1573719554.9224\n",
      "Epoch 2741/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1462493602.6928 - val_loss: 1573640969.6438\n",
      "Epoch 2742/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1462370453.6673 - val_loss: 1574221992.9132\n",
      "Epoch 2743/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1462213027.3190 - val_loss: 1573960381.9543\n",
      "Epoch 2744/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1462818887.7652 - val_loss: 1574114392.2557\n",
      "Epoch 2745/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1462836651.3346 - val_loss: 1573824693.7717\n",
      "Epoch 2746/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1462314544.5949 - val_loss: 1573679197.8082\n",
      "Epoch 2747/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1462200962.5049 - val_loss: 1573744213.6256\n",
      "Epoch 2748/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1462056546.4423 - val_loss: 1573359783.7443\n",
      "Epoch 2749/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1462026204.6810 - val_loss: 1573046939.1781\n",
      "Epoch 2750/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1462260259.5695 - val_loss: 1573019375.9269\n",
      "Epoch 2751/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1462159300.5088 - val_loss: 1573296281.1324\n",
      "Epoch 2752/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1461997000.2661 - val_loss: 1572872344.8402\n",
      "Epoch 2753/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1461787553.8160 - val_loss: 1572966872.5479\n",
      "Epoch 2754/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1461928206.0274 - val_loss: 1572610965.9178\n",
      "Epoch 2755/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1461909019.8043 - val_loss: 1572789677.0046\n",
      "Epoch 2756/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1461759414.3562 - val_loss: 1573493840.0731\n",
      "Epoch 2757/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1462240422.3249 - val_loss: 1571794950.1370\n",
      "Epoch 2758/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1462429952.0000 - val_loss: 1573357872.8037\n",
      "Epoch 2759/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1461843304.2035 - val_loss: 1572179373.8813\n",
      "Epoch 2760/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1461584228.5088 - val_loss: 1572282355.1416\n",
      "Epoch 2761/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1461838114.9432 - val_loss: 1573502418.4110\n",
      "Epoch 2762/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1461889832.8297 - val_loss: 1573100171.1050\n",
      "Epoch 2763/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1461769748.5401 - val_loss: 1572356704.1461\n",
      "Epoch 2764/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1461285526.4188 - val_loss: 1572691126.9406\n",
      "Epoch 2765/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1461657771.8356 - val_loss: 1572255197.5160\n",
      "Epoch 2766/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1461412631.1703 - val_loss: 1572067566.1735\n",
      "Epoch 2767/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 44us/step - loss: 1462196193.9413 - val_loss: 1573416114.2648\n",
      "Epoch 2768/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1461349670.8258 - val_loss: 1572444898.7763\n",
      "Epoch 2769/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1461416674.3170 - val_loss: 1571475887.3425\n",
      "Epoch 2770/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1460977170.5362 - val_loss: 1571568872.3288\n",
      "Epoch 2771/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1461269536.0626 - val_loss: 1572486049.8995\n",
      "Epoch 2772/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1461025178.1761 - val_loss: 1571554379.6895\n",
      "Epoch 2773/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1460770927.4677 - val_loss: 1572007851.8356\n",
      "Epoch 2774/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1461206629.1977 - val_loss: 1571325853.8082\n",
      "Epoch 2775/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1460720927.8121 - val_loss: 1571313233.8265\n",
      "Epoch 2776/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1460636418.1918 - val_loss: 1571786531.9452\n",
      "Epoch 2777/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1460755404.7750 - val_loss: 1571165137.8265\n",
      "Epoch 2778/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1460599477.3542 - val_loss: 1570979611.1781\n",
      "Epoch 2779/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1460899687.8278 - val_loss: 1570730665.4977\n",
      "Epoch 2780/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1460696302.7162 - val_loss: 1571090427.6164\n",
      "Epoch 2781/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1460792880.0939 - val_loss: 1571949540.8219\n",
      "Epoch 2782/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1461168213.1663 - val_loss: 1571166777.8630\n",
      "Epoch 2783/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1460297160.0157 - val_loss: 1571501662.9772\n",
      "Epoch 2784/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1460493284.4462 - val_loss: 1571979175.1598\n",
      "Epoch 2785/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1460370690.5049 - val_loss: 1571141048.1096\n",
      "Epoch 2786/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1460214050.8180 - val_loss: 1571587002.7397\n",
      "Epoch 2787/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1460144839.1389 - val_loss: 1571150861.4429\n",
      "Epoch 2788/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1460203526.5127 - val_loss: 1570412332.4201\n",
      "Epoch 2789/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1460116907.8356 - val_loss: 1570273939.2877\n",
      "Epoch 2790/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1460658441.5186 - val_loss: 1571325644.5662\n",
      "Epoch 2791/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1460162280.9550 - val_loss: 1570641803.3973\n",
      "Epoch 2792/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1460232636.8689 - val_loss: 1569448305.0959\n",
      "Epoch 2793/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1459856657.3464 - val_loss: 1570855705.4247\n",
      "Epoch 2794/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1459829265.5342 - val_loss: 1570734167.6712\n",
      "Epoch 2795/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1459766679.0450 - val_loss: 1570838347.1050\n",
      "Epoch 2796/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1459671268.1957 - val_loss: 1570492513.0228\n",
      "Epoch 2797/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1459852042.5205 - val_loss: 1570817640.3288\n",
      "Epoch 2798/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1459995709.7456 - val_loss: 1569812069.9909\n",
      "Epoch 2799/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1459883223.9217 - val_loss: 1570686541.4429\n",
      "Epoch 2800/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1460262584.8611 - val_loss: 1569055608.9863\n",
      "Epoch 2801/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1459458577.1585 - val_loss: 1570417373.5160\n",
      "Epoch 2802/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1460135446.4188 - val_loss: 1569044228.6758\n",
      "Epoch 2803/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1459335368.1409 - val_loss: 1569524657.9726\n",
      "Epoch 2804/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1459473772.7123 - val_loss: 1570264283.7626\n",
      "Epoch 2805/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1459977927.8904 - val_loss: 1570322089.7900\n",
      "Epoch 2806/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1459237399.0450 - val_loss: 1570219504.8037\n",
      "Epoch 2807/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1459300235.6477 - val_loss: 1569731398.1370\n",
      "Epoch 2808/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1459051251.3503 - val_loss: 1569889934.9041\n",
      "Epoch 2809/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1459374141.6204 - val_loss: 1568921911.8174\n",
      "Epoch 2810/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1459803340.3992 - val_loss: 1570802997.4795\n",
      "Epoch 2811/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1459239450.5519 - val_loss: 1569418799.6347\n",
      "Epoch 2812/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1458963487.0607 - val_loss: 1569108170.5205\n",
      "Epoch 2813/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1458815731.9765 - val_loss: 1569586385.5342\n",
      "Epoch 2814/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1458847621.7613 - val_loss: 1569434485.1872\n",
      "Epoch 2815/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1458841528.1096 - val_loss: 1569762358.9406\n",
      "Epoch 2816/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1458576685.0881 - val_loss: 1569171885.5890\n",
      "Epoch 2817/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1459174000.9706 - val_loss: 1568715309.5890\n",
      "Epoch 2818/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1458605132.3366 - val_loss: 1568606608.6575\n",
      "Epoch 2819/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1458835231.8121 - val_loss: 1568715581.0776\n",
      "Epoch 2820/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1458666050.7554 - val_loss: 1568999810.9224\n",
      "Epoch 2821/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1458911306.7710 - val_loss: 1568524446.1005\n",
      "Epoch 2822/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1458489324.2114 - val_loss: 1568107510.9406\n",
      "Epoch 2823/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1458488227.8200 - val_loss: 1567970945.1689\n",
      "Epoch 2824/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1458807602.5988 - val_loss: 1567868525.0046\n",
      "Epoch 2825/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1458237167.9687 - val_loss: 1568782568.6210\n",
      "Epoch 2826/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1458371892.3523 - val_loss: 1568454380.7123\n",
      "Epoch 2827/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1458167476.6027 - val_loss: 1568777619.5799\n",
      "Epoch 2828/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1458041088.3757 - val_loss: 1568865023.4155\n",
      "Epoch 2829/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1458228351.2485 - val_loss: 1569102876.9315\n",
      "Epoch 2830/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1458187137.6282 - val_loss: 1568370865.3881\n",
      "Epoch 2831/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 36us/step - loss: 1457980297.6438 - val_loss: 1568732273.3881\n",
      "Epoch 2832/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1458116126.3092 - val_loss: 1568302052.8219\n",
      "Epoch 2833/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1458356312.6732 - val_loss: 1567379849.6438\n",
      "Epoch 2834/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1458263567.1546 - val_loss: 1568244924.4932\n",
      "Epoch 2835/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1458033587.0998 - val_loss: 1568215326.6849\n",
      "Epoch 2836/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1457785713.9726 - val_loss: 1567797875.1416\n",
      "Epoch 2837/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1458474209.1898 - val_loss: 1566993642.6667\n",
      "Epoch 2838/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1457757868.4618 - val_loss: 1568152787.2877\n",
      "Epoch 2839/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1457625787.3659 - val_loss: 1567565286.2831\n",
      "Epoch 2840/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1457667525.3855 - val_loss: 1568030480.6575\n",
      "Epoch 2841/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1457633624.0470 - val_loss: 1567435569.6804\n",
      "Epoch 2842/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1457427116.3366 - val_loss: 1567787923.8721\n",
      "Epoch 2843/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1457807313.5342 - val_loss: 1566538280.0365\n",
      "Epoch 2844/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1457894111.4364 - val_loss: 1566865313.6073\n",
      "Epoch 2845/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1457446053.8239 - val_loss: 1567338687.4155\n",
      "Epoch 2846/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1457602294.9824 - val_loss: 1566553262.4658\n",
      "Epoch 2847/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1458315585.3777 - val_loss: 1568575159.5251\n",
      "Epoch 2848/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1457272994.5675 - val_loss: 1567712621.0046\n",
      "Epoch 2849/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1457191749.8865 - val_loss: 1566966270.8311\n",
      "Epoch 2850/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1457686124.9628 - val_loss: 1566630790.1370\n",
      "Epoch 2851/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1456987410.5362 - val_loss: 1566301021.8082\n",
      "Epoch 2852/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1457336764.1174 - val_loss: 1567398717.0776\n",
      "Epoch 2853/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1457095239.6399 - val_loss: 1567082949.8447\n",
      "Epoch 2854/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1457118035.4129 - val_loss: 1565934119.7443\n",
      "Epoch 2855/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1456740718.7162 - val_loss: 1566548018.8493\n",
      "Epoch 2856/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1456828287.3738 - val_loss: 1567083967.7078\n",
      "Epoch 2857/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1456763381.6047 - val_loss: 1566362506.2283\n",
      "Epoch 2858/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1456626797.2133 - val_loss: 1566163364.8219\n",
      "Epoch 2859/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1456708536.2348 - val_loss: 1566606293.3333\n",
      "Epoch 2860/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1456541185.7534 - val_loss: 1566751153.6804\n",
      "Epoch 2861/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1456942502.0744 - val_loss: 1566163382.0639\n",
      "Epoch 2862/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1456506386.4110 - val_loss: 1566367977.7900\n",
      "Epoch 2863/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1456446148.8845 - val_loss: 1566162669.0046\n",
      "Epoch 2864/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1456327632.5323 - val_loss: 1566331383.8174\n",
      "Epoch 2865/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1456626501.6360 - val_loss: 1565600931.0685\n",
      "Epoch 2866/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1456435066.4892 - val_loss: 1566538154.6667\n",
      "Epoch 2867/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1456638787.4442 - val_loss: 1566222294.2100\n",
      "Epoch 2868/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1456159231.4990 - val_loss: 1566023539.1416\n",
      "Epoch 2869/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1456342613.6673 - val_loss: 1565488895.4155\n",
      "Epoch 2870/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1456122210.1918 - val_loss: 1565615549.0776\n",
      "Epoch 2871/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1456442639.2798 - val_loss: 1565962047.4155\n",
      "Epoch 2872/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1456379302.3249 - val_loss: 1566058963.8721\n",
      "Epoch 2873/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1456546997.7299 - val_loss: 1564552448.5845\n",
      "Epoch 2874/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1455797732.3209 - val_loss: 1565547034.0091\n",
      "Epoch 2875/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1456038380.9628 - val_loss: 1565415076.8219\n",
      "Epoch 2876/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1455694754.0665 - val_loss: 1565572550.7215\n",
      "Epoch 2877/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1455796284.8689 - val_loss: 1565004898.1918\n",
      "Epoch 2878/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1455831065.1742 - val_loss: 1565913213.9543\n",
      "Epoch 2879/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1456609929.5186 - val_loss: 1564935433.3516\n",
      "Epoch 2880/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1456077215.5616 - val_loss: 1565128403.5799\n",
      "Epoch 2881/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1455731042.4423 - val_loss: 1565631277.5890\n",
      "Epoch 2882/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1455614987.5851 - val_loss: 1565632443.0320\n",
      "Epoch 2883/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1455580667.2407 - val_loss: 1565435231.2694\n",
      "Epoch 2884/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1455914005.7926 - val_loss: 1565910339.5068\n",
      "Epoch 2885/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1455850040.4853 - val_loss: 1565221433.8630\n",
      "Epoch 2886/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1455239080.2035 - val_loss: 1564835895.5251\n",
      "Epoch 2887/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1455356737.3777 - val_loss: 1564898870.9406\n",
      "Epoch 2888/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1455488739.6947 - val_loss: 1565008761.5708\n",
      "Epoch 2889/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1455200890.1761 - val_loss: 1564763006.5388\n",
      "Epoch 2890/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1455588749.0254 - val_loss: 1564192440.9863\n",
      "Epoch 2891/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1455172305.1585 - val_loss: 1564005876.6027\n",
      "Epoch 2892/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1455674563.7573 - val_loss: 1565249008.8037\n",
      "Epoch 2893/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1455685842.9119 - val_loss: 1563453282.1918\n",
      "Epoch 2894/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1455232649.6438 - val_loss: 1563974535.5982\n",
      "Epoch 2895/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 39us/step - loss: 1455265241.4247 - val_loss: 1563716150.3562\n",
      "Epoch 2896/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1454849792.6262 - val_loss: 1564236084.8950\n",
      "Epoch 2897/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1454882942.9980 - val_loss: 1564300714.0822\n",
      "Epoch 2898/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1454902237.9335 - val_loss: 1564101649.2420\n",
      "Epoch 2899/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1454729687.9217 - val_loss: 1564529564.3470\n",
      "Epoch 2900/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1454750244.5088 - val_loss: 1564605819.3242\n",
      "Epoch 2901/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1455000140.9628 - val_loss: 1563529820.3470\n",
      "Epoch 2902/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1454882297.2368 - val_loss: 1564659884.4201\n",
      "Epoch 2903/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1455442812.2427 - val_loss: 1563914734.4658\n",
      "Epoch 2904/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1455043857.0333 - val_loss: 1564821110.3562\n",
      "Epoch 2905/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1454517931.0841 - val_loss: 1563738597.6986\n",
      "Epoch 2906/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1454735220.2270 - val_loss: 1563687501.7352\n",
      "Epoch 2907/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1454622967.7339 - val_loss: 1563457045.3333\n",
      "Epoch 2908/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1454878193.2211 - val_loss: 1563038704.5114\n",
      "Epoch 2909/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1454690733.4638 - val_loss: 1563871978.9589\n",
      "Epoch 2910/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1454553248.8141 - val_loss: 1564233313.3151\n",
      "Epoch 2911/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1454407991.4834 - val_loss: 1563470671.1963\n",
      "Epoch 2912/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1454607782.0744 - val_loss: 1563850708.4566\n",
      "Epoch 2913/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1454478788.5088 - val_loss: 1563298277.9909\n",
      "Epoch 2914/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1454344653.0254 - val_loss: 1563398839.5251\n",
      "Epoch 2915/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1454101627.3659 - val_loss: 1562820814.9041\n",
      "Epoch 2916/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1453890867.0998 - val_loss: 1563044195.6530\n",
      "Epoch 2917/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1454594670.0900 - val_loss: 1563433970.5571\n",
      "Epoch 2918/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1454008846.0274 - val_loss: 1563005392.0731\n",
      "Epoch 2919/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1453898755.5068 - val_loss: 1563143895.9635\n",
      "Epoch 2920/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1454250096.2192 - val_loss: 1561935393.8995\n",
      "Epoch 2921/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1455520371.4755 - val_loss: 1563772220.7854\n",
      "Epoch 2922/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1453954141.0568 - val_loss: 1563538417.9726\n",
      "Epoch 2923/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1453617173.5421 - val_loss: 1562956943.4886\n",
      "Epoch 2924/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1453948006.1996 - val_loss: 1562110691.9452\n",
      "Epoch 2925/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1454013298.2231 - val_loss: 1561581581.1507\n",
      "Epoch 2926/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1454374300.6810 - val_loss: 1563431902.9772\n",
      "Epoch 2927/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1453492813.6517 - val_loss: 1562714626.6301\n",
      "Epoch 2928/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1453424371.2250 - val_loss: 1562546498.3379\n",
      "Epoch 2929/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1453500495.1546 - val_loss: 1562013115.0320\n",
      "Epoch 2930/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1453387555.4442 - val_loss: 1562028088.9863\n",
      "Epoch 2931/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1453941587.6634 - val_loss: 1563115410.9954\n",
      "Epoch 2932/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1453958327.3581 - val_loss: 1561819821.8813\n",
      "Epoch 2933/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1453270391.6086 - val_loss: 1561833809.2420\n",
      "Epoch 2934/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1453276145.8474 - val_loss: 1561396551.8904\n",
      "Epoch 2935/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1453637220.5714 - val_loss: 1562411116.7123\n",
      "Epoch 2936/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1453093450.3953 - val_loss: 1562268741.5525\n",
      "Epoch 2937/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1453179571.8513 - val_loss: 1561583741.3699\n",
      "Epoch 2938/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1452909411.5695 - val_loss: 1561709714.1187\n",
      "Epoch 2939/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1453155071.6243 - val_loss: 1561963074.3379\n",
      "Epoch 2940/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1453281580.0861 - val_loss: 1561898068.7489\n",
      "Epoch 2941/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1453413262.5284 - val_loss: 1562665690.8858\n",
      "Epoch 2942/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1452736827.3659 - val_loss: 1561754164.8950\n",
      "Epoch 2943/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1453037870.0900 - val_loss: 1561589735.4521\n",
      "Epoch 2944/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1452928322.8806 - val_loss: 1561751060.7489\n",
      "Epoch 2945/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1453296604.4305 - val_loss: 1560246580.3105\n",
      "Epoch 2946/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1452613289.9569 - val_loss: 1561377572.5297\n",
      "Epoch 2947/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1452939156.7906 - val_loss: 1560903355.9087\n",
      "Epoch 2948/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1452756184.5479 - val_loss: 1561775603.7260\n",
      "Epoch 2949/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1452687403.8356 - val_loss: 1561494608.9498\n",
      "Epoch 2950/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1452567909.3229 - val_loss: 1561173049.5708\n",
      "Epoch 2951/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1452819543.4207 - val_loss: 1561093212.6393\n",
      "Epoch 2952/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1452629662.5597 - val_loss: 1560667295.5616\n",
      "Epoch 2953/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1452746991.8434 - val_loss: 1561100979.4338\n",
      "Epoch 2954/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1452685293.4638 - val_loss: 1560762564.0913\n",
      "Epoch 2955/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1452494248.8297 - val_loss: 1560114960.3653\n",
      "Epoch 2956/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1452479288.8611 - val_loss: 1561492647.7443\n",
      "Epoch 2957/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1452407340.5245 - val_loss: 1560618193.5342\n",
      "Epoch 2958/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1452358241.6908 - val_loss: 1559909538.7763\n",
      "Epoch 2959/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 31us/step - loss: 1452072917.4168 - val_loss: 1560400738.4840\n",
      "Epoch 2960/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1452529558.2935 - val_loss: 1561415784.0365\n",
      "Epoch 2961/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1452053836.2740 - val_loss: 1560298538.3744\n",
      "Epoch 2962/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1451983540.6027 - val_loss: 1560822087.8904\n",
      "Epoch 2963/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1452034533.1977 - val_loss: 1560944593.8265\n",
      "Epoch 2964/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1451974097.9100 - val_loss: 1560773439.4155\n",
      "Epoch 2965/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1451989031.9530 - val_loss: 1560087223.2329\n",
      "Epoch 2966/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1452041159.8904 - val_loss: 1560953821.8082\n",
      "Epoch 2967/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1452005033.5812 - val_loss: 1560687667.1416\n",
      "Epoch 2968/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1451916426.6458 - val_loss: 1560125991.4521\n",
      "Epoch 2969/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1452351980.7123 - val_loss: 1558867707.0320\n",
      "Epoch 2970/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1451882925.2133 - val_loss: 1560021343.2694\n",
      "Epoch 2971/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1451571411.5382 - val_loss: 1559967248.6575\n",
      "Epoch 2972/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1451582864.7828 - val_loss: 1559561268.3105\n",
      "Epoch 2973/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1451789655.9217 - val_loss: 1559860761.1324\n",
      "Epoch 2974/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1451446278.6380 - val_loss: 1559836530.2648\n",
      "Epoch 2975/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1451443957.4795 - val_loss: 1559844869.8447\n",
      "Epoch 2976/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1451592424.9550 - val_loss: 1559727163.6164\n",
      "Epoch 2977/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1451456460.2740 - val_loss: 1559266204.3470\n",
      "Epoch 2978/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1451529629.3072 - val_loss: 1560212235.6895\n",
      "Epoch 2979/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1451386385.2838 - val_loss: 1559848290.7763\n",
      "Epoch 2980/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1451287136.9393 - val_loss: 1559841262.4658\n",
      "Epoch 2981/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1451426351.4677 - val_loss: 1559047729.3881\n",
      "Epoch 2982/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1451367289.8630 - val_loss: 1559535170.3379\n",
      "Epoch 2983/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1451346322.7867 - val_loss: 1559333938.5571\n",
      "Epoch 2984/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1451347762.0978 - val_loss: 1559923133.0776\n",
      "Epoch 2985/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1450919010.5675 - val_loss: 1559328693.1872\n",
      "Epoch 2986/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1451032368.5949 - val_loss: 1559021407.5616\n",
      "Epoch 2987/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1451216789.0411 - val_loss: 1558235089.8265\n",
      "Epoch 2988/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1451130275.4442 - val_loss: 1559159732.6027\n",
      "Epoch 2989/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1450997808.5949 - val_loss: 1558793360.9498\n",
      "Epoch 2990/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1450787478.6693 - val_loss: 1558313653.1872\n",
      "Epoch 2991/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1450983441.5342 - val_loss: 1558999026.2648\n",
      "Epoch 2992/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1451941725.1820 - val_loss: 1557478778.4475\n",
      "Epoch 2993/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1450878023.1389 - val_loss: 1559191632.9498\n",
      "Epoch 2994/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1450859491.4442 - val_loss: 1559500426.8128\n",
      "Epoch 2995/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1450826020.5714 - val_loss: 1558233024.0000\n",
      "Epoch 2996/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1450932936.2661 - val_loss: 1558187082.5205\n",
      "Epoch 2997/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1451259548.3053 - val_loss: 1557364272.5114\n",
      "Epoch 2998/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1450423823.0294 - val_loss: 1559054785.7534\n",
      "Epoch 2999/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1450570723.4442 - val_loss: 1559358959.9269\n",
      "Epoch 3000/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1450380329.2368 - val_loss: 1558503418.1553\n",
      "Epoch 3001/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1450359509.4168 - val_loss: 1558532176.3653\n",
      "Epoch 3002/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1450192875.0841 - val_loss: 1558528977.5342\n",
      "Epoch 3003/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1450606539.8982 - val_loss: 1557039329.0228\n",
      "Epoch 3004/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1450255458.5675 - val_loss: 1558358112.7306\n",
      "Epoch 3005/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1450178556.2427 - val_loss: 1558620558.0274\n",
      "Epoch 3006/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1450644331.4599 - val_loss: 1558146366.2466\n",
      "Epoch 3007/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1450187922.7867 - val_loss: 1558063107.2146\n",
      "Epoch 3008/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1450180038.1370 - val_loss: 1557703796.0183\n",
      "Epoch 3009/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1450121190.9511 - val_loss: 1558762948.0913\n",
      "Epoch 3010/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1450518656.0000 - val_loss: 1557574198.6484\n",
      "Epoch 3011/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1450792091.8043 - val_loss: 1558361074.5571\n",
      "Epoch 3012/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1450995831.8591 - val_loss: 1556368293.6986\n",
      "Epoch 3013/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1449681750.0431 - val_loss: 1557417917.0776\n",
      "Epoch 3014/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1449842761.3933 - val_loss: 1557158850.0457\n",
      "Epoch 3015/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1449947857.6595 - val_loss: 1558134096.9498\n",
      "Epoch 3016/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1450052644.3209 - val_loss: 1557659001.2785\n",
      "Epoch 3017/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1450318067.8513 - val_loss: 1558133092.2374\n",
      "Epoch 3018/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1449601310.1840 - val_loss: 1557522650.3014\n",
      "Epoch 3019/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1449518021.8865 - val_loss: 1557511578.5936\n",
      "Epoch 3020/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1449601239.9843 - val_loss: 1557588951.0868\n",
      "Epoch 3021/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1449481229.5264 - val_loss: 1557694032.6575\n",
      "Epoch 3022/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1449633277.4951 - val_loss: 1557216869.6986\n",
      "Epoch 3023/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 34us/step - loss: 1449589548.5871 - val_loss: 1556110924.8584\n",
      "Epoch 3024/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1449942631.4521 - val_loss: 1556247435.1050\n",
      "Epoch 3025/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1449670633.4560 - val_loss: 1557245020.3470\n",
      "Epoch 3026/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1449167362.2544 - val_loss: 1557198536.1826\n",
      "Epoch 3027/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1449766624.4384 - val_loss: 1556479861.1872\n",
      "Epoch 3028/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1449162031.2172 - val_loss: 1557248954.1553\n",
      "Epoch 3029/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1449308984.8611 - val_loss: 1556836621.7352\n",
      "Epoch 3030/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1449097986.7554 - val_loss: 1556907460.6758\n",
      "Epoch 3031/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1449005388.5245 - val_loss: 1556787700.6027\n",
      "Epoch 3032/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1449172476.3679 - val_loss: 1556353659.0320\n",
      "Epoch 3033/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1449524655.5930 - val_loss: 1556767983.0502\n",
      "Epoch 3034/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1448989694.2466 - val_loss: 1556871019.2511\n",
      "Epoch 3035/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1449059840.1252 - val_loss: 1557175880.1826\n",
      "Epoch 3036/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1449328518.1370 - val_loss: 1555459090.9954\n",
      "Epoch 3037/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1448824656.7828 - val_loss: 1556175241.9361\n",
      "Epoch 3038/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1448680849.0333 - val_loss: 1555833398.6484\n",
      "Epoch 3039/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1448641976.3601 - val_loss: 1556354533.6986\n",
      "Epoch 3040/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1448800770.5049 - val_loss: 1556877680.8037\n",
      "Epoch 3041/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1448897997.6517 - val_loss: 1556439882.5205\n",
      "Epoch 3042/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1448593735.8904 - val_loss: 1555988499.5799\n",
      "Epoch 3043/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1448755624.7045 - val_loss: 1555625978.4475\n",
      "Epoch 3044/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1448461647.7808 - val_loss: 1555848678.8676\n",
      "Epoch 3045/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1448764475.3659 - val_loss: 1556067443.4338\n",
      "Epoch 3046/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1448353117.4325 - val_loss: 1555986946.9224\n",
      "Epoch 3047/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1448813450.2701 - val_loss: 1556117461.3333\n",
      "Epoch 3048/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1448252981.6047 - val_loss: 1555342989.7352\n",
      "Epoch 3049/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1448555383.2329 - val_loss: 1556249685.3333\n",
      "Epoch 3050/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1448307212.5245 - val_loss: 1555669395.2877\n",
      "Epoch 3051/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1448543377.4090 - val_loss: 1556153744.9498\n",
      "Epoch 3052/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1448235772.9941 - val_loss: 1555911496.7671\n",
      "Epoch 3053/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1448636093.6204 - val_loss: 1555459947.5434\n",
      "Epoch 3054/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1448408496.0313 - val_loss: 1555325742.4658\n",
      "Epoch 3055/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1448316724.9159 - val_loss: 1555742578.8493\n",
      "Epoch 3056/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1448242601.0802 - val_loss: 1554832721.2420\n",
      "Epoch 3057/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1447967951.9061 - val_loss: 1554587881.4977\n",
      "Epoch 3058/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1447956545.0020 - val_loss: 1554850763.6895\n",
      "Epoch 3059/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1448219871.8121 - val_loss: 1554267809.8995\n",
      "Epoch 3060/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1447977328.3444 - val_loss: 1555625438.1005\n",
      "Epoch 3061/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1448289065.3307 - val_loss: 1554721180.3470\n",
      "Epoch 3062/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1447663986.9746 - val_loss: 1554933038.4658\n",
      "Epoch 3063/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1447699742.8102 - val_loss: 1555551281.9726\n",
      "Epoch 3064/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1447976519.7652 - val_loss: 1554732145.0959\n",
      "Epoch 3065/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1447718550.5440 - val_loss: 1555127369.9361\n",
      "Epoch 3066/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1447675823.8434 - val_loss: 1555353421.4429\n",
      "Epoch 3067/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1447695130.0509 - val_loss: 1555605266.7032\n",
      "Epoch 3068/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1447373398.1683 - val_loss: 1555019578.4475\n",
      "Epoch 3069/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1447846656.5010 - val_loss: 1554052927.4155\n",
      "Epoch 3070/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1447255238.5127 - val_loss: 1554503568.0731\n",
      "Epoch 3071/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1448786014.1840 - val_loss: 1553654974.2466\n",
      "Epoch 3072/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1447138238.1213 - val_loss: 1555022009.5708\n",
      "Epoch 3073/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1447308727.4834 - val_loss: 1555239763.2877\n",
      "Epoch 3074/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1447494720.6262 - val_loss: 1554446774.0639\n",
      "Epoch 3075/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1447263039.2485 - val_loss: 1554908043.6895\n",
      "Epoch 3076/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1447365576.1409 - val_loss: 1554780467.7260\n",
      "Epoch 3077/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1448238658.0039 - val_loss: 1553652577.6073\n",
      "Epoch 3078/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1447103963.4286 - val_loss: 1554783699.5799\n",
      "Epoch 3079/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1447249873.4090 - val_loss: 1554633405.0776\n",
      "Epoch 3080/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1447014112.6888 - val_loss: 1554098415.6347\n",
      "Epoch 3081/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1446952490.0822 - val_loss: 1554385616.3653\n",
      "Epoch 3082/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1447038495.5616 - val_loss: 1554591226.1553\n",
      "Epoch 3083/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1447331127.6086 - val_loss: 1554648369.3881\n",
      "Epoch 3084/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1447516214.6067 - val_loss: 1552931989.3333\n",
      "Epoch 3085/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1446887411.2250 - val_loss: 1553319422.5388\n",
      "Epoch 3086/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1446931463.0763 - val_loss: 1554199088.5114\n",
      "Epoch 3087/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 33us/step - loss: 1446859994.3014 - val_loss: 1553445631.1233\n",
      "Epoch 3088/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1447058483.3503 - val_loss: 1554546917.9909\n",
      "Epoch 3089/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1446708475.3659 - val_loss: 1553779012.0913\n",
      "Epoch 3090/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1446802977.3151 - val_loss: 1553443083.3973\n",
      "Epoch 3091/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1446734378.7710 - val_loss: 1554091923.2877\n",
      "Epoch 3092/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1446993531.2407 - val_loss: 1553536898.3379\n",
      "Epoch 3093/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1446685333.0411 - val_loss: 1553775825.8265\n",
      "Epoch 3094/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1446838333.3699 - val_loss: 1552661147.7626\n",
      "Epoch 3095/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1446447514.3014 - val_loss: 1553844057.1324\n",
      "Epoch 3096/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1446449330.0978 - val_loss: 1553228772.8219\n",
      "Epoch 3097/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1447475285.1663 - val_loss: 1551733445.5525\n",
      "Epoch 3098/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1446098015.6869 - val_loss: 1553148359.0137\n",
      "Epoch 3099/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1446692510.8102 - val_loss: 1553054369.0228\n",
      "Epoch 3100/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1446307632.7202 - val_loss: 1553709373.3699\n",
      "Epoch 3101/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1446255446.1683 - val_loss: 1553808430.4658\n",
      "Epoch 3102/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1446513501.6830 - val_loss: 1553352460.5662\n",
      "Epoch 3103/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1446446931.4755 - val_loss: 1552809713.9726\n",
      "Epoch 3104/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1446214782.4344 - val_loss: 1552861253.5525\n",
      "Epoch 3105/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1446071739.3659 - val_loss: 1552979536.9498\n",
      "Epoch 3106/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1445903880.7045 - val_loss: 1553190752.7306\n",
      "Epoch 3107/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1445868950.1683 - val_loss: 1553082972.3470\n",
      "Epoch 3108/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1446504581.3855 - val_loss: 1552817113.1324\n",
      "Epoch 3109/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1445768494.3405 - val_loss: 1552877680.5114\n",
      "Epoch 3110/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1445877617.2211 - val_loss: 1552771861.9178\n",
      "Epoch 3111/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1445911381.1663 - val_loss: 1552775636.7489\n",
      "Epoch 3112/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1445829882.4892 - val_loss: 1553190272.5845\n",
      "Epoch 3113/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1446101426.8493 - val_loss: 1552093297.3881\n",
      "Epoch 3114/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1446164971.2094 - val_loss: 1552484140.1279\n",
      "Epoch 3115/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1445825844.7280 - val_loss: 1552204001.8995\n",
      "Epoch 3116/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1445663540.9785 - val_loss: 1553172088.6941\n",
      "Epoch 3117/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1445891052.2114 - val_loss: 1552945279.7078\n",
      "Epoch 3118/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1445528025.8004 - val_loss: 1552550420.7489\n",
      "Epoch 3119/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1446200401.4090 - val_loss: 1551943923.7260\n",
      "Epoch 3120/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1445461349.9491 - val_loss: 1552503697.2420\n",
      "Epoch 3121/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1445413159.4521 - val_loss: 1552638531.2146\n",
      "Epoch 3122/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1445295600.2192 - val_loss: 1552431524.8219\n",
      "Epoch 3123/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1445703016.8297 - val_loss: 1552648838.1370\n",
      "Epoch 3124/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1445499417.2994 - val_loss: 1551570538.0822\n",
      "Epoch 3125/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1445218194.6614 - val_loss: 1552030564.8219\n",
      "Epoch 3126/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1445580265.9569 - val_loss: 1551030599.8904\n",
      "Epoch 3127/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1445204286.2466 - val_loss: 1551904717.1507\n",
      "Epoch 3128/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1445101658.8023 - val_loss: 1552528371.1416\n",
      "Epoch 3129/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1445135333.1977 - val_loss: 1552647157.1872\n",
      "Epoch 3130/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1444943958.4188 - val_loss: 1552074588.9315\n",
      "Epoch 3131/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1445176809.9569 - val_loss: 1551507456.0000\n",
      "Epoch 3132/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1445297467.8669 - val_loss: 1551641250.7763\n",
      "Epoch 3133/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1445177833.9569 - val_loss: 1551604707.3607\n",
      "Epoch 3134/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1445512773.5108 - val_loss: 1552680651.9817\n",
      "Epoch 3135/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1444960218.6771 - val_loss: 1552044830.6849\n",
      "Epoch 3136/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1444847228.3679 - val_loss: 1551548962.1918\n",
      "Epoch 3137/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1445002696.8924 - val_loss: 1550547442.8493\n",
      "Epoch 3138/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1444848651.7730 - val_loss: 1551395844.6758\n",
      "Epoch 3139/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1444889085.4951 - val_loss: 1551274066.7032\n",
      "Epoch 3140/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1444703801.9883 - val_loss: 1551425923.2146\n",
      "Epoch 3141/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1444716845.8395 - val_loss: 1551938550.9406\n",
      "Epoch 3142/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1444477674.7084 - val_loss: 1551462329.2785\n",
      "Epoch 3143/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1444859401.0176 - val_loss: 1551261358.1735\n",
      "Epoch 3144/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1444771972.7593 - val_loss: 1551937981.3699\n",
      "Epoch 3145/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1444640039.3268 - val_loss: 1551232251.3242\n",
      "Epoch 3146/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1444605747.0998 - val_loss: 1551129837.0046\n",
      "Epoch 3147/15000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1444545711.4677 - val_loss: 1551298888.4749\n",
      "Epoch 3148/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1444636504.1722 - val_loss: 1550727435.3973\n",
      "Epoch 3149/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1444380628.9159 - val_loss: 1551195922.7032\n",
      "Epoch 3150/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1445021674.3327 - val_loss: 1551069746.2648\n",
      "Epoch 3151/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 32us/step - loss: 1445223181.0254 - val_loss: 1549852471.2329\n",
      "Epoch 3152/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1444477892.3836 - val_loss: 1551389809.3881\n",
      "Epoch 3153/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1444284785.9726 - val_loss: 1551528077.4429\n",
      "Epoch 3154/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1444527752.7671 - val_loss: 1550649845.1872\n",
      "Epoch 3155/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1444167993.2368 - val_loss: 1550416161.6073\n",
      "Epoch 3156/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1444502467.8826 - val_loss: 1551754432.5845\n",
      "Epoch 3157/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1444918164.7906 - val_loss: 1550628163.5068\n",
      "Epoch 3158/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1444262590.8728 - val_loss: 1551086315.8356\n",
      "Epoch 3159/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1443896050.2231 - val_loss: 1550633507.3607\n",
      "Epoch 3160/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1444459723.3973 - val_loss: 1550737191.4521\n",
      "Epoch 3161/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1444026022.8258 - val_loss: 1551288141.1507\n",
      "Epoch 3162/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1443848129.5029 - val_loss: 1550444711.7443\n",
      "Epoch 3163/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1444206098.7867 - val_loss: 1549718323.1416\n",
      "Epoch 3164/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1445004113.9100 - val_loss: 1551578211.3607\n",
      "Epoch 3165/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1443559533.2133 - val_loss: 1550804057.7169\n",
      "Epoch 3166/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1443841138.2231 - val_loss: 1550962268.0548\n",
      "Epoch 3167/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1443530389.5421 - val_loss: 1550326672.6575\n",
      "Epoch 3168/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1443918711.7339 - val_loss: 1549352718.3196\n",
      "Epoch 3169/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1443582885.3229 - val_loss: 1549919559.8904\n",
      "Epoch 3170/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1443729220.1331 - val_loss: 1549919530.6667\n",
      "Epoch 3171/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1443669757.1194 - val_loss: 1550311339.8356\n",
      "Epoch 3172/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1443899357.8082 - val_loss: 1549748200.3288\n",
      "Epoch 3173/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1443767698.1605 - val_loss: 1550565366.3562\n",
      "Epoch 3174/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1443587627.5851 - val_loss: 1549664709.8447\n",
      "Epoch 3175/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1443684338.7241 - val_loss: 1550372855.2329\n",
      "Epoch 3176/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1443352987.1781 - val_loss: 1549527590.5753\n",
      "Epoch 3177/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1443369523.3503 - val_loss: 1549154070.2100\n",
      "Epoch 3178/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1443276021.8552 - val_loss: 1549679439.7808\n",
      "Epoch 3179/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1443542217.2055 - val_loss: 1549059188.0183\n",
      "Epoch 3180/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1443727627.0215 - val_loss: 1549701345.8995\n",
      "Epoch 3181/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1443148748.3992 - val_loss: 1549379644.2009\n",
      "Epoch 3182/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1443433471.4990 - val_loss: 1549344266.8128\n",
      "Epoch 3183/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1443092568.5479 - val_loss: 1549570739.7260\n",
      "Epoch 3184/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1443074162.0978 - val_loss: 1549561342.2466\n",
      "Epoch 3185/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1442992700.9941 - val_loss: 1549400924.9315\n",
      "Epoch 3186/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1442916366.2779 - val_loss: 1549352919.3790\n",
      "Epoch 3187/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1443076228.5088 - val_loss: 1549318804.4566\n",
      "Epoch 3188/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1443203228.5558 - val_loss: 1550082819.7991\n",
      "Epoch 3189/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1442758017.7534 - val_loss: 1549352912.9498\n",
      "Epoch 3190/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1443065671.6399 - val_loss: 1549279404.4201\n",
      "Epoch 3191/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1442960579.3190 - val_loss: 1549063780.8219\n",
      "Epoch 3192/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1442808168.2035 - val_loss: 1549420619.9817\n",
      "Epoch 3193/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1443284536.3601 - val_loss: 1549401274.7397\n",
      "Epoch 3194/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1443165335.2955 - val_loss: 1549712354.7763\n",
      "Epoch 3195/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1442954762.2701 - val_loss: 1549286644.0183\n",
      "Epoch 3196/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1442922656.0626 - val_loss: 1549272118.9406\n",
      "Epoch 3197/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1442794801.7221 - val_loss: 1548319968.1461\n",
      "Epoch 3198/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1442994373.8865 - val_loss: 1548899735.9635\n",
      "Epoch 3199/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1443028280.1096 - val_loss: 1547942805.0411\n",
      "Epoch 3200/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1442425702.3249 - val_loss: 1548477847.6712\n",
      "Epoch 3201/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1442713984.6888 - val_loss: 1548476070.8676\n",
      "Epoch 3202/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1442824084.0391 - val_loss: 1549180837.9909\n",
      "Epoch 3203/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1442768015.2798 - val_loss: 1548161743.7808\n",
      "Epoch 3204/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1442638585.9883 - val_loss: 1547828887.3790\n",
      "Epoch 3205/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1442186373.6360 - val_loss: 1549037806.1735\n",
      "Epoch 3206/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1442269455.2798 - val_loss: 1549284150.9406\n",
      "Epoch 3207/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1442173804.9628 - val_loss: 1549226965.9178\n",
      "Epoch 3208/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1442510903.9843 - val_loss: 1548573666.7763\n",
      "Epoch 3209/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1442590955.5851 - val_loss: 1547573064.7671\n",
      "Epoch 3210/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1442204533.4795 - val_loss: 1548913537.4612\n",
      "Epoch 3211/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1442203855.9061 - val_loss: 1549217746.1187\n",
      "Epoch 3212/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1442638531.3816 - val_loss: 1548572176.6575\n",
      "Epoch 3213/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1441932431.7808 - val_loss: 1548398111.2694\n",
      "Epoch 3214/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1442072010.3953 - val_loss: 1549004962.1918\n",
      "Epoch 3215/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 31us/step - loss: 1442388037.1350 - val_loss: 1547589641.3516\n",
      "Epoch 3216/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1442166296.4227 - val_loss: 1547796358.4292\n",
      "Epoch 3217/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1441941400.9237 - val_loss: 1548591348.0183\n",
      "Epoch 3218/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1442121945.4247 - val_loss: 1547755229.5160\n",
      "Epoch 3219/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1441918865.5342 - val_loss: 1548150148.3836\n",
      "Epoch 3220/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1441789573.0098 - val_loss: 1548088861.2237\n",
      "Epoch 3221/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1441994906.0509 - val_loss: 1548295234.6301\n",
      "Epoch 3222/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1441834846.1840 - val_loss: 1547570434.3379\n",
      "Epoch 3223/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1441731574.6693 - val_loss: 1547323175.4521\n",
      "Epoch 3224/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1441683364.3209 - val_loss: 1547301472.4384\n",
      "Epoch 3225/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1441850930.3483 - val_loss: 1547833669.8447\n",
      "Epoch 3226/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1441507997.3072 - val_loss: 1547723014.7215\n",
      "Epoch 3227/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1442799408.8454 - val_loss: 1549266597.4064\n",
      "Epoch 3228/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1441513278.6223 - val_loss: 1548066680.1096\n",
      "Epoch 3229/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1441440928.8141 - val_loss: 1547780235.9817\n",
      "Epoch 3230/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1441733142.5440 - val_loss: 1547801732.3836\n",
      "Epoch 3231/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1441438760.4540 - val_loss: 1547823748.6758\n",
      "Epoch 3232/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1441453845.5421 - val_loss: 1547739153.8265\n",
      "Epoch 3233/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1441528588.5871 - val_loss: 1548058189.1507\n",
      "Epoch 3234/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1441760278.7945 - val_loss: 1546349639.0137\n",
      "Epoch 3235/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1441888743.2016 - val_loss: 1547500183.9635\n",
      "Epoch 3236/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1441123328.5010 - val_loss: 1547402297.2785\n",
      "Epoch 3237/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1441322493.2446 - val_loss: 1547126395.6164\n",
      "Epoch 3238/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1441306638.5284 - val_loss: 1547371220.7489\n",
      "Epoch 3239/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1441632478.5597 - val_loss: 1547382111.8539\n",
      "Epoch 3240/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1441270961.9726 - val_loss: 1547314857.4977\n",
      "Epoch 3241/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1441120986.8023 - val_loss: 1547531908.0913\n",
      "Epoch 3242/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1441344719.6556 - val_loss: 1546524185.7169\n",
      "Epoch 3243/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1440890611.3503 - val_loss: 1546877806.7580\n",
      "Epoch 3244/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1441459110.1996 - val_loss: 1546344227.3607\n",
      "Epoch 3245/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1440948673.6282 - val_loss: 1546680492.4201\n",
      "Epoch 3246/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1440928055.1076 - val_loss: 1547365082.8858\n",
      "Epoch 3247/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1441260112.5323 - val_loss: 1546782972.4932\n",
      "Epoch 3248/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1440813407.3112 - val_loss: 1546771334.7215\n",
      "Epoch 3249/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1442009668.1331 - val_loss: 1546969231.7808\n",
      "Epoch 3250/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1440756277.7299 - val_loss: 1547045625.5708\n",
      "Epoch 3251/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1440678864.6575 - val_loss: 1546769969.0959\n",
      "Epoch 3252/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1440856359.7025 - val_loss: 1546594925.0046\n",
      "Epoch 3253/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1440699856.2818 - val_loss: 1546465813.9178\n",
      "Epoch 3254/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1440705781.2290 - val_loss: 1546202363.6164\n",
      "Epoch 3255/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1441443596.2740 - val_loss: 1547451420.0548\n",
      "Epoch 3256/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1441458956.5245 - val_loss: 1546084514.4840\n",
      "Epoch 3257/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1440467657.1429 - val_loss: 1546542840.9863\n",
      "Epoch 3258/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1440606631.3268 - val_loss: 1546051318.0639\n",
      "Epoch 3259/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1440732065.9413 - val_loss: 1546370147.3607\n",
      "Epoch 3260/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1440603602.5362 - val_loss: 1546133588.1644\n",
      "Epoch 3261/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1440336358.5753 - val_loss: 1546380045.7352\n",
      "Epoch 3262/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1440442360.2348 - val_loss: 1546230074.7397\n",
      "Epoch 3263/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1440420589.2133 - val_loss: 1547188082.5571\n",
      "Epoch 3264/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1440440567.6086 - val_loss: 1546042214.2831\n",
      "Epoch 3265/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1440329048.1722 - val_loss: 1546734222.0274\n",
      "Epoch 3266/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1440842163.6008 - val_loss: 1547332760.8402\n",
      "Epoch 3267/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1440822688.1879 - val_loss: 1546415280.5114\n",
      "Epoch 3268/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1440300242.9119 - val_loss: 1546448439.2329\n",
      "Epoch 3269/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1440323122.2231 - val_loss: 1545912281.7169\n",
      "Epoch 3270/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1440216143.9061 - val_loss: 1545818542.7580\n",
      "Epoch 3271/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1441221275.9922 - val_loss: 1546150174.1005\n",
      "Epoch 3272/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1441122389.0411 - val_loss: 1544622032.3653\n",
      "Epoch 3273/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1440057333.7299 - val_loss: 1546068815.7808\n",
      "Epoch 3274/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1440114124.0235 - val_loss: 1546344322.3379\n",
      "Epoch 3275/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1439975778.4423 - val_loss: 1546104285.8082\n",
      "Epoch 3276/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1440095685.8865 - val_loss: 1546269947.0320\n",
      "Epoch 3277/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1440210915.6947 - val_loss: 1546594078.6849\n",
      "Epoch 3278/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1440056722.7867 - val_loss: 1545682462.6849\n",
      "Epoch 3279/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 35us/step - loss: 1439886044.9941 - val_loss: 1545788784.2192\n",
      "Epoch 3280/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1439802234.1135 - val_loss: 1545438395.3242\n",
      "Epoch 3281/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1439929405.8708 - val_loss: 1545328061.0776\n",
      "Epoch 3282/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1440078712.7358 - val_loss: 1546088998.5753\n",
      "Epoch 3283/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1439635416.5479 - val_loss: 1545684249.1324\n",
      "Epoch 3284/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1440102534.8885 - val_loss: 1545318634.9589\n",
      "Epoch 3285/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1439791514.3014 - val_loss: 1546194199.3790\n",
      "Epoch 3286/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1439858947.7573 - val_loss: 1545448989.8082\n",
      "Epoch 3287/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1439479648.4384 - val_loss: 1545831423.4155\n",
      "Epoch 3288/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1439758574.4658 - val_loss: 1546399318.2100\n",
      "Epoch 3289/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1439787799.1076 - val_loss: 1544980273.3881\n",
      "Epoch 3290/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1439676673.2524 - val_loss: 1545928581.8447\n",
      "Epoch 3291/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1439789441.7534 - val_loss: 1544136881.6804\n",
      "Epoch 3292/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1440001482.8963 - val_loss: 1545202322.9954\n",
      "Epoch 3293/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1439606817.8160 - val_loss: 1545586495.7078\n",
      "Epoch 3294/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1439499609.4873 - val_loss: 1545101493.4795\n",
      "Epoch 3295/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1439643613.5577 - val_loss: 1545424774.1370\n",
      "Epoch 3296/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1439413313.8787 - val_loss: 1545687964.6393\n",
      "Epoch 3297/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1439161457.5969 - val_loss: 1545302567.1598\n",
      "Epoch 3298/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1439194259.2877 - val_loss: 1545053319.3059\n",
      "Epoch 3299/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1439467404.6497 - val_loss: 1544907234.1918\n",
      "Epoch 3300/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1439416487.5773 - val_loss: 1544322652.3470\n",
      "Epoch 3301/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1439615133.3072 - val_loss: 1543745841.3881\n",
      "Epoch 3302/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1439251388.4932 - val_loss: 1544950208.0000\n",
      "Epoch 3303/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1439788258.8180 - val_loss: 1544378700.5662\n",
      "Epoch 3304/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1439113435.1781 - val_loss: 1545222087.0137\n",
      "Epoch 3305/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1439031944.2661 - val_loss: 1545216057.5708\n",
      "Epoch 3306/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1439045886.7476 - val_loss: 1545181428.6027\n",
      "Epoch 3307/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1439093537.0333 - val_loss: 1545157276.3470\n",
      "Epoch 3308/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1439590263.8591 - val_loss: 1544538183.0137\n",
      "Epoch 3309/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1438970429.7456 - val_loss: 1544281753.4247\n",
      "Epoch 3310/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1439532148.3523 - val_loss: 1544422296.8402\n",
      "Epoch 3311/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1438882173.2446 - val_loss: 1544996989.6621\n",
      "Epoch 3312/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1438859745.6908 - val_loss: 1544940437.0411\n",
      "Epoch 3313/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1438700888.6732 - val_loss: 1545112576.5845\n",
      "Epoch 3314/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1438704583.2642 - val_loss: 1544389929.7900\n",
      "Epoch 3315/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1438686741.1663 - val_loss: 1545018460.9315\n",
      "Epoch 3316/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1438988935.7652 - val_loss: 1545379129.5708\n",
      "Epoch 3317/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1438569162.8963 - val_loss: 1544076228.3836\n",
      "Epoch 3318/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1438897417.0176 - val_loss: 1544142529.4612\n",
      "Epoch 3319/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1438933167.8434 - val_loss: 1544555830.0639\n",
      "Epoch 3320/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1438545187.8200 - val_loss: 1543910602.5205\n",
      "Epoch 3321/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1438835049.7065 - val_loss: 1543122326.2100\n",
      "Epoch 3322/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1438252810.7710 - val_loss: 1544128506.4475\n",
      "Epoch 3323/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1438384446.3718 - val_loss: 1544465243.1781\n",
      "Epoch 3324/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1438384818.3483 - val_loss: 1544394161.6804\n",
      "Epoch 3325/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1438285855.5616 - val_loss: 1544374253.8813\n",
      "Epoch 3326/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1438320314.4892 - val_loss: 1544221103.6347\n",
      "Epoch 3327/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1438273192.8297 - val_loss: 1544556032.8767\n",
      "Epoch 3328/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1438242312.1409 - val_loss: 1544359360.8767\n",
      "Epoch 3329/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1438151305.0176 - val_loss: 1544089664.2922\n",
      "Epoch 3330/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1438348987.4912 - val_loss: 1544394026.3744\n",
      "Epoch 3331/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1438313769.7065 - val_loss: 1544714090.0822\n",
      "Epoch 3332/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1438602625.5029 - val_loss: 1543569698.7763\n",
      "Epoch 3333/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1439050970.0509 - val_loss: 1544692108.2740\n",
      "Epoch 3334/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1438128572.3679 - val_loss: 1544334493.8082\n",
      "Epoch 3335/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1438103270.7006 - val_loss: 1544148811.1050\n",
      "Epoch 3336/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1438238588.9941 - val_loss: 1543201118.9772\n",
      "Epoch 3337/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1438125084.1800 - val_loss: 1543220691.8721\n",
      "Epoch 3338/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1437871178.2701 - val_loss: 1543862389.4795\n",
      "Epoch 3339/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1437911424.2505 - val_loss: 1544169166.9041\n",
      "Epoch 3340/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1437935187.6634 - val_loss: 1544393152.0000\n",
      "Epoch 3341/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1437778592.5636 - val_loss: 1544072121.8630\n",
      "Epoch 3342/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1437995633.7221 - val_loss: 1542809683.8721\n",
      "Epoch 3343/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 32us/step - loss: 1437884317.9335 - val_loss: 1542843440.2192\n",
      "Epoch 3344/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1438423255.1703 - val_loss: 1542590860.2740\n",
      "Epoch 3345/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1438824760.2348 - val_loss: 1544910025.9361\n",
      "Epoch 3346/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1437749862.7006 - val_loss: 1544357807.0502\n",
      "Epoch 3347/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1438190202.9902 - val_loss: 1542519617.4612\n",
      "Epoch 3348/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1438505346.0039 - val_loss: 1543211705.8630\n",
      "Epoch 3349/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1437709195.7730 - val_loss: 1543538043.9087\n",
      "Epoch 3350/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1437968289.8160 - val_loss: 1542250636.2740\n",
      "Epoch 3351/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1438301889.1272 - val_loss: 1543568921.7169\n",
      "Epoch 3352/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1437880634.8650 - val_loss: 1544283472.0731\n",
      "Epoch 3353/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1438142097.0333 - val_loss: 1542267605.6256\n",
      "Epoch 3354/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1437597952.7515 - val_loss: 1543294011.6164\n",
      "Epoch 3355/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1437553208.9863 - val_loss: 1543306657.0228\n",
      "Epoch 3356/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1437453956.7593 - val_loss: 1542897242.0091\n",
      "Epoch 3357/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1437287255.9217 - val_loss: 1543379789.4429\n",
      "Epoch 3358/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1437504826.2387 - val_loss: 1543560462.6119\n",
      "Epoch 3359/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1437508722.2231 - val_loss: 1543006974.8311\n",
      "Epoch 3360/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1437290092.7123 - val_loss: 1543568511.4155\n",
      "Epoch 3361/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1437413477.4481 - val_loss: 1543715021.4429\n",
      "Epoch 3362/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1437416519.0137 - val_loss: 1543440993.3151\n",
      "Epoch 3363/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1437298286.0900 - val_loss: 1543312798.6849\n",
      "Epoch 3364/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1437373325.4012 - val_loss: 1543316999.3059\n",
      "Epoch 3365/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1437220017.5969 - val_loss: 1543375581.5160\n",
      "Epoch 3366/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1437066065.9100 - val_loss: 1542557625.8630\n",
      "Epoch 3367/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1436975298.3796 - val_loss: 1542830585.2785\n",
      "Epoch 3368/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1437472124.4932 - val_loss: 1542414083.7991\n",
      "Epoch 3369/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1437327136.5636 - val_loss: 1543239281.9726\n",
      "Epoch 3370/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1437051512.6106 - val_loss: 1542062057.7900\n",
      "Epoch 3371/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1437044381.8082 - val_loss: 1543186982.8676\n",
      "Epoch 3372/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1437682659.0685 - val_loss: 1543081142.3562\n",
      "Epoch 3373/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1437410482.5988 - val_loss: 1542240614.8676\n",
      "Epoch 3374/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1437000096.5636 - val_loss: 1542893470.9772\n",
      "Epoch 3375/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1437849413.8865 - val_loss: 1541722561.7534\n",
      "Epoch 3376/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1437345362.4110 - val_loss: 1542676489.0594\n",
      "Epoch 3377/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1436927434.8963 - val_loss: 1542940275.1416\n",
      "Epoch 3378/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1436701252.5714 - val_loss: 1542738475.5434\n",
      "Epoch 3379/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1436889378.8180 - val_loss: 1542891370.9589\n",
      "Epoch 3380/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1436773357.4638 - val_loss: 1542703951.7808\n",
      "Epoch 3381/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1436628326.1996 - val_loss: 1542695367.0137\n",
      "Epoch 3382/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1437719531.4599 - val_loss: 1541269746.2648\n",
      "Epoch 3383/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1436510049.5656 - val_loss: 1541607161.2785\n",
      "Epoch 3384/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1436373582.6536 - val_loss: 1542266112.8767\n",
      "Epoch 3385/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1436472967.5147 - val_loss: 1542479094.3562\n",
      "Epoch 3386/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1436535767.9217 - val_loss: 1542623235.7991\n",
      "Epoch 3387/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1436491176.2035 - val_loss: 1542660399.6347\n",
      "Epoch 3388/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1436570088.8297 - val_loss: 1542135626.5205\n",
      "Epoch 3389/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1436615119.2798 - val_loss: 1542541219.0685\n",
      "Epoch 3390/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1436960665.8004 - val_loss: 1542363712.0000\n",
      "Epoch 3391/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1436842363.7417 - val_loss: 1541693446.1370\n",
      "Epoch 3392/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1436327185.7847 - val_loss: 1542166205.6621\n",
      "Epoch 3393/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1436899599.5303 - val_loss: 1542896256.8767\n",
      "Epoch 3394/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1436472214.6693 - val_loss: 1541579073.4612\n",
      "Epoch 3395/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1437149222.8258 - val_loss: 1542942481.5342\n",
      "Epoch 3396/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1436181639.5147 - val_loss: 1542481288.7671\n",
      "Epoch 3397/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1436348649.8317 - val_loss: 1541211275.3973\n",
      "Epoch 3398/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1435983925.1037 - val_loss: 1541653254.7215\n",
      "Epoch 3399/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1436199183.0294 - val_loss: 1541778334.3927\n",
      "Epoch 3400/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1437247742.4971 - val_loss: 1543201852.7854\n",
      "Epoch 3401/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1436556377.4247 - val_loss: 1541977808.9498\n",
      "Epoch 3402/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1436050455.6712 - val_loss: 1541471831.0868\n",
      "Epoch 3403/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1436030401.1272 - val_loss: 1541482075.7626\n",
      "Epoch 3404/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1436069953.3777 - val_loss: 1542101343.5616\n",
      "Epoch 3405/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1436307409.4090 - val_loss: 1542041018.7397\n",
      "Epoch 3406/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1435985615.1546 - val_loss: 1541426624.2922\n",
      "Epoch 3407/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 41us/step - loss: 1436131690.7084 - val_loss: 1541809595.0320\n",
      "Epoch 3408/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1436149708.1487 - val_loss: 1541157108.0183\n",
      "Epoch 3409/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1435824505.9883 - val_loss: 1541292667.6164\n",
      "Epoch 3410/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1435790867.1624 - val_loss: 1541745490.7032\n",
      "Epoch 3411/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1435839470.7162 - val_loss: 1541481607.8904\n",
      "Epoch 3412/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1436014705.9726 - val_loss: 1541255321.7169\n",
      "Epoch 3413/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1435907780.3836 - val_loss: 1541487685.8447\n",
      "Epoch 3414/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1435712927.5616 - val_loss: 1541689854.5388\n",
      "Epoch 3415/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1436873230.9041 - val_loss: 1540311452.3470\n",
      "Epoch 3416/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1435935074.3170 - val_loss: 1541993671.5982\n",
      "Epoch 3417/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1435898709.6673 - val_loss: 1542015265.3151\n",
      "Epoch 3418/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1435887957.1663 - val_loss: 1540974077.9543\n",
      "Epoch 3419/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1435781815.1703 - val_loss: 1541836051.5799\n",
      "Epoch 3420/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1435956247.5460 - val_loss: 1541195504.5114\n",
      "Epoch 3421/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1435867751.4521 - val_loss: 1542043997.5160\n",
      "Epoch 3422/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1435586346.8337 - val_loss: 1541169418.2283\n",
      "Epoch 3423/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1435720815.9687 - val_loss: 1541021121.7534\n",
      "Epoch 3424/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1435544084.6654 - val_loss: 1541382732.2740\n",
      "Epoch 3425/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1435345246.8102 - val_loss: 1541219673.7169\n",
      "Epoch 3426/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1435562247.2642 - val_loss: 1540706997.1872\n",
      "Epoch 3427/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1435464848.0313 - val_loss: 1541368238.1735\n",
      "Epoch 3428/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1435303053.9022 - val_loss: 1541300201.4977\n",
      "Epoch 3429/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1435689736.7671 - val_loss: 1540644584.9132\n",
      "Epoch 3430/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1435537189.3229 - val_loss: 1541155988.7489\n",
      "Epoch 3431/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1435846215.3894 - val_loss: 1540148900.5297\n",
      "Epoch 3432/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1435352225.4403 - val_loss: 1541529614.6119\n",
      "Epoch 3433/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1435221727.3112 - val_loss: 1541376071.0137\n",
      "Epoch 3434/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1435169283.7573 - val_loss: 1541151504.6575\n",
      "Epoch 3435/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1435089698.0665 - val_loss: 1540475034.0091\n",
      "Epoch 3436/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1435170666.2074 - val_loss: 1541293130.2283\n",
      "Epoch 3437/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1436417665.9413 - val_loss: 1539962893.4429\n",
      "Epoch 3438/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1434855922.7241 - val_loss: 1540575964.6393\n",
      "Epoch 3439/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1434900000.5636 - val_loss: 1540727519.2694\n",
      "Epoch 3440/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1435668846.2153 - val_loss: 1542183067.1781\n",
      "Epoch 3441/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1435162506.9589 - val_loss: 1540326319.0502\n",
      "Epoch 3442/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1435026633.8943 - val_loss: 1540061801.7900\n",
      "Epoch 3443/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1434684453.0724 - val_loss: 1540254662.7215\n",
      "Epoch 3444/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1434850430.2466 - val_loss: 1540898377.9361\n",
      "Epoch 3445/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1435297256.2035 - val_loss: 1541233726.2466\n",
      "Epoch 3446/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1434748331.3346 - val_loss: 1540398376.0365\n",
      "Epoch 3447/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1435283455.8748 - val_loss: 1540050416.8037\n",
      "Epoch 3448/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1434778579.4129 - val_loss: 1540339717.2603\n",
      "Epoch 3449/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1434991947.1468 - val_loss: 1541180425.3516\n",
      "Epoch 3450/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1434717866.4579 - val_loss: 1540691455.1233\n",
      "Epoch 3451/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1435741493.6047 - val_loss: 1542038003.1416\n",
      "Epoch 3452/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1435576500.3523 - val_loss: 1539234920.0365\n",
      "Epoch 3453/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1434956000.6262 - val_loss: 1540340122.5936\n",
      "Epoch 3454/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1434515837.9961 - val_loss: 1540571472.0731\n",
      "Epoch 3455/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1434698584.6732 - val_loss: 1541037945.8630\n",
      "Epoch 3456/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1434828587.9609 - val_loss: 1539662910.2466\n",
      "Epoch 3457/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1434605140.5401 - val_loss: 1539905330.2648\n",
      "Epoch 3458/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1434660711.4521 - val_loss: 1540754174.5388\n",
      "Epoch 3459/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1434518777.9883 - val_loss: 1540175062.2100\n",
      "Epoch 3460/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1434803117.9648 - val_loss: 1539729267.4338\n",
      "Epoch 3461/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1434353127.4521 - val_loss: 1540061506.0457\n",
      "Epoch 3462/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1434316766.0587 - val_loss: 1539761756.3470\n",
      "Epoch 3463/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1434378506.7710 - val_loss: 1540453167.0502\n",
      "Epoch 3464/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1434342031.0294 - val_loss: 1539634592.4384\n",
      "Epoch 3465/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1434214778.7397 - val_loss: 1539991204.8219\n",
      "Epoch 3466/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1434253645.6517 - val_loss: 1539599935.4155\n",
      "Epoch 3467/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1434576175.3425 - val_loss: 1539932226.3379\n",
      "Epoch 3468/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1434378005.7926 - val_loss: 1540518693.4064\n",
      "Epoch 3469/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1434333734.8258 - val_loss: 1540069496.9863\n",
      "Epoch 3470/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1434385583.5930 - val_loss: 1540035569.3881\n",
      "Epoch 3471/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 41us/step - loss: 1434989318.0117 - val_loss: 1540391632.0731\n",
      "Epoch 3472/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1434246324.8532 - val_loss: 1539235695.6347\n",
      "Epoch 3473/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1434433071.5930 - val_loss: 1539093475.9452\n",
      "Epoch 3474/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1434378526.6849 - val_loss: 1539046017.1689\n",
      "Epoch 3475/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1433781769.2055 - val_loss: 1539770986.6667\n",
      "Epoch 3476/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1433969736.6419 - val_loss: 1540135029.1872\n",
      "Epoch 3477/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1434023557.5108 - val_loss: 1539591307.1050\n",
      "Epoch 3478/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1434159667.9765 - val_loss: 1539872347.1781\n",
      "Epoch 3479/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1433936570.3640 - val_loss: 1540207559.3059\n",
      "Epoch 3480/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1434069946.8650 - val_loss: 1538853753.5708\n",
      "Epoch 3481/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1434232158.4344 - val_loss: 1540309506.6301\n",
      "Epoch 3482/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1433810404.0705 - val_loss: 1539405983.2694\n",
      "Epoch 3483/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1434072866.6928 - val_loss: 1539294075.6164\n",
      "Epoch 3484/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1433657564.5558 - val_loss: 1539899682.7763\n",
      "Epoch 3485/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1433592765.3699 - val_loss: 1539733176.9863\n",
      "Epoch 3486/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1433709069.5264 - val_loss: 1539617249.8995\n",
      "Epoch 3487/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1434224395.7730 - val_loss: 1540533823.4155\n",
      "Epoch 3488/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1434514997.7299 - val_loss: 1538284715.8356\n",
      "Epoch 3489/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1433843155.2877 - val_loss: 1539580045.7352\n",
      "Epoch 3490/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1433627615.1859 - val_loss: 1539129660.4932\n",
      "Epoch 3491/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1433932782.5910 - val_loss: 1538616702.8311\n",
      "Epoch 3492/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1433827109.7613 - val_loss: 1538671877.8447\n",
      "Epoch 3493/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1433699691.7104 - val_loss: 1538543868.2009\n",
      "Epoch 3494/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1433388665.1115 - val_loss: 1539674531.9452\n",
      "Epoch 3495/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1433458904.7358 - val_loss: 1540147303.4521\n",
      "Epoch 3496/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1433257191.9530 - val_loss: 1539561314.4840\n",
      "Epoch 3497/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1433327440.1566 - val_loss: 1539432541.2237\n",
      "Epoch 3498/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1433657263.9687 - val_loss: 1538921589.4795\n",
      "Epoch 3499/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1433586084.5714 - val_loss: 1539934403.2146\n",
      "Epoch 3500/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1433236828.8063 - val_loss: 1539530545.3881\n",
      "Epoch 3501/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1433307638.3562 - val_loss: 1539443258.7397\n",
      "Epoch 3502/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1434990245.6986 - val_loss: 1538194970.8858\n",
      "Epoch 3503/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1433412980.9785 - val_loss: 1539562514.4110\n",
      "Epoch 3504/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1433115964.3679 - val_loss: 1539030666.5205\n",
      "Epoch 3505/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1433306029.3386 - val_loss: 1539670437.6986\n",
      "Epoch 3506/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1433101593.4247 - val_loss: 1538930184.1826\n",
      "Epoch 3507/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1433210795.0841 - val_loss: 1539147608.2557\n",
      "Epoch 3508/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1432999835.0528 - val_loss: 1539279165.9543\n",
      "Epoch 3509/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1433125882.3014 - val_loss: 1538903147.5434\n",
      "Epoch 3510/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1433309930.2074 - val_loss: 1538742735.4886\n",
      "Epoch 3511/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1433186085.0724 - val_loss: 1538243570.5571\n",
      "Epoch 3512/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1433011049.8943 - val_loss: 1538621240.1096\n",
      "Epoch 3513/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1432810173.1194 - val_loss: 1538666792.0365\n",
      "Epoch 3514/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1433068028.2427 - val_loss: 1538287691.3973\n",
      "Epoch 3515/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1433288896.3757 - val_loss: 1537684387.9452\n",
      "Epoch 3516/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1432690586.8023 - val_loss: 1538709129.0594\n",
      "Epoch 3517/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1433044214.3562 - val_loss: 1538632291.0685\n",
      "Epoch 3518/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1433093803.3346 - val_loss: 1538435998.9772\n",
      "Epoch 3519/15000\n",
      "1022/1022 [==============================] - 0s 71us/step - loss: 1432695160.3601 - val_loss: 1538996294.4292\n",
      "Epoch 3520/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1432817150.4971 - val_loss: 1538428494.6119\n",
      "Epoch 3521/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1432840969.7691 - val_loss: 1539270268.7854\n",
      "Epoch 3522/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1433103052.9002 - val_loss: 1537971961.8630\n",
      "Epoch 3523/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1433173057.7534 - val_loss: 1538751035.3242\n",
      "Epoch 3524/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1432870639.9687 - val_loss: 1539229494.3562\n",
      "Epoch 3525/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1434041722.2387 - val_loss: 1537019039.5616\n",
      "Epoch 3526/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1433367114.1448 - val_loss: 1539151072.4384\n",
      "Epoch 3527/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1432972133.1350 - val_loss: 1537874045.6621\n",
      "Epoch 3528/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1432594055.3894 - val_loss: 1537839899.4703\n",
      "Epoch 3529/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1432373836.2740 - val_loss: 1538650369.1689\n",
      "Epoch 3530/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1432682026.0822 - val_loss: 1538763879.4521\n",
      "Epoch 3531/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1432667675.5538 - val_loss: 1538264334.0274\n",
      "Epoch 3532/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1432701762.3796 - val_loss: 1538893270.7945\n",
      "Epoch 3533/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1432249722.3640 - val_loss: 1538469003.9817\n",
      "Epoch 3534/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1432837075.7886 - val_loss: 1537470675.5799\n",
      "Epoch 3535/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 33us/step - loss: 1433008566.6067 - val_loss: 1538344750.4658\n",
      "Epoch 3536/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1432643421.6830 - val_loss: 1538630356.1644\n",
      "Epoch 3537/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1432581094.7006 - val_loss: 1538651622.8676\n",
      "Epoch 3538/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1432392072.2661 - val_loss: 1538761138.5571\n",
      "Epoch 3539/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1432451757.5890 - val_loss: 1537535173.2603\n",
      "Epoch 3540/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1432186789.6986 - val_loss: 1537847553.7534\n",
      "Epoch 3541/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1432430909.2446 - val_loss: 1538630889.4977\n",
      "Epoch 3542/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1432488727.0450 - val_loss: 1538241689.7169\n",
      "Epoch 3543/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1432888144.6575 - val_loss: 1536565459.5799\n",
      "Epoch 3544/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1432504841.2681 - val_loss: 1537808486.2831\n",
      "Epoch 3545/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1432578340.7593 - val_loss: 1538975078.5753\n",
      "Epoch 3546/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1431951278.2153 - val_loss: 1538014236.3470\n",
      "Epoch 3547/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1432120877.0881 - val_loss: 1537609368.8402\n",
      "Epoch 3548/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1432044047.0294 - val_loss: 1537362741.4795\n",
      "Epoch 3549/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1432043326.7476 - val_loss: 1537247115.1050\n",
      "Epoch 3550/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1432091495.2016 - val_loss: 1537427483.4703\n",
      "Epoch 3551/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1431999363.0059 - val_loss: 1538332228.6758\n",
      "Epoch 3552/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1432179114.5832 - val_loss: 1537776205.4429\n",
      "Epoch 3553/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1432867735.1703 - val_loss: 1538548634.5936\n",
      "Epoch 3554/15000\n",
      "1022/1022 [==============================] - 0s 65us/step - loss: 1432783754.7710 - val_loss: 1539280273.5342\n",
      "Epoch 3555/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1431754229.7299 - val_loss: 1537937640.3288\n",
      "Epoch 3556/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1431851237.0098 - val_loss: 1537635792.0731\n",
      "Epoch 3557/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1431852370.1605 - val_loss: 1537619328.0000\n",
      "Epoch 3558/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1432182834.0978 - val_loss: 1538067478.7945\n",
      "Epoch 3559/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1431618553.4873 - val_loss: 1537531701.7717\n",
      "Epoch 3560/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1432877593.5499 - val_loss: 1536071005.8082\n",
      "Epoch 3561/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1432165627.8669 - val_loss: 1536738996.6027\n",
      "Epoch 3562/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1431663312.9080 - val_loss: 1536662000.5114\n",
      "Epoch 3563/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1431520481.4403 - val_loss: 1537159479.8174\n",
      "Epoch 3564/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1431831074.3170 - val_loss: 1538068410.4475\n",
      "Epoch 3565/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1431621259.4599 - val_loss: 1537391619.5068\n",
      "Epoch 3566/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1431432825.7378 - val_loss: 1537636832.7306\n",
      "Epoch 3567/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1431462973.1194 - val_loss: 1537490386.9954\n",
      "Epoch 3568/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1431628214.7319 - val_loss: 1537077857.3151\n",
      "Epoch 3569/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1432022416.7828 - val_loss: 1537659085.1507\n",
      "Epoch 3570/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1432455759.4051 - val_loss: 1536043378.5571\n",
      "Epoch 3571/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1431529506.3170 - val_loss: 1537718446.4658\n",
      "Epoch 3572/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1431661194.0196 - val_loss: 1537066543.9269\n",
      "Epoch 3573/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1431585491.0372 - val_loss: 1537896007.0137\n",
      "Epoch 3574/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1431865403.1155 - val_loss: 1536420056.2557\n",
      "Epoch 3575/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1432358122.0822 - val_loss: 1538187704.9863\n",
      "Epoch 3576/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1431221949.1820 - val_loss: 1537093019.4703\n",
      "Epoch 3577/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1431263283.6008 - val_loss: 1537011636.6027\n",
      "Epoch 3578/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1431377140.4775 - val_loss: 1537428007.1598\n",
      "Epoch 3579/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1431301573.3855 - val_loss: 1537738474.6667\n",
      "Epoch 3580/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1431265504.0626 - val_loss: 1536587069.0776\n",
      "Epoch 3581/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1432033999.9061 - val_loss: 1537281614.6119\n",
      "Epoch 3582/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1432470657.8787 - val_loss: 1536160749.8813\n",
      "Epoch 3583/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1431076703.6869 - val_loss: 1536877202.1187\n",
      "Epoch 3584/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1431330063.4051 - val_loss: 1537405709.7352\n",
      "Epoch 3585/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1431282596.0705 - val_loss: 1536962595.9452\n",
      "Epoch 3586/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1431486987.3973 - val_loss: 1537113274.1553\n",
      "Epoch 3587/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1431319772.1800 - val_loss: 1536858664.0365\n",
      "Epoch 3588/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1430960024.2975 - val_loss: 1536332815.1963\n",
      "Epoch 3589/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1430864630.4814 - val_loss: 1536868248.2557\n",
      "Epoch 3590/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1430885035.3346 - val_loss: 1537370910.3927\n",
      "Epoch 3591/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1431015305.7691 - val_loss: 1536627676.0548\n",
      "Epoch 3592/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1430857516.3366 - val_loss: 1536658762.8128\n",
      "Epoch 3593/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1431825818.4266 - val_loss: 1535669121.7534\n",
      "Epoch 3594/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1430783444.4149 - val_loss: 1536583954.4110\n",
      "Epoch 3595/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1430929982.2466 - val_loss: 1537531678.3927\n",
      "Epoch 3596/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1431031874.6928 - val_loss: 1537086392.4018\n",
      "Epoch 3597/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1430802101.3542 - val_loss: 1537084515.0685\n",
      "Epoch 3598/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1431433998.7789 - val_loss: 1536260053.9178\n",
      "Epoch 3599/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 33us/step - loss: 1430713726.7476 - val_loss: 1536325946.1553\n",
      "Epoch 3600/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1431084243.4129 - val_loss: 1537058371.2146\n",
      "Epoch 3601/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1431328962.6301 - val_loss: 1535738188.5662\n",
      "Epoch 3602/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1430670456.1096 - val_loss: 1536244227.2146\n",
      "Epoch 3603/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1431117760.3757 - val_loss: 1537676829.2237\n",
      "Epoch 3604/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1431533377.3777 - val_loss: 1536231530.6667\n",
      "Epoch 3605/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1430536458.2701 - val_loss: 1536645866.6667\n",
      "Epoch 3606/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1430639546.8650 - val_loss: 1536823450.5936\n",
      "Epoch 3607/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1430574528.6262 - val_loss: 1536201961.7900\n",
      "Epoch 3608/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1430795695.8434 - val_loss: 1537340163.5068\n",
      "Epoch 3609/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1430638830.9667 - val_loss: 1536849783.2329\n",
      "Epoch 3610/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1430493609.3307 - val_loss: 1536363085.1507\n",
      "Epoch 3611/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1430616167.3268 - val_loss: 1535743096.1096\n",
      "Epoch 3612/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1430634779.1781 - val_loss: 1536368456.7671\n",
      "Epoch 3613/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1430873783.9843 - val_loss: 1535304213.0411\n",
      "Epoch 3614/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1430359762.9119 - val_loss: 1536485529.7169\n",
      "Epoch 3615/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1430216027.6791 - val_loss: 1536867716.6758\n",
      "Epoch 3616/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1430369521.9726 - val_loss: 1536486371.3607\n",
      "Epoch 3617/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1430955794.5362 - val_loss: 1535140965.9909\n",
      "Epoch 3618/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1430278823.0763 - val_loss: 1536763488.4384\n",
      "Epoch 3619/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1430352826.4892 - val_loss: 1536228136.0365\n",
      "Epoch 3620/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1430288668.3053 - val_loss: 1535912898.0457\n",
      "Epoch 3621/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1430260854.1057 - val_loss: 1535612000.7306\n",
      "Epoch 3622/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1430987920.2818 - val_loss: 1537398321.0959\n",
      "Epoch 3623/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1430422784.5010 - val_loss: 1536868879.7808\n",
      "Epoch 3624/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1430184539.1781 - val_loss: 1535889711.3425\n",
      "Epoch 3625/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1431190958.3405 - val_loss: 1537523436.7123\n",
      "Epoch 3626/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1430548487.5147 - val_loss: 1535179522.0457\n",
      "Epoch 3627/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1429840618.5832 - val_loss: 1535702048.4384\n",
      "Epoch 3628/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1429939757.0881 - val_loss: 1535897496.5479\n",
      "Epoch 3629/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1430256271.7808 - val_loss: 1536044886.2100\n",
      "Epoch 3630/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1429961699.3190 - val_loss: 1535859216.3653\n",
      "Epoch 3631/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1429859258.7397 - val_loss: 1535892446.1005\n",
      "Epoch 3632/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1429911601.8474 - val_loss: 1536077406.3927\n",
      "Epoch 3633/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1430017088.1252 - val_loss: 1535790060.7123\n",
      "Epoch 3634/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1430059512.3601 - val_loss: 1536365812.0183\n",
      "Epoch 3635/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1430147074.1292 - val_loss: 1536571760.2192\n",
      "Epoch 3636/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1430792560.2192 - val_loss: 1534474506.8128\n",
      "Epoch 3637/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1431307267.2564 - val_loss: 1537081300.7489\n",
      "Epoch 3638/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1430299247.7182 - val_loss: 1535803391.4155\n",
      "Epoch 3639/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1429776036.3209 - val_loss: 1535395648.2922\n",
      "Epoch 3640/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1429771203.1311 - val_loss: 1536042690.3379\n",
      "Epoch 3641/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1429688617.3307 - val_loss: 1535378333.5160\n",
      "Epoch 3642/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1429828511.4364 - val_loss: 1535700631.3790\n",
      "Epoch 3643/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1430088133.7613 - val_loss: 1536619126.9406\n",
      "Epoch 3644/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1429799816.5166 - val_loss: 1535039379.2877\n",
      "Epoch 3645/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1429431884.3366 - val_loss: 1535735126.2100\n",
      "Epoch 3646/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1429523830.6067 - val_loss: 1535870326.3562\n",
      "Epoch 3647/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1429610635.5225 - val_loss: 1535043061.1872\n",
      "Epoch 3648/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1429529937.6595 - val_loss: 1535347239.4521\n",
      "Epoch 3649/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1429814593.1272 - val_loss: 1536213547.5434\n",
      "Epoch 3650/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1429458615.8591 - val_loss: 1535975174.7215\n",
      "Epoch 3651/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1429421013.0411 - val_loss: 1535341006.0274\n",
      "Epoch 3652/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1429373850.1761 - val_loss: 1535513795.7991\n",
      "Epoch 3653/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1430113981.4951 - val_loss: 1534801338.7397\n",
      "Epoch 3654/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1429445285.6986 - val_loss: 1535928339.2877\n",
      "Epoch 3655/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1429689623.2955 - val_loss: 1535121369.1324\n",
      "Epoch 3656/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1429450878.4971 - val_loss: 1535030072.1096\n",
      "Epoch 3657/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1429261914.6771 - val_loss: 1535110346.2283\n",
      "Epoch 3658/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1429569967.7182 - val_loss: 1536268596.6027\n",
      "Epoch 3659/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1429426068.4149 - val_loss: 1535801344.2922\n",
      "Epoch 3660/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1429148281.1115 - val_loss: 1535571443.4338\n",
      "Epoch 3661/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1429696734.8102 - val_loss: 1535045684.8950\n",
      "Epoch 3662/15000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1429205983.1859 - val_loss: 1535718761.2055\n",
      "Epoch 3663/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 45us/step - loss: 1429096324.7593 - val_loss: 1535727551.4155\n",
      "Epoch 3664/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1429394263.9217 - val_loss: 1535612820.4566\n",
      "Epoch 3665/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1429373295.0920 - val_loss: 1535009208.4018\n",
      "Epoch 3666/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1429157085.9335 - val_loss: 1534786607.3425\n",
      "Epoch 3667/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1429051325.9961 - val_loss: 1535395933.8082\n",
      "Epoch 3668/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1429238520.2348 - val_loss: 1535134050.4840\n",
      "Epoch 3669/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1429125982.3092 - val_loss: 1534538788.2374\n",
      "Epoch 3670/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1429071709.9335 - val_loss: 1535378722.4840\n",
      "Epoch 3671/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1428972037.4481 - val_loss: 1535070395.9087\n",
      "Epoch 3672/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1429401988.2583 - val_loss: 1534504112.2192\n",
      "Epoch 3673/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1428824658.0352 - val_loss: 1535018811.3242\n",
      "Epoch 3674/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1429013539.8200 - val_loss: 1534684393.7900\n",
      "Epoch 3675/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1428964548.8845 - val_loss: 1535251223.3790\n",
      "Epoch 3676/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1428845992.8297 - val_loss: 1534901929.2055\n",
      "Epoch 3677/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1428838110.5597 - val_loss: 1534883125.1872\n",
      "Epoch 3678/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1428999666.9746 - val_loss: 1535887880.4749\n",
      "Epoch 3679/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1428906211.1937 - val_loss: 1534766115.9452\n",
      "Epoch 3680/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1428865476.7593 - val_loss: 1534346968.5479\n",
      "Epoch 3681/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1428731571.3503 - val_loss: 1534775861.4795\n",
      "Epoch 3682/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1429010157.9648 - val_loss: 1535961975.5251\n",
      "Epoch 3683/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1428868276.3523 - val_loss: 1535367658.6667\n",
      "Epoch 3684/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1428600365.3386 - val_loss: 1534281663.1233\n",
      "Epoch 3685/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1428756922.3640 - val_loss: 1535309610.3744\n",
      "Epoch 3686/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1429342700.1487 - val_loss: 1534113963.5434\n",
      "Epoch 3687/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1428678597.5108 - val_loss: 1534952589.4429\n",
      "Epoch 3688/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1429190896.4697 - val_loss: 1535888248.6941\n",
      "Epoch 3689/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1428675901.6204 - val_loss: 1534391585.8995\n",
      "Epoch 3690/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1428764350.1213 - val_loss: 1535195873.6073\n",
      "Epoch 3691/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1428596905.4560 - val_loss: 1535066097.9726\n",
      "Epoch 3692/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1428695793.2211 - val_loss: 1534515111.1598\n",
      "Epoch 3693/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1428523663.2798 - val_loss: 1534230737.2420\n",
      "Epoch 3694/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1428272094.4344 - val_loss: 1534478589.0776\n",
      "Epoch 3695/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1428870594.1292 - val_loss: 1535488382.8311\n",
      "Epoch 3696/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1428391892.4149 - val_loss: 1534639744.2922\n",
      "Epoch 3697/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1429085441.5029 - val_loss: 1533084747.3973\n",
      "Epoch 3698/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1428370444.9002 - val_loss: 1534630374.5753\n",
      "Epoch 3699/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1428402381.1507 - val_loss: 1535178119.8904\n",
      "Epoch 3700/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1428302446.8415 - val_loss: 1534786013.5160\n",
      "Epoch 3701/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1428681245.5577 - val_loss: 1533926891.5434\n",
      "Epoch 3702/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1428602944.1252 - val_loss: 1535253051.6164\n",
      "Epoch 3703/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1428110273.6282 - val_loss: 1534538312.4749\n",
      "Epoch 3704/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1428787380.7280 - val_loss: 1533883386.4475\n",
      "Epoch 3705/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1428230746.0509 - val_loss: 1534535197.8082\n",
      "Epoch 3706/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1428543125.2916 - val_loss: 1534440069.8447\n",
      "Epoch 3707/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1428239257.9256 - val_loss: 1534415688.4749\n",
      "Epoch 3708/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1428406457.3620 - val_loss: 1535372087.2329\n",
      "Epoch 3709/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1428501652.7906 - val_loss: 1533945170.1187\n",
      "Epoch 3710/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1428636823.2955 - val_loss: 1533071481.2785\n",
      "Epoch 3711/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1428759001.9256 - val_loss: 1535211789.7352\n",
      "Epoch 3712/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1428101134.0274 - val_loss: 1534682190.9041\n",
      "Epoch 3713/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1428479774.5597 - val_loss: 1534203830.0639\n",
      "Epoch 3714/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1428126569.2055 - val_loss: 1534465181.8082\n",
      "Epoch 3715/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1427957785.8004 - val_loss: 1534013546.6667\n",
      "Epoch 3716/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1428196390.0744 - val_loss: 1534785745.2420\n",
      "Epoch 3717/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1428290773.6673 - val_loss: 1533978660.2374\n",
      "Epoch 3718/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1427985206.1057 - val_loss: 1534265696.1461\n",
      "Epoch 3719/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1427971343.2798 - val_loss: 1533826448.6575\n",
      "Epoch 3720/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1427981509.6360 - val_loss: 1534731459.5068\n",
      "Epoch 3721/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1427782927.2798 - val_loss: 1534102800.0731\n",
      "Epoch 3722/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1428084267.7104 - val_loss: 1534011407.4886\n",
      "Epoch 3723/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1427926549.2916 - val_loss: 1534599405.8813\n",
      "Epoch 3724/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1428406362.9276 - val_loss: 1533934613.9178\n",
      "Epoch 3725/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1428129128.5793 - val_loss: 1534655315.8721\n",
      "Epoch 3726/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1428204257.4403 - val_loss: 1533196930.0457\n",
      "Epoch 3727/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 31us/step - loss: 1427881689.9256 - val_loss: 1534620541.3699\n",
      "Epoch 3728/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1427674766.9041 - val_loss: 1534202715.7626\n",
      "Epoch 3729/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1428022598.8885 - val_loss: 1534668261.9909\n",
      "Epoch 3730/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1427765186.0039 - val_loss: 1533606314.6667\n",
      "Epoch 3731/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1427662776.1096 - val_loss: 1533960225.3151\n",
      "Epoch 3732/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1427750976.0000 - val_loss: 1534539194.7397\n",
      "Epoch 3733/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1428141144.5479 - val_loss: 1534133359.0502\n",
      "Epoch 3734/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1427502784.5010 - val_loss: 1533845887.4155\n",
      "Epoch 3735/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1427386912.6888 - val_loss: 1533484139.2511\n",
      "Epoch 3736/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1427526953.0802 - val_loss: 1534012921.2785\n",
      "Epoch 3737/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1428003530.0196 - val_loss: 1532828470.6484\n",
      "Epoch 3738/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1427353723.9922 - val_loss: 1533595029.3333\n",
      "Epoch 3739/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1427665521.2211 - val_loss: 1534425794.3379\n",
      "Epoch 3740/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1427951900.3053 - val_loss: 1534469339.7626\n",
      "Epoch 3741/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1427460173.1507 - val_loss: 1533647919.3425\n",
      "Epoch 3742/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1427499994.3014 - val_loss: 1533301932.7123\n",
      "Epoch 3743/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1427172033.0020 - val_loss: 1534014960.8037\n",
      "Epoch 3744/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1428000888.7358 - val_loss: 1532905372.6393\n",
      "Epoch 3745/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1428203183.0920 - val_loss: 1534287527.4521\n",
      "Epoch 3746/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1427542767.7182 - val_loss: 1533670414.6119\n",
      "Epoch 3747/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1427281314.0039 - val_loss: 1534091489.0228\n",
      "Epoch 3748/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1427164766.0587 - val_loss: 1533712903.0137\n",
      "Epoch 3749/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1427929813.7926 - val_loss: 1534577130.3744\n",
      "Epoch 3750/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1427539554.3170 - val_loss: 1533123977.6438\n",
      "Epoch 3751/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1427634470.7006 - val_loss: 1534191123.5799\n",
      "Epoch 3752/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1427380584.4540 - val_loss: 1533872949.4795\n",
      "Epoch 3753/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1427293580.7750 - val_loss: 1533924643.3607\n",
      "Epoch 3754/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1427039504.5323 - val_loss: 1533427401.9361\n",
      "Epoch 3755/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1427533896.6419 - val_loss: 1532476580.2374\n",
      "Epoch 3756/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1426801433.9256 - val_loss: 1533661309.6621\n",
      "Epoch 3757/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1427297429.2916 - val_loss: 1534487527.4521\n",
      "Epoch 3758/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1427303327.0607 - val_loss: 1533137292.2740\n",
      "Epoch 3759/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1427179847.6399 - val_loss: 1532682090.3744\n",
      "Epoch 3760/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1427228151.7339 - val_loss: 1534116831.2694\n",
      "Epoch 3761/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1426956891.4286 - val_loss: 1533617592.4018\n",
      "Epoch 3762/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1427526602.5205 - val_loss: 1533145579.5434\n",
      "Epoch 3763/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1427227713.5029 - val_loss: 1532728021.0411\n",
      "Epoch 3764/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1426716780.7123 - val_loss: 1533786344.3288\n",
      "Epoch 3765/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1426967674.4892 - val_loss: 1533162004.7489\n",
      "Epoch 3766/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1426680702.9980 - val_loss: 1533566237.8082\n",
      "Epoch 3767/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1427421304.4853 - val_loss: 1532802636.2740\n",
      "Epoch 3768/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1427144455.3894 - val_loss: 1534082977.0228\n",
      "Epoch 3769/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1427041657.2368 - val_loss: 1533340876.5662\n",
      "Epoch 3770/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1426690497.1898 - val_loss: 1533442661.1142\n",
      "Epoch 3771/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1427063636.1644 - val_loss: 1533855864.1096\n",
      "Epoch 3772/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1427007888.7828 - val_loss: 1532802862.1735\n",
      "Epoch 3773/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1426925907.9139 - val_loss: 1533876444.9315\n",
      "Epoch 3774/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1426790013.7456 - val_loss: 1533568821.7717\n",
      "Epoch 3775/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1426735542.1057 - val_loss: 1533014563.0685\n",
      "Epoch 3776/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1426553244.4305 - val_loss: 1532801878.2100\n",
      "Epoch 3777/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1426565497.7378 - val_loss: 1533527415.5251\n",
      "Epoch 3778/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1426683949.8395 - val_loss: 1533697387.8356\n",
      "Epoch 3779/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1426400776.2661 - val_loss: 1533355984.0731\n",
      "Epoch 3780/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1426869692.8689 - val_loss: 1533836920.4018\n",
      "Epoch 3781/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1426565121.5029 - val_loss: 1532828387.3607\n",
      "Epoch 3782/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1426544541.8082 - val_loss: 1532934065.9726\n",
      "Epoch 3783/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1426386876.3679 - val_loss: 1533250995.4338\n",
      "Epoch 3784/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1426779234.4423 - val_loss: 1532430938.5936\n",
      "Epoch 3785/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1426484502.2935 - val_loss: 1533006430.9772\n",
      "Epoch 3786/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1426278779.2407 - val_loss: 1532941971.5799\n",
      "Epoch 3787/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1426279801.3620 - val_loss: 1533112209.2420\n",
      "Epoch 3788/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1426362542.0900 - val_loss: 1532782340.0913\n",
      "Epoch 3789/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1426512489.8317 - val_loss: 1532886941.5160\n",
      "Epoch 3790/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1426422461.8708 - val_loss: 1533259683.3607\n",
      "Epoch 3791/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 33us/step - loss: 1426906135.1703 - val_loss: 1533196531.4338\n",
      "Epoch 3792/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1426497195.0841 - val_loss: 1532725309.9543\n",
      "Epoch 3793/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1426649812.5401 - val_loss: 1532766087.8904\n",
      "Epoch 3794/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1426483196.4932 - val_loss: 1533240524.8584\n",
      "Epoch 3795/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1427566158.2779 - val_loss: 1531406522.4475\n",
      "Epoch 3796/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1425944690.8493 - val_loss: 1533341962.5205\n",
      "Epoch 3797/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1426710869.7926 - val_loss: 1534144835.5068\n",
      "Epoch 3798/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1425938372.3836 - val_loss: 1533103712.7306\n",
      "Epoch 3799/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1426548267.5851 - val_loss: 1533136203.6895\n",
      "Epoch 3800/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1425983909.5734 - val_loss: 1532577169.2420\n",
      "Epoch 3801/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1426321286.2622 - val_loss: 1532520756.8950\n",
      "Epoch 3802/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1426014000.3444 - val_loss: 1532922659.6530\n",
      "Epoch 3803/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1426114662.2622 - val_loss: 1532700324.5297\n",
      "Epoch 3804/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1425894676.5401 - val_loss: 1532735497.0594\n",
      "Epoch 3805/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1425962148.6967 - val_loss: 1532483181.2968\n",
      "Epoch 3806/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1425910384.0939 - val_loss: 1532931272.1826\n",
      "Epoch 3807/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1425883426.0665 - val_loss: 1533013404.9315\n",
      "Epoch 3808/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1426054546.7867 - val_loss: 1533073511.7443\n",
      "Epoch 3809/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1425850670.3405 - val_loss: 1532179385.2785\n",
      "Epoch 3810/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1425689564.6810 - val_loss: 1532569684.1644\n",
      "Epoch 3811/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1425964518.5127 - val_loss: 1532176618.9589\n",
      "Epoch 3812/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1426412945.0333 - val_loss: 1533616983.9635\n",
      "Epoch 3813/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1425644958.0587 - val_loss: 1533019835.9087\n",
      "Epoch 3814/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1425897950.3092 - val_loss: 1532384668.3470\n",
      "Epoch 3815/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1425663196.9315 - val_loss: 1532203695.9269\n",
      "Epoch 3816/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1425663367.7652 - val_loss: 1532607578.0091\n",
      "Epoch 3817/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1425625062.9511 - val_loss: 1532073656.6941\n",
      "Epoch 3818/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1426199656.4540 - val_loss: 1533419375.3425\n",
      "Epoch 3819/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1425546636.0235 - val_loss: 1532361913.8630\n",
      "Epoch 3820/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1425528906.8963 - val_loss: 1532533209.1324\n",
      "Epoch 3821/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1425907897.3620 - val_loss: 1533211068.2009\n",
      "Epoch 3822/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1426628486.8258 - val_loss: 1531785565.5160\n",
      "Epoch 3823/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1425888314.6145 - val_loss: 1532274845.8082\n",
      "Epoch 3824/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1425378909.8082 - val_loss: 1532509045.1872\n",
      "Epoch 3825/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1426378310.1370 - val_loss: 1530948777.7900\n",
      "Epoch 3826/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1425613258.1448 - val_loss: 1533153753.1324\n",
      "Epoch 3827/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1425645694.2466 - val_loss: 1532492293.8447\n",
      "Epoch 3828/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1426687887.5303 - val_loss: 1532037413.9909\n",
      "Epoch 3829/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1425572512.0626 - val_loss: 1533312500.3105\n",
      "Epoch 3830/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1425910465.0020 - val_loss: 1531853978.0091\n",
      "Epoch 3831/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1425323844.9472 - val_loss: 1532017360.6575\n",
      "Epoch 3832/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1425657021.1194 - val_loss: 1532701624.4018\n",
      "Epoch 3833/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1425685366.1057 - val_loss: 1531867784.4749\n",
      "Epoch 3834/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1425334792.1409 - val_loss: 1532451765.7717\n",
      "Epoch 3835/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1425300029.8708 - val_loss: 1532251337.0594\n",
      "Epoch 3836/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1425862197.6047 - val_loss: 1532112217.1324\n",
      "Epoch 3837/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1425145168.6575 - val_loss: 1532044492.2740\n",
      "Epoch 3838/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1426341328.7828 - val_loss: 1533192163.9452\n",
      "Epoch 3839/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1425664087.1703 - val_loss: 1533249787.0320\n",
      "Epoch 3840/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1425691570.0978 - val_loss: 1531826387.8721\n",
      "Epoch 3841/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1425255347.8513 - val_loss: 1531854875.4703\n",
      "Epoch 3842/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1425073296.2192 - val_loss: 1532521491.8721\n",
      "Epoch 3843/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1425246516.3523 - val_loss: 1531900886.7945\n",
      "Epoch 3844/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1425916053.0411 - val_loss: 1532359488.0000\n",
      "Epoch 3845/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1425128044.4618 - val_loss: 1532163847.5982\n",
      "Epoch 3846/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1425228694.4188 - val_loss: 1532419067.9087\n",
      "Epoch 3847/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1425219828.2270 - val_loss: 1532340038.1370\n",
      "Epoch 3848/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1425156504.5479 - val_loss: 1532567607.8174\n",
      "Epoch 3849/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1424975687.2642 - val_loss: 1531841064.9132\n",
      "Epoch 3850/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1424920235.8356 - val_loss: 1532129052.3470\n",
      "Epoch 3851/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1425123878.8258 - val_loss: 1532649875.5799\n",
      "Epoch 3852/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1424903326.9354 - val_loss: 1531974473.3516\n",
      "Epoch 3853/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1425100384.4384 - val_loss: 1531343511.3790\n",
      "Epoch 3854/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1425332565.2916 - val_loss: 1532529674.5205\n",
      "Epoch 3855/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 32us/step - loss: 1424868152.8611 - val_loss: 1531617682.9954\n",
      "Epoch 3856/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1425324265.9569 - val_loss: 1531606762.6667\n",
      "Epoch 3857/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1424977575.8278 - val_loss: 1531452448.1461\n",
      "Epoch 3858/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1424757934.0900 - val_loss: 1532329391.0502\n",
      "Epoch 3859/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1424943235.8826 - val_loss: 1531373624.6941\n",
      "Epoch 3860/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1425338069.7926 - val_loss: 1532366945.3151\n",
      "Epoch 3861/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1424779241.4560 - val_loss: 1532348668.7854\n",
      "Epoch 3862/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1424804386.7554 - val_loss: 1531367822.6119\n",
      "Epoch 3863/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1425397915.9922 - val_loss: 1531480069.5525\n",
      "Epoch 3864/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1425452636.0548 - val_loss: 1530801422.6119\n",
      "Epoch 3865/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1424633896.2035 - val_loss: 1532217026.9224\n",
      "Epoch 3866/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1424845499.3659 - val_loss: 1531653511.5982\n",
      "Epoch 3867/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1424640902.3249 - val_loss: 1531575754.5205\n",
      "Epoch 3868/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1425511399.7025 - val_loss: 1533224960.0000\n",
      "Epoch 3869/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1424635839.8748 - val_loss: 1531957884.4932\n",
      "Epoch 3870/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1424574742.2935 - val_loss: 1531493328.0731\n",
      "Epoch 3871/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1424619585.5029 - val_loss: 1531883112.6210\n",
      "Epoch 3872/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1424815041.1272 - val_loss: 1532318718.5388\n",
      "Epoch 3873/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1424417152.3757 - val_loss: 1531616588.5662\n",
      "Epoch 3874/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1425005010.6614 - val_loss: 1532053943.5251\n",
      "Epoch 3875/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1424522510.7789 - val_loss: 1531533265.2420\n",
      "Epoch 3876/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1424424812.8376 - val_loss: 1531651436.1279\n",
      "Epoch 3877/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1424621887.4364 - val_loss: 1530668650.0822\n",
      "Epoch 3878/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1425073575.5773 - val_loss: 1530365450.2283\n",
      "Epoch 3879/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1425301401.4247 - val_loss: 1531605888.5845\n",
      "Epoch 3880/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1424552804.1957 - val_loss: 1531916317.2237\n",
      "Epoch 3881/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1424298977.4403 - val_loss: 1531812709.4064\n",
      "Epoch 3882/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1425015158.3562 - val_loss: 1530676645.9909\n",
      "Epoch 3883/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1424540127.0607 - val_loss: 1531279225.5708\n",
      "Epoch 3884/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1424517425.2211 - val_loss: 1532272687.0502\n",
      "Epoch 3885/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1425769967.5930 - val_loss: 1530261793.6073\n",
      "Epoch 3886/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1424084605.9961 - val_loss: 1531789928.0365\n",
      "Epoch 3887/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1424266203.0528 - val_loss: 1531453980.9315\n",
      "Epoch 3888/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1424249544.6419 - val_loss: 1531435119.3425\n",
      "Epoch 3889/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1424300104.7671 - val_loss: 1531726161.5342\n",
      "Epoch 3890/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1424245165.4638 - val_loss: 1531863820.8584\n",
      "Epoch 3891/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1424718098.9119 - val_loss: 1530581837.4429\n",
      "Epoch 3892/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1424537812.4149 - val_loss: 1532185913.5708\n",
      "Epoch 3893/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1424664480.8141 - val_loss: 1531693008.9498\n",
      "Epoch 3894/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1424318543.6556 - val_loss: 1530889911.8174\n",
      "Epoch 3895/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1424241037.1507 - val_loss: 1531736934.5753\n",
      "Epoch 3896/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1424104596.0391 - val_loss: 1531941266.4110\n",
      "Epoch 3897/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1424052770.3170 - val_loss: 1531961156.0913\n",
      "Epoch 3898/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1424437519.0294 - val_loss: 1530890889.9361\n",
      "Epoch 3899/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1424099055.9687 - val_loss: 1531764269.8813\n",
      "Epoch 3900/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1423932686.0274 - val_loss: 1531453515.9817\n",
      "Epoch 3901/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1424008767.3738 - val_loss: 1530864515.2146\n",
      "Epoch 3902/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1423922859.0841 - val_loss: 1531407578.3014\n",
      "Epoch 3903/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1424130745.0489 - val_loss: 1531117208.5479\n",
      "Epoch 3904/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1423993852.1174 - val_loss: 1530775459.6530\n",
      "Epoch 3905/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1424332692.1644 - val_loss: 1531718552.5479\n",
      "Epoch 3906/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1424211669.6673 - val_loss: 1531217472.0000\n",
      "Epoch 3907/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1424043388.4932 - val_loss: 1531752245.4795\n",
      "Epoch 3908/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1424245044.3523 - val_loss: 1530818382.9041\n",
      "Epoch 3909/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1423827731.7886 - val_loss: 1531303071.2694\n",
      "Epoch 3910/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1423858514.4110 - val_loss: 1531210306.6301\n",
      "Epoch 3911/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1423841561.8004 - val_loss: 1531487127.6712\n",
      "Epoch 3912/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1423928587.8982 - val_loss: 1530908385.6073\n",
      "Epoch 3913/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1423819029.7926 - val_loss: 1531262354.9954\n",
      "Epoch 3914/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1423618936.7358 - val_loss: 1531279621.2603\n",
      "Epoch 3915/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1423704144.7828 - val_loss: 1531073930.2283\n",
      "Epoch 3916/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1423580830.5597 - val_loss: 1530960746.9589\n",
      "Epoch 3917/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1423634880.6262 - val_loss: 1531111929.5708\n",
      "Epoch 3918/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1424170224.4697 - val_loss: 1531448966.7215\n",
      "Epoch 3919/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 38us/step - loss: 1424160299.2720 - val_loss: 1530195870.3927\n",
      "Epoch 3920/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1424204978.5988 - val_loss: 1532136900.6758\n",
      "Epoch 3921/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1423416036.5714 - val_loss: 1531244305.2420\n",
      "Epoch 3922/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1423410043.2407 - val_loss: 1531205897.3516\n",
      "Epoch 3923/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1423699802.4266 - val_loss: 1531091034.0091\n",
      "Epoch 3924/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1423798335.1233 - val_loss: 1530954131.5799\n",
      "Epoch 3925/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1423440348.4305 - val_loss: 1530254293.6256\n",
      "Epoch 3926/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1423741307.7417 - val_loss: 1529649423.1963\n",
      "Epoch 3927/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1424133483.7104 - val_loss: 1531113782.0639\n",
      "Epoch 3928/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1423305028.0078 - val_loss: 1531148920.1096\n",
      "Epoch 3929/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1423363949.4638 - val_loss: 1531065376.4384\n",
      "Epoch 3930/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1423404392.2035 - val_loss: 1531124970.0822\n",
      "Epoch 3931/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1423284131.3190 - val_loss: 1530936732.6393\n",
      "Epoch 3932/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1423864818.4736 - val_loss: 1531293648.0731\n",
      "Epoch 3933/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1423248842.7710 - val_loss: 1530934402.6301\n",
      "Epoch 3934/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1423752741.4481 - val_loss: 1531383117.1507\n",
      "Epoch 3935/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1424417554.5362 - val_loss: 1529097108.1644\n",
      "Epoch 3936/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1423426389.4168 - val_loss: 1531012390.2831\n",
      "Epoch 3937/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1423361512.9550 - val_loss: 1530645451.9817\n",
      "Epoch 3938/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1423290880.2505 - val_loss: 1530624584.4749\n",
      "Epoch 3939/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1423768972.5245 - val_loss: 1529979815.1598\n",
      "Epoch 3940/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1423740308.2896 - val_loss: 1531138267.7626\n",
      "Epoch 3941/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1423269018.8023 - val_loss: 1531134056.0365\n",
      "Epoch 3942/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1424252374.6693 - val_loss: 1530017561.7169\n",
      "Epoch 3943/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1423568698.2387 - val_loss: 1531402992.5114\n",
      "Epoch 3944/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1423181040.4697 - val_loss: 1530803266.3379\n",
      "Epoch 3945/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1423466598.9511 - val_loss: 1531103495.3059\n",
      "Epoch 3946/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1423463465.9569 - val_loss: 1529842677.7717\n",
      "Epoch 3947/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1422890169.2368 - val_loss: 1530715420.0548\n",
      "Epoch 3948/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1423095185.1585 - val_loss: 1530990499.0685\n",
      "Epoch 3949/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1422949441.3777 - val_loss: 1530646369.3151\n",
      "Epoch 3950/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1423373636.8845 - val_loss: 1530801010.8493\n",
      "Epoch 3951/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1424077331.9139 - val_loss: 1530815848.6210\n",
      "Epoch 3952/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1423097859.5068 - val_loss: 1530165041.6804\n",
      "Epoch 3953/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1422983467.3346 - val_loss: 1530747454.8311\n",
      "Epoch 3954/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1422895854.2153 - val_loss: 1530200874.0822\n",
      "Epoch 3955/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1422809950.8102 - val_loss: 1530126228.4566\n",
      "Epoch 3956/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1422876046.2779 - val_loss: 1530900334.1735\n",
      "Epoch 3957/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1423410800.9706 - val_loss: 1530049885.5160\n",
      "Epoch 3958/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1422782524.8689 - val_loss: 1530089162.5205\n",
      "Epoch 3959/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1422867706.9902 - val_loss: 1530216699.3242\n",
      "Epoch 3960/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1422933923.5695 - val_loss: 1530221143.0868\n",
      "Epoch 3961/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1422650618.1135 - val_loss: 1530431440.0731\n",
      "Epoch 3962/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1422723459.1311 - val_loss: 1531124987.6164\n",
      "Epoch 3963/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1422944974.4031 - val_loss: 1530268919.8174\n",
      "Epoch 3964/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1422585698.1918 - val_loss: 1530404448.4384\n",
      "Epoch 3965/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1422653376.8767 - val_loss: 1530395997.2237\n",
      "Epoch 3966/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1423281480.0157 - val_loss: 1530195466.5205\n",
      "Epoch 3967/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1423001131.0841 - val_loss: 1530073115.7626\n",
      "Epoch 3968/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1422818979.4442 - val_loss: 1530916017.0959\n",
      "Epoch 3969/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1422709822.8728 - val_loss: 1530855151.6347\n",
      "Epoch 3970/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1422962359.8591 - val_loss: 1530904977.2420\n",
      "Epoch 3971/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1422522695.8904 - val_loss: 1530698566.4292\n",
      "Epoch 3972/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1422745361.4090 - val_loss: 1530920174.1735\n",
      "Epoch 3973/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1423023004.4305 - val_loss: 1529378368.2922\n",
      "Epoch 3974/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1422479814.3875 - val_loss: 1529984126.8311\n",
      "Epoch 3975/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1422494196.7280 - val_loss: 1530525223.1598\n",
      "Epoch 3976/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1422622692.6967 - val_loss: 1530356875.3973\n",
      "Epoch 3977/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1422665269.3542 - val_loss: 1530813542.2831\n",
      "Epoch 3978/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1423074171.6164 - val_loss: 1530011610.8858\n",
      "Epoch 3979/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1422700057.8004 - val_loss: 1530192733.5160\n",
      "Epoch 3980/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1423137207.3581 - val_loss: 1529495149.5890\n",
      "Epoch 3981/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1422585278.0587 - val_loss: 1530058079.8539\n",
      "Epoch 3982/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1422392014.4031 - val_loss: 1529709965.4429\n",
      "Epoch 3983/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1422273689.7378 - val_loss: 1530695183.7808\n",
      "Epoch 3984/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1422271314.4110 - val_loss: 1530478684.0548\n",
      "Epoch 3985/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1422416692.4775 - val_loss: 1530533654.2100\n",
      "Epoch 3986/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1422374584.4853 - val_loss: 1530749970.9954\n",
      "Epoch 3987/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1423095306.3953 - val_loss: 1529251768.4018\n",
      "Epoch 3988/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1422534431.3112 - val_loss: 1531007078.2831\n",
      "Epoch 3989/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1422440429.7143 - val_loss: 1529726112.1461\n",
      "Epoch 3990/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1422173465.0489 - val_loss: 1530316287.1233\n",
      "Epoch 3991/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1422186639.5303 - val_loss: 1530049812.1644\n",
      "Epoch 3992/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1422653024.9393 - val_loss: 1530725942.9406\n",
      "Epoch 3993/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1421989903.2798 - val_loss: 1530217261.2968\n",
      "Epoch 3994/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1422274182.2622 - val_loss: 1529624721.2420\n",
      "Epoch 3995/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1422490751.7495 - val_loss: 1530826423.2329\n",
      "Epoch 3996/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1421998676.2896 - val_loss: 1530285931.5434\n",
      "Epoch 3997/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1422572205.5890 - val_loss: 1529450813.9543\n",
      "Epoch 3998/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1422087881.5186 - val_loss: 1529835515.9087\n",
      "Epoch 3999/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1423139278.4031 - val_loss: 1529037262.6119\n",
      "Epoch 4000/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1422249766.0744 - val_loss: 1530518337.1689\n",
      "Epoch 4001/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1422046791.8904 - val_loss: 1530023921.3881\n",
      "Epoch 4002/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1422398778.9902 - val_loss: 1531151860.6027\n",
      "Epoch 4003/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1422212038.1370 - val_loss: 1529523292.9315\n",
      "Epoch 4004/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1422302735.9061 - val_loss: 1529257136.5114\n",
      "Epoch 4005/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1421929210.6145 - val_loss: 1530196903.7443\n",
      "Epoch 4006/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1422417770.7084 - val_loss: 1528891124.6027\n",
      "Epoch 4007/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1422678373.6986 - val_loss: 1530925650.4110\n",
      "Epoch 4008/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1422491179.3346 - val_loss: 1529317765.2603\n",
      "Epoch 4009/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1422479974.3249 - val_loss: 1531067666.4110\n",
      "Epoch 4010/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1421876962.1918 - val_loss: 1530627765.4795\n",
      "Epoch 4011/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1422417982.8728 - val_loss: 1529432806.8676\n",
      "Epoch 4012/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1422470717.3699 - val_loss: 1530332458.3744\n",
      "Epoch 4013/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1421798020.7593 - val_loss: 1529843769.5708\n",
      "Epoch 4014/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1422275449.3620 - val_loss: 1530106903.9635\n",
      "Epoch 4015/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1421598726.8885 - val_loss: 1529643722.8128\n",
      "Epoch 4016/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1422091888.2192 - val_loss: 1530195621.6986\n",
      "Epoch 4017/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1421620786.8493 - val_loss: 1529714856.0365\n",
      "Epoch 4018/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1422090309.6360 - val_loss: 1530227656.7671\n",
      "Epoch 4019/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1422146091.9609 - val_loss: 1528638123.2511\n",
      "Epoch 4020/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1421927530.4579 - val_loss: 1529611633.3881\n",
      "Epoch 4021/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1422198117.5734 - val_loss: 1528816547.6530\n",
      "Epoch 4022/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1421702767.3425 - val_loss: 1529993912.6941\n",
      "Epoch 4023/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1421713494.4188 - val_loss: 1529600804.8219\n",
      "Epoch 4024/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1421782389.7299 - val_loss: 1530499185.3881\n",
      "Epoch 4025/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1421404107.8982 - val_loss: 1529791210.6667\n",
      "Epoch 4026/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1421442494.8728 - val_loss: 1529742209.7534\n",
      "Epoch 4027/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1421757069.7769 - val_loss: 1530489589.4795\n",
      "Epoch 4028/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1421529929.5186 - val_loss: 1529890319.4886\n",
      "Epoch 4029/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1421385031.4521 - val_loss: 1529617094.7215\n",
      "Epoch 4030/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1421995952.3444 - val_loss: 1528864543.5616\n",
      "Epoch 4031/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1421678468.7593 - val_loss: 1530021686.3562\n",
      "Epoch 4032/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1421534185.5812 - val_loss: 1529219352.8402\n",
      "Epoch 4033/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1422230979.3816 - val_loss: 1530637060.3836\n",
      "Epoch 4034/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1421408313.8630 - val_loss: 1529415332.5297\n",
      "Epoch 4035/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1421386494.2466 - val_loss: 1529325594.8858\n",
      "Epoch 4036/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1421469868.2114 - val_loss: 1529755726.9041\n",
      "Epoch 4037/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1421518267.9922 - val_loss: 1529851487.2694\n",
      "Epoch 4038/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1421628424.0157 - val_loss: 1528754353.9726\n",
      "Epoch 4039/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1421372021.7299 - val_loss: 1529072888.1096\n",
      "Epoch 4040/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1422547338.5205 - val_loss: 1530539203.5068\n",
      "Epoch 4041/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1421263266.8180 - val_loss: 1529317393.8265\n",
      "Epoch 4042/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1421495253.0411 - val_loss: 1529023605.7717\n",
      "Epoch 4043/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1421274847.4364 - val_loss: 1528904531.5799\n",
      "Epoch 4044/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1421452529.0959 - val_loss: 1529589546.3744\n",
      "Epoch 4045/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1421479290.6145 - val_loss: 1529764709.4064\n",
      "Epoch 4046/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1421294225.2838 - val_loss: 1528891273.9361\n",
      "Epoch 4047/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1421221946.3640 - val_loss: 1529976612.2374\n",
      "Epoch 4048/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1421145647.3425 - val_loss: 1529743261.5160\n",
      "Epoch 4049/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1421207858.3483 - val_loss: 1529273323.8356\n",
      "Epoch 4050/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1421522873.9883 - val_loss: 1530087919.0502\n",
      "Epoch 4051/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1421634968.5479 - val_loss: 1529671819.3973\n",
      "Epoch 4052/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1420933324.5245 - val_loss: 1529293478.8676\n",
      "Epoch 4053/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1421073924.5088 - val_loss: 1529087897.1324\n",
      "Epoch 4054/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1420934872.4227 - val_loss: 1529527254.7945\n",
      "Epoch 4055/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1421366722.8806 - val_loss: 1529213731.0685\n",
      "Epoch 4056/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1421083019.0215 - val_loss: 1529182183.1598\n",
      "Epoch 4057/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1421080724.5401 - val_loss: 1529739181.0046\n",
      "Epoch 4058/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1421014779.9922 - val_loss: 1529493915.1781\n",
      "Epoch 4059/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1421145994.7710 - val_loss: 1529351822.0274\n",
      "Epoch 4060/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1420852066.9432 - val_loss: 1529322501.5525\n",
      "Epoch 4061/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1420867116.0861 - val_loss: 1529462069.7717\n",
      "Epoch 4062/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1420967786.8337 - val_loss: 1529894957.2968\n",
      "Epoch 4063/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1420760483.3190 - val_loss: 1529638499.3607\n",
      "Epoch 4064/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1420760480.8141 - val_loss: 1528891723.6895\n",
      "Epoch 4065/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1420923997.3699 - val_loss: 1528849294.9041\n",
      "Epoch 4066/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1421006371.8200 - val_loss: 1528846087.5982\n",
      "Epoch 4067/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1421068833.3151 - val_loss: 1529704433.0959\n",
      "Epoch 4068/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1421119403.8356 - val_loss: 1528583790.4658\n",
      "Epoch 4069/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1420630730.1448 - val_loss: 1528989837.7352\n",
      "Epoch 4070/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1422035050.7084 - val_loss: 1530711068.0548\n",
      "Epoch 4071/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1420738990.3405 - val_loss: 1528763106.4840\n",
      "Epoch 4072/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1421135465.3307 - val_loss: 1529445470.9772\n",
      "Epoch 4073/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1421494443.4599 - val_loss: 1528440098.1918\n",
      "Epoch 4074/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1420794981.1977 - val_loss: 1528712903.5982\n",
      "Epoch 4075/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1420665972.4775 - val_loss: 1528993660.4932\n",
      "Epoch 4076/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1421081992.0157 - val_loss: 1529614592.0000\n",
      "Epoch 4077/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1420617122.3170 - val_loss: 1528876844.4201\n",
      "Epoch 4078/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1420617139.0998 - val_loss: 1528816148.7489\n",
      "Epoch 4079/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1420706010.4266 - val_loss: 1529035332.6758\n",
      "Epoch 4080/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1420694580.1018 - val_loss: 1528455428.6758\n",
      "Epoch 4081/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1420577768.5166 - val_loss: 1529032723.5799\n",
      "Epoch 4082/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1421157627.2407 - val_loss: 1530060748.5662\n",
      "Epoch 4083/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1420305833.7065 - val_loss: 1529102513.3881\n",
      "Epoch 4084/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1420627524.8845 - val_loss: 1529289308.3470\n",
      "Epoch 4085/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1420425878.5440 - val_loss: 1529418270.1005\n",
      "Epoch 4086/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1420649894.8258 - val_loss: 1528923631.0502\n",
      "Epoch 4087/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1420835248.3444 - val_loss: 1528974052.2374\n",
      "Epoch 4088/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1420647863.3581 - val_loss: 1529108236.5662\n",
      "Epoch 4089/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1420255623.0137 - val_loss: 1528772440.5479\n",
      "Epoch 4090/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1420366911.3738 - val_loss: 1528378642.7032\n",
      "Epoch 4091/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1420266584.1722 - val_loss: 1528769125.9909\n",
      "Epoch 4092/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1420495040.8767 - val_loss: 1528709359.6347\n",
      "Epoch 4093/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1420250375.6399 - val_loss: 1528655905.6073\n",
      "Epoch 4094/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1420245670.5753 - val_loss: 1529305142.6484\n",
      "Epoch 4095/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1420399354.7397 - val_loss: 1529438253.2968\n",
      "Epoch 4096/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1420134776.9863 - val_loss: 1528970014.3927\n",
      "Epoch 4097/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1420299388.2427 - val_loss: 1529031725.5890\n",
      "Epoch 4098/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1420494883.0685 - val_loss: 1528584365.2968\n",
      "Epoch 4099/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1420784418.8180 - val_loss: 1527750832.8037\n",
      "Epoch 4100/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1420285917.9335 - val_loss: 1529194683.6164\n",
      "Epoch 4101/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1420334371.9452 - val_loss: 1528481759.2694\n",
      "Epoch 4102/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1420227411.1624 - val_loss: 1529010139.4703\n",
      "Epoch 4103/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1421414638.2153 - val_loss: 1529565999.0502\n",
      "Epoch 4104/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1420263192.1722 - val_loss: 1529198348.5662\n",
      "Epoch 4105/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1420774125.9648 - val_loss: 1528274934.6484\n",
      "Epoch 4106/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1420453654.5440 - val_loss: 1528384260.6758\n",
      "Epoch 4107/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1420067572.9785 - val_loss: 1528921287.5982\n",
      "Epoch 4108/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1420079465.2055 - val_loss: 1528411113.4977\n",
      "Epoch 4109/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1421134232.7984 - val_loss: 1530090932.0183\n",
      "Epoch 4110/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1420080796.3053 - val_loss: 1528751172.9680\n",
      "Epoch 4111/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 43us/step - loss: 1420235141.2603 - val_loss: 1529121115.1781\n",
      "Epoch 4112/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1420193071.0920 - val_loss: 1529247487.4155\n",
      "Epoch 4113/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1420163734.5440 - val_loss: 1528514419.7260\n",
      "Epoch 4114/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1420302449.4716 - val_loss: 1529099001.8630\n",
      "Epoch 4115/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1419780562.4110 - val_loss: 1528378929.6804\n",
      "Epoch 4116/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1420033829.5734 - val_loss: 1528772949.9178\n",
      "Epoch 4117/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1420053030.9511 - val_loss: 1528451281.2420\n",
      "Epoch 4118/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1420158956.8376 - val_loss: 1528537082.7397\n",
      "Epoch 4119/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1419786997.6047 - val_loss: 1528416255.4155\n",
      "Epoch 4120/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1420531833.4873 - val_loss: 1528173638.1370\n",
      "Epoch 4121/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1419899571.8513 - val_loss: 1528439896.2557\n",
      "Epoch 4122/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1420116477.6830 - val_loss: 1528039298.3379\n",
      "Epoch 4123/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1419755110.4501 - val_loss: 1528581749.7717\n",
      "Epoch 4124/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1420026621.9961 - val_loss: 1529642834.7032\n",
      "Epoch 4125/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1419647724.2114 - val_loss: 1528750504.0365\n",
      "Epoch 4126/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1420341664.6262 - val_loss: 1527955143.3059\n",
      "Epoch 4127/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1419593058.1918 - val_loss: 1528606501.1142\n",
      "Epoch 4128/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1419837296.2192 - val_loss: 1528128717.7352\n",
      "Epoch 4129/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1419964041.0176 - val_loss: 1529303943.8904\n",
      "Epoch 4130/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1420036420.3836 - val_loss: 1528184674.4840\n",
      "Epoch 4131/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1419943985.8474 - val_loss: 1529005134.6119\n",
      "Epoch 4132/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1419927654.4501 - val_loss: 1528870991.7808\n",
      "Epoch 4133/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1419770910.0587 - val_loss: 1529199133.2237\n",
      "Epoch 4134/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1420002883.1311 - val_loss: 1527557015.9635\n",
      "Epoch 4135/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1419555483.1781 - val_loss: 1528267949.0046\n",
      "Epoch 4136/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1419605977.0489 - val_loss: 1528138292.8950\n",
      "Epoch 4137/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1419609904.0939 - val_loss: 1528353192.6210\n",
      "Epoch 4138/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1419683801.4247 - val_loss: 1528268683.6895\n",
      "Epoch 4139/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1419626707.2877 - val_loss: 1529104815.3425\n",
      "Epoch 4140/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1420033793.1272 - val_loss: 1527691978.8128\n",
      "Epoch 4141/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1419878322.8493 - val_loss: 1529268098.0457\n",
      "Epoch 4142/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1419534408.7671 - val_loss: 1528572952.2557\n",
      "Epoch 4143/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1419398378.9589 - val_loss: 1528014622.6849\n",
      "Epoch 4144/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1419383491.3816 - val_loss: 1528543785.2055\n",
      "Epoch 4145/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1420474268.5558 - val_loss: 1529682552.6941\n",
      "Epoch 4146/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1419436909.2133 - val_loss: 1528509379.7991\n",
      "Epoch 4147/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1419455804.7436 - val_loss: 1528111182.6119\n",
      "Epoch 4148/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1419274211.9452 - val_loss: 1528286288.3653\n",
      "Epoch 4149/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1419179619.1937 - val_loss: 1527952113.0959\n",
      "Epoch 4150/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1419466005.0411 - val_loss: 1527250416.5114\n",
      "Epoch 4151/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1419068527.2172 - val_loss: 1527876162.9224\n",
      "Epoch 4152/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1419263606.7319 - val_loss: 1528397510.4292\n",
      "Epoch 4153/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1419698926.4658 - val_loss: 1528544157.8082\n",
      "Epoch 4154/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1419625040.2818 - val_loss: 1528748839.4521\n",
      "Epoch 4155/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1419337136.8454 - val_loss: 1528360156.9315\n",
      "Epoch 4156/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1419308391.0763 - val_loss: 1527964297.9361\n",
      "Epoch 4157/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1419557898.5205 - val_loss: 1529160068.6758\n",
      "Epoch 4158/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1419342354.1605 - val_loss: 1527842446.9041\n",
      "Epoch 4159/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1420008788.5401 - val_loss: 1528578460.6393\n",
      "Epoch 4160/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1419377871.0294 - val_loss: 1527961893.4064\n",
      "Epoch 4161/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1419095419.7417 - val_loss: 1527828062.3927\n",
      "Epoch 4162/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1419685794.5675 - val_loss: 1527614066.5571\n",
      "Epoch 4163/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1419239057.4090 - val_loss: 1528345417.9361\n",
      "Epoch 4164/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1419111983.8434 - val_loss: 1528037433.5708\n",
      "Epoch 4165/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1420165928.8924 - val_loss: 1527575477.1872\n",
      "Epoch 4166/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1419188819.1624 - val_loss: 1529087921.6804\n",
      "Epoch 4167/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1419123646.3718 - val_loss: 1529131984.6575\n",
      "Epoch 4168/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1418998092.6497 - val_loss: 1527764716.7123\n",
      "Epoch 4169/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1418980525.8395 - val_loss: 1527659221.6256\n",
      "Epoch 4170/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1418963461.2603 - val_loss: 1528305054.9772\n",
      "Epoch 4171/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1418917065.3933 - val_loss: 1528173788.0548\n",
      "Epoch 4172/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1419269456.0313 - val_loss: 1528543708.3470\n",
      "Epoch 4173/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1418881171.0372 - val_loss: 1527893118.5388\n",
      "Epoch 4174/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1419309365.4795 - val_loss: 1528592805.1142\n",
      "Epoch 4175/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 32us/step - loss: 1419141795.8200 - val_loss: 1527206518.3562\n",
      "Epoch 4176/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1418968908.7750 - val_loss: 1528262156.2740\n",
      "Epoch 4177/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1419125908.7906 - val_loss: 1528169415.0137\n",
      "Epoch 4178/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1418697150.6223 - val_loss: 1527855165.3699\n",
      "Epoch 4179/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1419078181.2603 - val_loss: 1527334344.7671\n",
      "Epoch 4180/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1418819165.8082 - val_loss: 1527893468.3470\n",
      "Epoch 4181/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1418894749.9335 - val_loss: 1527908712.9132\n",
      "Epoch 4182/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1418901815.4834 - val_loss: 1528250929.0959\n",
      "Epoch 4183/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1418747928.7984 - val_loss: 1528157267.5799\n",
      "Epoch 4184/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1419130197.7926 - val_loss: 1528178025.4977\n",
      "Epoch 4185/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1418779573.1037 - val_loss: 1527552711.3059\n",
      "Epoch 4186/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1418693039.8434 - val_loss: 1527268878.9041\n",
      "Epoch 4187/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1418610477.7143 - val_loss: 1527843198.8311\n",
      "Epoch 4188/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1418966961.8474 - val_loss: 1528180834.4840\n",
      "Epoch 4189/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1418811272.3914 - val_loss: 1527721933.4429\n",
      "Epoch 4190/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1418906386.7867 - val_loss: 1527970853.4064\n",
      "Epoch 4191/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1418863817.2055 - val_loss: 1527437774.3196\n",
      "Epoch 4192/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1418548743.5147 - val_loss: 1528571192.1096\n",
      "Epoch 4193/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1419154226.9746 - val_loss: 1529411991.0868\n",
      "Epoch 4194/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1418644755.5382 - val_loss: 1527704100.5297\n",
      "Epoch 4195/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1418574543.9061 - val_loss: 1527462588.2009\n",
      "Epoch 4196/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1419021496.3601 - val_loss: 1528912025.4247\n",
      "Epoch 4197/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1419061509.0098 - val_loss: 1528879514.5936\n",
      "Epoch 4198/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1418583058.9119 - val_loss: 1528005744.2192\n",
      "Epoch 4199/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1418526779.8669 - val_loss: 1526948147.4338\n",
      "Epoch 4200/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1418586166.4814 - val_loss: 1527910616.5479\n",
      "Epoch 4201/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1418538847.1859 - val_loss: 1527146084.5297\n",
      "Epoch 4202/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1418652673.7534 - val_loss: 1528413234.2648\n",
      "Epoch 4203/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1418493447.8904 - val_loss: 1528282567.0137\n",
      "Epoch 4204/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1418716458.2074 - val_loss: 1526715148.2740\n",
      "Epoch 4205/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1418374933.7926 - val_loss: 1527676251.1781\n",
      "Epoch 4206/15000\n",
      "1022/1022 [==============================] - ETA: 0s - loss: 759615744.000 - 0s 41us/step - loss: 1418322604.6497 - val_loss: 1527777980.4932\n",
      "Epoch 4207/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1418434938.8650 - val_loss: 1527250339.9452\n",
      "Epoch 4208/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1418289397.8552 - val_loss: 1527590397.3699\n",
      "Epoch 4209/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1418441550.6536 - val_loss: 1527393591.8174\n",
      "Epoch 4210/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1418200436.7280 - val_loss: 1527658794.3744\n",
      "Epoch 4211/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1418634783.8121 - val_loss: 1526874150.5753\n",
      "Epoch 4212/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1418087537.4716 - val_loss: 1528122227.1416\n",
      "Epoch 4213/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1419344587.3973 - val_loss: 1526532521.2055\n",
      "Epoch 4214/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1418672156.5558 - val_loss: 1528498862.1735\n",
      "Epoch 4215/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1418167008.0626 - val_loss: 1528300787.4338\n",
      "Epoch 4216/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1419342674.1605 - val_loss: 1526805800.0365\n",
      "Epoch 4217/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1418411098.6771 - val_loss: 1527685157.6986\n",
      "Epoch 4218/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1418240078.2779 - val_loss: 1528241905.0959\n",
      "Epoch 4219/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1418256511.2485 - val_loss: 1527036820.7489\n",
      "Epoch 4220/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1418225448.7045 - val_loss: 1527974829.0046\n",
      "Epoch 4221/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1418613705.1429 - val_loss: 1527104639.1233\n",
      "Epoch 4222/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1418149114.4892 - val_loss: 1526871204.5297\n",
      "Epoch 4223/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1417962257.7847 - val_loss: 1528219396.0913\n",
      "Epoch 4224/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1418013879.3581 - val_loss: 1527525273.1324\n",
      "Epoch 4225/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1418213663.5616 - val_loss: 1527328874.0822\n",
      "Epoch 4226/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1418788201.4560 - val_loss: 1528321276.4932\n",
      "Epoch 4227/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1418049471.6243 - val_loss: 1527467031.0868\n",
      "Epoch 4228/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1417862327.8591 - val_loss: 1527958326.6484\n",
      "Epoch 4229/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1417933753.5499 - val_loss: 1528278175.8539\n",
      "Epoch 4230/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1418210442.0196 - val_loss: 1526889379.9452\n",
      "Epoch 4231/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1417933650.6614 - val_loss: 1527885172.8950\n",
      "Epoch 4232/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1417982246.0744 - val_loss: 1527856835.2146\n",
      "Epoch 4233/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1417784946.9746 - val_loss: 1527530230.3562\n",
      "Epoch 4234/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1417978523.8043 - val_loss: 1528037582.9041\n",
      "Epoch 4235/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1417968414.0587 - val_loss: 1527371449.5708\n",
      "Epoch 4236/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1418156917.2290 - val_loss: 1528510182.5753\n",
      "Epoch 4237/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1418336496.9706 - val_loss: 1527610237.6621\n",
      "Epoch 4238/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1417922597.1977 - val_loss: 1527428924.2009\n",
      "Epoch 4239/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 41us/step - loss: 1417866355.6008 - val_loss: 1527389661.8082\n",
      "Epoch 4240/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1417873904.7202 - val_loss: 1527683848.7671\n",
      "Epoch 4241/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1417729970.0978 - val_loss: 1526997627.3242\n",
      "Epoch 4242/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1418924284.4932 - val_loss: 1528251855.7808\n",
      "Epoch 4243/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1417801160.9550 - val_loss: 1527819058.5571\n",
      "Epoch 4244/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1418075303.3268 - val_loss: 1526428512.1461\n",
      "Epoch 4245/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1417697695.1859 - val_loss: 1527325621.7717\n",
      "Epoch 4246/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1417638863.4051 - val_loss: 1527709157.9909\n",
      "Epoch 4247/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1417560143.4051 - val_loss: 1527294086.4292\n",
      "Epoch 4248/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1417676501.9178 - val_loss: 1527850895.4886\n",
      "Epoch 4249/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1417595443.3503 - val_loss: 1527432584.1826\n",
      "Epoch 4250/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1417787824.5949 - val_loss: 1527847417.8630\n",
      "Epoch 4251/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1417585291.2720 - val_loss: 1527529359.7808\n",
      "Epoch 4252/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1417693569.2524 - val_loss: 1527333024.1461\n",
      "Epoch 4253/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1417842572.2740 - val_loss: 1527372235.1050\n",
      "Epoch 4254/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1417543745.1272 - val_loss: 1527180492.8584\n",
      "Epoch 4255/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1417640191.3738 - val_loss: 1527148600.1096\n",
      "Epoch 4256/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1417991136.4384 - val_loss: 1526405003.9817\n",
      "Epoch 4257/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1417612403.9765 - val_loss: 1526796073.2055\n",
      "Epoch 4258/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1417567716.8219 - val_loss: 1526768579.5068\n",
      "Epoch 4259/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1417311547.6164 - val_loss: 1527386047.1233\n",
      "Epoch 4260/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1417500098.3796 - val_loss: 1527944684.4201\n",
      "Epoch 4261/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1417397204.9159 - val_loss: 1527543644.9315\n",
      "Epoch 4262/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1417502184.7045 - val_loss: 1528086893.8813\n",
      "Epoch 4263/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1417282401.5656 - val_loss: 1527675553.6073\n",
      "Epoch 4264/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1417700125.1820 - val_loss: 1526478235.4703\n",
      "Epoch 4265/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1417301816.8611 - val_loss: 1526931602.1187\n",
      "Epoch 4266/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1417332715.5851 - val_loss: 1526779865.1324\n",
      "Epoch 4267/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1417456528.7828 - val_loss: 1527829180.7854\n",
      "Epoch 4268/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1417483803.0528 - val_loss: 1526852150.3562\n",
      "Epoch 4269/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1417268288.6262 - val_loss: 1527359973.4064\n",
      "Epoch 4270/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1417401478.2622 - val_loss: 1526541214.3927\n",
      "Epoch 4271/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1417850825.7691 - val_loss: 1528067884.7123\n",
      "Epoch 4272/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1417656823.5460 - val_loss: 1527445475.9452\n",
      "Epoch 4273/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1417646734.9041 - val_loss: 1526935495.3059\n",
      "Epoch 4274/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1417095136.9393 - val_loss: 1527171423.8539\n",
      "Epoch 4275/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1417175991.1076 - val_loss: 1527525183.4155\n",
      "Epoch 4276/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1417116344.2348 - val_loss: 1527509655.3790\n",
      "Epoch 4277/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1417257781.3542 - val_loss: 1526768977.2420\n",
      "Epoch 4278/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1417058372.6341 - val_loss: 1527223161.2785\n",
      "Epoch 4279/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1417052618.3953 - val_loss: 1527090905.4247\n",
      "Epoch 4280/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1417279343.3425 - val_loss: 1527633692.0548\n",
      "Epoch 4281/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1417698944.3131 - val_loss: 1526646410.2283\n",
      "Epoch 4282/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1417259702.3562 - val_loss: 1527278222.6119\n",
      "Epoch 4283/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1417010730.9589 - val_loss: 1527484054.5023\n",
      "Epoch 4284/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1417402536.8297 - val_loss: 1528057725.6621\n",
      "Epoch 4285/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1417598642.4110 - val_loss: 1527202461.2237\n",
      "Epoch 4286/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1417306323.6634 - val_loss: 1527786374.1370\n",
      "Epoch 4287/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1417152137.7691 - val_loss: 1527449441.6073\n",
      "Epoch 4288/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1416885360.4697 - val_loss: 1526751910.2831\n",
      "Epoch 4289/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1417236617.5186 - val_loss: 1526763992.5479\n",
      "Epoch 4290/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1417345998.4031 - val_loss: 1526015402.0822\n",
      "Epoch 4291/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1417282878.8728 - val_loss: 1527104707.7991\n",
      "Epoch 4292/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1417276770.1918 - val_loss: 1527355355.4703\n",
      "Epoch 4293/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1416946608.8454 - val_loss: 1526880574.5388\n",
      "Epoch 4294/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1417067958.6067 - val_loss: 1527663578.5936\n",
      "Epoch 4295/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1416762455.5460 - val_loss: 1526956372.4566\n",
      "Epoch 4296/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1417292028.6184 - val_loss: 1526269987.9452\n",
      "Epoch 4297/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1416968409.5499 - val_loss: 1527226816.0000\n",
      "Epoch 4298/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1416986974.6849 - val_loss: 1526841298.4110\n",
      "Epoch 4299/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1416724206.4658 - val_loss: 1526960058.1553\n",
      "Epoch 4300/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1416787104.9393 - val_loss: 1526696327.5982\n",
      "Epoch 4301/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1417136437.1037 - val_loss: 1526377150.5388\n",
      "Epoch 4302/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1416776049.7221 - val_loss: 1527399639.0868\n",
      "Epoch 4303/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 44us/step - loss: 1417399304.2661 - val_loss: 1526723359.8539\n",
      "Epoch 4304/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1416711132.4305 - val_loss: 1527128864.1461\n",
      "Epoch 4305/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1416824790.9198 - val_loss: 1527515566.7580\n",
      "Epoch 4306/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1416666322.4110 - val_loss: 1527120275.2877\n",
      "Epoch 4307/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1416901619.4755 - val_loss: 1527656794.8858\n",
      "Epoch 4308/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1416570946.7554 - val_loss: 1526951715.9452\n",
      "Epoch 4309/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1416585180.8063 - val_loss: 1526919779.9452\n",
      "Epoch 4310/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1417422732.0235 - val_loss: 1527409790.8311\n",
      "Epoch 4311/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1416852344.1096 - val_loss: 1526513682.7032\n",
      "Epoch 4312/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1416725036.5871 - val_loss: 1526262604.8584\n",
      "Epoch 4313/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1416734624.7515 - val_loss: 1525837768.4749\n",
      "Epoch 4314/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1416516638.4344 - val_loss: 1526728068.0913\n",
      "Epoch 4315/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1417060068.9472 - val_loss: 1526825235.2877\n",
      "Epoch 4316/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1416411556.8219 - val_loss: 1526895348.3105\n",
      "Epoch 4317/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1416700025.5499 - val_loss: 1526018799.6347\n",
      "Epoch 4318/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1417109864.0783 - val_loss: 1526795623.1598\n",
      "Epoch 4319/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1416426479.9687 - val_loss: 1526870535.3059\n",
      "Epoch 4320/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1417168518.8885 - val_loss: 1527672725.0411\n",
      "Epoch 4321/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1416246800.5323 - val_loss: 1526723583.1233\n",
      "Epoch 4322/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1416462291.9139 - val_loss: 1526264973.7352\n",
      "Epoch 4323/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1416515625.5812 - val_loss: 1526583099.0320\n",
      "Epoch 4324/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1416453777.5342 - val_loss: 1526592779.9817\n",
      "Epoch 4325/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1416375288.2348 - val_loss: 1526372899.3607\n",
      "Epoch 4326/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1416233832.2035 - val_loss: 1526585410.9224\n",
      "Epoch 4327/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1416719372.7123 - val_loss: 1526143554.9224\n",
      "Epoch 4328/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1416308818.5362 - val_loss: 1526723238.5753\n",
      "Epoch 4329/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1416678596.6341 - val_loss: 1526236799.4155\n",
      "Epoch 4330/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1416659328.2505 - val_loss: 1527293096.9132\n",
      "Epoch 4331/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1416325992.4540 - val_loss: 1526837893.5525\n",
      "Epoch 4332/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1416242983.5773 - val_loss: 1526191455.2694\n",
      "Epoch 4333/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1416177261.5890 - val_loss: 1526262710.3562\n",
      "Epoch 4334/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1416605575.5147 - val_loss: 1526151992.4018\n",
      "Epoch 4335/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1416248083.5382 - val_loss: 1527475769.8630\n",
      "Epoch 4336/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1416113945.6751 - val_loss: 1527068200.3288\n",
      "Epoch 4337/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1416211738.8023 - val_loss: 1526878927.7808\n",
      "Epoch 4338/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1416214053.5734 - val_loss: 1526773297.0959\n",
      "Epoch 4339/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1417265066.7084 - val_loss: 1528177024.5845\n",
      "Epoch 4340/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1415955672.4227 - val_loss: 1526372049.2420\n",
      "Epoch 4341/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1416253166.9667 - val_loss: 1526443429.9909\n",
      "Epoch 4342/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1416492480.6262 - val_loss: 1525669966.6119\n",
      "Epoch 4343/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1416140686.9667 - val_loss: 1526609433.1324\n",
      "Epoch 4344/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1416143985.4716 - val_loss: 1526427438.7580\n",
      "Epoch 4345/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1416336478.1213 - val_loss: 1526059411.5799\n",
      "Epoch 4346/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1416420785.0959 - val_loss: 1526847455.5616\n",
      "Epoch 4347/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1416422935.6712 - val_loss: 1525602990.1735\n",
      "Epoch 4348/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1417034773.7926 - val_loss: 1527248689.6804\n",
      "Epoch 4349/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1415988941.1507 - val_loss: 1526715944.3288\n",
      "Epoch 4350/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1416689077.3542 - val_loss: 1526695365.8447\n",
      "Epoch 4351/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1416640370.7241 - val_loss: 1525840485.4064\n",
      "Epoch 4352/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1416209012.3523 - val_loss: 1526720761.2785\n",
      "Epoch 4353/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1416350296.6106 - val_loss: 1525666108.4932\n",
      "Epoch 4354/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1416301445.7613 - val_loss: 1527488850.1187\n",
      "Epoch 4355/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1415828369.5342 - val_loss: 1527001105.2420\n",
      "Epoch 4356/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1416044472.9863 - val_loss: 1525996205.8813\n",
      "Epoch 4357/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1415998535.2642 - val_loss: 1525961736.4749\n",
      "Epoch 4358/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1416166571.3346 - val_loss: 1525930927.0502\n",
      "Epoch 4359/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1416050096.8454 - val_loss: 1527051887.0502\n",
      "Epoch 4360/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1416100998.2622 - val_loss: 1527486669.7352\n",
      "Epoch 4361/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1415837956.2583 - val_loss: 1526051157.0411\n",
      "Epoch 4362/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1415730890.1448 - val_loss: 1526697131.8356\n",
      "Epoch 4363/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1415930625.6282 - val_loss: 1526688225.0228\n",
      "Epoch 4364/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1415734614.0431 - val_loss: 1526186235.0320\n",
      "Epoch 4365/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1416047177.6438 - val_loss: 1526863352.4018\n",
      "Epoch 4366/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1415701279.1859 - val_loss: 1526024667.4703\n",
      "Epoch 4367/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 46us/step - loss: 1416104136.0157 - val_loss: 1526904364.4201\n",
      "Epoch 4368/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1415742802.1605 - val_loss: 1526170237.0776\n",
      "Epoch 4369/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1415722470.3249 - val_loss: 1525750918.1370\n",
      "Epoch 4370/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1415967232.5010 - val_loss: 1526865194.0822\n",
      "Epoch 4371/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1416769173.9178 - val_loss: 1524859495.7443\n",
      "Epoch 4372/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1415639789.4638 - val_loss: 1526609893.1142\n",
      "Epoch 4373/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1416078287.9061 - val_loss: 1525584863.2694\n",
      "Epoch 4374/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1415781279.3112 - val_loss: 1526390134.3562\n",
      "Epoch 4375/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1416191730.8493 - val_loss: 1526511373.4429\n",
      "Epoch 4376/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1416016904.5166 - val_loss: 1526348075.5434\n",
      "Epoch 4377/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1415444630.0431 - val_loss: 1526478521.2785\n",
      "Epoch 4378/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1416229245.9961 - val_loss: 1527348426.5205\n",
      "Epoch 4379/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1415391269.6986 - val_loss: 1526293260.8584\n",
      "Epoch 4380/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1415640047.9687 - val_loss: 1525470502.5753\n",
      "Epoch 4381/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1415298401.3151 - val_loss: 1525996834.7763\n",
      "Epoch 4382/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1415879124.9159 - val_loss: 1526715657.6438\n",
      "Epoch 4383/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1415417499.5538 - val_loss: 1526199351.5251\n",
      "Epoch 4384/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1415566455.9843 - val_loss: 1526474849.6073\n",
      "Epoch 4385/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1415733881.6125 - val_loss: 1525772899.9452\n",
      "Epoch 4386/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1417006111.5616 - val_loss: 1526289703.7443\n",
      "Epoch 4387/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1415439823.1546 - val_loss: 1526743725.8813\n",
      "Epoch 4388/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1415617084.3053 - val_loss: 1525975554.0457\n",
      "Epoch 4389/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1415859077.0098 - val_loss: 1526605764.0913\n",
      "Epoch 4390/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1415253692.4932 - val_loss: 1526353017.2785\n",
      "Epoch 4391/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1415839773.4951 - val_loss: 1525097154.9224\n",
      "Epoch 4392/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1415509052.3679 - val_loss: 1526813959.3059\n",
      "Epoch 4393/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1415736791.5460 - val_loss: 1525329774.4658\n",
      "Epoch 4394/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1415263553.1272 - val_loss: 1526131553.0228\n",
      "Epoch 4395/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1415533467.1781 - val_loss: 1525478259.1416\n",
      "Epoch 4396/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1415367085.7143 - val_loss: 1525431351.8174\n",
      "Epoch 4397/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1415114594.1918 - val_loss: 1526013161.2055\n",
      "Epoch 4398/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1415467416.7984 - val_loss: 1526425460.6027\n",
      "Epoch 4399/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1415046907.4912 - val_loss: 1526588724.8950\n",
      "Epoch 4400/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1415119278.3405 - val_loss: 1526247086.4658\n",
      "Epoch 4401/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1415252355.5068 - val_loss: 1526319797.4795\n",
      "Epoch 4402/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1415504574.6223 - val_loss: 1526250463.2694\n",
      "Epoch 4403/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1415466902.5440 - val_loss: 1526464214.2100\n",
      "Epoch 4404/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1416296263.9530 - val_loss: 1524988538.4475\n",
      "Epoch 4405/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1415606299.5538 - val_loss: 1527066890.5205\n",
      "Epoch 4406/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1414921882.1761 - val_loss: 1526197401.1324\n",
      "Epoch 4407/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1415008169.8943 - val_loss: 1525549060.9680\n",
      "Epoch 4408/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1415283876.0705 - val_loss: 1526119273.2055\n",
      "Epoch 4409/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1415037027.4442 - val_loss: 1525749101.5890\n",
      "Epoch 4410/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1415084605.8708 - val_loss: 1526095094.6484\n",
      "Epoch 4411/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1415718811.3033 - val_loss: 1526801058.4840\n",
      "Epoch 4412/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1415957068.2740 - val_loss: 1524977151.1233\n",
      "Epoch 4413/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1415016981.5421 - val_loss: 1525792668.6393\n",
      "Epoch 4414/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1415473115.0528 - val_loss: 1526446478.3196\n",
      "Epoch 4415/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1414912567.1076 - val_loss: 1525652960.4384\n",
      "Epoch 4416/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1414842391.5460 - val_loss: 1526035926.7945\n",
      "Epoch 4417/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1415106725.3229 - val_loss: 1525987294.1005\n",
      "Epoch 4418/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1415299659.7730 - val_loss: 1525579009.7534\n",
      "Epoch 4419/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1414980975.9687 - val_loss: 1525616229.9909\n",
      "Epoch 4420/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1414990571.9609 - val_loss: 1525358548.4566\n",
      "Epoch 4421/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1414830034.0352 - val_loss: 1525924652.1279\n",
      "Epoch 4422/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1414955730.4110 - val_loss: 1525959067.1781\n",
      "Epoch 4423/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1415403708.7436 - val_loss: 1526422116.2374\n",
      "Epoch 4424/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1414844381.5577 - val_loss: 1525932855.5251\n",
      "Epoch 4425/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1414979201.2524 - val_loss: 1526679854.7580\n",
      "Epoch 4426/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1414851954.4736 - val_loss: 1525904090.8858\n",
      "Epoch 4427/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1415099843.3816 - val_loss: 1525200236.7123\n",
      "Epoch 4428/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1414813315.0059 - val_loss: 1525230582.9406\n",
      "Epoch 4429/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1415213501.3699 - val_loss: 1526349636.3836\n",
      "Epoch 4430/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1415273542.6380 - val_loss: 1525315683.3607\n",
      "Epoch 4431/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 40us/step - loss: 1414668233.1429 - val_loss: 1526040197.5525\n",
      "Epoch 4432/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1414742773.4795 - val_loss: 1526371897.5708\n",
      "Epoch 4433/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1414536353.6908 - val_loss: 1526118573.8813\n",
      "Epoch 4434/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1415265542.1370 - val_loss: 1525588729.2785\n",
      "Epoch 4435/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1415352462.5284 - val_loss: 1526695839.2694\n",
      "Epoch 4436/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1414705369.5499 - val_loss: 1526244141.5890\n",
      "Epoch 4437/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1414651648.6262 - val_loss: 1525506014.3927\n",
      "Epoch 4438/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1414780175.0294 - val_loss: 1525591044.0913\n",
      "Epoch 4439/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1414674786.4423 - val_loss: 1525694412.8584\n",
      "Epoch 4440/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1414768743.2016 - val_loss: 1526108791.2329\n",
      "Epoch 4441/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1414620035.1311 - val_loss: 1525440302.7580\n",
      "Epoch 4442/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1414578002.9119 - val_loss: 1525257543.5982\n",
      "Epoch 4443/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1414891261.6204 - val_loss: 1526004628.7489\n",
      "Epoch 4444/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1414696453.2603 - val_loss: 1525906132.1644\n",
      "Epoch 4445/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1414587392.5010 - val_loss: 1525275559.7443\n",
      "Epoch 4446/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1415029310.6223 - val_loss: 1526540989.0776\n",
      "Epoch 4447/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1414537474.7554 - val_loss: 1525455452.6393\n",
      "Epoch 4448/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1414689408.8767 - val_loss: 1525032042.6667\n",
      "Epoch 4449/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1414749396.0391 - val_loss: 1526372430.9041\n",
      "Epoch 4450/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1414461392.9080 - val_loss: 1525570809.2785\n",
      "Epoch 4451/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1414477026.4423 - val_loss: 1525582350.9041\n",
      "Epoch 4452/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1414485015.2955 - val_loss: 1525426355.1416\n",
      "Epoch 4453/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1414455314.5362 - val_loss: 1525410162.8493\n",
      "Epoch 4454/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1414829379.5068 - val_loss: 1526424745.7900\n",
      "Epoch 4455/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1414290168.6106 - val_loss: 1525476977.9726\n",
      "Epoch 4456/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1415093514.0196 - val_loss: 1526589415.4521\n",
      "Epoch 4457/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1415014579.3503 - val_loss: 1524402023.1598\n",
      "Epoch 4458/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1415166345.6438 - val_loss: 1524459993.7169\n",
      "Epoch 4459/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1414925835.0215 - val_loss: 1526440365.5890\n",
      "Epoch 4460/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1414158688.4384 - val_loss: 1525325235.4338\n",
      "Epoch 4461/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1414304225.6908 - val_loss: 1525179135.4155\n",
      "Epoch 4462/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1414931520.8767 - val_loss: 1525732786.8493\n",
      "Epoch 4463/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1414252725.3542 - val_loss: 1525413194.8128\n",
      "Epoch 4464/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1414556053.5421 - val_loss: 1525177433.7169\n",
      "Epoch 4465/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1414307770.3014 - val_loss: 1525018151.4521\n",
      "Epoch 4466/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1413978160.2192 - val_loss: 1525374843.6164\n",
      "Epoch 4467/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1414830619.5538 - val_loss: 1524261004.2740\n",
      "Epoch 4468/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1413993314.6928 - val_loss: 1525821730.1918\n",
      "Epoch 4469/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1414317087.1859 - val_loss: 1526249368.2557\n",
      "Epoch 4470/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1414781688.3601 - val_loss: 1525390213.8447\n",
      "Epoch 4471/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1413984836.8845 - val_loss: 1525524051.2877\n",
      "Epoch 4472/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1414202792.0783 - val_loss: 1526101535.2694\n",
      "Epoch 4473/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1415048312.7358 - val_loss: 1525096811.8356\n",
      "Epoch 4474/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1413937014.6067 - val_loss: 1525819232.1461\n",
      "Epoch 4475/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1413999358.2466 - val_loss: 1525919911.1598\n",
      "Epoch 4476/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1414109172.2270 - val_loss: 1525812167.5982\n",
      "Epoch 4477/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1413965900.6497 - val_loss: 1526116984.1096\n",
      "Epoch 4478/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1414616773.5734 - val_loss: 1524976049.6804\n",
      "Epoch 4479/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1414129589.8552 - val_loss: 1526396985.2785\n",
      "Epoch 4480/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1414021775.7808 - val_loss: 1525659652.3836\n",
      "Epoch 4481/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1414396270.5910 - val_loss: 1525760929.8995\n",
      "Epoch 4482/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1414371947.9609 - val_loss: 1524496252.4932\n",
      "Epoch 4483/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1413917796.4462 - val_loss: 1525394243.7991\n",
      "Epoch 4484/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1413930359.9843 - val_loss: 1525964674.3379\n",
      "Epoch 4485/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1414007952.9080 - val_loss: 1525518878.1005\n",
      "Epoch 4486/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1413924272.5949 - val_loss: 1525092098.6301\n",
      "Epoch 4487/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1413789376.8767 - val_loss: 1525292645.6986\n",
      "Epoch 4488/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1413992895.4990 - val_loss: 1525851566.4658\n",
      "Epoch 4489/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1413732029.3699 - val_loss: 1525285873.9726\n",
      "Epoch 4490/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1414014697.2055 - val_loss: 1525670061.8813\n",
      "Epoch 4491/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1414007370.1448 - val_loss: 1525665050.0091\n",
      "Epoch 4492/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1414346417.2838 - val_loss: 1525245377.7534\n",
      "Epoch 4493/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1413750421.5421 - val_loss: 1525253184.0000\n",
      "Epoch 4494/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1413882054.0744 - val_loss: 1524732575.8539\n",
      "Epoch 4495/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 42us/step - loss: 1414495210.0822 - val_loss: 1526020873.3516\n",
      "Epoch 4496/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1414148801.6282 - val_loss: 1525205650.1187\n",
      "Epoch 4497/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1413779492.3209 - val_loss: 1525185133.2968\n",
      "Epoch 4498/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1413768944.9706 - val_loss: 1525078025.9361\n",
      "Epoch 4499/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1414011203.3816 - val_loss: 1525098926.4658\n",
      "Epoch 4500/15000\n",
      "1022/1022 [==============================] - 0s 74us/step - loss: 1413668260.1331 - val_loss: 1525152743.7443\n",
      "Epoch 4501/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1413683756.5871 - val_loss: 1525460332.4201\n",
      "Epoch 4502/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1413637602.3170 - val_loss: 1525257655.5251\n",
      "Epoch 4503/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1413499256.3601 - val_loss: 1525207073.6073\n",
      "Epoch 4504/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1413692639.6869 - val_loss: 1525420981.7717\n",
      "Epoch 4505/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1414302906.7397 - val_loss: 1525120386.9224\n",
      "Epoch 4506/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1413885793.1898 - val_loss: 1526097022.8311\n",
      "Epoch 4507/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1413645910.1683 - val_loss: 1525110707.7260\n",
      "Epoch 4508/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1413865842.9746 - val_loss: 1525751027.4338\n",
      "Epoch 4509/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1414488133.1350 - val_loss: 1524160763.9087\n",
      "Epoch 4510/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1413467856.8454 - val_loss: 1525064395.3973\n",
      "Epoch 4511/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1413879041.3777 - val_loss: 1525157678.1735\n",
      "Epoch 4512/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1413988634.9276 - val_loss: 1525817772.7123\n",
      "Epoch 4513/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1413345884.6810 - val_loss: 1525504495.3425\n",
      "Epoch 4514/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1413730637.0254 - val_loss: 1525133550.4658\n",
      "Epoch 4515/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1413400625.3464 - val_loss: 1525211281.8265\n",
      "Epoch 4516/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1413425658.4892 - val_loss: 1524982358.2100\n",
      "Epoch 4517/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1413541502.7476 - val_loss: 1524995436.7123\n",
      "Epoch 4518/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1413391276.0861 - val_loss: 1525386250.5205\n",
      "Epoch 4519/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1413517096.9550 - val_loss: 1525169372.0548\n",
      "Epoch 4520/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1413315435.4599 - val_loss: 1525511985.3881\n",
      "Epoch 4521/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1413498235.1155 - val_loss: 1524938933.7717\n",
      "Epoch 4522/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1413564407.4834 - val_loss: 1525423375.1963\n",
      "Epoch 4523/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1413379312.9706 - val_loss: 1525192185.5708\n",
      "Epoch 4524/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1413605295.1546 - val_loss: 1525117647.7808\n",
      "Epoch 4525/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1413366756.1957 - val_loss: 1524927715.9452\n",
      "Epoch 4526/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1413311473.3464 - val_loss: 1524547794.4110\n",
      "Epoch 4527/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1413974074.1135 - val_loss: 1524906078.3927\n",
      "Epoch 4528/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1413715055.2172 - val_loss: 1525660572.3470\n",
      "Epoch 4529/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1413304932.6967 - val_loss: 1524835084.5662\n",
      "Epoch 4530/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1413146355.9765 - val_loss: 1524646177.0228\n",
      "Epoch 4531/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1413238870.9198 - val_loss: 1524515184.5114\n",
      "Epoch 4532/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1413164328.5793 - val_loss: 1525224453.8447\n",
      "Epoch 4533/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1413498709.7926 - val_loss: 1525032379.3242\n",
      "Epoch 4534/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1413439660.7123 - val_loss: 1524082795.8356\n",
      "Epoch 4535/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1413110119.2016 - val_loss: 1525368403.2877\n",
      "Epoch 4536/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1413431691.7730 - val_loss: 1524541842.1187\n",
      "Epoch 4537/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1413084046.2779 - val_loss: 1524951367.0137\n",
      "Epoch 4538/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1413178800.0313 - val_loss: 1525433139.7260\n",
      "Epoch 4539/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1413173534.8102 - val_loss: 1525065831.4521\n",
      "Epoch 4540/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1413050456.6732 - val_loss: 1525092621.7352\n",
      "Epoch 4541/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1413509236.2270 - val_loss: 1524178433.4612\n",
      "Epoch 4542/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1413009074.4736 - val_loss: 1524909122.6301\n",
      "Epoch 4543/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1413018764.0235 - val_loss: 1524853792.7306\n",
      "Epoch 4544/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1413131509.4795 - val_loss: 1525289399.5251\n",
      "Epoch 4545/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1413070688.0626 - val_loss: 1524764303.1963\n",
      "Epoch 4546/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1413490726.3249 - val_loss: 1525193231.4886\n",
      "Epoch 4547/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1413224654.5284 - val_loss: 1525064772.9680\n",
      "Epoch 4548/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1412853044.3523 - val_loss: 1525113580.4201\n",
      "Epoch 4549/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1413600973.5264 - val_loss: 1524902191.9269\n",
      "Epoch 4550/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1413790730.5205 - val_loss: 1524327686.4292\n",
      "Epoch 4551/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1413172034.7554 - val_loss: 1524320568.9863\n",
      "Epoch 4552/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1412945600.0000 - val_loss: 1525593611.6895\n",
      "Epoch 4553/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1413432034.9432 - val_loss: 1524362650.0091\n",
      "Epoch 4554/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1412727202.3170 - val_loss: 1525293448.1826\n",
      "Epoch 4555/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1412925463.6712 - val_loss: 1525468240.6575\n",
      "Epoch 4556/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1413730859.0841 - val_loss: 1523941096.3288\n",
      "Epoch 4557/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1413442455.9217 - val_loss: 1525833611.1050\n",
      "Epoch 4558/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1412876119.1703 - val_loss: 1524851572.0183\n",
      "Epoch 4559/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 41us/step - loss: 1413010021.9491 - val_loss: 1525274087.7443\n",
      "Epoch 4560/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1413123349.0411 - val_loss: 1524757323.1050\n",
      "Epoch 4561/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1412833960.9550 - val_loss: 1525363697.3881\n",
      "Epoch 4562/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1412924179.0372 - val_loss: 1524872779.9817\n",
      "Epoch 4563/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1413069107.7260 - val_loss: 1525354569.9361\n",
      "Epoch 4564/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1412914274.4423 - val_loss: 1525623091.1416\n",
      "Epoch 4565/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1412929496.5479 - val_loss: 1524968134.1370\n",
      "Epoch 4566/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1412547207.2642 - val_loss: 1524506085.1142\n",
      "Epoch 4567/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1412850536.7045 - val_loss: 1524498674.5571\n",
      "Epoch 4568/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1412756357.0098 - val_loss: 1524590625.8995\n",
      "Epoch 4569/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1412727347.9765 - val_loss: 1524274555.0320\n",
      "Epoch 4570/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1412602695.0137 - val_loss: 1524814168.8402\n",
      "Epoch 4571/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1412760228.8219 - val_loss: 1524930546.5571\n",
      "Epoch 4572/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1412798814.4344 - val_loss: 1524593220.3836\n",
      "Epoch 4573/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1412782333.6204 - val_loss: 1524296043.5434\n",
      "Epoch 4574/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1412719115.5225 - val_loss: 1524318190.4658\n",
      "Epoch 4575/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1412560450.8806 - val_loss: 1524458351.0502\n",
      "Epoch 4576/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1412888223.3112 - val_loss: 1524046105.4247\n",
      "Epoch 4577/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1412348564.4149 - val_loss: 1524544984.2557\n",
      "Epoch 4578/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1413029051.8669 - val_loss: 1525518860.2740\n",
      "Epoch 4579/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1412910692.8219 - val_loss: 1524566923.6895\n",
      "Epoch 4580/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1412748077.0254 - val_loss: 1525619152.0731\n",
      "Epoch 4581/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1413179722.3953 - val_loss: 1526185670.4292\n",
      "Epoch 4582/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1412891013.5108 - val_loss: 1523786980.8219\n",
      "Epoch 4583/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1412470588.6184 - val_loss: 1524193411.2146\n",
      "Epoch 4584/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1412543591.7025 - val_loss: 1524723549.2237\n",
      "Epoch 4585/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1412444538.2387 - val_loss: 1525638167.0868\n",
      "Epoch 4586/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1412455003.8043 - val_loss: 1524308740.9680\n",
      "Epoch 4587/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1413154509.9022 - val_loss: 1524554680.6941\n",
      "Epoch 4588/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1412474981.1977 - val_loss: 1525066750.5388\n",
      "Epoch 4589/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1412593897.7691 - val_loss: 1525238783.1233\n",
      "Epoch 4590/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1412472117.9804 - val_loss: 1524682162.2648\n",
      "Epoch 4591/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1412259836.1174 - val_loss: 1524541952.8767\n",
      "Epoch 4592/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1412613136.2818 - val_loss: 1525361573.6986\n",
      "Epoch 4593/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1412449338.7397 - val_loss: 1524482746.1553\n",
      "Epoch 4594/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1412467515.4912 - val_loss: 1524296802.4840\n",
      "Epoch 4595/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1412396990.9980 - val_loss: 1525003212.5662\n",
      "Epoch 4596/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1412134519.1076 - val_loss: 1524665521.6804\n",
      "Epoch 4597/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1412247891.9139 - val_loss: 1524612596.6027\n",
      "Epoch 4598/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1412238039.2955 - val_loss: 1524664249.8630\n",
      "Epoch 4599/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1412050300.2427 - val_loss: 1524802322.7032\n",
      "Epoch 4600/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1412484979.3503 - val_loss: 1525050831.1963\n",
      "Epoch 4601/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1412228945.4090 - val_loss: 1523962674.5571\n",
      "Epoch 4602/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1412306184.7671 - val_loss: 1524634997.4795\n",
      "Epoch 4603/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1412291450.4892 - val_loss: 1524837977.7169\n",
      "Epoch 4604/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1412290401.9413 - val_loss: 1524114390.7945\n",
      "Epoch 4605/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1412218425.8004 - val_loss: 1524144240.8037\n",
      "Epoch 4606/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1412306280.9550 - val_loss: 1524795994.0091\n",
      "Epoch 4607/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1412018463.0607 - val_loss: 1524777199.6347\n",
      "Epoch 4608/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1412177166.0274 - val_loss: 1524688029.5160\n",
      "Epoch 4609/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1412050551.2329 - val_loss: 1524517650.9954\n",
      "Epoch 4610/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1412159948.9002 - val_loss: 1523688619.8356\n",
      "Epoch 4611/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1412767375.2798 - val_loss: 1524954655.8539\n",
      "Epoch 4612/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1412056667.6791 - val_loss: 1524419288.5479\n",
      "Epoch 4613/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1412207611.4912 - val_loss: 1523940338.8493\n",
      "Epoch 4614/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1412148487.0137 - val_loss: 1524397887.1233\n",
      "Epoch 4615/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1412736642.6301 - val_loss: 1523979825.9726\n",
      "Epoch 4616/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1412739271.8904 - val_loss: 1525485521.8265\n",
      "Epoch 4617/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1411899401.2681 - val_loss: 1524603343.4886\n",
      "Epoch 4618/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1411841666.8806 - val_loss: 1524067060.6027\n",
      "Epoch 4619/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1412001911.4834 - val_loss: 1524560509.0776\n",
      "Epoch 4620/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1412203807.0607 - val_loss: 1524198106.3014\n",
      "Epoch 4621/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1412103589.8239 - val_loss: 1524372441.7169\n",
      "Epoch 4622/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1414007460.5714 - val_loss: 1525625514.9589\n",
      "Epoch 4623/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 32us/step - loss: 1411840677.0724 - val_loss: 1524194246.4292\n",
      "Epoch 4624/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1412385222.3875 - val_loss: 1524490445.4429\n",
      "Epoch 4625/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1411990979.6321 - val_loss: 1524010909.2237\n",
      "Epoch 4626/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1412832758.4814 - val_loss: 1522953287.5982\n",
      "Epoch 4627/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1411795882.3327 - val_loss: 1524163021.4429\n",
      "Epoch 4628/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1411971408.1566 - val_loss: 1524154770.1187\n",
      "Epoch 4629/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1412035096.0470 - val_loss: 1524881254.8676\n",
      "Epoch 4630/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1412018938.4892 - val_loss: 1523443917.7352\n",
      "Epoch 4631/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1411648829.9961 - val_loss: 1524083850.8128\n",
      "Epoch 4632/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1411744649.2681 - val_loss: 1524268494.6119\n",
      "Epoch 4633/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1411644396.3366 - val_loss: 1524716592.2192\n",
      "Epoch 4634/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1411768774.5127 - val_loss: 1524745177.7169\n",
      "Epoch 4635/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1411754441.6438 - val_loss: 1524010022.5753\n",
      "Epoch 4636/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1411678010.7397 - val_loss: 1524117299.1416\n",
      "Epoch 4637/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1411650695.8904 - val_loss: 1524468283.0320\n",
      "Epoch 4638/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1412017069.8395 - val_loss: 1525008176.8037\n",
      "Epoch 4639/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1411959741.1194 - val_loss: 1524313280.2922\n",
      "Epoch 4640/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1411738686.3718 - val_loss: 1524078157.4429\n",
      "Epoch 4641/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1411523187.7260 - val_loss: 1524148461.0046\n",
      "Epoch 4642/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1411719454.3092 - val_loss: 1523407577.7169\n",
      "Epoch 4643/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1411495800.2348 - val_loss: 1523933444.6758\n",
      "Epoch 4644/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1411494087.8904 - val_loss: 1524696512.8767\n",
      "Epoch 4645/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1412078376.7045 - val_loss: 1523695588.5297\n",
      "Epoch 4646/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1411664840.7671 - val_loss: 1524135541.7717\n",
      "Epoch 4647/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1411559838.8102 - val_loss: 1524246274.9224\n",
      "Epoch 4648/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1412754528.1879 - val_loss: 1525398655.1233\n",
      "Epoch 4649/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1411951010.6928 - val_loss: 1524543797.7717\n",
      "Epoch 4650/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1411627131.7417 - val_loss: 1523447563.9817\n",
      "Epoch 4651/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1411402717.4325 - val_loss: 1524292135.7443\n",
      "Epoch 4652/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1411402462.6849 - val_loss: 1524283841.4612\n",
      "Epoch 4653/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1411729775.0920 - val_loss: 1524749771.6895\n",
      "Epoch 4654/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1411414751.9374 - val_loss: 1523562433.7534\n",
      "Epoch 4655/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1412060103.8904 - val_loss: 1523607808.0000\n",
      "Epoch 4656/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1411324590.5910 - val_loss: 1524535533.2968\n",
      "Epoch 4657/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1411895411.4755 - val_loss: 1524628761.4247\n",
      "Epoch 4658/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1412052235.5225 - val_loss: 1523293276.0548\n",
      "Epoch 4659/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1411487984.8454 - val_loss: 1523820731.9087\n",
      "Epoch 4660/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1411819938.5049 - val_loss: 1523429589.9178\n",
      "Epoch 4661/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1412459400.2661 - val_loss: 1524038449.9726\n",
      "Epoch 4662/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1411265619.0372 - val_loss: 1523583354.1553\n",
      "Epoch 4663/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1411298837.5421 - val_loss: 1523886401.4612\n",
      "Epoch 4664/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1411160775.6399 - val_loss: 1523887376.0731\n",
      "Epoch 4665/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1411448640.6262 - val_loss: 1524040483.3607\n",
      "Epoch 4666/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1411241470.4971 - val_loss: 1523977238.7945\n",
      "Epoch 4667/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1411379709.9961 - val_loss: 1524636719.0502\n",
      "Epoch 4668/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1411199657.7065 - val_loss: 1523706253.4429\n",
      "Epoch 4669/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1411219411.4129 - val_loss: 1523951410.5571\n",
      "Epoch 4670/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1411148209.7221 - val_loss: 1523546831.4886\n",
      "Epoch 4671/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1411237536.8141 - val_loss: 1524120384.0000\n",
      "Epoch 4672/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1411267551.4364 - val_loss: 1524297634.7763\n",
      "Epoch 4673/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1412472173.8395 - val_loss: 1524861969.5342\n",
      "Epoch 4674/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1410981204.2896 - val_loss: 1523589691.3242\n",
      "Epoch 4675/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1411052444.8063 - val_loss: 1523800708.6758\n",
      "Epoch 4676/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1410993432.0470 - val_loss: 1523557044.8950\n",
      "Epoch 4677/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1410949504.0000 - val_loss: 1523582603.3973\n",
      "Epoch 4678/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1411136799.6243 - val_loss: 1523547875.6530\n",
      "Epoch 4679/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1411741780.2896 - val_loss: 1524421950.5388\n",
      "Epoch 4680/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1410920560.9706 - val_loss: 1524214778.1553\n",
      "Epoch 4681/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1411912070.2622 - val_loss: 1524843572.8950\n",
      "Epoch 4682/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1410718903.1076 - val_loss: 1523742363.4703\n",
      "Epoch 4683/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1411400239.3425 - val_loss: 1522989237.7717\n",
      "Epoch 4684/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1411243879.2016 - val_loss: 1523411482.3014\n",
      "Epoch 4685/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1410901861.1977 - val_loss: 1523252022.6484\n",
      "Epoch 4686/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1411195386.8650 - val_loss: 1523623021.0046\n",
      "Epoch 4687/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1410995091.9139 - val_loss: 1524140349.6621\n",
      "Epoch 4688/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1411334938.3014 - val_loss: 1523586841.4247\n",
      "Epoch 4689/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1411315548.0548 - val_loss: 1524435896.6941\n",
      "Epoch 4690/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1411979870.4971 - val_loss: 1522705238.7945\n",
      "Epoch 4691/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1410916072.4540 - val_loss: 1523865009.3881\n",
      "Epoch 4692/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1410921017.1115 - val_loss: 1523812197.9909\n",
      "Epoch 4693/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1411199406.9667 - val_loss: 1523204928.0000\n",
      "Epoch 4694/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1410882906.1761 - val_loss: 1524472275.8721\n",
      "Epoch 4695/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1410781274.6771 - val_loss: 1524219423.5616\n",
      "Epoch 4696/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1411496661.9178 - val_loss: 1525053009.2420\n",
      "Epoch 4697/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1411750246.1996 - val_loss: 1523280031.2694\n",
      "Epoch 4698/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1410925598.8102 - val_loss: 1524377834.0822\n",
      "Epoch 4699/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1410619096.4227 - val_loss: 1523787845.2603\n",
      "Epoch 4700/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1411009775.7182 - val_loss: 1523651770.1553\n",
      "Epoch 4701/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1410693479.5773 - val_loss: 1523668888.2557\n",
      "Epoch 4702/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1411034156.1487 - val_loss: 1522738986.0822\n",
      "Epoch 4703/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1410773028.6967 - val_loss: 1523756225.1689\n",
      "Epoch 4704/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1410776028.6810 - val_loss: 1523503296.2922\n",
      "Epoch 4705/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1410765697.5029 - val_loss: 1524198480.6575\n",
      "Epoch 4706/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1410522263.5460 - val_loss: 1524198905.5708\n",
      "Epoch 4707/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1410595598.6536 - val_loss: 1523849838.1735\n",
      "Epoch 4708/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1410725593.2994 - val_loss: 1523969696.4384\n",
      "Epoch 4709/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1410817661.4951 - val_loss: 1524176640.2922\n",
      "Epoch 4710/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1410690749.3699 - val_loss: 1524102406.1370\n",
      "Epoch 4711/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1410416846.1526 - val_loss: 1523575191.9635\n",
      "Epoch 4712/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1410897027.0059 - val_loss: 1523386778.5936\n",
      "Epoch 4713/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1410825506.1918 - val_loss: 1523522490.4475\n",
      "Epoch 4714/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1410797246.8728 - val_loss: 1524488070.1370\n",
      "Epoch 4715/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1410609509.6986 - val_loss: 1523160793.1324\n",
      "Epoch 4716/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1410408111.5930 - val_loss: 1523407685.5525\n",
      "Epoch 4717/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1411111595.2094 - val_loss: 1523106882.3379\n",
      "Epoch 4718/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1410453786.0509 - val_loss: 1523817527.8174\n",
      "Epoch 4719/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1410673893.6986 - val_loss: 1523910011.6164\n",
      "Epoch 4720/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1410689770.2074 - val_loss: 1523290901.3333\n",
      "Epoch 4721/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1410710400.7515 - val_loss: 1522485172.0183\n",
      "Epoch 4722/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1410658544.2192 - val_loss: 1523775741.6621\n",
      "Epoch 4723/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1410757409.9413 - val_loss: 1523869171.7260\n",
      "Epoch 4724/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1410386332.8063 - val_loss: 1524086907.0320\n",
      "Epoch 4725/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1410451705.1115 - val_loss: 1523266552.1096\n",
      "Epoch 4726/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1410488223.3112 - val_loss: 1524243105.0228\n",
      "Epoch 4727/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1410761280.1252 - val_loss: 1524650919.4521\n",
      "Epoch 4728/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1411030077.1194 - val_loss: 1524693800.9132\n",
      "Epoch 4729/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1410718914.3796 - val_loss: 1522979728.3653\n",
      "Epoch 4730/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1410274975.3112 - val_loss: 1523102552.2557\n",
      "Epoch 4731/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1410292283.1155 - val_loss: 1522490111.1233\n",
      "Epoch 4732/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1410189062.0117 - val_loss: 1523587029.0411\n",
      "Epoch 4733/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1410149934.0900 - val_loss: 1523371900.2009\n",
      "Epoch 4734/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1410128002.7554 - val_loss: 1523583467.2511\n",
      "Epoch 4735/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1410247704.5479 - val_loss: 1523437577.0594\n",
      "Epoch 4736/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1410499230.3092 - val_loss: 1524329753.1324\n",
      "Epoch 4737/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1410195384.7358 - val_loss: 1523075469.7352\n",
      "Epoch 4738/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1410292567.2955 - val_loss: 1523062511.9269\n",
      "Epoch 4739/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1411043291.1781 - val_loss: 1524522412.7123\n",
      "Epoch 4740/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1409992659.2877 - val_loss: 1523536714.5205\n",
      "Epoch 4741/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1410199254.6693 - val_loss: 1523092508.0548\n",
      "Epoch 4742/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1410177798.2622 - val_loss: 1522476318.6849\n",
      "Epoch 4743/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1410152502.3562 - val_loss: 1522660058.5936\n",
      "Epoch 4744/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1411128955.2407 - val_loss: 1524583044.6758\n",
      "Epoch 4745/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1410082830.7789 - val_loss: 1524029220.5297\n",
      "Epoch 4746/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1410128121.6751 - val_loss: 1523173657.7169\n",
      "Epoch 4747/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1410113501.9335 - val_loss: 1523711663.9269\n",
      "Epoch 4748/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1410044091.6164 - val_loss: 1523529536.8767\n",
      "Epoch 4749/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1410004203.8356 - val_loss: 1523114704.6575\n",
      "Epoch 4750/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1410060754.9746 - val_loss: 1523711274.0822\n",
      "Epoch 4751/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 49us/step - loss: 1410033623.2955 - val_loss: 1522886909.3699\n",
      "Epoch 4752/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1409950993.1585 - val_loss: 1522971101.2237\n",
      "Epoch 4753/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1409973747.7260 - val_loss: 1522839571.2877\n",
      "Epoch 4754/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1409923504.7828 - val_loss: 1523118602.2283\n",
      "Epoch 4755/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1409988036.3836 - val_loss: 1524107666.9954\n",
      "Epoch 4756/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1410134049.1898 - val_loss: 1522939846.4292\n",
      "Epoch 4757/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1409847022.3405 - val_loss: 1523929457.6804\n",
      "Epoch 4758/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1409862901.4795 - val_loss: 1523487382.7945\n",
      "Epoch 4759/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1410124918.1057 - val_loss: 1522968272.6575\n",
      "Epoch 4760/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1410005117.9961 - val_loss: 1523920685.5890\n",
      "Epoch 4761/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1409939567.3425 - val_loss: 1523654175.2694\n",
      "Epoch 4762/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1410016605.3072 - val_loss: 1523555548.6393\n",
      "Epoch 4763/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1410062626.5675 - val_loss: 1523225123.0685\n",
      "Epoch 4764/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1409770958.0274 - val_loss: 1523230181.9909\n",
      "Epoch 4765/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1409988349.7456 - val_loss: 1523765140.7489\n",
      "Epoch 4766/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1410037830.7632 - val_loss: 1523718245.6986\n",
      "Epoch 4767/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1409970540.2114 - val_loss: 1524079509.3333\n",
      "Epoch 4768/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1410072380.8689 - val_loss: 1522693668.2374\n",
      "Epoch 4769/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1409725969.0333 - val_loss: 1522868725.4795\n",
      "Epoch 4770/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1409772756.9159 - val_loss: 1522956390.2831\n",
      "Epoch 4771/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1409766099.4129 - val_loss: 1522980617.0594\n",
      "Epoch 4772/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1410432646.8258 - val_loss: 1522755144.1826\n",
      "Epoch 4773/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1409793597.1194 - val_loss: 1522865929.0594\n",
      "Epoch 4774/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1409721154.1292 - val_loss: 1523237447.5982\n",
      "Epoch 4775/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1410136866.6928 - val_loss: 1522709078.5023\n",
      "Epoch 4776/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1409635759.9687 - val_loss: 1522803727.1963\n",
      "Epoch 4777/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1409753729.3777 - val_loss: 1523412590.4658\n",
      "Epoch 4778/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1409629167.3425 - val_loss: 1523467791.1963\n",
      "Epoch 4779/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1409948644.9472 - val_loss: 1522876643.6530\n",
      "Epoch 4780/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1409741562.3640 - val_loss: 1523644412.2009\n",
      "Epoch 4781/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1409545980.7436 - val_loss: 1523872594.9954\n",
      "Epoch 4782/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1409606764.7123 - val_loss: 1523416601.4247\n",
      "Epoch 4783/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1409531820.8376 - val_loss: 1522629956.0913\n",
      "Epoch 4784/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1409468841.2055 - val_loss: 1523479165.3699\n",
      "Epoch 4785/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1409780528.8454 - val_loss: 1522914134.5023\n",
      "Epoch 4786/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1409388166.2622 - val_loss: 1523285914.0091\n",
      "Epoch 4787/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1409409843.4755 - val_loss: 1523143741.6621\n",
      "Epoch 4788/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1409574211.0059 - val_loss: 1523817145.5708\n",
      "Epoch 4789/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1409330529.3151 - val_loss: 1523053263.4886\n",
      "Epoch 4790/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1409521379.9452 - val_loss: 1523510525.3699\n",
      "Epoch 4791/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1409247059.9139 - val_loss: 1522949213.8082\n",
      "Epoch 4792/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1409974270.1213 - val_loss: 1522025275.3242\n",
      "Epoch 4793/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1409424300.1487 - val_loss: 1523213765.2603\n",
      "Epoch 4794/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1409496622.5910 - val_loss: 1522761506.7763\n",
      "Epoch 4795/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1409567805.3699 - val_loss: 1522583345.3881\n",
      "Epoch 4796/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1409402463.6869 - val_loss: 1523491111.4521\n",
      "Epoch 4797/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1409686239.9374 - val_loss: 1523726087.0137\n",
      "Epoch 4798/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1409252413.6204 - val_loss: 1523527531.2511\n",
      "Epoch 4799/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1409499613.9335 - val_loss: 1522405634.0457\n",
      "Epoch 4800/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1410047630.6536 - val_loss: 1523355039.8539\n",
      "Epoch 4801/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1409300060.6810 - val_loss: 1523027749.4064\n",
      "Epoch 4802/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1409418013.5577 - val_loss: 1522607409.3881\n",
      "Epoch 4803/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1409283902.6223 - val_loss: 1522554389.3333\n",
      "Epoch 4804/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1409877207.4834 - val_loss: 1523798479.7808\n",
      "Epoch 4805/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1409485606.1996 - val_loss: 1523430744.5479\n",
      "Epoch 4806/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1409428140.8376 - val_loss: 1522766643.7260\n",
      "Epoch 4807/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1409173865.4560 - val_loss: 1522975750.1370\n",
      "Epoch 4808/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1409753185.8160 - val_loss: 1521995990.5023\n",
      "Epoch 4809/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1409480054.6067 - val_loss: 1523368498.5571\n",
      "Epoch 4810/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1409480616.5793 - val_loss: 1523873309.2237\n",
      "Epoch 4811/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1409403633.8474 - val_loss: 1523309732.5297\n",
      "Epoch 4812/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1409078741.6673 - val_loss: 1522582837.7717\n",
      "Epoch 4813/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1409400426.2074 - val_loss: 1523811019.3973\n",
      "Epoch 4814/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1409130616.4853 - val_loss: 1523233931.6895\n",
      "Epoch 4815/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 32us/step - loss: 1409139813.4481 - val_loss: 1522122808.6941\n",
      "Epoch 4816/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1409296674.5675 - val_loss: 1522689121.0228\n",
      "Epoch 4817/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1409067148.7750 - val_loss: 1522481161.0594\n",
      "Epoch 4818/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1409024843.1468 - val_loss: 1522347353.7169\n",
      "Epoch 4819/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1409190484.1644 - val_loss: 1523393703.1598\n",
      "Epoch 4820/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1409010336.8141 - val_loss: 1523142596.3836\n",
      "Epoch 4821/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1408884333.2133 - val_loss: 1522618871.5251\n",
      "Epoch 4822/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1409062991.5303 - val_loss: 1522997204.7489\n",
      "Epoch 4823/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1409044367.2798 - val_loss: 1522355708.2009\n",
      "Epoch 4824/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1409583534.9667 - val_loss: 1521745891.0685\n",
      "Epoch 4825/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1408902851.3816 - val_loss: 1523067211.3973\n",
      "Epoch 4826/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1409088856.7984 - val_loss: 1522160901.2603\n",
      "Epoch 4827/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1408979108.3209 - val_loss: 1522950849.1689\n",
      "Epoch 4828/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1408863404.9002 - val_loss: 1523299598.3196\n",
      "Epoch 4829/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1408681384.5793 - val_loss: 1523145305.7169\n",
      "Epoch 4830/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1409141563.6164 - val_loss: 1521897691.4703\n",
      "Epoch 4831/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1408679888.2818 - val_loss: 1522835539.5799\n",
      "Epoch 4832/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1408741514.0196 - val_loss: 1523165829.5525\n",
      "Epoch 4833/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1408640114.4736 - val_loss: 1523072431.3425\n",
      "Epoch 4834/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1409546882.5049 - val_loss: 1521763833.5708\n",
      "Epoch 4835/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1408820425.8943 - val_loss: 1523257604.9680\n",
      "Epoch 4836/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1408762829.2759 - val_loss: 1523327629.4429\n",
      "Epoch 4837/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1408616430.3405 - val_loss: 1522783121.2420\n",
      "Epoch 4838/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1408797899.1468 - val_loss: 1522492841.4977\n",
      "Epoch 4839/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1408706638.0274 - val_loss: 1522805643.1050\n",
      "Epoch 4840/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1408678393.7378 - val_loss: 1522232746.9589\n",
      "Epoch 4841/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1408927994.6145 - val_loss: 1522146350.1735\n",
      "Epoch 4842/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1408683951.7182 - val_loss: 1522168779.3973\n",
      "Epoch 4843/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1408721563.6791 - val_loss: 1522892425.9361\n",
      "Epoch 4844/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1408846593.0020 - val_loss: 1522870631.4521\n",
      "Epoch 4845/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1408650708.9159 - val_loss: 1522507458.3379\n",
      "Epoch 4846/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1409077112.7358 - val_loss: 1523613153.6073\n",
      "Epoch 4847/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1409073730.6301 - val_loss: 1522186220.4201\n",
      "Epoch 4848/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1408776496.3444 - val_loss: 1523490725.9909\n",
      "Epoch 4849/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1408916431.6556 - val_loss: 1522639134.3927\n",
      "Epoch 4850/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1408560490.8337 - val_loss: 1523023805.0776\n",
      "Epoch 4851/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1408737767.5773 - val_loss: 1523329912.1096\n",
      "Epoch 4852/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1408405334.7945 - val_loss: 1522658935.8174\n",
      "Epoch 4853/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1408472192.5010 - val_loss: 1522379650.0457\n",
      "Epoch 4854/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1409313118.8102 - val_loss: 1521494072.4018\n",
      "Epoch 4855/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1408783004.8063 - val_loss: 1522363114.6667\n",
      "Epoch 4856/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1408343552.5010 - val_loss: 1522883065.8630\n",
      "Epoch 4857/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1408522926.0900 - val_loss: 1523631139.9452\n",
      "Epoch 4858/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1408479975.9530 - val_loss: 1522188195.6530\n",
      "Epoch 4859/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1408404632.5479 - val_loss: 1522568650.5205\n",
      "Epoch 4860/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1409006351.5303 - val_loss: 1523350770.5571\n",
      "Epoch 4861/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1408486556.8063 - val_loss: 1523509542.5753\n",
      "Epoch 4862/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1408248849.7847 - val_loss: 1522821223.7443\n",
      "Epoch 4863/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1408238107.0528 - val_loss: 1522189053.3699\n",
      "Epoch 4864/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1408204588.0861 - val_loss: 1522003789.4429\n",
      "Epoch 4865/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1408515846.0117 - val_loss: 1521828929.4612\n",
      "Epoch 4866/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1408192936.0783 - val_loss: 1522350887.4521\n",
      "Epoch 4867/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1408392079.9061 - val_loss: 1521772136.9132\n",
      "Epoch 4868/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1408214318.8415 - val_loss: 1522649251.0685\n",
      "Epoch 4869/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1408254877.3072 - val_loss: 1522726285.7352\n",
      "Epoch 4870/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1408482901.0411 - val_loss: 1522079083.5434\n",
      "Epoch 4871/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1408550427.9295 - val_loss: 1523008155.4703\n",
      "Epoch 4872/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1408348903.4521 - val_loss: 1521923381.1872\n",
      "Epoch 4873/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1408540939.1468 - val_loss: 1523200113.3881\n",
      "Epoch 4874/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1409083987.2877 - val_loss: 1522387812.5297\n",
      "Epoch 4875/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1408642445.5264 - val_loss: 1521909267.8721\n",
      "Epoch 4876/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1408573674.4579 - val_loss: 1523439883.3973\n",
      "Epoch 4877/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1408158815.6869 - val_loss: 1523005874.5571\n",
      "Epoch 4878/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1408434277.8239 - val_loss: 1521625259.8356\n",
      "Epoch 4879/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 29us/step - loss: 1408355986.7241 - val_loss: 1522263756.2740\n",
      "Epoch 4880/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1408614566.3249 - val_loss: 1523224992.1461\n",
      "Epoch 4881/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1408373405.3072 - val_loss: 1521677238.0639\n",
      "Epoch 4882/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1408452230.2622 - val_loss: 1523236663.5251\n",
      "Epoch 4883/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1408205431.9843 - val_loss: 1522007418.4475\n",
      "Epoch 4884/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1408213876.2270 - val_loss: 1521565178.4475\n",
      "Epoch 4885/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1408343930.1135 - val_loss: 1522427765.1872\n",
      "Epoch 4886/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1407963000.7358 - val_loss: 1522922963.5799\n",
      "Epoch 4887/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1408216410.6771 - val_loss: 1522861271.6712\n",
      "Epoch 4888/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1407851421.0568 - val_loss: 1522410200.8402\n",
      "Epoch 4889/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1408109580.5245 - val_loss: 1522302097.5342\n",
      "Epoch 4890/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1408030618.6771 - val_loss: 1521793439.2694\n",
      "Epoch 4891/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1407944772.6341 - val_loss: 1521916334.4658\n",
      "Epoch 4892/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1407950025.7691 - val_loss: 1522779013.2603\n",
      "Epoch 4893/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1407971322.4892 - val_loss: 1522136719.1963\n",
      "Epoch 4894/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1408146105.9883 - val_loss: 1521407037.0776\n",
      "Epoch 4895/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1408430303.4364 - val_loss: 1520999002.0091\n",
      "Epoch 4896/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1408579009.0020 - val_loss: 1522992413.5160\n",
      "Epoch 4897/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1407991658.5832 - val_loss: 1522470963.4338\n",
      "Epoch 4898/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1407847587.2564 - val_loss: 1522564114.4110\n",
      "Epoch 4899/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1407851150.0274 - val_loss: 1522476339.7260\n",
      "Epoch 4900/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1407733072.0313 - val_loss: 1522131342.6119\n",
      "Epoch 4901/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1407861637.7613 - val_loss: 1522773304.9863\n",
      "Epoch 4902/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1408054641.4716 - val_loss: 1522123866.3014\n",
      "Epoch 4903/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1407777820.0548 - val_loss: 1522630664.1826\n",
      "Epoch 4904/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1407595500.4618 - val_loss: 1522017214.2466\n",
      "Epoch 4905/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1408799090.7241 - val_loss: 1520844625.8265\n",
      "Epoch 4906/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1408905309.5577 - val_loss: 1523562996.6027\n",
      "Epoch 4907/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1408517541.3229 - val_loss: 1521659554.1918\n",
      "Epoch 4908/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1407565119.7495 - val_loss: 1522550302.3927\n",
      "Epoch 4909/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1407903257.5499 - val_loss: 1521884412.2009\n",
      "Epoch 4910/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1407529855.4990 - val_loss: 1522469138.7032\n",
      "Epoch 4911/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1407647154.8493 - val_loss: 1522155956.0183\n",
      "Epoch 4912/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1408131966.0587 - val_loss: 1521717045.4795\n",
      "Epoch 4913/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1407546723.4442 - val_loss: 1522312997.4064\n",
      "Epoch 4914/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1407875942.4501 - val_loss: 1521940025.5708\n",
      "Epoch 4915/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1407561828.4462 - val_loss: 1521861991.7443\n",
      "Epoch 4916/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1407693729.5656 - val_loss: 1522922600.0365\n",
      "Epoch 4917/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1407789506.5049 - val_loss: 1522642902.2100\n",
      "Epoch 4918/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1408071575.5460 - val_loss: 1522566120.0365\n",
      "Epoch 4919/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1407548576.3131 - val_loss: 1522787870.1005\n",
      "Epoch 4920/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1407577314.4423 - val_loss: 1521863867.6164\n",
      "Epoch 4921/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1407645843.5382 - val_loss: 1521451231.5616\n",
      "Epoch 4922/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1408181715.4129 - val_loss: 1523082166.6484\n",
      "Epoch 4923/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1407392365.7143 - val_loss: 1522743230.5388\n",
      "Epoch 4924/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1407504235.0841 - val_loss: 1521541761.7534\n",
      "Epoch 4925/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1407489463.4207 - val_loss: 1522083260.7854\n",
      "Epoch 4926/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1408021066.0196 - val_loss: 1522484430.6119\n",
      "Epoch 4927/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1407577077.9804 - val_loss: 1521257503.2694\n",
      "Epoch 4928/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1407736158.9354 - val_loss: 1520938774.7945\n",
      "Epoch 4929/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1407617182.0587 - val_loss: 1521224002.6301\n",
      "Epoch 4930/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1407807067.6791 - val_loss: 1520899456.2922\n",
      "Epoch 4931/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1407579153.7847 - val_loss: 1521514313.9361\n",
      "Epoch 4932/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1408341416.5793 - val_loss: 1522651178.3744\n",
      "Epoch 4933/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1407995221.9178 - val_loss: 1521297816.2557\n",
      "Epoch 4934/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1407336183.9843 - val_loss: 1522088917.9178\n",
      "Epoch 4935/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1407156859.2407 - val_loss: 1522436694.7945\n",
      "Epoch 4936/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1407459347.5382 - val_loss: 1522443807.5616\n",
      "Epoch 4937/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1407735500.7123 - val_loss: 1522214486.7945\n",
      "Epoch 4938/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1408114909.6830 - val_loss: 1521781952.5845\n",
      "Epoch 4939/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1407321517.9648 - val_loss: 1521968610.4840\n",
      "Epoch 4940/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1407654669.0254 - val_loss: 1521466163.4338\n",
      "Epoch 4941/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1407253409.3151 - val_loss: 1522750130.5571\n",
      "Epoch 4942/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1407364308.5401 - val_loss: 1522805391.4886\n",
      "Epoch 4943/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 33us/step - loss: 1407393922.7554 - val_loss: 1521571170.4840\n",
      "Epoch 4944/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1407461774.2779 - val_loss: 1521612235.1050\n",
      "Epoch 4945/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1407186341.8239 - val_loss: 1521377054.9772\n",
      "Epoch 4946/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1406991201.4403 - val_loss: 1521631442.9954\n",
      "Epoch 4947/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1407078155.2720 - val_loss: 1522172089.8630\n",
      "Epoch 4948/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1406988051.7886 - val_loss: 1521913200.2192\n",
      "Epoch 4949/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1407038254.7162 - val_loss: 1521695481.2785\n",
      "Epoch 4950/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1407221135.2798 - val_loss: 1522407902.3927\n",
      "Epoch 4951/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1407278105.0489 - val_loss: 1521049161.9361\n",
      "Epoch 4952/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1407014095.9061 - val_loss: 1521783035.9087\n",
      "Epoch 4953/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1407074341.4481 - val_loss: 1521794702.6119\n",
      "Epoch 4954/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1407000235.8356 - val_loss: 1521321295.7808\n",
      "Epoch 4955/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1407049024.6262 - val_loss: 1521021310.2466\n",
      "Epoch 4956/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1407979822.5910 - val_loss: 1522968600.5479\n",
      "Epoch 4957/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1407337650.7241 - val_loss: 1521245674.0822\n",
      "Epoch 4958/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1406923586.1292 - val_loss: 1521724912.2192\n",
      "Epoch 4959/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1406797830.0117 - val_loss: 1522205778.9954\n",
      "Epoch 4960/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1407262273.3777 - val_loss: 1521851368.6210\n",
      "Epoch 4961/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1406935064.6732 - val_loss: 1521906837.6256\n",
      "Epoch 4962/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1407471610.9902 - val_loss: 1520368592.0731\n",
      "Epoch 4963/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1406646373.8239 - val_loss: 1521926636.1279\n",
      "Epoch 4964/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1406919762.7867 - val_loss: 1522413470.6849\n",
      "Epoch 4965/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1406879353.4873 - val_loss: 1521523692.7123\n",
      "Epoch 4966/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1406973127.7652 - val_loss: 1521058708.7489\n",
      "Epoch 4967/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1406836638.8102 - val_loss: 1522026654.6849\n",
      "Epoch 4968/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1406828560.5323 - val_loss: 1522039886.3196\n",
      "Epoch 4969/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1406803394.0039 - val_loss: 1521952818.8493\n",
      "Epoch 4970/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1407203776.5010 - val_loss: 1522658134.2100\n",
      "Epoch 4971/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1406651565.3386 - val_loss: 1521586868.6027\n",
      "Epoch 4972/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1407618498.8806 - val_loss: 1522230239.2694\n",
      "Epoch 4973/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1407039924.8532 - val_loss: 1521050531.0685\n",
      "Epoch 4974/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1406794931.3503 - val_loss: 1521231812.3836\n",
      "Epoch 4975/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1406736408.7984 - val_loss: 1521817325.2968\n",
      "Epoch 4976/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1406667058.0978 - val_loss: 1521959340.7123\n",
      "Epoch 4977/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1406536505.3620 - val_loss: 1521517310.5388\n",
      "Epoch 4978/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1406694490.1761 - val_loss: 1521278470.7215\n",
      "Epoch 4979/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1407570352.9706 - val_loss: 1522659150.9041\n",
      "Epoch 4980/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1406637179.9922 - val_loss: 1521247080.9132\n",
      "Epoch 4981/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1406515737.9256 - val_loss: 1521206829.5890\n",
      "Epoch 4982/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1406786097.2838 - val_loss: 1521121180.9315\n",
      "Epoch 4983/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1406860838.4501 - val_loss: 1521212328.3288\n",
      "Epoch 4984/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1406713035.8982 - val_loss: 1520866771.2877\n",
      "Epoch 4985/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1407055174.6380 - val_loss: 1520499557.9909\n",
      "Epoch 4986/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1406683110.6380 - val_loss: 1520970845.2237\n",
      "Epoch 4987/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1406489801.6438 - val_loss: 1521971026.1187\n",
      "Epoch 4988/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1406543600.9706 - val_loss: 1522070054.2831\n",
      "Epoch 4989/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1406885860.4462 - val_loss: 1521066563.7991\n",
      "Epoch 4990/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1406458642.2857 - val_loss: 1521911793.3881\n",
      "Epoch 4991/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1406248063.2485 - val_loss: 1521465275.0320\n",
      "Epoch 4992/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1406286530.7554 - val_loss: 1521403576.1096\n",
      "Epoch 4993/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1406389756.8689 - val_loss: 1521151919.3425\n",
      "Epoch 4994/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1406362096.2192 - val_loss: 1521387299.9452\n",
      "Epoch 4995/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1406698309.6360 - val_loss: 1522269272.2557\n",
      "Epoch 4996/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1406391220.9785 - val_loss: 1520739114.3744\n",
      "Epoch 4997/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1406831003.5538 - val_loss: 1521864515.7991\n",
      "Epoch 4998/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1406421754.7397 - val_loss: 1521503208.9132\n",
      "Epoch 4999/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1406237782.9198 - val_loss: 1521166592.0000\n",
      "Epoch 5000/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1406265678.9041 - val_loss: 1520945774.7580\n",
      "Epoch 5001/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1406239140.0705 - val_loss: 1521453400.5479\n",
      "Epoch 5002/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1406563890.9746 - val_loss: 1521925955.5068\n",
      "Epoch 5003/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1406012039.2016 - val_loss: 1521089179.1781\n",
      "Epoch 5004/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1406234604.4618 - val_loss: 1521287579.7626\n",
      "Epoch 5005/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1406221674.4579 - val_loss: 1521278061.0046\n",
      "Epoch 5006/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1406088600.2975 - val_loss: 1521214046.6849\n",
      "Epoch 5007/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 39us/step - loss: 1406501115.4912 - val_loss: 1520259600.3653\n",
      "Epoch 5008/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1406122927.5930 - val_loss: 1521357292.1279\n",
      "Epoch 5009/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1406319053.4012 - val_loss: 1522130884.0913\n",
      "Epoch 5010/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1406203889.7221 - val_loss: 1521132779.2511\n",
      "Epoch 5011/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1406251113.0802 - val_loss: 1520817871.7808\n",
      "Epoch 5012/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1406148235.8982 - val_loss: 1521537776.5114\n",
      "Epoch 5013/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1405943030.2309 - val_loss: 1521124637.5160\n",
      "Epoch 5014/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1406078680.9237 - val_loss: 1521883393.7534\n",
      "Epoch 5015/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1406030732.7750 - val_loss: 1520790741.9178\n",
      "Epoch 5016/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1406254684.6810 - val_loss: 1521078290.4110\n",
      "Epoch 5017/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1405818191.4051 - val_loss: 1521326627.0685\n",
      "Epoch 5018/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1406532455.9530 - val_loss: 1521823594.6667\n",
      "Epoch 5019/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1405911313.2838 - val_loss: 1521068972.7123\n",
      "Epoch 5020/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1406052925.6204 - val_loss: 1521125105.0959\n",
      "Epoch 5021/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1406674077.6830 - val_loss: 1521924620.5662\n",
      "Epoch 5022/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1405813892.6341 - val_loss: 1520635566.7580\n",
      "Epoch 5023/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1406215221.1037 - val_loss: 1520344789.0411\n",
      "Epoch 5024/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1406050269.0568 - val_loss: 1520805462.2100\n",
      "Epoch 5025/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1405905787.9922 - val_loss: 1520420673.1689\n",
      "Epoch 5026/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1406156845.8395 - val_loss: 1521490313.3516\n",
      "Epoch 5027/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1406035400.6419 - val_loss: 1520529893.1142\n",
      "Epoch 5028/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1406178014.1840 - val_loss: 1520985493.9178\n",
      "Epoch 5029/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1406519304.3914 - val_loss: 1521618407.1598\n",
      "Epoch 5030/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1406158866.9119 - val_loss: 1520311682.9224\n",
      "Epoch 5031/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1406155042.6928 - val_loss: 1520635086.6119\n",
      "Epoch 5032/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1405708706.0039 - val_loss: 1521029549.2968\n",
      "Epoch 5033/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1405892020.8532 - val_loss: 1521598608.3653\n",
      "Epoch 5034/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1405783395.1937 - val_loss: 1520693546.6667\n",
      "Epoch 5035/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1405704081.2838 - val_loss: 1521177755.7626\n",
      "Epoch 5036/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1405982672.4070 - val_loss: 1521090516.4566\n",
      "Epoch 5037/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1405913512.0783 - val_loss: 1521090783.8539\n",
      "Epoch 5038/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1405735145.4560 - val_loss: 1520410370.6301\n",
      "Epoch 5039/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1406797391.0294 - val_loss: 1521856941.8813\n",
      "Epoch 5040/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1405927335.7025 - val_loss: 1520827064.4018\n",
      "Epoch 5041/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1405690314.0196 - val_loss: 1520189831.3059\n",
      "Epoch 5042/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1405692521.0802 - val_loss: 1520350165.0411\n",
      "Epoch 5043/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1405953115.1781 - val_loss: 1519845078.2100\n",
      "Epoch 5044/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1405581985.8160 - val_loss: 1521189980.3470\n",
      "Epoch 5045/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1406451387.3659 - val_loss: 1520830402.0457\n",
      "Epoch 5046/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1405588396.8376 - val_loss: 1521805778.9954\n",
      "Epoch 5047/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1405457242.4266 - val_loss: 1521240549.4064\n",
      "Epoch 5048/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1405503360.2505 - val_loss: 1521073684.7489\n",
      "Epoch 5049/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1405429985.0646 - val_loss: 1520743797.1872\n",
      "Epoch 5050/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1405849587.7260 - val_loss: 1521438179.0685\n",
      "Epoch 5051/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1405276791.0450 - val_loss: 1520771151.4886\n",
      "Epoch 5052/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1406290789.1977 - val_loss: 1519820969.7900\n",
      "Epoch 5053/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1405964651.7104 - val_loss: 1520833546.2283\n",
      "Epoch 5054/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1405458263.0450 - val_loss: 1521076321.8995\n",
      "Epoch 5055/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1405350987.7730 - val_loss: 1521083949.2968\n",
      "Epoch 5056/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1405366123.7104 - val_loss: 1521030494.9772\n",
      "Epoch 5057/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1405487575.9217 - val_loss: 1519941178.1553\n",
      "Epoch 5058/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1405319139.8200 - val_loss: 1520913587.1416\n",
      "Epoch 5059/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1405420632.4227 - val_loss: 1521280182.3562\n",
      "Epoch 5060/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1405367263.1859 - val_loss: 1520352194.0457\n",
      "Epoch 5061/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1405921401.9256 - val_loss: 1521483954.8493\n",
      "Epoch 5062/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1405253667.8200 - val_loss: 1521004056.2557\n",
      "Epoch 5063/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1405653911.7965 - val_loss: 1520800974.9041\n",
      "Epoch 5064/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1405107526.6380 - val_loss: 1520691227.4703\n",
      "Epoch 5065/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1405295261.3072 - val_loss: 1520633441.3151\n",
      "Epoch 5066/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1405741193.5186 - val_loss: 1520080778.5205\n",
      "Epoch 5067/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1405213341.6830 - val_loss: 1520113251.9452\n",
      "Epoch 5068/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1405133232.2818 - val_loss: 1520949073.8265\n",
      "Epoch 5069/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1405041292.5245 - val_loss: 1521159473.0959\n",
      "Epoch 5070/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1405100899.9452 - val_loss: 1520274464.4384\n",
      "Epoch 5071/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 42us/step - loss: 1405856450.2544 - val_loss: 1521100794.7397\n",
      "Epoch 5072/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1405621540.4462 - val_loss: 1519884853.7717\n",
      "Epoch 5073/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1405066066.4110 - val_loss: 1520849755.7626\n",
      "Epoch 5074/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1405222351.1546 - val_loss: 1520644471.5251\n",
      "Epoch 5075/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1405176909.9022 - val_loss: 1520796176.9498\n",
      "Epoch 5076/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1405349708.1487 - val_loss: 1520504807.1598\n",
      "Epoch 5077/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1405293276.9315 - val_loss: 1520287580.0548\n",
      "Epoch 5078/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1404961740.6497 - val_loss: 1520628268.4201\n",
      "Epoch 5079/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1405312540.0548 - val_loss: 1519938771.5799\n",
      "Epoch 5080/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1405161568.1879 - val_loss: 1520910705.9726\n",
      "Epoch 5081/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1405320640.8767 - val_loss: 1519835510.6484\n",
      "Epoch 5082/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1405431310.0274 - val_loss: 1519408020.1644\n",
      "Epoch 5083/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1404665030.8885 - val_loss: 1520848104.9132\n",
      "Epoch 5084/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1405203874.3170 - val_loss: 1521150353.2420\n",
      "Epoch 5085/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1405864042.2074 - val_loss: 1519380292.9680\n",
      "Epoch 5086/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1405214949.5734 - val_loss: 1521729353.6438\n",
      "Epoch 5087/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1404856769.3777 - val_loss: 1521539670.7945\n",
      "Epoch 5088/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1405159972.6967 - val_loss: 1521225438.6849\n",
      "Epoch 5089/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1405091783.2642 - val_loss: 1520107453.6621\n",
      "Epoch 5090/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1405522369.3777 - val_loss: 1521511915.8356\n",
      "Epoch 5091/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1404863402.8337 - val_loss: 1520732814.6119\n",
      "Epoch 5092/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1404903360.0000 - val_loss: 1520998527.7078\n",
      "Epoch 5093/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1405039450.5519 - val_loss: 1520121195.5434\n",
      "Epoch 5094/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1405075240.9550 - val_loss: 1520850606.4658\n",
      "Epoch 5095/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1405064360.5793 - val_loss: 1521005035.2511\n",
      "Epoch 5096/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1405738690.6301 - val_loss: 1519294229.6256\n",
      "Epoch 5097/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1404912755.2250 - val_loss: 1520355001.8630\n",
      "Epoch 5098/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1404658802.5988 - val_loss: 1520397993.2055\n",
      "Epoch 5099/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1404988559.7808 - val_loss: 1520053458.7032\n",
      "Epoch 5100/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1405051021.7769 - val_loss: 1521579007.1233\n",
      "Epoch 5101/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1404382925.4012 - val_loss: 1520748229.8447\n",
      "Epoch 5102/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1405627520.6262 - val_loss: 1519117031.7443\n",
      "Epoch 5103/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1404540456.0783 - val_loss: 1520169731.2146\n",
      "Epoch 5104/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1404586337.9413 - val_loss: 1520693518.6119\n",
      "Epoch 5105/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1404723565.8395 - val_loss: 1520626474.0822\n",
      "Epoch 5106/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1405011014.3875 - val_loss: 1521034689.7534\n",
      "Epoch 5107/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1404554613.8552 - val_loss: 1520866785.3151\n",
      "Epoch 5108/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1404554318.1526 - val_loss: 1519663141.9909\n",
      "Epoch 5109/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1405136379.2407 - val_loss: 1520972356.6758\n",
      "Epoch 5110/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1404492559.0294 - val_loss: 1520215550.8311\n",
      "Epoch 5111/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1405211008.0000 - val_loss: 1520157390.6119\n",
      "Epoch 5112/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1404955709.8708 - val_loss: 1520537664.8767\n",
      "Epoch 5113/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1404289052.8063 - val_loss: 1520166976.8767\n",
      "Epoch 5114/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1404440919.4207 - val_loss: 1520389848.5479\n",
      "Epoch 5115/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1404577058.5675 - val_loss: 1519789098.9589\n",
      "Epoch 5116/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1404758672.7828 - val_loss: 1520400903.5982\n",
      "Epoch 5117/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1404367169.8787 - val_loss: 1519930308.0913\n",
      "Epoch 5118/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1404519866.3640 - val_loss: 1520182117.1142\n",
      "Epoch 5119/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1405529772.5871 - val_loss: 1520225612.5662\n",
      "Epoch 5120/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1404347085.6517 - val_loss: 1520173765.5525\n",
      "Epoch 5121/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1404826089.0802 - val_loss: 1519897711.3425\n",
      "Epoch 5122/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1404617645.5890 - val_loss: 1519777067.2511\n",
      "Epoch 5123/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1404525802.9589 - val_loss: 1520975161.2785\n",
      "Epoch 5124/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1404303856.4697 - val_loss: 1520457592.4018\n",
      "Epoch 5125/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1404165704.6419 - val_loss: 1520644979.1416\n",
      "Epoch 5126/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1404672828.1174 - val_loss: 1519552361.7900\n",
      "Epoch 5127/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1404591185.6595 - val_loss: 1520702917.2603\n",
      "Epoch 5128/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1404380631.1703 - val_loss: 1520182206.2466\n",
      "Epoch 5129/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1404462832.5949 - val_loss: 1519048069.2603\n",
      "Epoch 5130/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1404444248.6732 - val_loss: 1519710337.4612\n",
      "Epoch 5131/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1405175335.8278 - val_loss: 1521316930.9224\n",
      "Epoch 5132/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1404337823.6869 - val_loss: 1520084946.7032\n",
      "Epoch 5133/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1404105871.1546 - val_loss: 1519866310.4292\n",
      "Epoch 5134/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1404352972.7750 - val_loss: 1520254546.4110\n",
      "Epoch 5135/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 46us/step - loss: 1404036795.7417 - val_loss: 1519997913.1324\n",
      "Epoch 5136/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1404145341.3699 - val_loss: 1520187761.0959\n",
      "Epoch 5137/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1403946812.6184 - val_loss: 1519780200.3288\n",
      "Epoch 5138/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1404029799.4521 - val_loss: 1519414815.2694\n",
      "Epoch 5139/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1403925219.8200 - val_loss: 1520020166.1370\n",
      "Epoch 5140/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1404066266.9276 - val_loss: 1520253989.4064\n",
      "Epoch 5141/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1404240702.1213 - val_loss: 1520388829.5160\n",
      "Epoch 5142/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1404175701.6673 - val_loss: 1519684515.9452\n",
      "Epoch 5143/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1404160437.1037 - val_loss: 1519933590.7945\n",
      "Epoch 5144/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1404159301.8865 - val_loss: 1519473206.0639\n",
      "Epoch 5145/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1404190350.7789 - val_loss: 1519098589.2237\n",
      "Epoch 5146/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1403763349.9178 - val_loss: 1519987601.2420\n",
      "Epoch 5147/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1404527976.0783 - val_loss: 1520740773.9909\n",
      "Epoch 5148/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1404040275.1624 - val_loss: 1520294056.3288\n",
      "Epoch 5149/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1404890072.4227 - val_loss: 1520538132.1644\n",
      "Epoch 5150/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1404587870.6849 - val_loss: 1519261963.9817\n",
      "Epoch 5151/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1403700268.9628 - val_loss: 1519574435.6530\n",
      "Epoch 5152/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1403720447.8121 - val_loss: 1519801521.6804\n",
      "Epoch 5153/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1403995304.0783 - val_loss: 1520054913.7534\n",
      "Epoch 5154/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1404021251.9452 - val_loss: 1520582827.8356\n",
      "Epoch 5155/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1403834047.6243 - val_loss: 1520233569.0228\n",
      "Epoch 5156/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1403773676.2114 - val_loss: 1519236622.9041\n",
      "Epoch 5157/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1403888547.2564 - val_loss: 1519525438.8311\n",
      "Epoch 5158/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1404283120.4697 - val_loss: 1519109563.3242\n",
      "Epoch 5159/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1404215164.3679 - val_loss: 1520268021.4795\n",
      "Epoch 5160/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1403688596.7280 - val_loss: 1519632927.2694\n",
      "Epoch 5161/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1404422973.7456 - val_loss: 1520654471.0137\n",
      "Epoch 5162/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1403609988.3836 - val_loss: 1519711260.6393\n",
      "Epoch 5163/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1403580628.1644 - val_loss: 1519441074.5571\n",
      "Epoch 5164/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1403690667.3346 - val_loss: 1518826529.3151\n",
      "Epoch 5165/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1404209253.6986 - val_loss: 1520637775.4886\n",
      "Epoch 5166/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1403606875.6791 - val_loss: 1520025799.5982\n",
      "Epoch 5167/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1403597285.4481 - val_loss: 1519865302.7945\n",
      "Epoch 5168/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1403722499.1311 - val_loss: 1519571565.2968\n",
      "Epoch 5169/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1403837725.9335 - val_loss: 1519876139.2511\n",
      "Epoch 5170/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1403914454.2935 - val_loss: 1518660036.3836\n",
      "Epoch 5171/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1403283778.3796 - val_loss: 1519237559.2329\n",
      "Epoch 5172/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1403550427.8043 - val_loss: 1519376860.9315\n",
      "Epoch 5173/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1403509673.3307 - val_loss: 1519448691.4338\n",
      "Epoch 5174/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1403804904.4540 - val_loss: 1519299688.0365\n",
      "Epoch 5175/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1403581814.7319 - val_loss: 1519776930.4840\n",
      "Epoch 5176/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1403955332.7593 - val_loss: 1519422913.7534\n",
      "Epoch 5177/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1403858537.7065 - val_loss: 1520336249.5708\n",
      "Epoch 5178/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1404327511.5460 - val_loss: 1518890109.3699\n",
      "Epoch 5179/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1403296722.4110 - val_loss: 1519866904.5479\n",
      "Epoch 5180/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1403270585.4873 - val_loss: 1519807348.3105\n",
      "Epoch 5181/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1403959661.7143 - val_loss: 1519374755.6530\n",
      "Epoch 5182/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1403602250.7710 - val_loss: 1519440713.3516\n",
      "Epoch 5183/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1403370196.9159 - val_loss: 1519728625.9726\n",
      "Epoch 5184/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1403367895.4207 - val_loss: 1520492993.4612\n",
      "Epoch 5185/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1403832589.5264 - val_loss: 1518683574.0639\n",
      "Epoch 5186/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1403351800.2348 - val_loss: 1520288468.1644\n",
      "Epoch 5187/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1403148368.6575 - val_loss: 1519870530.3379\n",
      "Epoch 5188/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1403060151.1076 - val_loss: 1519681565.2237\n",
      "Epoch 5189/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1403175043.2564 - val_loss: 1519498470.2831\n",
      "Epoch 5190/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1403571310.2779 - val_loss: 1520142425.7169\n",
      "Epoch 5191/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1403298337.5656 - val_loss: 1519692960.4384\n",
      "Epoch 5192/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1403038738.9746 - val_loss: 1519521236.1644\n",
      "Epoch 5193/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1404090162.3483 - val_loss: 1520312725.9178\n",
      "Epoch 5194/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1403063235.1311 - val_loss: 1518715754.9589\n",
      "Epoch 5195/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1403927732.7280 - val_loss: 1518519290.4475\n",
      "Epoch 5196/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1403338521.6751 - val_loss: 1519117948.2009\n",
      "Epoch 5197/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1403011200.2505 - val_loss: 1518732925.0776\n",
      "Epoch 5198/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1403424074.7710 - val_loss: 1518698740.0183\n",
      "Epoch 5199/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1403260922.4892 - val_loss: 1518912782.0274\n",
      "Epoch 5200/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1403418742.7319 - val_loss: 1518713800.4749\n",
      "Epoch 5201/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1403369176.4227 - val_loss: 1519048497.9726\n",
      "Epoch 5202/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1403109296.0939 - val_loss: 1518865822.9772\n",
      "Epoch 5203/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1403023327.6869 - val_loss: 1519474631.3059\n",
      "Epoch 5204/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1403644047.2798 - val_loss: 1518418593.0228\n",
      "Epoch 5205/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1402913840.4697 - val_loss: 1519379685.9909\n",
      "Epoch 5206/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1403711990.7319 - val_loss: 1520514258.7032\n",
      "Epoch 5207/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1403370537.5812 - val_loss: 1518671106.3379\n",
      "Epoch 5208/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1402825881.7378 - val_loss: 1519481692.6393\n",
      "Epoch 5209/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1402886733.9022 - val_loss: 1519322458.5936\n",
      "Epoch 5210/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1403338870.3562 - val_loss: 1518996003.9452\n",
      "Epoch 5211/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1403379097.8004 - val_loss: 1520093544.9132\n",
      "Epoch 5212/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1403060357.3855 - val_loss: 1518611143.8904\n",
      "Epoch 5213/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1402804083.0998 - val_loss: 1518909472.1461\n",
      "Epoch 5214/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1404492952.2975 - val_loss: 1519979033.4247\n",
      "Epoch 5215/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1402966314.0196 - val_loss: 1518901939.1416\n",
      "Epoch 5216/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1402908260.4462 - val_loss: 1519281671.5982\n",
      "Epoch 5217/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1402852975.7182 - val_loss: 1518720337.5342\n",
      "Epoch 5218/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1402781481.0802 - val_loss: 1518678188.1279\n",
      "Epoch 5219/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1402780919.7339 - val_loss: 1518476635.1781\n",
      "Epoch 5220/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1402700800.0000 - val_loss: 1518705280.5845\n",
      "Epoch 5221/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1402713086.6223 - val_loss: 1519366295.0868\n",
      "Epoch 5222/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1402877020.6810 - val_loss: 1518870615.9635\n",
      "Epoch 5223/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1402576238.9041 - val_loss: 1519167100.2009\n",
      "Epoch 5224/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1402917116.9941 - val_loss: 1518926791.8904\n",
      "Epoch 5225/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1402935925.4795 - val_loss: 1519609701.9909\n",
      "Epoch 5226/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1402677018.3014 - val_loss: 1519106755.2146\n",
      "Epoch 5227/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1402621989.3229 - val_loss: 1519540842.3744\n",
      "Epoch 5228/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1403091146.1448 - val_loss: 1518145175.3790\n",
      "Epoch 5229/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1403615339.5851 - val_loss: 1520218747.6164\n",
      "Epoch 5230/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1402376970.2074 - val_loss: 1518925267.2877\n",
      "Epoch 5231/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1402875678.4344 - val_loss: 1519334730.8128\n",
      "Epoch 5232/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1402419753.0802 - val_loss: 1519041839.3425\n",
      "Epoch 5233/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1402993816.2975 - val_loss: 1517711290.1553\n",
      "Epoch 5234/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1402785397.6047 - val_loss: 1519042661.9909\n",
      "Epoch 5235/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1402472519.8904 - val_loss: 1519168344.5479\n",
      "Epoch 5236/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1402649759.5616 - val_loss: 1519052537.2785\n",
      "Epoch 5237/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1403443462.5127 - val_loss: 1517027548.9315\n",
      "Epoch 5238/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1403400334.1526 - val_loss: 1519941949.3699\n",
      "Epoch 5239/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1402190747.5538 - val_loss: 1519083712.2922\n",
      "Epoch 5240/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1402802686.7476 - val_loss: 1518029198.9041\n",
      "Epoch 5241/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1402166069.5421 - val_loss: 1518694095.4886\n",
      "Epoch 5242/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1402470163.5382 - val_loss: 1518790984.4749\n",
      "Epoch 5243/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1402380093.3699 - val_loss: 1518256777.0594\n",
      "Epoch 5244/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1402535657.6438 - val_loss: 1518861958.1370\n",
      "Epoch 5245/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1402242431.8121 - val_loss: 1518868597.4795\n",
      "Epoch 5246/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1403210659.3190 - val_loss: 1519849223.0137\n",
      "Epoch 5247/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1402296647.8904 - val_loss: 1518466086.5753\n",
      "Epoch 5248/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1402234144.3131 - val_loss: 1518098480.2192\n",
      "Epoch 5249/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1402348802.6928 - val_loss: 1519261262.0274\n",
      "Epoch 5250/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1402403170.4423 - val_loss: 1518661824.8767\n",
      "Epoch 5251/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1402144128.6262 - val_loss: 1518845807.0502\n",
      "Epoch 5252/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1402264973.4012 - val_loss: 1518037221.4064\n",
      "Epoch 5253/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1402161743.6556 - val_loss: 1518546639.4886\n",
      "Epoch 5254/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1402035129.4873 - val_loss: 1518681089.4612\n",
      "Epoch 5255/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1402072608.5636 - val_loss: 1518671960.2557\n",
      "Epoch 5256/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1402044126.4344 - val_loss: 1518647647.8539\n",
      "Epoch 5257/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1403168246.2309 - val_loss: 1517103950.3196\n",
      "Epoch 5258/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1401750619.4286 - val_loss: 1518602752.8767\n",
      "Epoch 5259/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1402303010.6301 - val_loss: 1519122643.2877\n",
      "Epoch 5260/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1401998774.3562 - val_loss: 1518622319.3425\n",
      "Epoch 5261/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1402038512.7202 - val_loss: 1519021445.2603\n",
      "Epoch 5262/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1401996028.9941 - val_loss: 1518418842.3014\n",
      "Epoch 5263/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 31us/step - loss: 1401950602.2701 - val_loss: 1518114082.1918\n",
      "Epoch 5264/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1401945717.9178 - val_loss: 1518759567.7808\n",
      "Epoch 5265/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1402288437.8552 - val_loss: 1519380315.1781\n",
      "Epoch 5266/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1401887601.8474 - val_loss: 1518165622.0639\n",
      "Epoch 5267/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1402169492.7906 - val_loss: 1519271683.2146\n",
      "Epoch 5268/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1401676567.0450 - val_loss: 1518330884.9680\n",
      "Epoch 5269/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1402000540.5558 - val_loss: 1518913915.9087\n",
      "Epoch 5270/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1401679551.3738 - val_loss: 1518737561.7169\n",
      "Epoch 5271/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1402795440.5949 - val_loss: 1517433345.4612\n",
      "Epoch 5272/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1401713915.7417 - val_loss: 1517774516.3105\n",
      "Epoch 5273/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1401810056.7671 - val_loss: 1517983257.1324\n",
      "Epoch 5274/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1401600365.9022 - val_loss: 1518428979.1416\n",
      "Epoch 5275/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1401640465.2838 - val_loss: 1518480203.1050\n",
      "Epoch 5276/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1401895449.2994 - val_loss: 1518410971.7626\n",
      "Epoch 5277/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1401752677.1977 - val_loss: 1519140082.8493\n",
      "Epoch 5278/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1401511266.1918 - val_loss: 1518742435.3607\n",
      "Epoch 5279/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1402051921.6595 - val_loss: 1517606762.0822\n",
      "Epoch 5280/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1401717051.7417 - val_loss: 1518304262.1370\n",
      "Epoch 5281/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1401772902.1996 - val_loss: 1518701214.1005\n",
      "Epoch 5282/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1402008445.7456 - val_loss: 1517621179.0320\n",
      "Epoch 5283/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1401884131.1937 - val_loss: 1518930316.2740\n",
      "Epoch 5284/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1401566191.0920 - val_loss: 1518171514.7397\n",
      "Epoch 5285/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1401548733.4951 - val_loss: 1518098550.0639\n",
      "Epoch 5286/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1401508174.4031 - val_loss: 1518471326.9772\n",
      "Epoch 5287/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1401463190.7945 - val_loss: 1518418700.2740\n",
      "Epoch 5288/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1401587931.4286 - val_loss: 1517845163.2511\n",
      "Epoch 5289/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1401982677.6673 - val_loss: 1518262953.4977\n",
      "Epoch 5290/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1402139207.2642 - val_loss: 1519042073.1324\n",
      "Epoch 5291/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1401556536.1096 - val_loss: 1518870680.8402\n",
      "Epoch 5292/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1401363332.0705 - val_loss: 1518321688.5479\n",
      "Epoch 5293/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1401374895.5930 - val_loss: 1518165336.8402\n",
      "Epoch 5294/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1401401514.7084 - val_loss: 1518045079.6712\n",
      "Epoch 5295/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1401639021.9648 - val_loss: 1517500303.4886\n",
      "Epoch 5296/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1401795101.6204 - val_loss: 1518632679.7443\n",
      "Epoch 5297/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1401455609.1115 - val_loss: 1517612339.7260\n",
      "Epoch 5298/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1401740467.9139 - val_loss: 1519071717.4064\n",
      "Epoch 5299/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1401661329.0333 - val_loss: 1517255001.1324\n",
      "Epoch 5300/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1401730541.4638 - val_loss: 1518786064.3653\n",
      "Epoch 5301/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1401324371.1624 - val_loss: 1517570790.8676\n",
      "Epoch 5302/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1401229785.6751 - val_loss: 1518054824.0365\n",
      "Epoch 5303/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1401293901.2133 - val_loss: 1517275384.9863\n",
      "Epoch 5304/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1401843341.1507 - val_loss: 1519042056.1826\n",
      "Epoch 5305/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1401309879.3581 - val_loss: 1517904565.1872\n",
      "Epoch 5306/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1401560539.4286 - val_loss: 1518484006.2831\n",
      "Epoch 5307/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1401034924.3366 - val_loss: 1517991262.6849\n",
      "Epoch 5308/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1401244790.7319 - val_loss: 1517281597.9543\n",
      "Epoch 5309/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1401595196.6184 - val_loss: 1516381464.5479\n",
      "Epoch 5310/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1401005539.9452 - val_loss: 1517858086.8676\n",
      "Epoch 5311/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1401341601.3151 - val_loss: 1518029329.5342\n",
      "Epoch 5312/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1401447815.7652 - val_loss: 1518468457.4977\n",
      "Epoch 5313/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1401831597.7143 - val_loss: 1518860195.0685\n",
      "Epoch 5314/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1401027144.6419 - val_loss: 1517507802.5936\n",
      "Epoch 5315/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1401952923.9295 - val_loss: 1516306839.6712\n",
      "Epoch 5316/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1401026058.5205 - val_loss: 1517901936.8037\n",
      "Epoch 5317/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1400948245.4168 - val_loss: 1518075073.1689\n",
      "Epoch 5318/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1401167904.4384 - val_loss: 1517547790.0274\n",
      "Epoch 5319/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1401077362.9746 - val_loss: 1518179183.9269\n",
      "Epoch 5320/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1401334632.3288 - val_loss: 1517505765.6986\n",
      "Epoch 5321/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1400828472.9863 - val_loss: 1518246464.5845\n",
      "Epoch 5322/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1400859264.0000 - val_loss: 1518381485.8813\n",
      "Epoch 5323/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1400879633.5342 - val_loss: 1517640756.6027\n",
      "Epoch 5324/15000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1401629489.2211 - val_loss: 1517572466.5571\n",
      "Epoch 5325/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1400803436.2114 - val_loss: 1518041322.6667\n",
      "Epoch 5326/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1400979525.3855 - val_loss: 1517382697.4977\n",
      "Epoch 5327/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1400959233.0020 - val_loss: 1517981667.0685\n",
      "Epoch 5328/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1401042811.4912 - val_loss: 1518218754.6301\n",
      "Epoch 5329/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1401338702.9041 - val_loss: 1517959181.4429\n",
      "Epoch 5330/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1400806142.4971 - val_loss: 1517462353.8265\n",
      "Epoch 5331/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1401237626.9902 - val_loss: 1518191167.7078\n",
      "Epoch 5332/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1400843571.3503 - val_loss: 1518146166.3562\n",
      "Epoch 5333/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1400839757.6517 - val_loss: 1517183879.0137\n",
      "Epoch 5334/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1400695373.5264 - val_loss: 1517137746.1187\n",
      "Epoch 5335/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1400745854.9980 - val_loss: 1517056789.6256\n",
      "Epoch 5336/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1400733048.1722 - val_loss: 1517733592.2557\n",
      "Epoch 5337/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1400869435.1155 - val_loss: 1517214945.8995\n",
      "Epoch 5338/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1400499885.8395 - val_loss: 1517317876.8950\n",
      "Epoch 5339/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1400636939.6477 - val_loss: 1517610882.0457\n",
      "Epoch 5340/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1400595765.1037 - val_loss: 1518016260.6758\n",
      "Epoch 5341/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1400840160.9393 - val_loss: 1516562302.5388\n",
      "Epoch 5342/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1400813328.2818 - val_loss: 1517832458.2283\n",
      "Epoch 5343/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1400665838.2153 - val_loss: 1517803814.5753\n",
      "Epoch 5344/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1400729385.7065 - val_loss: 1517626694.1370\n",
      "Epoch 5345/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1401410341.5734 - val_loss: 1518799268.8219\n",
      "Epoch 5346/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1401572176.4070 - val_loss: 1516665261.5890\n",
      "Epoch 5347/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1400617088.5010 - val_loss: 1517712066.3379\n",
      "Epoch 5348/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1400548287.8748 - val_loss: 1517071435.9817\n",
      "Epoch 5349/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1400639111.1389 - val_loss: 1517813340.0548\n",
      "Epoch 5350/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1400430677.6673 - val_loss: 1517050116.6758\n",
      "Epoch 5351/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1400453228.8376 - val_loss: 1517636214.0639\n",
      "Epoch 5352/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1400498147.6947 - val_loss: 1517540818.9954\n",
      "Epoch 5353/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1400562119.8904 - val_loss: 1517705216.5845\n",
      "Epoch 5354/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1400403927.4207 - val_loss: 1517904521.3516\n",
      "Epoch 5355/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1400173596.1800 - val_loss: 1517313984.0000\n",
      "Epoch 5356/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1400152686.4658 - val_loss: 1517094589.0776\n",
      "Epoch 5357/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1400137838.4658 - val_loss: 1517492009.7900\n",
      "Epoch 5358/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1400458587.6791 - val_loss: 1517773766.7215\n",
      "Epoch 5359/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1400314273.4403 - val_loss: 1517593790.5388\n",
      "Epoch 5360/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1400490764.1487 - val_loss: 1517331246.7580\n",
      "Epoch 5361/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1400220182.5440 - val_loss: 1516896123.6164\n",
      "Epoch 5362/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1400478218.4579 - val_loss: 1517267394.3379\n",
      "Epoch 5363/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1400097449.0802 - val_loss: 1517198041.4247\n",
      "Epoch 5364/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1400462609.5342 - val_loss: 1517604620.2740\n",
      "Epoch 5365/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1400356035.5068 - val_loss: 1516469013.9178\n",
      "Epoch 5366/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1401509106.9746 - val_loss: 1518016936.9132\n",
      "Epoch 5367/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1400473965.7143 - val_loss: 1516315077.5525\n",
      "Epoch 5368/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1400207188.1644 - val_loss: 1517490223.9269\n",
      "Epoch 5369/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1400623926.9824 - val_loss: 1517780202.3744\n",
      "Epoch 5370/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1400732477.4951 - val_loss: 1516420990.5388\n",
      "Epoch 5371/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1399835936.3131 - val_loss: 1517011159.9635\n",
      "Epoch 5372/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1400181535.5616 - val_loss: 1516093586.4110\n",
      "Epoch 5373/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1399907924.9159 - val_loss: 1516383380.1644\n",
      "Epoch 5374/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1400191192.7984 - val_loss: 1517742641.9726\n",
      "Epoch 5375/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1399886177.1898 - val_loss: 1517530043.0320\n",
      "Epoch 5376/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1400100989.6204 - val_loss: 1517949684.0183\n",
      "Epoch 5377/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1400230912.2505 - val_loss: 1516522861.0046\n",
      "Epoch 5378/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1399923990.7945 - val_loss: 1517082131.5799\n",
      "Epoch 5379/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1399968101.6986 - val_loss: 1517745979.0320\n",
      "Epoch 5380/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1399706374.1370 - val_loss: 1517008230.5753\n",
      "Epoch 5381/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1399821478.3249 - val_loss: 1516633603.7991\n",
      "Epoch 5382/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1399833072.4697 - val_loss: 1516841653.1872\n",
      "Epoch 5383/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1399742588.9941 - val_loss: 1516831513.7169\n",
      "Epoch 5384/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1400203483.1781 - val_loss: 1516560486.2831\n",
      "Epoch 5385/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1399665470.8728 - val_loss: 1517451064.4018\n",
      "Epoch 5386/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1399917246.2466 - val_loss: 1516696870.5753\n",
      "Epoch 5387/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1400146369.3777 - val_loss: 1517856974.6119\n",
      "Epoch 5388/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1399970747.8669 - val_loss: 1516223002.8858\n",
      "Epoch 5389/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1399538633.0176 - val_loss: 1516999461.6986\n",
      "Epoch 5390/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1400228731.7417 - val_loss: 1516382587.3242\n",
      "Epoch 5391/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 37us/step - loss: 1400679996.2427 - val_loss: 1517594676.3105\n",
      "Epoch 5392/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1399337283.7573 - val_loss: 1516820451.6530\n",
      "Epoch 5393/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1399972138.3327 - val_loss: 1517274297.8630\n",
      "Epoch 5394/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1399557144.2975 - val_loss: 1516555544.5479\n",
      "Epoch 5395/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1399460750.5284 - val_loss: 1516634096.5114\n",
      "Epoch 5396/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1399377445.9491 - val_loss: 1516258224.2192\n",
      "Epoch 5397/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1399598979.6321 - val_loss: 1517065693.8082\n",
      "Epoch 5398/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1399470454.6067 - val_loss: 1516523927.3790\n",
      "Epoch 5399/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1399625833.5812 - val_loss: 1516669268.7489\n",
      "Epoch 5400/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1399285694.8728 - val_loss: 1516565668.5297\n",
      "Epoch 5401/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1399342883.5695 - val_loss: 1516709583.1963\n",
      "Epoch 5402/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1399248159.0607 - val_loss: 1516301279.8539\n",
      "Epoch 5403/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1399351879.0137 - val_loss: 1516345739.9817\n",
      "Epoch 5404/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1399262235.6791 - val_loss: 1516251665.2420\n",
      "Epoch 5405/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1399978922.2074 - val_loss: 1516684432.0731\n",
      "Epoch 5406/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1399237449.6438 - val_loss: 1516287830.7945\n",
      "Epoch 5407/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1399436118.3562 - val_loss: 1517042136.5479\n",
      "Epoch 5408/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1399618060.6497 - val_loss: 1516496307.7260\n",
      "Epoch 5409/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1399327231.4990 - val_loss: 1517199442.9954\n",
      "Epoch 5410/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1399214312.0157 - val_loss: 1516544827.9087\n",
      "Epoch 5411/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1399208373.2290 - val_loss: 1516492954.0091\n",
      "Epoch 5412/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1399109498.1135 - val_loss: 1516747451.9087\n",
      "Epoch 5413/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1399531989.2916 - val_loss: 1517459180.7123\n",
      "Epoch 5414/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1399545921.9413 - val_loss: 1516555498.3744\n",
      "Epoch 5415/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1399214642.2231 - val_loss: 1516530426.1553\n",
      "Epoch 5416/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1399681772.2114 - val_loss: 1516126564.2374\n",
      "Epoch 5417/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1399049773.8395 - val_loss: 1516458623.1233\n",
      "Epoch 5418/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1399409097.6438 - val_loss: 1516914943.7078\n",
      "Epoch 5419/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1399061504.7515 - val_loss: 1516016795.1781\n",
      "Epoch 5420/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1398878126.3405 - val_loss: 1516129359.7808\n",
      "Epoch 5421/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1399358038.6693 - val_loss: 1515971012.0913\n",
      "Epoch 5422/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1399222960.7202 - val_loss: 1516742493.2237\n",
      "Epoch 5423/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1399282917.9491 - val_loss: 1515680843.6895\n",
      "Epoch 5424/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1398888767.1233 - val_loss: 1515859885.2968\n",
      "Epoch 5425/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1399459267.7573 - val_loss: 1517462629.4064\n",
      "Epoch 5426/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1398874618.8650 - val_loss: 1516650924.7123\n",
      "Epoch 5427/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1398946292.4775 - val_loss: 1516562243.5068\n",
      "Epoch 5428/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1399316781.3386 - val_loss: 1515851073.4612\n",
      "Epoch 5429/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1398770741.3542 - val_loss: 1516389725.2237\n",
      "Epoch 5430/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1398839255.9217 - val_loss: 1515997039.9269\n",
      "Epoch 5431/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1399749322.8963 - val_loss: 1517184384.8767\n",
      "Epoch 5432/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1399167317.1663 - val_loss: 1515812423.5982\n",
      "Epoch 5433/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1399127614.8728 - val_loss: 1515366286.3196\n",
      "Epoch 5434/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1399423541.1037 - val_loss: 1517073118.9772\n",
      "Epoch 5435/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1398695049.2681 - val_loss: 1515948116.7489\n",
      "Epoch 5436/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1399068311.2955 - val_loss: 1515036326.8676\n",
      "Epoch 5437/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1398494419.3503 - val_loss: 1516220532.6027\n",
      "Epoch 5438/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1398844896.1879 - val_loss: 1516822092.8584\n",
      "Epoch 5439/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1398586559.2485 - val_loss: 1516479324.9315\n",
      "Epoch 5440/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1398748059.5538 - val_loss: 1515710023.5982\n",
      "Epoch 5441/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1398814136.6106 - val_loss: 1516717149.8082\n",
      "Epoch 5442/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1398411038.5597 - val_loss: 1516411016.7671\n",
      "Epoch 5443/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1398718230.7945 - val_loss: 1515463133.8082\n",
      "Epoch 5444/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1398473600.0000 - val_loss: 1516326248.3288\n",
      "Epoch 5445/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1398565093.1977 - val_loss: 1516330751.7078\n",
      "Epoch 5446/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1398565844.9159 - val_loss: 1516564434.7032\n",
      "Epoch 5447/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1398463503.0294 - val_loss: 1515208690.2648\n",
      "Epoch 5448/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1398385728.8767 - val_loss: 1515669741.2968\n",
      "Epoch 5449/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1399135821.7769 - val_loss: 1514601751.6712\n",
      "Epoch 5450/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1398946077.9335 - val_loss: 1515726395.0320\n",
      "Epoch 5451/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1398343240.4540 - val_loss: 1515964882.9954\n",
      "Epoch 5452/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1398399972.3209 - val_loss: 1515402168.6941\n",
      "Epoch 5453/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1398521402.3640 - val_loss: 1515130257.5342\n",
      "Epoch 5454/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1398551037.8708 - val_loss: 1515428121.1324\n",
      "Epoch 5455/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 40us/step - loss: 1398351583.6869 - val_loss: 1515730247.5982\n",
      "Epoch 5456/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1398326821.0724 - val_loss: 1515984461.7352\n",
      "Epoch 5457/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1398213810.4736 - val_loss: 1516420054.2100\n",
      "Epoch 5458/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1398353136.9706 - val_loss: 1515520229.6986\n",
      "Epoch 5459/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1398656163.3190 - val_loss: 1516039752.4749\n",
      "Epoch 5460/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1398902444.9002 - val_loss: 1514999261.2237\n",
      "Epoch 5461/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1398212814.5284 - val_loss: 1516089058.7763\n",
      "Epoch 5462/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1398557684.6027 - val_loss: 1515370935.8174\n",
      "Epoch 5463/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1398225568.8141 - val_loss: 1516214324.6027\n",
      "Epoch 5464/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1398693942.7945 - val_loss: 1515315035.4703\n",
      "Epoch 5465/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1398589819.2407 - val_loss: 1516070061.2968\n",
      "Epoch 5466/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1398370455.2955 - val_loss: 1516414891.2511\n",
      "Epoch 5467/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1398174044.3053 - val_loss: 1515355266.6301\n",
      "Epoch 5468/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1398328908.5245 - val_loss: 1515812480.2922\n",
      "Epoch 5469/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1398148944.6575 - val_loss: 1515061354.0822\n",
      "Epoch 5470/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1398265147.6164 - val_loss: 1516668746.8128\n",
      "Epoch 5471/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1398271911.9530 - val_loss: 1515298129.5342\n",
      "Epoch 5472/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1398001098.3953 - val_loss: 1515836307.5799\n",
      "Epoch 5473/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1397827699.2250 - val_loss: 1515782119.1598\n",
      "Epoch 5474/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1398081123.9452 - val_loss: 1516175311.7808\n",
      "Epoch 5475/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1398060144.3444 - val_loss: 1515152333.1507\n",
      "Epoch 5476/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1398250340.9472 - val_loss: 1515624270.3196\n",
      "Epoch 5477/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1397823020.0861 - val_loss: 1515354172.2009\n",
      "Epoch 5478/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1398696538.6771 - val_loss: 1514999652.8219\n",
      "Epoch 5479/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1398089163.7730 - val_loss: 1515831903.8539\n",
      "Epoch 5480/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1397757984.3131 - val_loss: 1515796048.6575\n",
      "Epoch 5481/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1397671041.0020 - val_loss: 1515602959.4886\n",
      "Epoch 5482/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1398370001.4090 - val_loss: 1513971834.4475\n",
      "Epoch 5483/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1398014879.5616 - val_loss: 1516107188.3105\n",
      "Epoch 5484/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1398970105.2368 - val_loss: 1514372624.0731\n",
      "Epoch 5485/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1397810496.6262 - val_loss: 1515752391.5982\n",
      "Epoch 5486/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1397936496.7202 - val_loss: 1515102976.0000\n",
      "Epoch 5487/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1398076335.5303 - val_loss: 1516089303.0868\n",
      "Epoch 5488/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1397647987.8513 - val_loss: 1515681189.1142\n",
      "Epoch 5489/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1397548453.8239 - val_loss: 1515614446.4658\n",
      "Epoch 5490/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1397993979.7417 - val_loss: 1514555335.5982\n",
      "Epoch 5491/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1397804154.2387 - val_loss: 1515748234.8128\n",
      "Epoch 5492/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1397622765.9022 - val_loss: 1515297463.5251\n",
      "Epoch 5493/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1397926231.1703 - val_loss: 1516137008.2192\n",
      "Epoch 5494/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1397503284.4149 - val_loss: 1515547509.1872\n",
      "Epoch 5495/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1397668297.6438 - val_loss: 1514665293.1507\n",
      "Epoch 5496/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1397511873.6908 - val_loss: 1515079586.1918\n",
      "Epoch 5497/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1397450010.0509 - val_loss: 1514418040.1096\n",
      "Epoch 5498/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1397644206.7162 - val_loss: 1514449261.2968\n",
      "Epoch 5499/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1398107339.1468 - val_loss: 1514884118.5023\n",
      "Epoch 5500/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1397353601.7534 - val_loss: 1515360619.5434\n",
      "Epoch 5501/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1397362658.0665 - val_loss: 1515432389.5525\n",
      "Epoch 5502/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1397424406.0431 - val_loss: 1514795058.2648\n",
      "Epoch 5503/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1397320237.9648 - val_loss: 1515376848.9498\n",
      "Epoch 5504/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1398183334.3249 - val_loss: 1515554470.8676\n",
      "Epoch 5505/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1397306846.1840 - val_loss: 1514883267.5068\n",
      "Epoch 5506/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1397546766.5284 - val_loss: 1514142045.5160\n",
      "Epoch 5507/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1397280805.9491 - val_loss: 1514413013.6256\n",
      "Epoch 5508/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1397274739.6008 - val_loss: 1514700248.5479\n",
      "Epoch 5509/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1397088747.7104 - val_loss: 1514934712.1096\n",
      "Epoch 5510/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1397536985.9256 - val_loss: 1514774173.8082\n",
      "Epoch 5511/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1397578500.0078 - val_loss: 1514205657.7169\n",
      "Epoch 5512/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1397426492.6184 - val_loss: 1515794899.8721\n",
      "Epoch 5513/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1397603986.2231 - val_loss: 1514706471.1598\n",
      "Epoch 5514/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1397053058.6301 - val_loss: 1514834086.8676\n",
      "Epoch 5515/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1397234176.7515 - val_loss: 1515129350.7215\n",
      "Epoch 5516/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1397284321.8160 - val_loss: 1514781795.3607\n",
      "Epoch 5517/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1397287450.5519 - val_loss: 1514759901.5160\n",
      "Epoch 5518/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1397089207.8591 - val_loss: 1514451508.8950\n",
      "Epoch 5519/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 32us/step - loss: 1397101729.1898 - val_loss: 1515646975.7078\n",
      "Epoch 5520/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1397057696.0626 - val_loss: 1514814865.5342\n",
      "Epoch 5521/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1397041215.8748 - val_loss: 1515054524.2009\n",
      "Epoch 5522/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1397289446.9511 - val_loss: 1515822978.9224\n",
      "Epoch 5523/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1396713497.2994 - val_loss: 1514625664.0000\n",
      "Epoch 5524/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1396955282.9119 - val_loss: 1514491544.2557\n",
      "Epoch 5525/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1397007792.8454 - val_loss: 1514732124.0548\n",
      "Epoch 5526/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1397252246.4188 - val_loss: 1514924351.4155\n",
      "Epoch 5527/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1397129729.6282 - val_loss: 1514470543.4886\n",
      "Epoch 5528/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1396992568.9863 - val_loss: 1514296538.8858\n",
      "Epoch 5529/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1397314278.4501 - val_loss: 1515114308.0913\n",
      "Epoch 5530/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1396698791.5773 - val_loss: 1514698872.4018\n",
      "Epoch 5531/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1397082676.6027 - val_loss: 1513633052.6393\n",
      "Epoch 5532/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1397317088.4384 - val_loss: 1514865804.8584\n",
      "Epoch 5533/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1396624904.7045 - val_loss: 1514632510.2466\n",
      "Epoch 5534/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1396737603.3816 - val_loss: 1514313016.1096\n",
      "Epoch 5535/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1396555838.6223 - val_loss: 1514086908.7854\n",
      "Epoch 5536/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1397141927.8278 - val_loss: 1513669090.4840\n",
      "Epoch 5537/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1396589283.3816 - val_loss: 1514302367.2694\n",
      "Epoch 5538/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1396986968.6732 - val_loss: 1514935682.6301\n",
      "Epoch 5539/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1396936676.6967 - val_loss: 1515479478.3562\n",
      "Epoch 5540/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1397446559.8121 - val_loss: 1513816177.0959\n",
      "Epoch 5541/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1396567975.7025 - val_loss: 1514012513.8995\n",
      "Epoch 5542/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1396908672.1252 - val_loss: 1514144645.8447\n",
      "Epoch 5543/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1396698243.2564 - val_loss: 1513866304.8767\n",
      "Epoch 5544/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1396582065.4716 - val_loss: 1514397077.3333\n",
      "Epoch 5545/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1396533314.1292 - val_loss: 1514015285.7717\n",
      "Epoch 5546/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1396681052.9315 - val_loss: 1514912839.3059\n",
      "Epoch 5547/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1396695690.1448 - val_loss: 1514289263.6347\n",
      "Epoch 5548/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1396630221.1507 - val_loss: 1515161444.2374\n",
      "Epoch 5549/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1396518046.8102 - val_loss: 1514064390.4292\n",
      "Epoch 5550/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1396832384.2505 - val_loss: 1513930063.4886\n",
      "Epoch 5551/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1396756459.3346 - val_loss: 1514027041.8995\n",
      "Epoch 5552/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1396591764.5401 - val_loss: 1514790117.9909\n",
      "Epoch 5553/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1396343676.8689 - val_loss: 1514277141.0411\n",
      "Epoch 5554/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1396131305.4560 - val_loss: 1514164575.2694\n",
      "Epoch 5555/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1397022328.1096 - val_loss: 1514576083.8721\n",
      "Epoch 5556/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1396195344.2818 - val_loss: 1514250815.7078\n",
      "Epoch 5557/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1396329672.5166 - val_loss: 1514331394.6301\n",
      "Epoch 5558/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1396496288.8141 - val_loss: 1512911423.7078\n",
      "Epoch 5559/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1396092067.8200 - val_loss: 1513504449.4612\n",
      "Epoch 5560/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1396197551.0920 - val_loss: 1513921244.6393\n",
      "Epoch 5561/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1396210159.0920 - val_loss: 1514137338.7397\n",
      "Epoch 5562/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1396041077.2290 - val_loss: 1513967508.4566\n",
      "Epoch 5563/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1396180384.9393 - val_loss: 1514147992.8402\n",
      "Epoch 5564/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1396024874.2074 - val_loss: 1513328378.1553\n",
      "Epoch 5565/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1396061287.7025 - val_loss: 1513915555.9452\n",
      "Epoch 5566/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1395914292.7280 - val_loss: 1513725198.6119\n",
      "Epoch 5567/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1396282736.9706 - val_loss: 1514525836.8584\n",
      "Epoch 5568/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1396115121.5969 - val_loss: 1513400583.0137\n",
      "Epoch 5569/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1395981939.2250 - val_loss: 1513155220.1644\n",
      "Epoch 5570/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1396462791.8904 - val_loss: 1513376206.0274\n",
      "Epoch 5571/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1395834868.9785 - val_loss: 1514029080.8402\n",
      "Epoch 5572/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1396335349.8552 - val_loss: 1513348805.8447\n",
      "Epoch 5573/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1395832481.1898 - val_loss: 1514357696.0000\n",
      "Epoch 5574/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1396224604.4305 - val_loss: 1513686298.0091\n",
      "Epoch 5575/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1396033423.7808 - val_loss: 1514672774.4292\n",
      "Epoch 5576/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1396214112.8141 - val_loss: 1515041175.9635\n",
      "Epoch 5577/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1395711648.3131 - val_loss: 1513961849.8630\n",
      "Epoch 5578/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1395655145.3933 - val_loss: 1513671536.2192\n",
      "Epoch 5579/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1395665627.4286 - val_loss: 1513419924.7489\n",
      "Epoch 5580/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1395753061.6986 - val_loss: 1513454475.9817\n",
      "Epoch 5581/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1396479451.8043 - val_loss: 1512316109.1507\n",
      "Epoch 5582/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1395699264.1252 - val_loss: 1513655150.4658\n",
      "Epoch 5583/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 34us/step - loss: 1395517448.6419 - val_loss: 1513907752.0365\n",
      "Epoch 5584/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1395884628.1018 - val_loss: 1513539375.0502\n",
      "Epoch 5585/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1395494461.1194 - val_loss: 1513739419.4703\n",
      "Epoch 5586/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1395551473.8474 - val_loss: 1514167641.4247\n",
      "Epoch 5587/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1395919848.0157 - val_loss: 1512689831.7443\n",
      "Epoch 5588/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1395993335.2329 - val_loss: 1514010783.5616\n",
      "Epoch 5589/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1395477115.9922 - val_loss: 1513942290.4110\n",
      "Epoch 5590/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1395497542.0117 - val_loss: 1513976789.9178\n",
      "Epoch 5591/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1395409581.3386 - val_loss: 1513356658.2648\n",
      "Epoch 5592/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1395552129.3777 - val_loss: 1513322756.6758\n",
      "Epoch 5593/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1395463699.7886 - val_loss: 1512781445.2603\n",
      "Epoch 5594/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1395389201.1585 - val_loss: 1513732671.7078\n",
      "Epoch 5595/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1395140750.5284 - val_loss: 1513120021.0411\n",
      "Epoch 5596/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1395411590.3875 - val_loss: 1513600270.6119\n",
      "Epoch 5597/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1395337465.4873 - val_loss: 1513338360.6941\n",
      "Epoch 5598/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1395302235.1781 - val_loss: 1513074387.2877\n",
      "Epoch 5599/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1396227985.0333 - val_loss: 1511755271.5982\n",
      "Epoch 5600/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1394930548.7280 - val_loss: 1513195570.8493\n",
      "Epoch 5601/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1395357190.5127 - val_loss: 1513673362.7032\n",
      "Epoch 5602/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1395520230.9511 - val_loss: 1512650930.8493\n",
      "Epoch 5603/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1395101648.6575 - val_loss: 1513597508.0913\n",
      "Epoch 5604/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1394995636.1018 - val_loss: 1513684574.6849\n",
      "Epoch 5605/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1395012929.6282 - val_loss: 1512803104.4384\n",
      "Epoch 5606/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1395249105.4090 - val_loss: 1513602000.6575\n",
      "Epoch 5607/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1395011384.3601 - val_loss: 1513431206.8676\n",
      "Epoch 5608/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1395200555.5851 - val_loss: 1513060757.6256\n",
      "Epoch 5609/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1395002491.7417 - val_loss: 1513245260.8584\n",
      "Epoch 5610/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1395279553.6282 - val_loss: 1512729305.4247\n",
      "Epoch 5611/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1394831740.2427 - val_loss: 1513607060.1644\n",
      "Epoch 5612/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1394976374.5440 - val_loss: 1513110886.5753\n",
      "Epoch 5613/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1394828108.9002 - val_loss: 1513248914.4110\n",
      "Epoch 5614/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1394918736.4070 - val_loss: 1513764462.7580\n",
      "Epoch 5615/15000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1394987020.5245 - val_loss: 1513024806.5753\n",
      "Epoch 5616/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1395062792.0157 - val_loss: 1513607199.8539\n",
      "Epoch 5617/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1394733661.3072 - val_loss: 1513269396.1644\n",
      "Epoch 5618/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1394807592.7045 - val_loss: 1513090281.7900\n",
      "Epoch 5619/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1394611641.3620 - val_loss: 1512949953.1689\n",
      "Epoch 5620/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1394717621.0411 - val_loss: 1512343407.6347\n",
      "Epoch 5621/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1395367231.1233 - val_loss: 1513463493.5525\n",
      "Epoch 5622/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1394651741.4325 - val_loss: 1512380197.4064\n",
      "Epoch 5623/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1395258103.9843 - val_loss: 1513143891.2877\n",
      "Epoch 5624/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1394941825.2524 - val_loss: 1512103060.4566\n",
      "Epoch 5625/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1395210275.9452 - val_loss: 1511854723.7991\n",
      "Epoch 5626/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1394399857.5969 - val_loss: 1512553952.7306\n",
      "Epoch 5627/15000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1394605604.0705 - val_loss: 1513466949.8447\n",
      "Epoch 5628/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1394367165.8708 - val_loss: 1512810094.4658\n",
      "Epoch 5629/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1394355473.6595 - val_loss: 1512751130.5936\n",
      "Epoch 5630/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1394823208.0783 - val_loss: 1512251288.5479\n",
      "Epoch 5631/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1394732087.6086 - val_loss: 1513370123.3973\n",
      "Epoch 5632/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1394901030.5753 - val_loss: 1511656911.1963\n",
      "Epoch 5633/15000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1394613383.2642 - val_loss: 1513425037.4429\n",
      "Epoch 5634/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1394326125.0881 - val_loss: 1512401587.4338\n",
      "Epoch 5635/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1394770139.9295 - val_loss: 1512320200.1826\n",
      "Epoch 5636/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1394609226.8963 - val_loss: 1512587737.7169\n",
      "Epoch 5637/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1394585529.2368 - val_loss: 1512918800.0731\n",
      "Epoch 5638/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1394497172.6027 - val_loss: 1511838651.3242\n",
      "Epoch 5639/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1394159739.7417 - val_loss: 1512508340.8950\n",
      "Epoch 5640/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1394481656.1096 - val_loss: 1512848504.4018\n",
      "Epoch 5641/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1394538469.1977 - val_loss: 1513203814.2831\n",
      "Epoch 5642/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1394145892.9472 - val_loss: 1512030525.3699\n",
      "Epoch 5643/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1394135970.1918 - val_loss: 1512294695.4521\n",
      "Epoch 5644/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1394496870.8885 - val_loss: 1512324077.8813\n",
      "Epoch 5645/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1394656725.9178 - val_loss: 1511573334.2100\n",
      "Epoch 5646/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1394358661.5108 - val_loss: 1512038863.1963\n",
      "Epoch 5647/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 39us/step - loss: 1394510507.3346 - val_loss: 1511535112.1826\n",
      "Epoch 5648/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1394433965.3386 - val_loss: 1511862725.8447\n",
      "Epoch 5649/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1393983434.5205 - val_loss: 1512117145.7169\n",
      "Epoch 5650/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1394065464.7358 - val_loss: 1512157754.7397\n",
      "Epoch 5651/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1394304510.7476 - val_loss: 1513304129.7534\n",
      "Epoch 5652/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1393966327.1076 - val_loss: 1512967405.8813\n",
      "Epoch 5653/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1394253501.1194 - val_loss: 1513059051.5434\n",
      "Epoch 5654/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1394502233.6751 - val_loss: 1511163752.9132\n",
      "Epoch 5655/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1394071475.0998 - val_loss: 1512670204.2009\n",
      "Epoch 5656/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1393902163.6634 - val_loss: 1511961977.8630\n",
      "Epoch 5657/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1393739502.3405 - val_loss: 1511865806.0274\n",
      "Epoch 5658/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1393962667.5225 - val_loss: 1512580142.1735\n",
      "Epoch 5659/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1393812854.0431 - val_loss: 1511683714.0457\n",
      "Epoch 5660/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1393636746.6458 - val_loss: 1512045722.8858\n",
      "Epoch 5661/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1393942557.0568 - val_loss: 1511948361.6438\n",
      "Epoch 5662/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1393702263.9843 - val_loss: 1511696433.9726\n",
      "Epoch 5663/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1393792730.4266 - val_loss: 1511765928.6210\n",
      "Epoch 5664/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1393638538.2701 - val_loss: 1511627494.8676\n",
      "Epoch 5665/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1394554112.0000 - val_loss: 1511645841.8265\n",
      "Epoch 5666/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1393737732.6341 - val_loss: 1512558286.9041\n",
      "Epoch 5667/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1393796079.8434 - val_loss: 1511579226.3014\n",
      "Epoch 5668/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1394417276.2427 - val_loss: 1512737506.4840\n",
      "Epoch 5669/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1393632937.4560 - val_loss: 1511490841.4247\n",
      "Epoch 5670/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1393791083.2094 - val_loss: 1512458133.9178\n",
      "Epoch 5671/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1393341068.5245 - val_loss: 1512245143.6712\n",
      "Epoch 5672/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1393402622.3718 - val_loss: 1511995643.0320\n",
      "Epoch 5673/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1393304234.4579 - val_loss: 1511656761.2785\n",
      "Epoch 5674/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1393986979.8200 - val_loss: 1511093640.1826\n",
      "Epoch 5675/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1393529255.0763 - val_loss: 1512197209.1324\n",
      "Epoch 5676/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1393540829.3072 - val_loss: 1512227331.2146\n",
      "Epoch 5677/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1393493128.0157 - val_loss: 1511865358.6119\n",
      "Epoch 5678/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1393419637.2290 - val_loss: 1511813399.9635\n",
      "Epoch 5679/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1393567022.9667 - val_loss: 1511962746.1553\n",
      "Epoch 5680/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1393178149.0724 - val_loss: 1511509940.0183\n",
      "Epoch 5681/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1393848908.3992 - val_loss: 1511740630.7945\n",
      "Epoch 5682/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1393354223.4677 - val_loss: 1511520779.1050\n",
      "Epoch 5683/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1393866806.6067 - val_loss: 1510226266.8858\n",
      "Epoch 5684/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1393249938.2857 - val_loss: 1511030605.4429\n",
      "Epoch 5685/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1393013297.3464 - val_loss: 1511608552.9132\n",
      "Epoch 5686/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1393150773.8552 - val_loss: 1511821381.2603\n",
      "Epoch 5687/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1393292508.6810 - val_loss: 1511066520.5479\n",
      "Epoch 5688/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1393391073.1898 - val_loss: 1511760274.4110\n",
      "Epoch 5689/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1393003824.4697 - val_loss: 1511194587.4703\n",
      "Epoch 5690/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1393121299.0372 - val_loss: 1510940603.3242\n",
      "Epoch 5691/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1392924262.7006 - val_loss: 1511198859.6895\n",
      "Epoch 5692/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1393053336.0470 - val_loss: 1511203644.2009\n",
      "Epoch 5693/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1393293466.8023 - val_loss: 1510407087.3425\n",
      "Epoch 5694/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1393388374.1683 - val_loss: 1510415576.2557\n",
      "Epoch 5695/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1392626543.3425 - val_loss: 1511445570.9224\n",
      "Epoch 5696/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1392956968.0783 - val_loss: 1512026416.2192\n",
      "Epoch 5697/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1393944628.3523 - val_loss: 1510193230.0274\n",
      "Epoch 5698/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1392880861.6830 - val_loss: 1511421783.3790\n",
      "Epoch 5699/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1392957911.4207 - val_loss: 1511942092.5662\n",
      "Epoch 5700/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1392756660.9785 - val_loss: 1511507338.2283\n",
      "Epoch 5701/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1393383018.6458 - val_loss: 1510774105.7169\n",
      "Epoch 5702/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1392730057.8943 - val_loss: 1511294325.1872\n",
      "Epoch 5703/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1393254044.9315 - val_loss: 1510351559.0137\n",
      "Epoch 5704/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1392748163.6321 - val_loss: 1510789310.8311\n",
      "Epoch 5705/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1392600120.6106 - val_loss: 1511812643.9452\n",
      "Epoch 5706/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1392653305.4873 - val_loss: 1510713666.3379\n",
      "Epoch 5707/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1392452015.8434 - val_loss: 1510774970.4475\n",
      "Epoch 5708/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1392668930.3796 - val_loss: 1510990449.9726\n",
      "Epoch 5709/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1392485800.3288 - val_loss: 1511446554.8858\n",
      "Epoch 5710/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1392539991.1703 - val_loss: 1511665089.7534\n",
      "Epoch 5711/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 37us/step - loss: 1392438954.0822 - val_loss: 1510130533.4064\n",
      "Epoch 5712/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1392605861.5734 - val_loss: 1510301906.1187\n",
      "Epoch 5713/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1393038029.9022 - val_loss: 1511892440.5479\n",
      "Epoch 5714/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1392764156.7436 - val_loss: 1509662321.9726\n",
      "Epoch 5715/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1392194272.8141 - val_loss: 1510657242.5936\n",
      "Epoch 5716/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1392602552.6106 - val_loss: 1511251655.8904\n",
      "Epoch 5717/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1392104412.1800 - val_loss: 1510741165.5890\n",
      "Epoch 5718/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1392284282.6145 - val_loss: 1510187629.0046\n",
      "Epoch 5719/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1392122890.0822 - val_loss: 1510496746.6667\n",
      "Epoch 5720/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1392675691.9609 - val_loss: 1509499277.7352\n",
      "Epoch 5721/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1394211708.4932 - val_loss: 1512401364.1644\n",
      "Epoch 5722/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1392192716.9002 - val_loss: 1510367156.0183\n",
      "Epoch 5723/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1392045100.9628 - val_loss: 1510043452.4932\n",
      "Epoch 5724/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1391946453.4168 - val_loss: 1510611498.9589\n",
      "Epoch 5725/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1392031977.9569 - val_loss: 1510585943.3790\n",
      "Epoch 5726/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1392225802.1448 - val_loss: 1510706862.4658\n",
      "Epoch 5727/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1391933385.8943 - val_loss: 1510759983.9269\n",
      "Epoch 5728/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1391760470.6693 - val_loss: 1510562342.8676\n",
      "Epoch 5729/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1392008068.0705 - val_loss: 1510040481.3151\n",
      "Epoch 5730/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1392606737.6595 - val_loss: 1509563181.0046\n",
      "Epoch 5731/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1391899381.4795 - val_loss: 1510418087.1598\n",
      "Epoch 5732/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1392122770.2857 - val_loss: 1511161918.2466\n",
      "Epoch 5733/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1392700261.0724 - val_loss: 1509873436.0548\n",
      "Epoch 5734/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1391854600.0157 - val_loss: 1510870937.1324\n",
      "Epoch 5735/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1391742693.9491 - val_loss: 1510546319.4886\n",
      "Epoch 5736/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1392821505.2524 - val_loss: 1509507535.4886\n",
      "Epoch 5737/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1391625149.3699 - val_loss: 1510346452.7489\n",
      "Epoch 5738/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1391748221.2446 - val_loss: 1509792740.8219\n",
      "Epoch 5739/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1392053776.9080 - val_loss: 1511517206.2100\n",
      "Epoch 5740/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1391467981.9022 - val_loss: 1510529845.7717\n",
      "Epoch 5741/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1392191958.7319 - val_loss: 1509493040.2192\n",
      "Epoch 5742/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1391665460.2270 - val_loss: 1510457565.2237\n",
      "Epoch 5743/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1391616096.4384 - val_loss: 1510275236.5297\n",
      "Epoch 5744/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1391807720.2035 - val_loss: 1509998873.1324\n",
      "Epoch 5745/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1391534916.3836 - val_loss: 1509523134.5388\n",
      "Epoch 5746/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1391389271.6712 - val_loss: 1509554991.0502\n",
      "Epoch 5747/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1391727801.2368 - val_loss: 1510043378.2648\n",
      "Epoch 5748/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1391726050.3796 - val_loss: 1509598241.8995\n",
      "Epoch 5749/15000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1391568441.6125 - val_loss: 1508916827.4703\n",
      "Epoch 5750/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1391263611.8669 - val_loss: 1509935819.6895\n",
      "Epoch 5751/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1391314990.3405 - val_loss: 1509628211.1416\n",
      "Epoch 5752/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1391530195.9139 - val_loss: 1509967552.8767\n",
      "Epoch 5753/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1391322200.1722 - val_loss: 1509814404.0913\n",
      "Epoch 5754/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1391338924.3366 - val_loss: 1510727002.8858\n",
      "Epoch 5755/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1391268058.9276 - val_loss: 1509937536.5845\n",
      "Epoch 5756/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1392397491.3503 - val_loss: 1511087459.0685\n",
      "Epoch 5757/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1391110787.3816 - val_loss: 1509286027.9817\n",
      "Epoch 5758/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1391360385.8160 - val_loss: 1509829987.9452\n",
      "Epoch 5759/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1390942567.4521 - val_loss: 1509418515.8721\n",
      "Epoch 5760/15000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1391057370.9276 - val_loss: 1509607171.5068\n",
      "Epoch 5761/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1391341905.0333 - val_loss: 1509062286.0274\n",
      "Epoch 5762/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1391334594.7554 - val_loss: 1510172859.0320\n",
      "Epoch 5763/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1390981971.6634 - val_loss: 1509959431.3059\n",
      "Epoch 5764/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1391926675.6634 - val_loss: 1508185605.8447\n",
      "Epoch 5765/15000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1391327780.6967 - val_loss: 1509732838.2831\n",
      "Epoch 5766/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1391229511.1389 - val_loss: 1508932509.5160\n",
      "Epoch 5767/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1390819541.1663 - val_loss: 1509471947.9817\n",
      "Epoch 5768/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1390799457.6908 - val_loss: 1509373777.5342\n",
      "Epoch 5769/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1390811565.8395 - val_loss: 1509308921.5708\n",
      "Epoch 5770/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1390743266.9432 - val_loss: 1508621578.2283\n",
      "Epoch 5771/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1390784607.9374 - val_loss: 1509734960.5114\n",
      "Epoch 5772/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1390756347.6164 - val_loss: 1509191745.1689\n",
      "Epoch 5773/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1390858068.1644 - val_loss: 1509917392.6575\n",
      "Epoch 5774/15000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1391598907.6164 - val_loss: 1507800693.7717\n",
      "Epoch 5775/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 43us/step - loss: 1390447415.1076 - val_loss: 1509309257.6438\n",
      "Epoch 5776/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1390475608.7984 - val_loss: 1509593781.1872\n",
      "Epoch 5777/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1391259326.5597 - val_loss: 1508711698.4110\n",
      "Epoch 5778/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1390671061.7926 - val_loss: 1508980029.9543\n",
      "Epoch 5779/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1391408755.9765 - val_loss: 1510463834.3014\n",
      "Epoch 5780/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1390545363.7886 - val_loss: 1509841443.3607\n",
      "Epoch 5781/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1390316485.3855 - val_loss: 1509650756.0913\n",
      "Epoch 5782/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1391267174.7006 - val_loss: 1508078579.4338\n",
      "Epoch 5783/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1390453051.6164 - val_loss: 1509076359.8904\n",
      "Epoch 5784/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1390488937.7065 - val_loss: 1508779975.8904\n",
      "Epoch 5785/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1390706508.7750 - val_loss: 1508521842.8493\n",
      "Epoch 5786/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1390298614.4814 - val_loss: 1509370375.0137\n",
      "Epoch 5787/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1390859795.4129 - val_loss: 1509422706.8493\n",
      "Epoch 5788/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1390325181.1194 - val_loss: 1509323903.1233\n",
      "Epoch 5789/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1390451958.6067 - val_loss: 1509379012.3836\n",
      "Epoch 5790/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1390195739.3033 - val_loss: 1508614116.2374\n",
      "Epoch 5791/15000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1390537712.9706 - val_loss: 1509034737.9726\n",
      "Epoch 5792/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1390246603.6477 - val_loss: 1508760577.1689\n",
      "Epoch 5793/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1390476557.9022 - val_loss: 1507956104.4749\n",
      "Epoch 5794/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1389958892.2114 - val_loss: 1508308256.4384\n",
      "Epoch 5795/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1390094127.0920 - val_loss: 1507759203.0685\n",
      "Epoch 5796/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1390168730.6771 - val_loss: 1508914551.2329\n",
      "Epoch 5797/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1389887082.2074 - val_loss: 1508561195.8356\n",
      "Epoch 5798/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1390139876.8219 - val_loss: 1509023954.9954\n",
      "Epoch 5799/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1390469219.1937 - val_loss: 1507995167.5616\n",
      "Epoch 5800/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1389760050.4736 - val_loss: 1508957430.6484\n",
      "Epoch 5801/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1390960629.9804 - val_loss: 1508185742.0274\n",
      "Epoch 5802/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1390092394.7084 - val_loss: 1508984514.6301\n",
      "Epoch 5803/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1389717185.5029 - val_loss: 1509015574.7945\n",
      "Epoch 5804/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1389682944.2505 - val_loss: 1509012331.5434\n",
      "Epoch 5805/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1390277160.8297 - val_loss: 1508103008.7306\n",
      "Epoch 5806/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1389814540.0235 - val_loss: 1508568105.4977\n",
      "Epoch 5807/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1390394023.7025 - val_loss: 1508190241.8995\n",
      "Epoch 5808/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1389732727.2329 - val_loss: 1508016206.9041\n",
      "Epoch 5809/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1390383202.3170 - val_loss: 1507440765.0776\n",
      "Epoch 5810/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1389354690.7554 - val_loss: 1508083313.0959\n",
      "Epoch 5811/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1389591409.7221 - val_loss: 1508965281.3151\n",
      "Epoch 5812/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1389609757.8082 - val_loss: 1508739346.9954\n",
      "Epoch 5813/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1389492184.4227 - val_loss: 1507827759.6347\n",
      "Epoch 5814/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1389502641.0959 - val_loss: 1507886851.2146\n",
      "Epoch 5815/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1389318643.9139 - val_loss: 1508101297.3881\n",
      "Epoch 5816/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1389550256.5949 - val_loss: 1508413427.1416\n",
      "Epoch 5817/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1389586640.1566 - val_loss: 1508105277.3699\n",
      "Epoch 5818/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1389671345.3464 - val_loss: 1507918956.1279\n",
      "Epoch 5819/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1389319994.6145 - val_loss: 1508256500.8950\n",
      "Epoch 5820/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1389271823.5303 - val_loss: 1507315290.8858\n",
      "Epoch 5821/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1389411553.7534 - val_loss: 1507717947.9087\n",
      "Epoch 5822/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1389459096.8611 - val_loss: 1508516069.1142\n",
      "Epoch 5823/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1389352668.4305 - val_loss: 1507204436.4566\n",
      "Epoch 5824/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1389906064.7828 - val_loss: 1508958592.0000\n",
      "Epoch 5825/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1389876917.6047 - val_loss: 1507478448.8037\n",
      "Epoch 5826/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1389386884.8219 - val_loss: 1506985791.7078\n",
      "Epoch 5827/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1389041506.9432 - val_loss: 1507536264.1826\n",
      "Epoch 5828/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1389233924.0078 - val_loss: 1508305863.5982\n",
      "Epoch 5829/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1389007687.8904 - val_loss: 1508191011.3607\n",
      "Epoch 5830/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1389187574.4814 - val_loss: 1508589282.1918\n",
      "Epoch 5831/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1389812868.1331 - val_loss: 1507046531.5068\n",
      "Epoch 5832/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1389119150.5910 - val_loss: 1507121903.3425\n",
      "Epoch 5833/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1388978768.2818 - val_loss: 1508026611.1416\n",
      "Epoch 5834/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1389069076.2896 - val_loss: 1507651051.2511\n",
      "Epoch 5835/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1388805833.8943 - val_loss: 1507711086.7580\n",
      "Epoch 5836/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1389362787.6947 - val_loss: 1508003779.7991\n",
      "Epoch 5837/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1388884449.9413 - val_loss: 1507216687.3425\n",
      "Epoch 5838/15000\n",
      "1022/1022 [==============================] - 0s 91us/step - loss: 1389168612.9472 - val_loss: 1508292679.3059\n",
      "Epoch 5839/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 49us/step - loss: 1388772589.0881 - val_loss: 1506991229.3699\n",
      "Epoch 5840/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1388560545.0646 - val_loss: 1507279230.2466\n",
      "Epoch 5841/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1389010930.3483 - val_loss: 1506712121.8630\n",
      "Epoch 5842/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1389150801.9100 - val_loss: 1507710888.0365\n",
      "Epoch 5843/15000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1388527775.4990 - val_loss: 1507316690.1187\n",
      "Epoch 5844/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1388508610.2544 - val_loss: 1507300398.1735\n",
      "Epoch 5845/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1388462724.1331 - val_loss: 1507166739.8721\n",
      "Epoch 5846/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1388804180.5401 - val_loss: 1506324782.7580\n",
      "Epoch 5847/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1388432796.1800 - val_loss: 1507069363.1416\n",
      "Epoch 5848/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1388369695.9374 - val_loss: 1507358657.7534\n",
      "Epoch 5849/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1388895943.5147 - val_loss: 1506220705.3151\n",
      "Epoch 5850/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1389015845.0724 - val_loss: 1507899531.1050\n",
      "Epoch 5851/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1388144348.4305 - val_loss: 1507460577.8995\n",
      "Epoch 5852/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1388893093.4481 - val_loss: 1506395565.2968\n",
      "Epoch 5853/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1388794531.8200 - val_loss: 1507968253.3699\n",
      "Epoch 5854/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1388262828.4932 - val_loss: 1506657965.8813\n",
      "Epoch 5855/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1388297256.3288 - val_loss: 1507086774.0639\n",
      "Epoch 5856/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1388085147.3033 - val_loss: 1506961417.0594\n",
      "Epoch 5857/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1388303497.0176 - val_loss: 1507150829.2968\n",
      "Epoch 5858/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1388065741.9022 - val_loss: 1506610228.8950\n",
      "Epoch 5859/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1388235195.4286 - val_loss: 1506383466.3744\n",
      "Epoch 5860/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1387910517.7299 - val_loss: 1506138500.9680\n",
      "Epoch 5861/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1387936775.3894 - val_loss: 1507073312.7306\n",
      "Epoch 5862/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1388244282.6145 - val_loss: 1507016831.4155\n",
      "Epoch 5863/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1388280979.5382 - val_loss: 1507289858.6301\n",
      "Epoch 5864/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1387961803.7730 - val_loss: 1506215588.5297\n",
      "Epoch 5865/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1387721191.2016 - val_loss: 1506415972.5297\n",
      "Epoch 5866/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1388154218.9589 - val_loss: 1506965981.5160\n",
      "Epoch 5867/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1388050625.8787 - val_loss: 1505556046.6119\n",
      "Epoch 5868/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1387810942.4971 - val_loss: 1505745719.8174\n",
      "Epoch 5869/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1387844827.9295 - val_loss: 1507023391.8539\n",
      "Epoch 5870/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1387547240.7045 - val_loss: 1506592121.8630\n",
      "Epoch 5871/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1387802163.0998 - val_loss: 1506756280.1096\n",
      "Epoch 5872/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1387660066.6928 - val_loss: 1506359362.9224\n",
      "Epoch 5873/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1387610557.1194 - val_loss: 1506717865.2055\n",
      "Epoch 5874/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1387923816.4540 - val_loss: 1506470561.6073\n",
      "Epoch 5875/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1387621276.3053 - val_loss: 1505813657.7169\n",
      "Epoch 5876/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1387775501.0254 - val_loss: 1505873508.5297\n",
      "Epoch 5877/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1387621804.5871 - val_loss: 1506328212.7489\n",
      "Epoch 5878/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1387361537.6282 - val_loss: 1505834107.0320\n",
      "Epoch 5879/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1387391793.8474 - val_loss: 1506568599.9635\n",
      "Epoch 5880/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1387461468.1800 - val_loss: 1506009306.3014\n",
      "Epoch 5881/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1387361976.8611 - val_loss: 1505602433.7534\n",
      "Epoch 5882/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1387517024.3131 - val_loss: 1506401261.8813\n",
      "Epoch 5883/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1387216120.1096 - val_loss: 1505823687.3059\n",
      "Epoch 5884/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1387018921.3307 - val_loss: 1505953473.1689\n",
      "Epoch 5885/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1387350953.7065 - val_loss: 1505947814.8676\n",
      "Epoch 5886/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1387044329.9569 - val_loss: 1505552296.0365\n",
      "Epoch 5887/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1387127675.4912 - val_loss: 1505758978.3379\n",
      "Epoch 5888/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1387688349.8082 - val_loss: 1507136158.1005\n",
      "Epoch 5889/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1387790890.3327 - val_loss: 1507087831.6712\n",
      "Epoch 5890/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1386991735.7339 - val_loss: 1505673192.3288\n",
      "Epoch 5891/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1387098140.8063 - val_loss: 1505537701.6986\n",
      "Epoch 5892/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1387496104.5793 - val_loss: 1506091989.6256\n",
      "Epoch 5893/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1387133606.9511 - val_loss: 1505706518.5023\n",
      "Epoch 5894/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1386795934.8102 - val_loss: 1505227716.3836\n",
      "Epoch 5895/15000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1387239843.3190 - val_loss: 1504236702.1005\n",
      "Epoch 5896/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1386703773.9335 - val_loss: 1505114710.5023\n",
      "Epoch 5897/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1387035107.9452 - val_loss: 1505180633.4247\n",
      "Epoch 5898/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1387389557.2290 - val_loss: 1504280892.4932\n",
      "Epoch 5899/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1387522860.2114 - val_loss: 1506237589.6256\n",
      "Epoch 5900/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1387339138.5049 - val_loss: 1505038966.3562\n",
      "Epoch 5901/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1387142250.0822 - val_loss: 1504792201.6438\n",
      "Epoch 5902/15000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1386726050.8180 - val_loss: 1504837800.6210\n",
      "Epoch 5903/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 55us/step - loss: 1386594502.1370 - val_loss: 1505861656.5479\n",
      "Epoch 5904/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1386725082.4266 - val_loss: 1505397895.8904\n",
      "Epoch 5905/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1386478107.3659 - val_loss: 1505225993.6438\n",
      "Epoch 5906/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1386460717.0881 - val_loss: 1504963060.0183\n",
      "Epoch 5907/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1386409906.3483 - val_loss: 1505106397.5160\n",
      "Epoch 5908/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1386579478.4814 - val_loss: 1505692808.7671\n",
      "Epoch 5909/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1387513199.9687 - val_loss: 1506653390.9041\n",
      "Epoch 5910/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1386047259.5538 - val_loss: 1505162838.5023\n",
      "Epoch 5911/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1386727436.0235 - val_loss: 1504621232.2192\n",
      "Epoch 5912/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1386319451.5538 - val_loss: 1505067773.3699\n",
      "Epoch 5913/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1386579411.6634 - val_loss: 1504833728.0000\n",
      "Epoch 5914/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1386623039.6243 - val_loss: 1505345398.9406\n",
      "Epoch 5915/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1386138572.7750 - val_loss: 1504297131.5434\n",
      "Epoch 5916/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1386203812.5714 - val_loss: 1504670790.1370\n",
      "Epoch 5917/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1386161617.9100 - val_loss: 1504921729.7534\n",
      "Epoch 5918/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1385984664.6732 - val_loss: 1504562303.1233\n",
      "Epoch 5919/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1386080246.7319 - val_loss: 1504245330.9954\n",
      "Epoch 5920/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1385842073.1115 - val_loss: 1504643258.7397\n",
      "Epoch 5921/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1386273217.3777 - val_loss: 1504503373.4429\n",
      "Epoch 5922/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1386017370.6771 - val_loss: 1504947747.6530\n",
      "Epoch 5923/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1385822780.6184 - val_loss: 1505065979.9087\n",
      "Epoch 5924/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1386023636.1644 - val_loss: 1505207002.8858\n",
      "Epoch 5925/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1385957412.4462 - val_loss: 1503987065.2785\n",
      "Epoch 5926/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1385798751.8121 - val_loss: 1504501763.2146\n",
      "Epoch 5927/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1386047427.7573 - val_loss: 1504865064.6210\n",
      "Epoch 5928/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1385659282.6614 - val_loss: 1504417854.2466\n",
      "Epoch 5929/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1385780831.6869 - val_loss: 1504060098.0457\n",
      "Epoch 5930/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1385573016.7984 - val_loss: 1504480979.5799\n",
      "Epoch 5931/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1385702106.4266 - val_loss: 1503828656.5114\n",
      "Epoch 5932/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1385801227.5225 - val_loss: 1504256753.0959\n",
      "Epoch 5933/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1385676880.1566 - val_loss: 1504764754.4110\n",
      "Epoch 5934/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1385608155.0528 - val_loss: 1503903597.5890\n",
      "Epoch 5935/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1385596386.0665 - val_loss: 1504891640.6941\n",
      "Epoch 5936/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1386494998.7945 - val_loss: 1502752509.9543\n",
      "Epoch 5937/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1385466008.2975 - val_loss: 1504412486.1370\n",
      "Epoch 5938/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1385471275.5225 - val_loss: 1504076823.6712\n",
      "Epoch 5939/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1385362445.2759 - val_loss: 1503679852.4201\n",
      "Epoch 5940/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1385146897.4090 - val_loss: 1504234996.0183\n",
      "Epoch 5941/15000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1385201687.7965 - val_loss: 1504578413.5890\n",
      "Epoch 5942/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1385132818.0352 - val_loss: 1503988520.6210\n",
      "Epoch 5943/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1385196231.7652 - val_loss: 1504494176.1461\n",
      "Epoch 5944/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1385444808.6419 - val_loss: 1504231204.8219\n",
      "Epoch 5945/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1385107004.7436 - val_loss: 1503758126.7580\n",
      "Epoch 5946/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1385304137.8943 - val_loss: 1504448997.4064\n",
      "Epoch 5947/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1385061462.4814 - val_loss: 1503697062.8676\n",
      "Epoch 5948/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1385279828.2896 - val_loss: 1503574684.9315\n",
      "Epoch 5949/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1385989455.2798 - val_loss: 1504569020.4932\n",
      "Epoch 5950/15000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1384789769.7691 - val_loss: 1504087077.1142\n",
      "Epoch 5951/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1384761691.8043 - val_loss: 1503479423.7078\n",
      "Epoch 5952/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1385355001.7378 - val_loss: 1503773444.6758\n",
      "Epoch 5953/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1385664139.6477 - val_loss: 1503605725.8082\n",
      "Epoch 5954/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1384922263.9217 - val_loss: 1502572412.7854\n",
      "Epoch 5955/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1385093999.7182 - val_loss: 1503723745.6073\n",
      "Epoch 5956/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1384721534.7476 - val_loss: 1502968087.9635\n",
      "Epoch 5957/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1384870053.7613 - val_loss: 1503447272.9132\n",
      "Epoch 5958/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1384746157.8395 - val_loss: 1503683481.1324\n",
      "Epoch 5959/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1385623737.1115 - val_loss: 1504489945.4247\n",
      "Epoch 5960/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1384814433.1898 - val_loss: 1502134202.4475\n",
      "Epoch 5961/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1384578476.0861 - val_loss: 1503269339.4703\n",
      "Epoch 5962/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1384428411.8669 - val_loss: 1502840827.9087\n",
      "Epoch 5963/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1384683378.7241 - val_loss: 1502183354.1553\n",
      "Epoch 5964/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1384542677.9178 - val_loss: 1502109433.2785\n",
      "Epoch 5965/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1384208278.9198 - val_loss: 1503020100.6758\n",
      "Epoch 5966/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1384729518.3405 - val_loss: 1503621062.7215\n",
      "Epoch 5967/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 36us/step - loss: 1384136130.0039 - val_loss: 1503296146.4110\n",
      "Epoch 5968/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1384251994.4266 - val_loss: 1502748165.8447\n",
      "Epoch 5969/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1384392571.3659 - val_loss: 1503340928.0000\n",
      "Epoch 5970/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1384118076.6184 - val_loss: 1502548415.4155\n",
      "Epoch 5971/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1384263926.9824 - val_loss: 1502120435.7260\n",
      "Epoch 5972/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1384317720.1096 - val_loss: 1503465997.1507\n",
      "Epoch 5973/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1384190551.1703 - val_loss: 1503163301.9909\n",
      "Epoch 5974/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1383920084.6654 - val_loss: 1502682598.8676\n",
      "Epoch 5975/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1383921763.4442 - val_loss: 1502768325.5525\n",
      "Epoch 5976/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1384173129.6438 - val_loss: 1501664381.9543\n",
      "Epoch 5977/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1384276301.5264 - val_loss: 1501894502.2831\n",
      "Epoch 5978/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1384276035.9452 - val_loss: 1502218093.5890\n",
      "Epoch 5979/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1384109582.5284 - val_loss: 1503160212.7489\n",
      "Epoch 5980/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1383855153.3464 - val_loss: 1502819798.7945\n",
      "Epoch 5981/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1383726431.0607 - val_loss: 1502755394.6301\n",
      "Epoch 5982/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1383891138.8806 - val_loss: 1501680463.1963\n",
      "Epoch 5983/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1383741781.4168 - val_loss: 1501743404.1279\n",
      "Epoch 5984/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1383597919.3112 - val_loss: 1502317452.5662\n",
      "Epoch 5985/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1383943858.8493 - val_loss: 1501496142.0274\n",
      "Epoch 5986/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1383424509.5577 - val_loss: 1502158889.4977\n",
      "Epoch 5987/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1383681577.2055 - val_loss: 1501940783.3425\n",
      "Epoch 5988/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1383561048.1722 - val_loss: 1502512684.1279\n",
      "Epoch 5989/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1383437377.8160 - val_loss: 1502306648.8402\n",
      "Epoch 5990/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1383526922.0196 - val_loss: 1501926207.4155\n",
      "Epoch 5991/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1383283675.4286 - val_loss: 1502330399.8539\n",
      "Epoch 5992/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1383368747.8356 - val_loss: 1502343116.2740\n",
      "Epoch 5993/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1383446579.7260 - val_loss: 1502838853.8447\n",
      "Epoch 5994/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1384058175.9374 - val_loss: 1502895066.3014\n",
      "Epoch 5995/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1383156122.8023 - val_loss: 1501431874.6301\n",
      "Epoch 5996/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1384115843.4442 - val_loss: 1500411337.6438\n",
      "Epoch 5997/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1383312246.7319 - val_loss: 1502132237.7352\n",
      "Epoch 5998/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1383157332.2896 - val_loss: 1502102757.6986\n",
      "Epoch 5999/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1383094548.0391 - val_loss: 1501443536.3653\n",
      "Epoch 6000/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1383181833.7691 - val_loss: 1500836499.8721\n",
      "Epoch 6001/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1383470946.0665 - val_loss: 1502524205.0046\n",
      "Epoch 6002/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1382922738.4736 - val_loss: 1501030432.1461\n",
      "Epoch 6003/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1382747837.8708 - val_loss: 1501310086.7215\n",
      "Epoch 6004/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1382919856.5949 - val_loss: 1501830386.5571\n",
      "Epoch 6005/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1382798087.0137 - val_loss: 1501404402.2648\n",
      "Epoch 6006/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1382631086.8415 - val_loss: 1501140336.5114\n",
      "Epoch 6007/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383237206.6693 - val_loss: 1500735184.9498\n",
      "Epoch 6008/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1382997717.6673 - val_loss: 1501217440.7306\n",
      "Epoch 6009/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1382676197.5108 - val_loss: 1501478879.8539\n",
      "Epoch 6010/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1382920132.3836 - val_loss: 1502035616.1461\n",
      "Epoch 6011/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1382713960.4540 - val_loss: 1501997817.8630\n",
      "Epoch 6012/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1382511537.8474 - val_loss: 1500972163.7991\n",
      "Epoch 6013/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1382871659.9609 - val_loss: 1500482849.6073\n",
      "Epoch 6014/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1382546394.0509 - val_loss: 1500585904.5114\n",
      "Epoch 6015/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1382877674.3327 - val_loss: 1500568698.4475\n",
      "Epoch 6016/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1382387523.6321 - val_loss: 1501354375.8904\n",
      "Epoch 6017/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1382275171.1937 - val_loss: 1500977562.0091\n",
      "Epoch 6018/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1382636815.7808 - val_loss: 1501299930.5936\n",
      "Epoch 6019/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1382435265.9413 - val_loss: 1500622000.5114\n",
      "Epoch 6020/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1382253317.0098 - val_loss: 1501195811.0685\n",
      "Epoch 6021/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1382252091.8669 - val_loss: 1500700058.3014\n",
      "Epoch 6022/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1382215916.9628 - val_loss: 1500896882.5571\n",
      "Epoch 6023/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1382214017.2524 - val_loss: 1500802454.2100\n",
      "Epoch 6024/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1382538407.4521 - val_loss: 1500540193.0228\n",
      "Epoch 6025/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1382339853.1507 - val_loss: 1500573948.2009\n",
      "Epoch 6026/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1382268673.2524 - val_loss: 1500388911.6347\n",
      "Epoch 6027/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1382287883.7730 - val_loss: 1501254407.0137\n",
      "Epoch 6028/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1381903446.5440 - val_loss: 1500548029.9543\n",
      "Epoch 6029/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1382010678.3562 - val_loss: 1501189694.2466\n",
      "Epoch 6030/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1381873279.7495 - val_loss: 1500401478.1370\n",
      "Epoch 6031/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 35us/step - loss: 1381975596.3366 - val_loss: 1500822274.6301\n",
      "Epoch 6032/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1382087957.0411 - val_loss: 1499032357.4064\n",
      "Epoch 6033/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1381868190.3092 - val_loss: 1500115921.5342\n",
      "Epoch 6034/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1381538789.6986 - val_loss: 1499940009.4977\n",
      "Epoch 6035/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1381652459.7104 - val_loss: 1499816002.6301\n",
      "Epoch 6036/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1381696751.8434 - val_loss: 1499562253.7352\n",
      "Epoch 6037/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1381473804.6497 - val_loss: 1499759181.7352\n",
      "Epoch 6038/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1381809132.4618 - val_loss: 1499436298.5205\n",
      "Epoch 6039/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1381476851.2250 - val_loss: 1499831601.0959\n",
      "Epoch 6040/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1381562663.7025 - val_loss: 1500407526.8676\n",
      "Epoch 6041/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1381662387.2250 - val_loss: 1500034343.7443\n",
      "Epoch 6042/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1381470427.1781 - val_loss: 1500456867.6530\n",
      "Epoch 6043/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1382036252.0548 - val_loss: 1498885484.4201\n",
      "Epoch 6044/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1381282171.4912 - val_loss: 1500322263.6712\n",
      "Epoch 6045/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1381087705.4247 - val_loss: 1499767513.7169\n",
      "Epoch 6046/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1381046916.8845 - val_loss: 1499656723.8721\n",
      "Epoch 6047/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1381092788.8532 - val_loss: 1499515221.6256\n",
      "Epoch 6048/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1381076583.5773 - val_loss: 1499798737.8265\n",
      "Epoch 6049/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1380956135.4521 - val_loss: 1499457218.6301\n",
      "Epoch 6050/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1380956533.4795 - val_loss: 1499136310.0639\n",
      "Epoch 6051/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1380971641.2368 - val_loss: 1499008000.5845\n",
      "Epoch 6052/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1381060362.7710 - val_loss: 1499570104.6941\n",
      "Epoch 6053/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1381649337.8630 - val_loss: 1499880180.0183\n",
      "Epoch 6054/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1380681089.2524 - val_loss: 1499062780.2009\n",
      "Epoch 6055/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1380734478.6536 - val_loss: 1498594392.8402\n",
      "Epoch 6056/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1380746609.2211 - val_loss: 1499086113.6073\n",
      "Epoch 6057/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1380803937.6908 - val_loss: 1498957774.0274\n",
      "Epoch 6058/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1380720693.3542 - val_loss: 1499440334.3196\n",
      "Epoch 6059/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1380602613.2290 - val_loss: 1499092263.4521\n",
      "Epoch 6060/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1380685137.0333 - val_loss: 1499006484.4566\n",
      "Epoch 6061/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1380609536.5010 - val_loss: 1499453421.2968\n",
      "Epoch 6062/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1381040110.2153 - val_loss: 1499385136.5114\n",
      "Epoch 6063/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1380813521.5342 - val_loss: 1498672379.6164\n",
      "Epoch 6064/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1380995027.9139 - val_loss: 1499667461.5525\n",
      "Epoch 6065/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1380755152.2818 - val_loss: 1497711046.7215\n",
      "Epoch 6066/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1380279523.3190 - val_loss: 1498504139.3973\n",
      "Epoch 6067/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1380256281.2994 - val_loss: 1498739364.5297\n",
      "Epoch 6068/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1380165987.6947 - val_loss: 1498403798.2100\n",
      "Epoch 6069/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1381736188.2427 - val_loss: 1497088069.8447\n",
      "Epoch 6070/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1379985000.9550 - val_loss: 1498591242.8128\n",
      "Epoch 6071/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1380050435.0059 - val_loss: 1498394274.4840\n",
      "Epoch 6072/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1381515826.5988 - val_loss: 1499504524.5662\n",
      "Epoch 6073/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1380306910.4344 - val_loss: 1498797885.0776\n",
      "Epoch 6074/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1380097004.5871 - val_loss: 1498452364.8584\n",
      "Epoch 6075/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1379835086.5284 - val_loss: 1497927030.6484\n",
      "Epoch 6076/15000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1380379924.7906 - val_loss: 1496652146.2648\n",
      "Epoch 6077/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1379712169.3307 - val_loss: 1498311465.4977\n",
      "Epoch 6078/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1379933284.6967 - val_loss: 1498272944.8037\n",
      "Epoch 6079/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1380266252.8376 - val_loss: 1497438703.0502\n",
      "Epoch 6080/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1379703508.9159 - val_loss: 1498029481.2055\n",
      "Epoch 6081/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1380311510.9198 - val_loss: 1497041386.6667\n",
      "Epoch 6082/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1379592579.2564 - val_loss: 1498115655.5982\n",
      "Epoch 6083/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1379840462.9041 - val_loss: 1497545161.0594\n",
      "Epoch 6084/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1379725834.8963 - val_loss: 1497880168.3288\n",
      "Epoch 6085/15000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1379730432.8767 - val_loss: 1497136502.3562\n",
      "Epoch 6086/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1379364726.7319 - val_loss: 1498204701.5160\n",
      "Epoch 6087/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1379552668.0548 - val_loss: 1498077072.0731\n",
      "Epoch 6088/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1379399871.4990 - val_loss: 1497803971.5068\n",
      "Epoch 6089/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1379393466.8650 - val_loss: 1498172313.1324\n",
      "Epoch 6090/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1379848816.2192 - val_loss: 1498643092.7489\n",
      "Epoch 6091/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1379301949.2446 - val_loss: 1497846955.8356\n",
      "Epoch 6092/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1379218161.7221 - val_loss: 1497079359.7078\n",
      "Epoch 6093/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1379083350.7945 - val_loss: 1496914317.4429\n",
      "Epoch 6094/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1379339346.1605 - val_loss: 1497545067.8356\n",
      "Epoch 6095/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 34us/step - loss: 1379371421.3072 - val_loss: 1497556294.4292\n",
      "Epoch 6096/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1378908963.6947 - val_loss: 1497171034.0091\n",
      "Epoch 6097/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1379360351.4364 - val_loss: 1496449935.7808\n",
      "Epoch 6098/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1379201776.7202 - val_loss: 1497691996.3470\n",
      "Epoch 6099/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1380529222.6380 - val_loss: 1499105250.4840\n",
      "Epoch 6100/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1379139216.1566 - val_loss: 1496874377.9361\n",
      "Epoch 6101/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1379959972.1957 - val_loss: 1495302624.4384\n",
      "Epoch 6102/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1379889520.2192 - val_loss: 1497004514.4840\n",
      "Epoch 6103/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1378859788.9002 - val_loss: 1496824686.7580\n",
      "Epoch 6104/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1378855777.1898 - val_loss: 1495960698.4475\n",
      "Epoch 6105/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1378685050.6145 - val_loss: 1496653917.2237\n",
      "Epoch 6106/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1380232085.9178 - val_loss: 1498670169.1324\n",
      "Epoch 6107/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1379085833.1429 - val_loss: 1495958205.9543\n",
      "Epoch 6108/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1378720534.9198 - val_loss: 1496218787.0685\n",
      "Epoch 6109/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1378631091.6008 - val_loss: 1496321081.2785\n",
      "Epoch 6110/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1378710383.2172 - val_loss: 1496639390.1005\n",
      "Epoch 6111/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1378887420.4932 - val_loss: 1495304500.3105\n",
      "Epoch 6112/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1378704449.0646 - val_loss: 1496006624.4384\n",
      "Epoch 6113/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1378988203.2094 - val_loss: 1497588063.5616\n",
      "Epoch 6114/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1378923919.2798 - val_loss: 1495882208.1461\n",
      "Epoch 6115/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1378423884.6497 - val_loss: 1497200012.8584\n",
      "Epoch 6116/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1378013117.6204 - val_loss: 1496448368.2192\n",
      "Epoch 6117/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1379077505.1272 - val_loss: 1494990185.2055\n",
      "Epoch 6118/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1378319958.1683 - val_loss: 1497119651.0685\n",
      "Epoch 6119/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1378256995.3190 - val_loss: 1496694464.5845\n",
      "Epoch 6120/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1377993977.2368 - val_loss: 1496725321.9361\n",
      "Epoch 6121/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1378008645.3855 - val_loss: 1496203895.5251\n",
      "Epoch 6122/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1378384096.9393 - val_loss: 1495818702.3196\n",
      "Epoch 6123/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1378425107.7886 - val_loss: 1494884940.2740\n",
      "Epoch 6124/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1377980955.4286 - val_loss: 1495373434.7397\n",
      "Epoch 6125/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1377759904.5636 - val_loss: 1496336678.5753\n",
      "Epoch 6126/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1378019160.4227 - val_loss: 1496091793.5342\n",
      "Epoch 6127/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1377814287.5303 - val_loss: 1496267059.7260\n",
      "Epoch 6128/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1377709512.3914 - val_loss: 1495851167.5616\n",
      "Epoch 6129/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1377487846.5753 - val_loss: 1495803941.4064\n",
      "Epoch 6130/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1378031954.1605 - val_loss: 1494980197.6986\n",
      "Epoch 6131/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1377750656.5010 - val_loss: 1495688522.8128\n",
      "Epoch 6132/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1377306807.4834 - val_loss: 1495644672.8767\n",
      "Epoch 6133/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1377376641.1272 - val_loss: 1495757817.8630\n",
      "Epoch 6134/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1377272078.0274 - val_loss: 1494978560.0000\n",
      "Epoch 6135/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1377309756.6184 - val_loss: 1494796081.3881\n",
      "Epoch 6136/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1377457911.2329 - val_loss: 1495693696.0000\n",
      "Epoch 6137/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1377045463.9217 - val_loss: 1495502482.7032\n",
      "Epoch 6138/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1377049846.7319 - val_loss: 1495176476.0548\n",
      "Epoch 6139/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1377055699.7886 - val_loss: 1494867600.0731\n",
      "Epoch 6140/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1377418209.4403 - val_loss: 1495446313.2055\n",
      "Epoch 6141/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1377330314.7084 - val_loss: 1495548881.2420\n",
      "Epoch 6142/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1376940450.8180 - val_loss: 1495185590.9406\n",
      "Epoch 6143/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1377704501.1037 - val_loss: 1495584155.1781\n",
      "Epoch 6144/15000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1377306848.3131 - val_loss: 1493949148.9315\n",
      "Epoch 6145/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1377159884.2740 - val_loss: 1494931142.7215\n",
      "Epoch 6146/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1376780097.1898 - val_loss: 1494146369.1689\n",
      "Epoch 6147/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1377087327.9374 - val_loss: 1495006304.7306\n",
      "Epoch 6148/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1377526149.6360 - val_loss: 1493885869.0046\n",
      "Epoch 6149/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1376775750.6380 - val_loss: 1494864714.8128\n",
      "Epoch 6150/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1376778061.9022 - val_loss: 1493837104.8037\n",
      "Epoch 6151/15000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1376855423.4990 - val_loss: 1493811413.9178\n",
      "Epoch 6152/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1376310486.7945 - val_loss: 1494495512.5479\n",
      "Epoch 6153/15000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1376923245.7143 - val_loss: 1494022003.7260\n",
      "Epoch 6154/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1377170811.7417 - val_loss: 1495421746.5571\n",
      "Epoch 6155/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1376689598.4971 - val_loss: 1493975557.8447\n",
      "Epoch 6156/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1376315901.2446 - val_loss: 1494122029.0046\n",
      "Epoch 6157/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1376260482.0039 - val_loss: 1494432706.0457\n",
      "Epoch 6158/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1376404544.6262 - val_loss: 1493873045.3333\n",
      "Epoch 6159/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 33us/step - loss: 1376736497.5342 - val_loss: 1494979887.0502\n",
      "Epoch 6160/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1376049298.9119 - val_loss: 1494080300.4201\n",
      "Epoch 6161/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1376668351.3738 - val_loss: 1494820489.3516\n",
      "Epoch 6162/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1375980973.5890 - val_loss: 1493236522.3744\n",
      "Epoch 6163/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1376138962.1605 - val_loss: 1493787474.1187\n",
      "Epoch 6164/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1376600671.4364 - val_loss: 1494129861.8447\n",
      "Epoch 6165/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1376115862.7945 - val_loss: 1493162151.7443\n",
      "Epoch 6166/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1376132364.9002 - val_loss: 1492695165.6621\n",
      "Epoch 6167/15000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1375983107.0059 - val_loss: 1493913052.9315\n",
      "Epoch 6168/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1375887613.3699 - val_loss: 1493597495.8174\n",
      "Epoch 6169/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1375756094.1213 - val_loss: 1493018391.0868\n",
      "Epoch 6170/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1375770626.2544 - val_loss: 1493384538.3014\n",
      "Epoch 6171/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1375563501.1507 - val_loss: 1493223406.1735\n",
      "Epoch 6172/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1375806530.3796 - val_loss: 1493675534.9041\n",
      "Epoch 6173/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1375729945.4247 - val_loss: 1492538573.4429\n",
      "Epoch 6174/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1375501394.1605 - val_loss: 1493015426.3379\n",
      "Epoch 6175/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1376136413.6204 - val_loss: 1491812570.5936\n",
      "Epoch 6176/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1375794108.6184 - val_loss: 1493936806.2831\n",
      "Epoch 6177/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1375436672.5010 - val_loss: 1493337902.1735\n",
      "Epoch 6178/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1375223355.8669 - val_loss: 1493162147.6530\n",
      "Epoch 6179/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1375346873.7378 - val_loss: 1492836608.2922\n",
      "Epoch 6180/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1375587181.7143 - val_loss: 1492955221.3333\n",
      "Epoch 6181/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1375445671.7025 - val_loss: 1491848153.7169\n",
      "Epoch 6182/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1375172068.9472 - val_loss: 1491759021.2968\n",
      "Epoch 6183/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1375263544.6106 - val_loss: 1493453327.4886\n",
      "Epoch 6184/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1375072787.1624 - val_loss: 1492143075.0685\n",
      "Epoch 6185/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1374909390.9041 - val_loss: 1492561517.2968\n",
      "Epoch 6186/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1374991225.7378 - val_loss: 1493103985.9726\n",
      "Epoch 6187/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1375080006.2622 - val_loss: 1491957913.1324\n",
      "Epoch 6188/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1375035102.1840 - val_loss: 1492081125.9909\n",
      "Epoch 6189/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1374628053.1663 - val_loss: 1492596581.4064\n",
      "Epoch 6190/15000\n",
      "1022/1022 [==============================] - 0s 72us/step - loss: 1374733896.9550 - val_loss: 1492646747.4703\n",
      "Epoch 6191/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1374881810.0352 - val_loss: 1492904605.5160\n",
      "Epoch 6192/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1374948054.5440 - val_loss: 1491573708.5662\n",
      "Epoch 6193/15000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1374514698.2701 - val_loss: 1492302442.3744\n",
      "Epoch 6194/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1374698918.8258 - val_loss: 1491410012.6393\n",
      "Epoch 6195/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1374561808.1566 - val_loss: 1492609673.0594\n",
      "Epoch 6196/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1374564375.0450 - val_loss: 1492608121.8630\n",
      "Epoch 6197/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1374582640.2192 - val_loss: 1492945758.6849\n",
      "Epoch 6198/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1374521974.7319 - val_loss: 1492064937.4977\n",
      "Epoch 6199/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1374894999.0450 - val_loss: 1491123946.6667\n",
      "Epoch 6200/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1373999771.9295 - val_loss: 1491641183.8539\n",
      "Epoch 6201/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1374095936.8767 - val_loss: 1491876981.7717\n",
      "Epoch 6202/15000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1374062680.0470 - val_loss: 1492090404.5297\n",
      "Epoch 6203/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1374159039.6243 - val_loss: 1491364051.5799\n",
      "Epoch 6204/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1373973829.3855 - val_loss: 1491639894.2100\n",
      "Epoch 6205/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1374231858.0978 - val_loss: 1491525866.6667\n",
      "Epoch 6206/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1373973836.1487 - val_loss: 1491994821.5525\n",
      "Epoch 6207/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1373771213.6517 - val_loss: 1491896180.3105\n",
      "Epoch 6208/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1374363547.8043 - val_loss: 1491234325.0411\n",
      "Epoch 6209/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1373818696.8924 - val_loss: 1491316736.8767\n",
      "Epoch 6210/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1374171504.7202 - val_loss: 1490884609.4612\n",
      "Epoch 6211/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1373757561.6125 - val_loss: 1491425094.4292\n",
      "Epoch 6212/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1373639029.3542 - val_loss: 1490919906.4840\n",
      "Epoch 6213/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1373652374.4188 - val_loss: 1490906471.7443\n",
      "Epoch 6214/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1373453568.9393 - val_loss: 1491053880.6941\n",
      "Epoch 6215/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1373436942.0274 - val_loss: 1490275027.2877\n",
      "Epoch 6216/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1373622616.5479 - val_loss: 1491345549.7352\n",
      "Epoch 6217/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1373558240.9393 - val_loss: 1491133851.1781\n",
      "Epoch 6218/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1373762648.9237 - val_loss: 1490806825.4977\n",
      "Epoch 6219/15000\n",
      "1022/1022 [==============================] - 0s 66us/step - loss: 1373288272.2192 - val_loss: 1490654007.8174\n",
      "Epoch 6220/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1373340435.9139 - val_loss: 1490928258.0457\n",
      "Epoch 6221/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1373841202.7241 - val_loss: 1491780276.8950\n",
      "Epoch 6222/15000\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 1373214565.1977 - val_loss: 1491363025.5342\n",
      "Epoch 6223/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 40us/step - loss: 1372897940.7906 - val_loss: 1490356822.5023\n",
      "Epoch 6224/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1373286361.2994 - val_loss: 1490056538.3014\n",
      "Epoch 6225/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1373135668.6027 - val_loss: 1490074021.1142\n",
      "Epoch 6226/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1373354042.4892 - val_loss: 1489585573.6986\n",
      "Epoch 6227/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1372978393.1115 - val_loss: 1489839103.1233\n",
      "Epoch 6228/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1373060570.5519 - val_loss: 1490595583.4155\n",
      "Epoch 6229/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1373110712.4853 - val_loss: 1489824046.7580\n",
      "Epoch 6230/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1372939840.0000 - val_loss: 1490172396.1279\n",
      "Epoch 6231/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1372662472.5166 - val_loss: 1489540745.9361\n",
      "Epoch 6232/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1372737943.2329 - val_loss: 1489118854.1370\n",
      "Epoch 6233/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1372867310.8415 - val_loss: 1488641408.0000\n",
      "Epoch 6234/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1372353709.3386 - val_loss: 1489827026.4110\n",
      "Epoch 6235/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1372342986.6458 - val_loss: 1489952627.1416\n",
      "Epoch 6236/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1372514100.7280 - val_loss: 1490489773.2968\n",
      "Epoch 6237/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1372290392.9237 - val_loss: 1490179869.8082\n",
      "Epoch 6238/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1372191296.8767 - val_loss: 1489539848.4749\n",
      "Epoch 6239/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1372160941.4638 - val_loss: 1489168888.1096\n",
      "Epoch 6240/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1372235344.7828 - val_loss: 1489085427.1416\n",
      "Epoch 6241/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1372808844.0235 - val_loss: 1490014923.3973\n",
      "Epoch 6242/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1372171002.7397 - val_loss: 1489747422.1005\n",
      "Epoch 6243/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1372394179.3816 - val_loss: 1488618676.8950\n",
      "Epoch 6244/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1372175078.1996 - val_loss: 1488714330.5936\n",
      "Epoch 6245/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1371912351.0607 - val_loss: 1488673355.9817\n",
      "Epoch 6246/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1371995694.4658 - val_loss: 1488305259.2511\n",
      "Epoch 6247/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1371957106.7241 - val_loss: 1489487943.0137\n",
      "Epoch 6248/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1372042406.7006 - val_loss: 1488764371.8721\n",
      "Epoch 6249/15000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1371719283.2250 - val_loss: 1489483714.6301\n",
      "Epoch 6250/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1371570358.5440 - val_loss: 1489060598.0639\n",
      "Epoch 6251/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1371822267.8669 - val_loss: 1488837651.5799\n",
      "Epoch 6252/15000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1371531904.2505 - val_loss: 1488729070.7580\n",
      "Epoch 6253/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1371676090.7397 - val_loss: 1489006541.7352\n",
      "Epoch 6254/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1371641414.1370 - val_loss: 1489068900.5297\n",
      "Epoch 6255/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1371243933.8082 - val_loss: 1488178045.3699\n",
      "Epoch 6256/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1371237379.0059 - val_loss: 1487945760.4384\n",
      "Epoch 6257/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1371189707.1468 - val_loss: 1487973935.6347\n",
      "Epoch 6258/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1371274047.3738 - val_loss: 1488349207.6712\n",
      "Epoch 6259/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1371103490.3796 - val_loss: 1488603655.8904\n",
      "Epoch 6260/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1371107448.2348 - val_loss: 1487449806.9041\n",
      "Epoch 6261/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1370999919.3425 - val_loss: 1488093351.7443\n",
      "Epoch 6262/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1371067274.2701 - val_loss: 1488517830.1370\n",
      "Epoch 6263/15000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1370962740.1018 - val_loss: 1487574736.6575\n",
      "Epoch 6264/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1370915199.2485 - val_loss: 1487492366.9041\n",
      "Epoch 6265/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1371019026.0978 - val_loss: 1487918695.7443\n",
      "Epoch 6266/15000\n",
      "1022/1022 [==============================] - 0s 81us/step - loss: 1370827394.6301 - val_loss: 1487321883.1781\n",
      "Epoch 6267/15000\n",
      "1022/1022 [==============================] - 0s 97us/step - loss: 1370791251.9139 - val_loss: 1488184086.7945\n",
      "Epoch 6268/15000\n",
      "1022/1022 [==============================] - 0s 132us/step - loss: 1371088589.5890 - val_loss: 1487260991.1233\n",
      "Epoch 6269/15000\n",
      "1022/1022 [==============================] - 0s 93us/step - loss: 1370731357.1820 - val_loss: 1488435223.6712\n",
      "Epoch 6270/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1370516562.9119 - val_loss: 1488050986.0822\n",
      "Epoch 6271/15000\n",
      "1022/1022 [==============================] - 0s 91us/step - loss: 1370581054.1213 - val_loss: 1488364359.5982\n",
      "Epoch 6272/15000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1370563659.8982 - val_loss: 1486845960.7671\n",
      "Epoch 6273/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1370711056.2818 - val_loss: 1486997326.0274\n",
      "Epoch 6274/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1370446989.7769 - val_loss: 1487238396.4932\n",
      "Epoch 6275/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1370295873.1272 - val_loss: 1486924342.3562\n",
      "Epoch 6276/15000\n",
      "1022/1022 [==============================] - 0s 63us/step - loss: 1371134178.6928 - val_loss: 1488094509.5890\n",
      "Epoch 6277/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1370323238.0744 - val_loss: 1486523953.9726\n",
      "Epoch 6278/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1370385589.8552 - val_loss: 1486168765.0776\n",
      "Epoch 6279/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1370279065.6751 - val_loss: 1486300838.2831\n",
      "Epoch 6280/15000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1370290429.9961 - val_loss: 1487857825.8995\n",
      "Epoch 6281/15000\n",
      "1022/1022 [==============================] - 0s 71us/step - loss: 1370310913.0020 - val_loss: 1486648970.5205\n",
      "Epoch 6282/15000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1370581161.8317 - val_loss: 1487502974.8311\n",
      "Epoch 6283/15000\n",
      "1022/1022 [==============================] - 0s 72us/step - loss: 1370045367.8591 - val_loss: 1486466231.5251\n",
      "Epoch 6284/15000\n",
      "1022/1022 [==============================] - 0s 70us/step - loss: 1370208964.3836 - val_loss: 1485914505.9361\n",
      "Epoch 6285/15000\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 1369901198.5284 - val_loss: 1486994034.8493\n",
      "Epoch 6286/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1369791898.5519 - val_loss: 1486668859.0320\n",
      "Epoch 6287/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 54us/step - loss: 1369596512.8141 - val_loss: 1486401493.0411\n",
      "Epoch 6288/15000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1369572211.7260 - val_loss: 1486466193.2420\n",
      "Epoch 6289/15000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1369782553.1742 - val_loss: 1485828700.3470\n",
      "Epoch 6290/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1369351953.2838 - val_loss: 1485804109.7352\n",
      "Epoch 6291/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1369487055.9061 - val_loss: 1486497418.5205\n",
      "Epoch 6292/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1369511970.5675 - val_loss: 1487196818.1187\n",
      "Epoch 6293/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1369391106.0039 - val_loss: 1486383018.6667\n",
      "Epoch 6294/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1369471070.5597 - val_loss: 1486488118.3562\n",
      "Epoch 6295/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1369559214.9667 - val_loss: 1485677281.3151\n",
      "Epoch 6296/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1369149028.4462 - val_loss: 1485030704.5114\n",
      "Epoch 6297/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1369101167.3425 - val_loss: 1485779224.8402\n",
      "Epoch 6298/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1368943685.6360 - val_loss: 1485116088.6941\n",
      "Epoch 6299/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1369174895.9061 - val_loss: 1485543144.3288\n",
      "Epoch 6300/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1369090818.5049 - val_loss: 1485607608.9863\n",
      "Epoch 6301/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1368949560.9863 - val_loss: 1484650263.6712\n",
      "Epoch 6302/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1369259284.0391 - val_loss: 1484231717.9909\n",
      "Epoch 6303/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1368922174.6223 - val_loss: 1485482943.7078\n",
      "Epoch 6304/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1368706195.1624 - val_loss: 1485233606.4292\n",
      "Epoch 6305/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1368887343.6556 - val_loss: 1485709581.1507\n",
      "Epoch 6306/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1368748986.7397 - val_loss: 1485399772.6393\n",
      "Epoch 6307/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1368408529.9100 - val_loss: 1485480881.3881\n",
      "Epoch 6308/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1368523410.5362 - val_loss: 1484769393.6804\n",
      "Epoch 6309/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1368241088.6262 - val_loss: 1485103798.9406\n",
      "Epoch 6310/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1368386731.5851 - val_loss: 1485286839.2329\n",
      "Epoch 6311/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1368293990.7006 - val_loss: 1485362543.0502\n",
      "Epoch 6312/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1368948541.8708 - val_loss: 1483547618.4840\n",
      "Epoch 6313/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1369306560.6262 - val_loss: 1485048137.9361\n",
      "Epoch 6314/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1368237080.0470 - val_loss: 1484905927.5982\n",
      "Epoch 6315/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1368039014.0744 - val_loss: 1483451906.9224\n",
      "Epoch 6316/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1367993622.0431 - val_loss: 1484254417.5342\n",
      "Epoch 6317/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1367771579.8669 - val_loss: 1484157983.2694\n",
      "Epoch 6318/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1367750810.3014 - val_loss: 1484184455.8904\n",
      "Epoch 6319/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1368341649.7847 - val_loss: 1485025609.3516\n",
      "Epoch 6320/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1368089991.7652 - val_loss: 1483478304.7306\n",
      "Epoch 6321/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1367824192.8767 - val_loss: 1482852655.6347\n",
      "Epoch 6322/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1368337237.6673 - val_loss: 1484721146.7397\n",
      "Epoch 6323/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1367491355.8043 - val_loss: 1484106778.8858\n",
      "Epoch 6324/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1367318729.8943 - val_loss: 1483354370.6301\n",
      "Epoch 6325/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1367651831.2329 - val_loss: 1484193023.7078\n",
      "Epoch 6326/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1367283172.1957 - val_loss: 1483083093.0411\n",
      "Epoch 6327/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1367291847.0137 - val_loss: 1482493941.7717\n",
      "Epoch 6328/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1367117738.3327 - val_loss: 1482726658.3379\n",
      "Epoch 6329/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1367530364.7436 - val_loss: 1484121493.6256\n",
      "Epoch 6330/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1367319486.3718 - val_loss: 1483142160.3653\n",
      "Epoch 6331/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1367550399.3738 - val_loss: 1483058930.2648\n",
      "Epoch 6332/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1366932106.7710 - val_loss: 1482697963.2511\n",
      "Epoch 6333/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1366951055.4051 - val_loss: 1482804489.6438\n",
      "Epoch 6334/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1366858373.5108 - val_loss: 1483590794.8128\n",
      "Epoch 6335/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1367232509.3699 - val_loss: 1484199648.7306\n",
      "Epoch 6336/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1367181222.0744 - val_loss: 1483975850.0822\n",
      "Epoch 6337/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1366717393.6595 - val_loss: 1482489096.4749\n",
      "Epoch 6338/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1367219826.8493 - val_loss: 1481628631.3790\n",
      "Epoch 6339/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1366798517.9804 - val_loss: 1482232122.7397\n",
      "Epoch 6340/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1366618241.2524 - val_loss: 1482214065.0959\n",
      "Epoch 6341/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1366314544.0939 - val_loss: 1482812744.1826\n",
      "Epoch 6342/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1366401538.8806 - val_loss: 1483014826.6667\n",
      "Epoch 6343/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1366198533.8865 - val_loss: 1482455209.7900\n",
      "Epoch 6344/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1366207440.4070 - val_loss: 1481852059.4703\n",
      "Epoch 6345/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1366580227.0059 - val_loss: 1481320069.5525\n",
      "Epoch 6346/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1366344334.2779 - val_loss: 1483057423.1963\n",
      "Epoch 6347/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1365883771.3659 - val_loss: 1482245169.0959\n",
      "Epoch 6348/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1365858714.3014 - val_loss: 1481958410.8128\n",
      "Epoch 6349/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1365818018.4423 - val_loss: 1482311469.5890\n",
      "Epoch 6350/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1366193271.4834 - val_loss: 1482119149.2968\n",
      "Epoch 6351/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 35us/step - loss: 1365639107.3816 - val_loss: 1481652161.7534\n",
      "Epoch 6352/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1365748168.8924 - val_loss: 1481682268.3470\n",
      "Epoch 6353/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1365652698.0509 - val_loss: 1480933852.9315\n",
      "Epoch 6354/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1366048787.0372 - val_loss: 1482086156.2740\n",
      "Epoch 6355/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1365919904.0626 - val_loss: 1482106843.4703\n",
      "Epoch 6356/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1365864309.8552 - val_loss: 1480568042.6667\n",
      "Epoch 6357/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1366048047.5930 - val_loss: 1481910871.0868\n",
      "Epoch 6358/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1365225265.0959 - val_loss: 1481091730.9954\n",
      "Epoch 6359/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1365162662.5753 - val_loss: 1480857458.8493\n",
      "Epoch 6360/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1365448079.2798 - val_loss: 1481079016.9132\n",
      "Epoch 6361/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1365540297.8943 - val_loss: 1480425064.9132\n",
      "Epoch 6362/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1365072643.5068 - val_loss: 1480543410.2648\n",
      "Epoch 6363/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1365068131.1937 - val_loss: 1480753549.7352\n",
      "Epoch 6364/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1364872828.7436 - val_loss: 1481018446.6119\n",
      "Epoch 6365/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1364807126.4188 - val_loss: 1480429786.0091\n",
      "Epoch 6366/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1364863287.6086 - val_loss: 1480406279.8904\n",
      "Epoch 6367/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1364817103.1546 - val_loss: 1480977649.3881\n",
      "Epoch 6368/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1364810049.9413 - val_loss: 1480122661.4064\n",
      "Epoch 6369/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1364513385.9569 - val_loss: 1480683105.3151\n",
      "Epoch 6370/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1364553481.0176 - val_loss: 1480642848.7306\n",
      "Epoch 6371/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1364672622.0900 - val_loss: 1480596318.6849\n",
      "Epoch 6372/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1364605680.5949 - val_loss: 1480107417.7169\n",
      "Epoch 6373/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1364235766.6067 - val_loss: 1479811108.5297\n",
      "Epoch 6374/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1364515132.7436 - val_loss: 1480047970.7763\n",
      "Epoch 6375/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1364199799.2329 - val_loss: 1479816815.0502\n",
      "Epoch 6376/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1364259723.2720 - val_loss: 1478957210.8858\n",
      "Epoch 6377/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1364709004.2740 - val_loss: 1479321083.9087\n",
      "Epoch 6378/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1364017448.9550 - val_loss: 1479215504.3653\n",
      "Epoch 6379/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1364436742.2622 - val_loss: 1478603068.7854\n",
      "Epoch 6380/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1364169512.5793 - val_loss: 1479597507.2146\n",
      "Epoch 6381/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1364110196.2270 - val_loss: 1478855497.6438\n",
      "Epoch 6382/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1364089594.7397 - val_loss: 1478577652.8950\n",
      "Epoch 6383/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1364644792.3601 - val_loss: 1480945213.3699\n",
      "Epoch 6384/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1363581440.7515 - val_loss: 1479972672.8767\n",
      "Epoch 6385/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1363521024.7515 - val_loss: 1479193995.9817\n",
      "Epoch 6386/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1363697532.3679 - val_loss: 1479324469.7717\n",
      "Epoch 6387/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1363447234.5675 - val_loss: 1478413733.9909\n",
      "Epoch 6388/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1363505666.1292 - val_loss: 1479049360.3653\n",
      "Epoch 6389/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1363850663.8278 - val_loss: 1479118793.0594\n",
      "Epoch 6390/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1363072206.9041 - val_loss: 1478584539.7626\n",
      "Epoch 6391/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1363604082.7241 - val_loss: 1477384695.8174\n",
      "Epoch 6392/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1363154386.9119 - val_loss: 1478246549.9178\n",
      "Epoch 6393/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1362967205.3229 - val_loss: 1478928099.6530\n",
      "Epoch 6394/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1362906341.8239 - val_loss: 1478401951.2694\n",
      "Epoch 6395/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1362896561.4716 - val_loss: 1478437882.1553\n",
      "Epoch 6396/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1363340452.5714 - val_loss: 1477512396.8584\n",
      "Epoch 6397/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1362776601.2994 - val_loss: 1478834619.0320\n",
      "Epoch 6398/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1362813214.6849 - val_loss: 1478710081.7534\n",
      "Epoch 6399/15000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1362703074.9432 - val_loss: 1478444757.6256\n",
      "Epoch 6400/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1362889180.5558 - val_loss: 1477211665.8265\n",
      "Epoch 6401/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1362505740.0235 - val_loss: 1478037810.2648\n",
      "Epoch 6402/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1362534443.4599 - val_loss: 1478118602.2283\n",
      "Epoch 6403/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1362864745.4560 - val_loss: 1477557554.5571\n",
      "Epoch 6404/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1362536514.1292 - val_loss: 1476928038.8676\n",
      "Epoch 6405/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1362645474.4423 - val_loss: 1477692737.1689\n",
      "Epoch 6406/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1362326931.0372 - val_loss: 1477442535.7443\n",
      "Epoch 6407/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1362277690.6145 - val_loss: 1477934197.4795\n",
      "Epoch 6408/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1362698521.0489 - val_loss: 1476002274.4840\n",
      "Epoch 6409/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1362005587.9139 - val_loss: 1476633323.5434\n",
      "Epoch 6410/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1362149066.6458 - val_loss: 1477309556.3105\n",
      "Epoch 6411/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1362182235.9295 - val_loss: 1476390141.9543\n",
      "Epoch 6412/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1361749597.6204 - val_loss: 1476909995.8356\n",
      "Epoch 6413/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1361966422.1683 - val_loss: 1476424227.6530\n",
      "Epoch 6414/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1361661384.0157 - val_loss: 1476065519.6347\n",
      "Epoch 6415/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 43us/step - loss: 1362544359.4521 - val_loss: 1477525216.7306\n",
      "Epoch 6416/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1362432471.4207 - val_loss: 1476857339.6164\n",
      "Epoch 6417/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1361395936.3131 - val_loss: 1475900087.5251\n",
      "Epoch 6418/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1361530242.2544 - val_loss: 1476836659.7260\n",
      "Epoch 6419/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1361532605.6204 - val_loss: 1476323211.1050\n",
      "Epoch 6420/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1361406915.8826 - val_loss: 1475699153.8265\n",
      "Epoch 6421/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1361376515.5068 - val_loss: 1475372484.6758\n",
      "Epoch 6422/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1361014665.0176 - val_loss: 1476125915.1781\n",
      "Epoch 6423/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1361785692.6810 - val_loss: 1476979666.1187\n",
      "Epoch 6424/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1360979507.4755 - val_loss: 1475644926.5388\n",
      "Epoch 6425/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1360815492.0078 - val_loss: 1475391362.6301\n",
      "Epoch 6426/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1360787425.4403 - val_loss: 1476029608.6210\n",
      "Epoch 6427/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1360892057.6751 - val_loss: 1474868616.1826\n",
      "Epoch 6428/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1360908472.3601 - val_loss: 1475023745.7534\n",
      "Epoch 6429/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1360718687.1859 - val_loss: 1475722768.6575\n",
      "Epoch 6430/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1361122828.3992 - val_loss: 1475825594.4475\n",
      "Epoch 6431/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1360569406.6223 - val_loss: 1475445328.6575\n",
      "Epoch 6432/15000\n",
      "1022/1022 [==============================] - 0s 82us/step - loss: 1360390263.9843 - val_loss: 1475243130.1553\n",
      "Epoch 6433/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1360221106.2231 - val_loss: 1474831711.5616\n",
      "Epoch 6434/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1361313865.1429 - val_loss: 1473124258.4840\n",
      "Epoch 6435/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1360193591.3581 - val_loss: 1475375199.5616\n",
      "Epoch 6436/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1360332556.2740 - val_loss: 1474464661.9178\n",
      "Epoch 6437/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1360283576.1096 - val_loss: 1473919129.7169\n",
      "Epoch 6438/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1359944952.7358 - val_loss: 1474650877.6621\n",
      "Epoch 6439/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1359856799.9374 - val_loss: 1474350717.0776\n",
      "Epoch 6440/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1360047111.0137 - val_loss: 1475521809.8265\n",
      "Epoch 6441/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1360175630.2779 - val_loss: 1474403793.2420\n",
      "Epoch 6442/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1360002504.6419 - val_loss: 1474846315.8356\n",
      "Epoch 6443/15000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1359965547.2094 - val_loss: 1473463642.8858\n",
      "Epoch 6444/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1360171710.8728 - val_loss: 1474571570.5571\n",
      "Epoch 6445/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1360019330.0039 - val_loss: 1474507669.0411\n",
      "Epoch 6446/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1359322416.3444 - val_loss: 1473933470.6849\n",
      "Epoch 6447/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1359663227.3659 - val_loss: 1472686700.1279\n",
      "Epoch 6448/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1359190532.0078 - val_loss: 1473608268.2740\n",
      "Epoch 6449/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1359593066.3327 - val_loss: 1473072549.9909\n",
      "Epoch 6450/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1359223247.7808 - val_loss: 1473959703.3790\n",
      "Epoch 6451/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1359401881.5499 - val_loss: 1474287813.5525\n",
      "Epoch 6452/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1359061909.0411 - val_loss: 1473841960.6210\n",
      "Epoch 6453/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1359288500.3523 - val_loss: 1474193580.1279\n",
      "Epoch 6454/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1359039354.3640 - val_loss: 1472565620.0183\n",
      "Epoch 6455/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1359164492.3992 - val_loss: 1472737806.3196\n",
      "Epoch 6456/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1358869476.0705 - val_loss: 1472702696.0365\n",
      "Epoch 6457/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1359278441.4560 - val_loss: 1473526034.4110\n",
      "Epoch 6458/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1359217663.7495 - val_loss: 1471765307.6164\n",
      "Epoch 6459/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1359555495.0763 - val_loss: 1474164445.5160\n",
      "Epoch 6460/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1358147286.7945 - val_loss: 1472676816.0731\n",
      "Epoch 6461/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1358509786.4266 - val_loss: 1471587254.3562\n",
      "Epoch 6462/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1358789080.2975 - val_loss: 1472274274.4840\n",
      "Epoch 6463/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1358395119.2172 - val_loss: 1472621680.2192\n",
      "Epoch 6464/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1358220244.1644 - val_loss: 1472161961.7900\n",
      "Epoch 6465/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1358285630.3718 - val_loss: 1472207288.1096\n",
      "Epoch 6466/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1358153875.6634 - val_loss: 1471912184.1096\n",
      "Epoch 6467/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1357945079.2329 - val_loss: 1471944964.0913\n",
      "Epoch 6468/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1357922650.9276 - val_loss: 1471763175.1598\n",
      "Epoch 6469/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1357992733.8082 - val_loss: 1471801508.2374\n",
      "Epoch 6470/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1358045052.8689 - val_loss: 1472641396.3105\n",
      "Epoch 6471/15000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1357798118.9511 - val_loss: 1472849210.7397\n",
      "Epoch 6472/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1357667548.1800 - val_loss: 1471177049.1324\n",
      "Epoch 6473/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1358122935.2329 - val_loss: 1470557084.9315\n",
      "Epoch 6474/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1357375575.4207 - val_loss: 1471673377.6073\n",
      "Epoch 6475/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1357368350.4344 - val_loss: 1472002683.0320\n",
      "Epoch 6476/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1357313500.4305 - val_loss: 1471491203.7991\n",
      "Epoch 6477/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1357532683.3346 - val_loss: 1471521672.7671\n",
      "Epoch 6478/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1357620471.4834 - val_loss: 1470412989.9543\n",
      "Epoch 6479/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 48us/step - loss: 1357349803.0841 - val_loss: 1470850123.1050\n",
      "Epoch 6480/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1357327643.3033 - val_loss: 1471457721.5708\n",
      "Epoch 6481/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1357377491.9139 - val_loss: 1471886841.5708\n",
      "Epoch 6482/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1356990507.7104 - val_loss: 1470954258.9954\n",
      "Epoch 6483/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1356825474.7554 - val_loss: 1470274624.2922\n",
      "Epoch 6484/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1356916857.4873 - val_loss: 1471015278.4658\n",
      "Epoch 6485/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1356789041.2524 - val_loss: 1470117061.5525\n",
      "Epoch 6486/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1357103477.7299 - val_loss: 1469813677.5890\n",
      "Epoch 6487/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1356493084.1800 - val_loss: 1470153019.3242\n",
      "Epoch 6488/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1356371194.7397 - val_loss: 1470182484.1644\n",
      "Epoch 6489/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1356503863.4834 - val_loss: 1469785369.4247\n",
      "Epoch 6490/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1356761980.3679 - val_loss: 1469405990.5753\n",
      "Epoch 6491/15000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1356446177.6908 - val_loss: 1470055254.2100\n",
      "Epoch 6492/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1356332833.3151 - val_loss: 1469503427.7991\n",
      "Epoch 6493/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1356132089.6125 - val_loss: 1469852567.0868\n",
      "Epoch 6494/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1356201283.8826 - val_loss: 1469353877.6256\n",
      "Epoch 6495/15000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1356476531.8513 - val_loss: 1470377825.3151\n",
      "Epoch 6496/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1356106162.8493 - val_loss: 1469481409.7534\n",
      "Epoch 6497/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1355877487.9687 - val_loss: 1469955031.0868\n",
      "Epoch 6498/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1356138739.3503 - val_loss: 1468773110.3562\n",
      "Epoch 6499/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1355722568.6419 - val_loss: 1468908335.0502\n",
      "Epoch 6500/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1356331368.2035 - val_loss: 1470320461.7352\n",
      "Epoch 6501/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1355583059.1624 - val_loss: 1469523866.0091\n",
      "Epoch 6502/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1356000309.1037 - val_loss: 1468971702.3562\n",
      "Epoch 6503/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1356112101.5734 - val_loss: 1467889249.0228\n",
      "Epoch 6504/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1355583061.1663 - val_loss: 1468076256.1461\n",
      "Epoch 6505/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1355189661.5577 - val_loss: 1468882520.5479\n",
      "Epoch 6506/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1355369639.5773 - val_loss: 1468690880.8767\n",
      "Epoch 6507/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1355320894.7476 - val_loss: 1468606322.8493\n",
      "Epoch 6508/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1355702967.3581 - val_loss: 1467007211.2511\n",
      "Epoch 6509/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1354966867.0372 - val_loss: 1469127043.2146\n",
      "Epoch 6510/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1354741463.5460 - val_loss: 1468590910.8311\n",
      "Epoch 6511/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1354984001.6282 - val_loss: 1469100674.6301\n",
      "Epoch 6512/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1354927299.5068 - val_loss: 1468016000.8767\n",
      "Epoch 6513/15000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1354663613.6204 - val_loss: 1468247460.8219\n",
      "Epoch 6514/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1355254555.9295 - val_loss: 1467294161.5342\n",
      "Epoch 6515/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1355546260.9159 - val_loss: 1468695145.4977\n",
      "Epoch 6516/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1354792581.7613 - val_loss: 1467789518.9041\n",
      "Epoch 6517/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1355408629.3542 - val_loss: 1466455812.9680\n",
      "Epoch 6518/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1354645087.3112 - val_loss: 1467815485.0776\n",
      "Epoch 6519/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1354106346.5832 - val_loss: 1467621565.6621\n",
      "Epoch 6520/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1354293833.3933 - val_loss: 1467487241.9361\n",
      "Epoch 6521/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1354075618.9432 - val_loss: 1466975800.4018\n",
      "Epoch 6522/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1353868062.5597 - val_loss: 1467199957.9178\n",
      "Epoch 6523/15000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1353913052.9315 - val_loss: 1467072926.9772\n",
      "Epoch 6524/15000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1354413169.0333 - val_loss: 1467120062.2466\n",
      "Epoch 6525/15000\n",
      "1022/1022 [==============================] - 0s 96us/step - loss: 1353870715.2407 - val_loss: 1466823820.2740\n",
      "Epoch 6526/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1354243626.8337 - val_loss: 1467108537.5708\n",
      "Epoch 6527/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1353766297.6751 - val_loss: 1466829601.0228\n",
      "Epoch 6528/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1353607732.1018 - val_loss: 1466535787.5434\n",
      "Epoch 6529/15000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1353633230.9041 - val_loss: 1466072887.2329\n",
      "Epoch 6530/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1353537319.5773 - val_loss: 1465837224.9132\n",
      "Epoch 6531/15000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1353913831.0137 - val_loss: 1465415042.6301\n",
      "Epoch 6532/15000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1353526747.8043 - val_loss: 1466157152.1461\n",
      "Epoch 6533/15000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1353702129.3464 - val_loss: 1466704069.5525\n",
      "Epoch 6534/15000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1353388820.7906 - val_loss: 1466496916.4566\n",
      "Epoch 6535/15000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1352947024.7828 - val_loss: 1465532190.9772\n",
      "Epoch 6536/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1352993616.9080 - val_loss: 1464832794.0091\n",
      "Epoch 6537/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1352771166.3092 - val_loss: 1465548705.0228\n",
      "Epoch 6538/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1352898558.9980 - val_loss: 1464983675.0320\n",
      "Epoch 6539/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1353307008.5010 - val_loss: 1465749439.4155\n",
      "Epoch 6540/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1352648500.8532 - val_loss: 1465505632.4384\n",
      "Epoch 6541/15000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1352452487.9530 - val_loss: 1465236183.9635\n",
      "Epoch 6542/15000\n",
      "1022/1022 [==============================] - 0s 66us/step - loss: 1352453360.9706 - val_loss: 1465098818.9224\n",
      "Epoch 6543/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 48us/step - loss: 1352560914.2857 - val_loss: 1465512421.6986\n",
      "Epoch 6544/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1352708055.9217 - val_loss: 1465437460.7489\n",
      "Epoch 6545/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1353537265.4716 - val_loss: 1463045481.2055\n",
      "Epoch 6546/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1352369794.3170 - val_loss: 1464057246.9772\n",
      "Epoch 6547/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1352327460.5714 - val_loss: 1465351016.9132\n",
      "Epoch 6548/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1352135225.9883 - val_loss: 1465014541.7352\n",
      "Epoch 6549/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1351893829.6360 - val_loss: 1464690350.1735\n",
      "Epoch 6550/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1351936804.0705 - val_loss: 1464387287.9635\n",
      "Epoch 6551/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1351971643.2407 - val_loss: 1464254245.6986\n",
      "Epoch 6552/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1351795063.8591 - val_loss: 1464335293.6621\n",
      "Epoch 6553/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1352114864.3444 - val_loss: 1465086767.3425\n",
      "Epoch 6554/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1353078890.5832 - val_loss: 1462871866.4475\n",
      "Epoch 6555/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1351406305.8160 - val_loss: 1464013301.1872\n",
      "Epoch 6556/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1351764566.1683 - val_loss: 1464797996.4201\n",
      "Epoch 6557/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1351380892.9315 - val_loss: 1463991386.0091\n",
      "Epoch 6558/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1351266898.2857 - val_loss: 1463764023.2329\n",
      "Epoch 6559/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1351124014.3405 - val_loss: 1463462136.4018\n",
      "Epoch 6560/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1351037407.0607 - val_loss: 1462918415.7808\n",
      "Epoch 6561/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1351053383.2642 - val_loss: 1462928862.3927\n",
      "Epoch 6562/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1350931746.0665 - val_loss: 1462796354.0457\n",
      "Epoch 6563/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1351052618.6458 - val_loss: 1463223380.1644\n",
      "Epoch 6564/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1350894318.7162 - val_loss: 1462629989.4064\n",
      "Epoch 6565/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1351089381.4481 - val_loss: 1462478978.3379\n",
      "Epoch 6566/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1350856016.5323 - val_loss: 1463018796.4201\n",
      "Epoch 6567/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1350669602.8180 - val_loss: 1463491560.9132\n",
      "Epoch 6568/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1350461946.9902 - val_loss: 1463256208.3653\n",
      "Epoch 6569/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1350622400.8767 - val_loss: 1463644553.9361\n",
      "Epoch 6570/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1350054618.4266 - val_loss: 1462755705.5708\n",
      "Epoch 6571/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1350348816.3444 - val_loss: 1462243048.9132\n",
      "Epoch 6572/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1350954946.1292 - val_loss: 1461359357.3699\n",
      "Epoch 6573/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1350250159.2172 - val_loss: 1461401619.5799\n",
      "Epoch 6574/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1350477548.2114 - val_loss: 1462252540.2009\n",
      "Epoch 6575/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1350015779.6947 - val_loss: 1461827268.3836\n",
      "Epoch 6576/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1349819779.3816 - val_loss: 1462178847.2694\n",
      "Epoch 6577/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1350315339.5225 - val_loss: 1461574901.1872\n",
      "Epoch 6578/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1349819589.2603 - val_loss: 1461798854.7215\n",
      "Epoch 6579/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1349707809.6908 - val_loss: 1461523709.0776\n",
      "Epoch 6580/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1349736139.1468 - val_loss: 1462182379.2511\n",
      "Epoch 6581/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1351166189.0881 - val_loss: 1460275152.0731\n",
      "Epoch 6582/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1350445405.4325 - val_loss: 1462294130.5571\n",
      "Epoch 6583/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1349778804.9785 - val_loss: 1461344789.9178\n",
      "Epoch 6584/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1349237410.3170 - val_loss: 1461431231.1233\n",
      "Epoch 6585/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1349587959.7339 - val_loss: 1460592424.9132\n",
      "Epoch 6586/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1349365857.7534 - val_loss: 1460028515.6530\n",
      "Epoch 6587/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1348919302.0117 - val_loss: 1460347044.5297\n",
      "Epoch 6588/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1349345166.5284 - val_loss: 1461638200.9863\n",
      "Epoch 6589/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1349467254.7319 - val_loss: 1461938869.4795\n",
      "Epoch 6590/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1349696326.8885 - val_loss: 1459974972.7854\n",
      "Epoch 6591/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1348626612.7280 - val_loss: 1460082824.1826\n",
      "Epoch 6592/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1348815882.2701 - val_loss: 1459639417.5708\n",
      "Epoch 6593/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1348512159.0607 - val_loss: 1459853957.8447\n",
      "Epoch 6594/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1349088501.8552 - val_loss: 1460320736.4384\n",
      "Epoch 6595/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1348336651.2720 - val_loss: 1459623740.4932\n",
      "Epoch 6596/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1348269720.5479 - val_loss: 1460264734.6849\n",
      "Epoch 6597/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1348453041.2211 - val_loss: 1459308929.1689\n",
      "Epoch 6598/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1348247161.6125 - val_loss: 1459044330.6667\n",
      "Epoch 6599/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1348704821.1037 - val_loss: 1460372185.4247\n",
      "Epoch 6600/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1348267708.8689 - val_loss: 1460190056.0365\n",
      "Epoch 6601/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1347815462.8258 - val_loss: 1459100583.7443\n",
      "Epoch 6602/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1348036623.5303 - val_loss: 1459417650.2648\n",
      "Epoch 6603/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1347775439.0920 - val_loss: 1459298411.5434\n",
      "Epoch 6604/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1347590879.4364 - val_loss: 1458984259.7991\n",
      "Epoch 6605/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1347582268.0548 - val_loss: 1458341165.8813\n",
      "Epoch 6606/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1347489134.4658 - val_loss: 1458444639.8539\n",
      "Epoch 6607/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 33us/step - loss: 1347719081.8317 - val_loss: 1457467098.8858\n",
      "Epoch 6608/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1349069867.5851 - val_loss: 1459049760.7306\n",
      "Epoch 6609/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1347478738.9119 - val_loss: 1458773189.5525\n",
      "Epoch 6610/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1347246810.6771 - val_loss: 1459054336.2922\n",
      "Epoch 6611/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1346887064.9237 - val_loss: 1458566935.6712\n",
      "Epoch 6612/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1347640939.9609 - val_loss: 1457246796.2740\n",
      "Epoch 6613/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1347571914.6458 - val_loss: 1458608480.1461\n",
      "Epoch 6614/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1346802684.9315 - val_loss: 1458108751.1963\n",
      "Epoch 6615/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1346790828.0861 - val_loss: 1457840496.5114\n",
      "Epoch 6616/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1346980009.5812 - val_loss: 1457046199.8174\n",
      "Epoch 6617/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1347311343.4677 - val_loss: 1458776404.4566\n",
      "Epoch 6618/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1346959055.6556 - val_loss: 1457394896.0731\n",
      "Epoch 6619/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1346858565.1350 - val_loss: 1458629355.5434\n",
      "Epoch 6620/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1346656232.5166 - val_loss: 1458226076.3470\n",
      "Epoch 6621/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1346419987.5382 - val_loss: 1457790611.5799\n",
      "Epoch 6622/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1346515927.6712 - val_loss: 1456162071.6712\n",
      "Epoch 6623/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1347009392.5949 - val_loss: 1457583846.2831\n",
      "Epoch 6624/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1346408742.0744 - val_loss: 1457079371.9817\n",
      "Epoch 6625/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1345950832.2192 - val_loss: 1456328028.3470\n",
      "Epoch 6626/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1346404444.1800 - val_loss: 1455359053.4429\n",
      "Epoch 6627/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1347073872.9080 - val_loss: 1458077783.9635\n",
      "Epoch 6628/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1345692282.8023 - val_loss: 1456548390.2831\n",
      "Epoch 6629/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1345564842.8963 - val_loss: 1456531507.7260\n",
      "Epoch 6630/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1346119327.0607 - val_loss: 1457486395.9087\n",
      "Epoch 6631/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1346602169.7378 - val_loss: 1456383729.0959\n",
      "Epoch 6632/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1345791611.9922 - val_loss: 1456041138.5571\n",
      "Epoch 6633/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1345546377.6438 - val_loss: 1456656290.4840\n",
      "Epoch 6634/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1345311312.0313 - val_loss: 1455502249.2055\n",
      "Epoch 6635/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1345885352.8297 - val_loss: 1455328857.7169\n",
      "Epoch 6636/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1346358188.7123 - val_loss: 1454522039.2329\n",
      "Epoch 6637/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1344730283.6477 - val_loss: 1455744860.3470\n",
      "Epoch 6638/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1345307579.4286 - val_loss: 1454887524.8219\n",
      "Epoch 6639/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1345075285.2916 - val_loss: 1455663736.4018\n",
      "Epoch 6640/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1345070773.9804 - val_loss: 1456732840.0365\n",
      "Epoch 6641/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1344807760.1566 - val_loss: 1455283290.5936\n",
      "Epoch 6642/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1344842433.5029 - val_loss: 1454841449.2055\n",
      "Epoch 6643/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1344591256.0470 - val_loss: 1455831368.4749\n",
      "Epoch 6644/15000\n",
      "1022/1022 [==============================] - 0s 78us/step - loss: 1344737440.9393 - val_loss: 1455299050.6667\n",
      "Epoch 6645/15000\n",
      "1022/1022 [==============================] - 0s 71us/step - loss: 1344508254.6849 - val_loss: 1455769680.0731\n",
      "Epoch 6646/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1344251308.5871 - val_loss: 1454673483.6895\n",
      "Epoch 6647/15000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1344401233.7847 - val_loss: 1454940710.2831\n",
      "Epoch 6648/15000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1344894385.7221 - val_loss: 1455245515.1050\n",
      "Epoch 6649/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1344387788.3992 - val_loss: 1453264962.6301\n",
      "Epoch 6650/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1343889432.2975 - val_loss: 1454371247.3425\n",
      "Epoch 6651/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1344030905.8630 - val_loss: 1453616726.2100\n",
      "Epoch 6652/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1343976033.6908 - val_loss: 1454639286.9406\n",
      "Epoch 6653/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1343810673.2211 - val_loss: 1453725789.2237\n",
      "Epoch 6654/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1343763798.6067 - val_loss: 1453417377.8995\n",
      "Epoch 6655/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1343831924.4775 - val_loss: 1453537552.0731\n",
      "Epoch 6656/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1344274829.2759 - val_loss: 1455213796.2374\n",
      "Epoch 6657/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1343219927.1703 - val_loss: 1454478304.1461\n",
      "Epoch 6658/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1343256219.6164 - val_loss: 1453177621.3333\n",
      "Epoch 6659/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1343518373.8239 - val_loss: 1453637445.8447\n",
      "Epoch 6660/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1343229098.3327 - val_loss: 1454191303.0137\n",
      "Epoch 6661/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1343414069.1037 - val_loss: 1452034086.5753\n",
      "Epoch 6662/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1343163119.4677 - val_loss: 1453172891.4703\n",
      "Epoch 6663/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1343225634.4423 - val_loss: 1453839515.1781\n",
      "Epoch 6664/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1343402489.3620 - val_loss: 1453123603.8721\n",
      "Epoch 6665/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1342633907.8513 - val_loss: 1452690351.0502\n",
      "Epoch 6666/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1342815942.3875 - val_loss: 1451950556.9315\n",
      "Epoch 6667/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1342678333.3699 - val_loss: 1452351951.7808\n",
      "Epoch 6668/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1342694194.8493 - val_loss: 1452937102.9041\n",
      "Epoch 6669/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1342405599.6869 - val_loss: 1452531273.6438\n",
      "Epoch 6670/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1342207260.0548 - val_loss: 1452278310.2831\n",
      "Epoch 6671/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1342511337.9569 - val_loss: 1452436993.1689\n",
      "Epoch 6672/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1342376906.9589 - val_loss: 1452157719.3790\n",
      "Epoch 6673/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1342306849.6908 - val_loss: 1451880443.9087\n",
      "Epoch 6674/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1342204780.9628 - val_loss: 1451243525.2603\n",
      "Epoch 6675/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1342272493.4638 - val_loss: 1451223256.8402\n",
      "Epoch 6676/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1341835073.7534 - val_loss: 1451598348.8584\n",
      "Epoch 6677/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1342245640.2661 - val_loss: 1452144916.1644\n",
      "Epoch 6678/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1341636436.1644 - val_loss: 1451289776.2192\n",
      "Epoch 6679/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1342183368.7671 - val_loss: 1450033173.3333\n",
      "Epoch 6680/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1341442142.6849 - val_loss: 1450949619.7260\n",
      "Epoch 6681/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1341418322.6614 - val_loss: 1451742476.2740\n",
      "Epoch 6682/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1341322261.6673 - val_loss: 1451606021.2603\n",
      "Epoch 6683/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1341773594.1761 - val_loss: 1450561715.1416\n",
      "Epoch 6684/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1341158534.1996 - val_loss: 1450690496.0000\n",
      "Epoch 6685/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1340973528.2975 - val_loss: 1450510082.6301\n",
      "Epoch 6686/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1341104046.3405 - val_loss: 1450655099.9087\n",
      "Epoch 6687/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1341401442.6928 - val_loss: 1449605871.3425\n",
      "Epoch 6688/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1341055438.8415 - val_loss: 1449690457.1324\n",
      "Epoch 6689/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1340829350.3249 - val_loss: 1450912974.9041\n",
      "Epoch 6690/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1340543251.1624 - val_loss: 1450816947.7260\n",
      "Epoch 6691/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1340639095.7339 - val_loss: 1449945238.7945\n",
      "Epoch 6692/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1340662209.6282 - val_loss: 1449476233.6438\n",
      "Epoch 6693/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1340347027.6634 - val_loss: 1449613435.9087\n",
      "Epoch 6694/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1340281424.7202 - val_loss: 1449766920.4749\n",
      "Epoch 6695/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1340436662.3562 - val_loss: 1449122063.4886\n",
      "Epoch 6696/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1340575946.3953 - val_loss: 1449143413.7717\n",
      "Epoch 6697/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1340103887.4051 - val_loss: 1449640919.6712\n",
      "Epoch 6698/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1340138029.9648 - val_loss: 1449161521.0959\n",
      "Epoch 6699/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1339928880.8454 - val_loss: 1449335263.5616\n",
      "Epoch 6700/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1339719023.8434 - val_loss: 1449730296.1096\n",
      "Epoch 6701/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1339621435.3659 - val_loss: 1449294424.2557\n",
      "Epoch 6702/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1339828846.9667 - val_loss: 1449470728.1826\n",
      "Epoch 6703/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1339711732.4775 - val_loss: 1449223589.6986\n",
      "Epoch 6704/15000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1339414080.3757 - val_loss: 1449268098.3379\n",
      "Epoch 6705/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1340214572.5871 - val_loss: 1446879659.5434\n",
      "Epoch 6706/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1339191653.6986 - val_loss: 1448662125.0046\n",
      "Epoch 6707/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1339464328.1409 - val_loss: 1448050305.7534\n",
      "Epoch 6708/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1339148092.6184 - val_loss: 1448503035.3242\n",
      "Epoch 6709/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1340458822.3875 - val_loss: 1449406750.1005\n",
      "Epoch 6710/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1338878428.0548 - val_loss: 1448027366.5753\n",
      "Epoch 6711/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1339106133.1663 - val_loss: 1447824292.5297\n",
      "Epoch 6712/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1338943098.3014 - val_loss: 1447333026.4840\n",
      "Epoch 6713/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1339092901.4481 - val_loss: 1448289131.8356\n",
      "Epoch 6714/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1338842951.6399 - val_loss: 1446729144.4018\n",
      "Epoch 6715/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1338848932.1957 - val_loss: 1447183611.0320\n",
      "Epoch 6716/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1338499286.6693 - val_loss: 1447123810.1918\n",
      "Epoch 6717/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1338655926.3562 - val_loss: 1446685325.1507\n",
      "Epoch 6718/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1338242772.2896 - val_loss: 1446973242.7397\n",
      "Epoch 6719/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1338275483.4286 - val_loss: 1446439641.1324\n",
      "Epoch 6720/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1338491943.0763 - val_loss: 1447154713.4247\n",
      "Epoch 6721/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1338045733.1977 - val_loss: 1446858962.1187\n",
      "Epoch 6722/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1338530010.1135 - val_loss: 1446369227.9817\n",
      "Epoch 6723/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1338106285.0881 - val_loss: 1446680612.2374\n",
      "Epoch 6724/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1338490445.9022 - val_loss: 1447239394.1918\n",
      "Epoch 6725/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1337860521.5812 - val_loss: 1446878864.0731\n",
      "Epoch 6726/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1337512394.8963 - val_loss: 1445956852.6027\n",
      "Epoch 6727/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1337460731.4912 - val_loss: 1446028590.7580\n",
      "Epoch 6728/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1337465903.1546 - val_loss: 1445744716.2740\n",
      "Epoch 6729/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1337450512.2818 - val_loss: 1446399152.8037\n",
      "Epoch 6730/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1337464552.3914 - val_loss: 1445761868.2740\n",
      "Epoch 6731/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1337259348.2896 - val_loss: 1446389180.7854\n",
      "Epoch 6732/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1337214198.7319 - val_loss: 1446004145.6804\n",
      "Epoch 6733/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1337186242.1292 - val_loss: 1445579653.2603\n",
      "Epoch 6734/15000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1336957241.3620 - val_loss: 1444745373.5160\n",
      "Epoch 6735/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 35us/step - loss: 1336844508.5558 - val_loss: 1444909961.0594\n",
      "Epoch 6736/15000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1337021152.5636 - val_loss: 1444692694.5023\n",
      "Epoch 6737/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1336827745.4403 - val_loss: 1445370521.4247\n",
      "Epoch 6738/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1337119405.8395 - val_loss: 1445871558.1370\n",
      "Epoch 6739/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1336847168.6262 - val_loss: 1443464594.1187\n",
      "Epoch 6740/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1336781051.9922 - val_loss: 1444844287.7078\n",
      "Epoch 6741/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1336770595.1937 - val_loss: 1444673467.6164\n",
      "Epoch 6742/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1336668214.9198 - val_loss: 1443492434.9954\n",
      "Epoch 6743/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1336388315.6791 - val_loss: 1444916507.1781\n",
      "Epoch 6744/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1336443703.6086 - val_loss: 1443219235.6530\n",
      "Epoch 6745/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1335903629.4638 - val_loss: 1444131812.2374\n",
      "Epoch 6746/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1336049065.3307 - val_loss: 1444145635.3607\n",
      "Epoch 6747/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1336279463.3268 - val_loss: 1444160243.7260\n",
      "Epoch 6748/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1335670478.2153 - val_loss: 1443426853.4064\n",
      "Epoch 6749/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1335848444.2427 - val_loss: 1444296072.7671\n",
      "Epoch 6750/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1335989151.9374 - val_loss: 1444137982.2466\n",
      "Epoch 6751/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1336330350.2779 - val_loss: 1443525426.8493\n",
      "Epoch 6752/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1335870917.5108 - val_loss: 1442631254.7945\n",
      "Epoch 6753/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1335618121.3933 - val_loss: 1443828577.3151\n",
      "Epoch 6754/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1335291441.0959 - val_loss: 1442970777.4247\n",
      "Epoch 6755/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1335303060.9159 - val_loss: 1442686348.5662\n",
      "Epoch 6756/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1334979198.1213 - val_loss: 1442811384.6941\n",
      "Epoch 6757/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1335137895.2016 - val_loss: 1443173451.6895\n",
      "Epoch 6758/15000\n",
      "1022/1022 [==============================] - 0s 66us/step - loss: 1334845375.8748 - val_loss: 1442448338.4110\n",
      "Epoch 6759/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1334803220.4149 - val_loss: 1441817227.1050\n",
      "Epoch 6760/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1334809798.6380 - val_loss: 1442605859.6530\n",
      "Epoch 6761/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1334656505.4247 - val_loss: 1442554659.6530\n",
      "Epoch 6762/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1335006229.5421 - val_loss: 1442585652.8950\n",
      "Epoch 6763/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1334709609.7065 - val_loss: 1441191497.6438\n",
      "Epoch 6764/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1334771515.3659 - val_loss: 1440791849.7900\n",
      "Epoch 6765/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1334998278.1996 - val_loss: 1442176356.2374\n",
      "Epoch 6766/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1334515828.2270 - val_loss: 1441396575.5616\n",
      "Epoch 6767/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1334106509.0881 - val_loss: 1441728193.1689\n",
      "Epoch 6768/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1334218962.9119 - val_loss: 1441129216.0000\n",
      "Epoch 6769/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1334214632.9550 - val_loss: 1441536785.5342\n",
      "Epoch 6770/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1334221928.2035 - val_loss: 1441969828.5297\n",
      "Epoch 6771/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1333677863.0763 - val_loss: 1441270123.8356\n",
      "Epoch 6772/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1333697238.9824 - val_loss: 1440636336.8037\n",
      "Epoch 6773/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1333730056.7671 - val_loss: 1440775639.0868\n",
      "Epoch 6774/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1333622379.7104 - val_loss: 1441090220.1279\n",
      "Epoch 6775/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1333456131.6321 - val_loss: 1440335933.0776\n",
      "Epoch 6776/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1333204712.9550 - val_loss: 1440463403.2511\n",
      "Epoch 6777/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1333186951.8904 - val_loss: 1440628965.4064\n",
      "Epoch 6778/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1333193173.0411 - val_loss: 1440405348.8219\n",
      "Epoch 6779/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1333524996.1331 - val_loss: 1439292423.0137\n",
      "Epoch 6780/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1334145795.8826 - val_loss: 1440292048.9498\n",
      "Epoch 6781/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1332874782.0587 - val_loss: 1440086523.6164\n",
      "Epoch 6782/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1332765611.1468 - val_loss: 1439737840.8037\n",
      "Epoch 6783/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1333060587.4599 - val_loss: 1439145667.5068\n",
      "Epoch 6784/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1333165396.9159 - val_loss: 1439669107.4338\n",
      "Epoch 6785/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1332706334.0587 - val_loss: 1439511030.3562\n",
      "Epoch 6786/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1332714019.9452 - val_loss: 1439457197.2968\n",
      "Epoch 6787/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1332307199.2485 - val_loss: 1438982745.7169\n",
      "Epoch 6788/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1332930489.7378 - val_loss: 1438583070.6849\n",
      "Epoch 6789/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1332361087.2485 - val_loss: 1439063578.5936\n",
      "Epoch 6790/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1333139167.4364 - val_loss: 1437037400.8402\n",
      "Epoch 6791/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1332020498.5362 - val_loss: 1438449546.2283\n",
      "Epoch 6792/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1332440702.2466 - val_loss: 1438396391.4521\n",
      "Epoch 6793/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1332059387.3973 - val_loss: 1438438534.7215\n",
      "Epoch 6794/15000\n",
      "1022/1022 [==============================] - 0s 69us/step - loss: 1331829589.2916 - val_loss: 1439296201.9361\n",
      "Epoch 6795/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1333576205.7769 - val_loss: 1436620238.9041\n",
      "Epoch 6796/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1331636403.6008 - val_loss: 1438704452.0913\n",
      "Epoch 6797/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1331660628.0391 - val_loss: 1438164688.9498\n",
      "Epoch 6798/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1332871462.9511 - val_loss: 1438891755.5434\n",
      "Epoch 6799/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 31us/step - loss: 1331319102.1213 - val_loss: 1438080085.0411\n",
      "Epoch 6800/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1331667686.9511 - val_loss: 1438407858.5571\n",
      "Epoch 6801/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1331509973.9178 - val_loss: 1437578175.1233\n",
      "Epoch 6802/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1331510522.6145 - val_loss: 1437376893.9543\n",
      "Epoch 6803/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1331123869.5577 - val_loss: 1437550072.1096\n",
      "Epoch 6804/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1331154127.9061 - val_loss: 1437334332.7854\n",
      "Epoch 6805/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1331067345.4090 - val_loss: 1437138355.7260\n",
      "Epoch 6806/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1330786611.7260 - val_loss: 1436712298.6667\n",
      "Epoch 6807/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1330728243.9765 - val_loss: 1436858458.8858\n",
      "Epoch 6808/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1330780793.9883 - val_loss: 1437226378.5205\n",
      "Epoch 6809/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1331105953.0646 - val_loss: 1435574764.1279\n",
      "Epoch 6810/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1330772888.5479 - val_loss: 1436746157.8813\n",
      "Epoch 6811/15000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1330952464.1566 - val_loss: 1435512641.4612\n",
      "Epoch 6812/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1330114740.3523 - val_loss: 1436145352.4749\n",
      "Epoch 6813/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1330531565.3386 - val_loss: 1437333564.2009\n",
      "Epoch 6814/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1330051977.5186 - val_loss: 1436287382.5023\n",
      "Epoch 6815/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1330139242.9589 - val_loss: 1435677602.1918\n",
      "Epoch 6816/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1330524661.2290 - val_loss: 1437263750.7215\n",
      "Epoch 6817/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1330518958.8415 - val_loss: 1434922206.9772\n",
      "Epoch 6818/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1330219785.5186 - val_loss: 1436548514.1918\n",
      "Epoch 6819/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1329761395.4755 - val_loss: 1435737244.6393\n",
      "Epoch 6820/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1329912255.3738 - val_loss: 1436001031.8904\n",
      "Epoch 6821/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1329483460.0078 - val_loss: 1435291521.7534\n",
      "Epoch 6822/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1329592442.8650 - val_loss: 1434676685.4429\n",
      "Epoch 6823/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1329383450.0509 - val_loss: 1435114539.5434\n",
      "Epoch 6824/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1329385863.5147 - val_loss: 1434917813.4795\n",
      "Epoch 6825/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1329910864.9080 - val_loss: 1434823655.4521\n",
      "Epoch 6826/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1329194642.1605 - val_loss: 1434922787.9452\n",
      "Epoch 6827/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1329419287.5460 - val_loss: 1435399470.7580\n",
      "Epoch 6828/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1329176962.8806 - val_loss: 1434676862.5388\n",
      "Epoch 6829/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1328803166.9354 - val_loss: 1434612188.9315\n",
      "Epoch 6830/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1328879896.0470 - val_loss: 1434322476.4201\n",
      "Epoch 6831/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1328771337.0176 - val_loss: 1434438098.7032\n",
      "Epoch 6832/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1328598270.8728 - val_loss: 1433618501.2603\n",
      "Epoch 6833/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1328465583.8434 - val_loss: 1433895598.4658\n",
      "Epoch 6834/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1328546742.7319 - val_loss: 1434278536.1826\n",
      "Epoch 6835/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1328683014.7632 - val_loss: 1433603396.3836\n",
      "Epoch 6836/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1328723278.4031 - val_loss: 1434262369.3151\n",
      "Epoch 6837/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1328408619.4599 - val_loss: 1432986626.3379\n",
      "Epoch 6838/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1328683713.1272 - val_loss: 1433550039.9635\n",
      "Epoch 6839/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1328788829.1820 - val_loss: 1433047062.2100\n",
      "Epoch 6840/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1328189473.9413 - val_loss: 1433053241.2785\n",
      "Epoch 6841/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1328182467.3816 - val_loss: 1433936767.7078\n",
      "Epoch 6842/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1329021929.4560 - val_loss: 1431573252.9680\n",
      "Epoch 6843/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1327622595.6321 - val_loss: 1432349250.3379\n",
      "Epoch 6844/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1328020647.3268 - val_loss: 1431355252.3105\n",
      "Epoch 6845/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1328221748.1018 - val_loss: 1433265915.0320\n",
      "Epoch 6846/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1327764678.3875 - val_loss: 1433008425.7900\n",
      "Epoch 6847/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1327416702.4971 - val_loss: 1432480642.9224\n",
      "Epoch 6848/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1327623139.7573 - val_loss: 1432147885.0046\n",
      "Epoch 6849/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1327227094.9198 - val_loss: 1432224874.3744\n",
      "Epoch 6850/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1327207246.4031 - val_loss: 1431494600.7671\n",
      "Epoch 6851/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1327018733.4638 - val_loss: 1431935546.4475\n",
      "Epoch 6852/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1327106646.4188 - val_loss: 1431451419.7626\n",
      "Epoch 6853/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1326757125.0098 - val_loss: 1432042871.2329\n",
      "Epoch 6854/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1326816945.5342 - val_loss: 1431855003.7626\n",
      "Epoch 6855/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1326705281.7534 - val_loss: 1431266088.3288\n",
      "Epoch 6856/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1326535207.2016 - val_loss: 1431079819.3973\n",
      "Epoch 6857/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1326584418.8180 - val_loss: 1431263782.2831\n",
      "Epoch 6858/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1326496897.5656 - val_loss: 1431593443.9452\n",
      "Epoch 6859/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1326767941.0098 - val_loss: 1430636519.4521\n",
      "Epoch 6860/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1326655126.7945 - val_loss: 1430292436.7489\n",
      "Epoch 6861/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1326621949.9961 - val_loss: 1431863825.2420\n",
      "Epoch 6862/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1326281535.6243 - val_loss: 1430814169.1324\n",
      "Epoch 6863/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1326504556.5871 - val_loss: 1429815912.6210\n",
      "Epoch 6864/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1326561266.9119 - val_loss: 1430769157.8447\n",
      "Epoch 6865/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1325854954.7084 - val_loss: 1429845813.4795\n",
      "Epoch 6866/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1325793820.5558 - val_loss: 1430245163.2511\n",
      "Epoch 6867/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1326169704.8297 - val_loss: 1430176785.2420\n",
      "Epoch 6868/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1325849821.9335 - val_loss: 1429405883.9087\n",
      "Epoch 6869/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1325396053.4168 - val_loss: 1429563853.4429\n",
      "Epoch 6870/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1325709238.8571 - val_loss: 1428807087.6347\n",
      "Epoch 6871/15000\n",
      "1022/1022 [==============================] - 0s 67us/step - loss: 1325352527.2172 - val_loss: 1428771317.7717\n",
      "Epoch 6872/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1325548872.8924 - val_loss: 1429326073.8630\n",
      "Epoch 6873/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1325821458.3483 - val_loss: 1430369776.5114\n",
      "Epoch 6874/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1325095870.1213 - val_loss: 1429794557.3699\n",
      "Epoch 6875/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1324857104.2818 - val_loss: 1428963581.3699\n",
      "Epoch 6876/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1325051834.9902 - val_loss: 1429059507.1416\n",
      "Epoch 6877/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1325109446.0117 - val_loss: 1429375322.8858\n",
      "Epoch 6878/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1325121988.2583 - val_loss: 1428228096.5845\n",
      "Epoch 6879/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1324609418.7710 - val_loss: 1428402313.3516\n",
      "Epoch 6880/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1324492220.2427 - val_loss: 1428242084.5297\n",
      "Epoch 6881/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1324785263.0920 - val_loss: 1428131421.5160\n",
      "Epoch 6882/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1324414607.7182 - val_loss: 1427933173.4795\n",
      "Epoch 6883/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1324589699.5068 - val_loss: 1428415868.7854\n",
      "Epoch 6884/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1324442864.3444 - val_loss: 1428096672.1461\n",
      "Epoch 6885/15000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1324451396.6341 - val_loss: 1427611565.5890\n",
      "Epoch 6886/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1325558870.0431 - val_loss: 1426020476.7854\n",
      "Epoch 6887/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1323833123.0685 - val_loss: 1427161620.4566\n",
      "Epoch 6888/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1323935497.2681 - val_loss: 1427527500.2740\n",
      "Epoch 6889/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1324322018.9432 - val_loss: 1427254633.2055\n",
      "Epoch 6890/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1323791969.1898 - val_loss: 1426897515.2511\n",
      "Epoch 6891/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1323964731.6164 - val_loss: 1426535925.1872\n",
      "Epoch 6892/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1323705073.7221 - val_loss: 1427547750.2831\n",
      "Epoch 6893/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1324062415.6556 - val_loss: 1426575882.8128\n",
      "Epoch 6894/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1323963240.7045 - val_loss: 1428467991.3790\n",
      "Epoch 6895/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1323399112.3914 - val_loss: 1427117856.4384\n",
      "Epoch 6896/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1323265998.4031 - val_loss: 1426900662.0639\n",
      "Epoch 6897/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1323553685.7926 - val_loss: 1425715098.3014\n",
      "Epoch 6898/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1323056375.3581 - val_loss: 1426815358.2466\n",
      "Epoch 6899/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1323221816.3601 - val_loss: 1426276680.7671\n",
      "Epoch 6900/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1323364410.4892 - val_loss: 1426640387.7991\n",
      "Epoch 6901/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1322930111.1233 - val_loss: 1426134657.1689\n",
      "Epoch 6902/15000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1322830283.8982 - val_loss: 1426601766.8676\n",
      "Epoch 6903/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1323992328.3914 - val_loss: 1424421550.1735\n",
      "Epoch 6904/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1322526304.1879 - val_loss: 1425416772.3836\n",
      "Epoch 6905/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1322669319.7652 - val_loss: 1425086153.9361\n",
      "Epoch 6906/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1322450475.5851 - val_loss: 1425020098.3379\n",
      "Epoch 6907/15000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1322354198.2935 - val_loss: 1425626559.4155\n",
      "Epoch 6908/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1322398138.1761 - val_loss: 1425492921.2785\n",
      "Epoch 6909/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1322213264.5323 - val_loss: 1425449683.8721\n",
      "Epoch 6910/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1322250290.8493 - val_loss: 1425176929.8995\n",
      "Epoch 6911/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1321965023.3112 - val_loss: 1424766977.4612\n",
      "Epoch 6912/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1321989815.1076 - val_loss: 1424186199.6712\n",
      "Epoch 6913/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1321964028.6184 - val_loss: 1424234626.0457\n",
      "Epoch 6914/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1321764178.5362 - val_loss: 1424702751.2694\n",
      "Epoch 6915/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1321936774.4501 - val_loss: 1425108256.7306\n",
      "Epoch 6916/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1321797274.8023 - val_loss: 1423480186.7397\n",
      "Epoch 6917/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1321849922.0039 - val_loss: 1424590404.3836\n",
      "Epoch 6918/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1322238857.8943 - val_loss: 1422760788.4566\n",
      "Epoch 6919/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1321323311.8434 - val_loss: 1424203896.4018\n",
      "Epoch 6920/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1321373110.1057 - val_loss: 1423393328.2192\n",
      "Epoch 6921/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1321295855.2798 - val_loss: 1423087969.8995\n",
      "Epoch 6922/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1321452071.3268 - val_loss: 1423933143.9635\n",
      "Epoch 6923/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1322081400.3601 - val_loss: 1422129872.9498\n",
      "Epoch 6924/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1321149756.6184 - val_loss: 1424280532.7489\n",
      "Epoch 6925/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1321135953.1585 - val_loss: 1423894288.0731\n",
      "Epoch 6926/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1321162979.3190 - val_loss: 1423052468.8950\n",
      "Epoch 6927/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 53us/step - loss: 1320900055.7965 - val_loss: 1423468044.5662\n",
      "Epoch 6928/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1320626514.9119 - val_loss: 1423238103.6712\n",
      "Epoch 6929/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1320702960.4697 - val_loss: 1422390913.1689\n",
      "Epoch 6930/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1320446464.2505 - val_loss: 1422373255.3059\n",
      "Epoch 6931/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1320898287.4677 - val_loss: 1423906010.3014\n",
      "Epoch 6932/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1320635882.7084 - val_loss: 1422663796.6027\n",
      "Epoch 6933/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1320713663.7495 - val_loss: 1422971535.1963\n",
      "Epoch 6934/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1320207342.9667 - val_loss: 1422053674.9589\n",
      "Epoch 6935/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1320161973.7299 - val_loss: 1421396888.2557\n",
      "Epoch 6936/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1320256450.1292 - val_loss: 1420734329.8630\n",
      "Epoch 6937/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1319974367.1859 - val_loss: 1421805909.6256\n",
      "Epoch 6938/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1319840539.0528 - val_loss: 1421819758.1735\n",
      "Epoch 6939/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1320286576.9706 - val_loss: 1421124634.0091\n",
      "Epoch 6940/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1319736082.7867 - val_loss: 1421456885.7717\n",
      "Epoch 6941/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1319887068.5558 - val_loss: 1421506259.8721\n",
      "Epoch 6942/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1319689437.1820 - val_loss: 1421825449.7900\n",
      "Epoch 6943/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1319506424.8611 - val_loss: 1420863833.1324\n",
      "Epoch 6944/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1319539294.4971 - val_loss: 1421777456.8037\n",
      "Epoch 6945/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1319666107.3659 - val_loss: 1421457815.9635\n",
      "Epoch 6946/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1319293868.2114 - val_loss: 1421338664.3288\n",
      "Epoch 6947/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1319719507.2877 - val_loss: 1421340432.6575\n",
      "Epoch 6948/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1318868871.2642 - val_loss: 1420656825.5708\n",
      "Epoch 6949/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1319001057.6908 - val_loss: 1419644022.9406\n",
      "Epoch 6950/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1319245739.0841 - val_loss: 1420782226.1187\n",
      "Epoch 6951/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1318928266.3953 - val_loss: 1419710691.6530\n",
      "Epoch 6952/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1319051183.8434 - val_loss: 1420110882.7763\n",
      "Epoch 6953/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1319152302.5910 - val_loss: 1420238214.4292\n",
      "Epoch 6954/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1318624880.4697 - val_loss: 1419607924.8950\n",
      "Epoch 6955/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1318803865.5499 - val_loss: 1419509096.6210\n",
      "Epoch 6956/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1318452375.7965 - val_loss: 1418888070.4292\n",
      "Epoch 6957/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1318285333.9178 - val_loss: 1418869479.1598\n",
      "Epoch 6958/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1318466181.8865 - val_loss: 1419058047.1233\n",
      "Epoch 6959/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1318357332.5401 - val_loss: 1419699270.4292\n",
      "Epoch 6960/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1318322569.2681 - val_loss: 1419063131.1781\n",
      "Epoch 6961/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1317944910.7789 - val_loss: 1419305388.1279\n",
      "Epoch 6962/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1318177426.5362 - val_loss: 1419526468.9680\n",
      "Epoch 6963/15000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1318038536.2661 - val_loss: 1418074438.4292\n",
      "Epoch 6964/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1317877018.0509 - val_loss: 1418246959.9269\n",
      "Epoch 6965/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1318242980.4462 - val_loss: 1417849071.9269\n",
      "Epoch 6966/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1317557253.0098 - val_loss: 1419112826.4475\n",
      "Epoch 6967/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1318158444.7123 - val_loss: 1419578545.0959\n",
      "Epoch 6968/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1317450280.3288 - val_loss: 1418870642.8493\n",
      "Epoch 6969/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1317861262.2779 - val_loss: 1417330426.4475\n",
      "Epoch 6970/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1317392696.3601 - val_loss: 1418159762.1187\n",
      "Epoch 6971/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1317103088.4697 - val_loss: 1417788214.6484\n",
      "Epoch 6972/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1317248587.9609 - val_loss: 1418385092.0913\n",
      "Epoch 6973/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1317166642.7241 - val_loss: 1417286369.6073\n",
      "Epoch 6974/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1317166320.7202 - val_loss: 1417428618.2283\n",
      "Epoch 6975/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1317108270.0900 - val_loss: 1416640450.9224\n",
      "Epoch 6976/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1316967051.5225 - val_loss: 1417695040.8767\n",
      "Epoch 6977/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1317162766.5284 - val_loss: 1416476310.7945\n",
      "Epoch 6978/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1316735898.4266 - val_loss: 1417710409.9361\n",
      "Epoch 6979/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1316610291.3503 - val_loss: 1417250689.1689\n",
      "Epoch 6980/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1316713706.4579 - val_loss: 1416169734.1370\n",
      "Epoch 6981/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1316755013.1350 - val_loss: 1417914165.1872\n",
      "Epoch 6982/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1316577316.6967 - val_loss: 1417369704.6210\n",
      "Epoch 6983/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1316232097.0646 - val_loss: 1416530271.8539\n",
      "Epoch 6984/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1316249590.3562 - val_loss: 1416404380.3470\n",
      "Epoch 6985/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1316375910.9511 - val_loss: 1415149549.8813\n",
      "Epoch 6986/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1316035499.3346 - val_loss: 1415420472.4018\n",
      "Epoch 6987/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1316062009.2368 - val_loss: 1415471226.7397\n",
      "Epoch 6988/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1316079618.8806 - val_loss: 1415703438.6119\n",
      "Epoch 6989/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1316157650.5362 - val_loss: 1417014808.8402\n",
      "Epoch 6990/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1316023291.8043 - val_loss: 1416156648.6210\n",
      "Epoch 6991/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 27us/step - loss: 1315974731.3346 - val_loss: 1416040335.7808\n",
      "Epoch 6992/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1315678966.9824 - val_loss: 1415629292.4201\n",
      "Epoch 6993/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1315677883.1155 - val_loss: 1415436385.0228\n",
      "Epoch 6994/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1315696705.8787 - val_loss: 1414794333.2237\n",
      "Epoch 6995/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1315431350.3562 - val_loss: 1415516850.8493\n",
      "Epoch 6996/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1315793574.8258 - val_loss: 1416396853.1872\n",
      "Epoch 6997/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1315498930.2231 - val_loss: 1414100577.3151\n",
      "Epoch 6998/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1315250490.6145 - val_loss: 1414766857.0594\n",
      "Epoch 6999/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1315327601.5969 - val_loss: 1415136561.0959\n",
      "Epoch 7000/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1314990100.9785 - val_loss: 1414338470.5753\n",
      "Epoch 7001/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1315614411.3346 - val_loss: 1413440304.8037\n",
      "Epoch 7002/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1314993731.8826 - val_loss: 1414563022.0274\n",
      "Epoch 7003/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1314989126.3875 - val_loss: 1415044207.0502\n",
      "Epoch 7004/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1315543432.7671 - val_loss: 1413507589.8447\n",
      "Epoch 7005/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1314995872.0626 - val_loss: 1414781013.6256\n",
      "Epoch 7006/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1314815734.2309 - val_loss: 1414104950.0639\n",
      "Epoch 7007/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1314724697.1115 - val_loss: 1413997454.9041\n",
      "Epoch 7008/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1315007171.1311 - val_loss: 1415221456.9498\n",
      "Epoch 7009/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1314523969.7534 - val_loss: 1412953720.1096\n",
      "Epoch 7010/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1314292986.6145 - val_loss: 1413702897.6804\n",
      "Epoch 7011/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1314185637.0724 - val_loss: 1413032625.3881\n",
      "Epoch 7012/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1314479801.2368 - val_loss: 1413451515.3242\n",
      "Epoch 7013/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1315571402.8963 - val_loss: 1414704313.8630\n",
      "Epoch 7014/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1314883477.4795 - val_loss: 1411970892.5662\n",
      "Epoch 7015/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1313889524.9785 - val_loss: 1412609422.3196\n",
      "Epoch 7016/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1313869721.2994 - val_loss: 1412581319.0137\n",
      "Epoch 7017/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1314438958.5910 - val_loss: 1413346445.4429\n",
      "Epoch 7018/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1313805850.3014 - val_loss: 1412861527.3790\n",
      "Epoch 7019/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1314931707.6164 - val_loss: 1411500300.2740\n",
      "Epoch 7020/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1313675260.4932 - val_loss: 1412637158.2831\n",
      "Epoch 7021/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1313856634.3640 - val_loss: 1411195544.2557\n",
      "Epoch 7022/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1314561358.2779 - val_loss: 1413353443.0685\n",
      "Epoch 7023/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1313348816.0313 - val_loss: 1411680266.2283\n",
      "Epoch 7024/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1313148814.4031 - val_loss: 1411554754.0457\n",
      "Epoch 7025/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1313741890.8180 - val_loss: 1410705420.5662\n",
      "Epoch 7026/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1313604980.1018 - val_loss: 1412210564.9680\n",
      "Epoch 7027/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1313409420.5245 - val_loss: 1410911144.3288\n",
      "Epoch 7028/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1312930893.4012 - val_loss: 1411586005.0411\n",
      "Epoch 7029/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1313558339.3816 - val_loss: 1411692287.4155\n",
      "Epoch 7030/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1313065998.4031 - val_loss: 1411384976.3653\n",
      "Epoch 7031/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1312994362.8650 - val_loss: 1410589367.2329\n",
      "Epoch 7032/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1313337013.2290 - val_loss: 1411207943.3059\n",
      "Epoch 7033/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1312576200.6419 - val_loss: 1411037245.6621\n",
      "Epoch 7034/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1312502414.0274 - val_loss: 1410380503.9635\n",
      "Epoch 7035/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1312765839.2798 - val_loss: 1410472095.8539\n",
      "Epoch 7036/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1312609333.4168 - val_loss: 1411225318.5753\n",
      "Epoch 7037/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1312306413.5890 - val_loss: 1409987509.4795\n",
      "Epoch 7038/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1312538855.6399 - val_loss: 1410033209.5708\n",
      "Epoch 7039/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1312418042.3640 - val_loss: 1410065969.9726\n",
      "Epoch 7040/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1312005830.3875 - val_loss: 1410157451.6895\n",
      "Epoch 7041/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1311888776.6419 - val_loss: 1409843197.0776\n",
      "Epoch 7042/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1312295881.7065 - val_loss: 1409197625.5708\n",
      "Epoch 7043/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1311907431.3268 - val_loss: 1410255793.6804\n",
      "Epoch 7044/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1312228121.1742 - val_loss: 1409023627.6895\n",
      "Epoch 7045/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1311603886.2153 - val_loss: 1409338440.1826\n",
      "Epoch 7046/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1311568605.0568 - val_loss: 1409268047.4886\n",
      "Epoch 7047/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1311641275.2407 - val_loss: 1409929469.3699\n",
      "Epoch 7048/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1311547583.1859 - val_loss: 1409349216.4384\n",
      "Epoch 7049/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1311473288.3914 - val_loss: 1409331305.7900\n",
      "Epoch 7050/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1311381475.3190 - val_loss: 1408817891.3607\n",
      "Epoch 7051/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1311345292.7750 - val_loss: 1409204649.7900\n",
      "Epoch 7052/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1311448288.9393 - val_loss: 1409407003.4703\n",
      "Epoch 7053/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1311498504.8924 - val_loss: 1408829820.4932\n",
      "Epoch 7054/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1311105786.7397 - val_loss: 1408665019.0320\n",
      "Epoch 7055/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1311158636.5245 - val_loss: 1408784719.7808\n",
      "Epoch 7056/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1311347938.1918 - val_loss: 1408078697.4977\n",
      "Epoch 7057/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1311354327.4207 - val_loss: 1407252968.3288\n",
      "Epoch 7058/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1311127536.9706 - val_loss: 1407944989.8082\n",
      "Epoch 7059/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1311024653.9022 - val_loss: 1407872678.8676\n",
      "Epoch 7060/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1310922450.7241 - val_loss: 1407835837.3699\n",
      "Epoch 7061/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1310810999.7339 - val_loss: 1408206819.0685\n",
      "Epoch 7062/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1310940638.4344 - val_loss: 1406592338.1187\n",
      "Epoch 7063/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1311080222.5597 - val_loss: 1408226087.7443\n",
      "Epoch 7064/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1310261566.8728 - val_loss: 1407388102.7215\n",
      "Epoch 7065/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1310310058.7084 - val_loss: 1407636697.4247\n",
      "Epoch 7066/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1310739199.2485 - val_loss: 1406816227.3607\n",
      "Epoch 7067/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1310328873.5812 - val_loss: 1407805177.8630\n",
      "Epoch 7068/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1309948477.8708 - val_loss: 1406748878.9041\n",
      "Epoch 7069/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1310194453.9178 - val_loss: 1407543115.1050\n",
      "Epoch 7070/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1310889605.0098 - val_loss: 1406364395.2511\n",
      "Epoch 7071/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1309878243.6947 - val_loss: 1406589109.4795\n",
      "Epoch 7072/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1309998198.3562 - val_loss: 1406559065.4247\n",
      "Epoch 7073/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1310006540.9002 - val_loss: 1406116582.5753\n",
      "Epoch 7074/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1309954347.0841 - val_loss: 1406376035.0685\n",
      "Epoch 7075/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1309564407.4834 - val_loss: 1405281370.3014\n",
      "Epoch 7076/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1309477286.3249 - val_loss: 1405871199.5616\n",
      "Epoch 7077/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1310329908.9785 - val_loss: 1405762098.5571\n",
      "Epoch 7078/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1309452011.4599 - val_loss: 1406171761.6804\n",
      "Epoch 7079/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1309402807.6086 - val_loss: 1405635912.1826\n",
      "Epoch 7080/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1309314190.5284 - val_loss: 1405147361.6073\n",
      "Epoch 7081/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1309542323.8513 - val_loss: 1404749258.8128\n",
      "Epoch 7082/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1309067092.4149 - val_loss: 1404990295.6712\n",
      "Epoch 7083/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1309404327.5773 - val_loss: 1405181446.4292\n",
      "Epoch 7084/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1308992267.8982 - val_loss: 1405126363.1781\n",
      "Epoch 7085/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1309667709.6204 - val_loss: 1406227632.5114\n",
      "Epoch 7086/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1308691470.0274 - val_loss: 1404886602.5205\n",
      "Epoch 7087/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1309168605.6830 - val_loss: 1403739298.7763\n",
      "Epoch 7088/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1309108342.4814 - val_loss: 1405042469.4064\n",
      "Epoch 7089/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1308879710.5597 - val_loss: 1403799291.3242\n",
      "Epoch 7090/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1308553707.9609 - val_loss: 1404862210.9224\n",
      "Epoch 7091/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1308608664.2975 - val_loss: 1404733408.7306\n",
      "Epoch 7092/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1308849123.6947 - val_loss: 1404311466.6667\n",
      "Epoch 7093/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1308525756.3679 - val_loss: 1403717420.4201\n",
      "Epoch 7094/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1308276384.6888 - val_loss: 1404256279.0868\n",
      "Epoch 7095/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1308471204.5714 - val_loss: 1403810721.6073\n",
      "Epoch 7096/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1308717511.6399 - val_loss: 1403354828.8584\n",
      "Epoch 7097/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1308841451.4599 - val_loss: 1404996486.1370\n",
      "Epoch 7098/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1308197284.5714 - val_loss: 1403200092.0548\n",
      "Epoch 7099/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1308420996.8845 - val_loss: 1402890135.9635\n",
      "Epoch 7100/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1307922083.6947 - val_loss: 1402746399.2694\n",
      "Epoch 7101/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1309374545.2838 - val_loss: 1405025494.5023\n",
      "Epoch 7102/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1307968272.2818 - val_loss: 1402511627.9817\n",
      "Epoch 7103/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1307898410.5832 - val_loss: 1403039611.9087\n",
      "Epoch 7104/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1307623784.9550 - val_loss: 1403570709.0411\n",
      "Epoch 7105/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1307650754.8806 - val_loss: 1402200992.4384\n",
      "Epoch 7106/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1307513469.3699 - val_loss: 1402733129.6438\n",
      "Epoch 7107/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1307398533.7613 - val_loss: 1403202751.4155\n",
      "Epoch 7108/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1307428749.9022 - val_loss: 1402596835.6530\n",
      "Epoch 7109/15000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1307466369.3777 - val_loss: 1402278814.9772\n",
      "Epoch 7110/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1307804857.3620 - val_loss: 1402576151.0868\n",
      "Epoch 7111/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1307239565.2759 - val_loss: 1401646098.1187\n",
      "Epoch 7112/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1307209575.2016 - val_loss: 1402277968.9498\n",
      "Epoch 7113/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1307037225.4560 - val_loss: 1401761357.1507\n",
      "Epoch 7114/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1307183679.4990 - val_loss: 1401277247.1233\n",
      "Epoch 7115/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1307528377.2368 - val_loss: 1401911811.5068\n",
      "Epoch 7116/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1306992342.4188 - val_loss: 1401574752.1461\n",
      "Epoch 7117/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1306766204.2427 - val_loss: 1401665979.0320\n",
      "Epoch 7118/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1306707480.7984 - val_loss: 1401850451.2877\n",
      "Epoch 7119/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 31us/step - loss: 1307425742.6536 - val_loss: 1399930951.3059\n",
      "Epoch 7120/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1306662587.1781 - val_loss: 1400192518.7215\n",
      "Epoch 7121/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1307007054.4031 - val_loss: 1402043508.6027\n",
      "Epoch 7122/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1306553909.9804 - val_loss: 1401252982.0639\n",
      "Epoch 7123/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1306886150.5127 - val_loss: 1401463436.8584\n",
      "Epoch 7124/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1306529314.0665 - val_loss: 1401704135.8904\n",
      "Epoch 7125/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1306294656.5010 - val_loss: 1400966907.6164\n",
      "Epoch 7126/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1307093576.7671 - val_loss: 1401684469.7717\n",
      "Epoch 7127/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1306069349.3229 - val_loss: 1401010499.5068\n",
      "Epoch 7128/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1306061755.6164 - val_loss: 1400675396.9680\n",
      "Epoch 7129/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1305996226.3796 - val_loss: 1400687664.2192\n",
      "Epoch 7130/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1306214401.8787 - val_loss: 1400322516.7489\n",
      "Epoch 7131/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1305931223.9217 - val_loss: 1398653317.2603\n",
      "Epoch 7132/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1305704067.2564 - val_loss: 1398714398.9772\n",
      "Epoch 7133/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1306615679.3738 - val_loss: 1400697835.8356\n",
      "Epoch 7134/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1305476954.6771 - val_loss: 1400005207.9635\n",
      "Epoch 7135/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1305792136.0157 - val_loss: 1400120749.2968\n",
      "Epoch 7136/15000\n",
      "1022/1022 [==============================] - 0s 68us/step - loss: 1305872013.4638 - val_loss: 1398522520.2557\n",
      "Epoch 7137/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1305328068.3836 - val_loss: 1399212273.6804\n",
      "Epoch 7138/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1305816007.3894 - val_loss: 1398760393.3516\n",
      "Epoch 7139/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1305489971.7260 - val_loss: 1399853412.5297\n",
      "Epoch 7140/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1305457274.3640 - val_loss: 1398961934.0274\n",
      "Epoch 7141/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1305294780.1174 - val_loss: 1399837037.8813\n",
      "Epoch 7142/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1305049903.8434 - val_loss: 1398752032.7306\n",
      "Epoch 7143/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1305297689.6751 - val_loss: 1398104655.1963\n",
      "Epoch 7144/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1305146518.2935 - val_loss: 1397597774.6119\n",
      "Epoch 7145/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1305357088.4384 - val_loss: 1399160856.5479\n",
      "Epoch 7146/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1304789498.2387 - val_loss: 1398935057.2420\n",
      "Epoch 7147/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1304721082.2387 - val_loss: 1398564088.9863\n",
      "Epoch 7148/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1304651389.2446 - val_loss: 1398659362.7763\n",
      "Epoch 7149/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1305067106.0039 - val_loss: 1397278826.0822\n",
      "Epoch 7150/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1304808403.1624 - val_loss: 1398524170.8128\n",
      "Epoch 7151/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1304647894.4188 - val_loss: 1397844104.7671\n",
      "Epoch 7152/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1304801985.6282 - val_loss: 1398468707.9452\n",
      "Epoch 7153/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1304879353.1115 - val_loss: 1396929211.9087\n",
      "Epoch 7154/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1304454639.7182 - val_loss: 1396954687.7078\n",
      "Epoch 7155/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1304549931.0841 - val_loss: 1398127530.6667\n",
      "Epoch 7156/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1305084342.0431 - val_loss: 1396375751.5982\n",
      "Epoch 7157/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1304403876.8219 - val_loss: 1397339371.2511\n",
      "Epoch 7158/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1304098350.1526 - val_loss: 1396771480.5479\n",
      "Epoch 7159/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1304165806.5910 - val_loss: 1396725808.8037\n",
      "Epoch 7160/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1304156214.6067 - val_loss: 1396993211.3242\n",
      "Epoch 7161/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1304157893.1350 - val_loss: 1397150240.4384\n",
      "Epoch 7162/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1304988541.3699 - val_loss: 1397709147.1781\n",
      "Epoch 7163/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1303773327.4051 - val_loss: 1397334393.2785\n",
      "Epoch 7164/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1304253191.6399 - val_loss: 1396565250.0457\n",
      "Epoch 7165/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1303629020.1800 - val_loss: 1396001301.6256\n",
      "Epoch 7166/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1303862623.0607 - val_loss: 1396213168.5114\n",
      "Epoch 7167/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1303416868.5714 - val_loss: 1396223909.1142\n",
      "Epoch 7168/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1303662214.6380 - val_loss: 1396709055.1233\n",
      "Epoch 7169/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1303546913.3151 - val_loss: 1395700114.7032\n",
      "Epoch 7170/15000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1304041487.4051 - val_loss: 1396679814.7215\n",
      "Epoch 7171/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1303483239.2016 - val_loss: 1396469924.5297\n",
      "Epoch 7172/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1303333178.7397 - val_loss: 1396178461.2237\n",
      "Epoch 7173/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1303610111.2485 - val_loss: 1396046667.6895\n",
      "Epoch 7174/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1303177764.3209 - val_loss: 1395686853.8447\n",
      "Epoch 7175/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1302979295.8748 - val_loss: 1395298143.2694\n",
      "Epoch 7176/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1303796209.9100 - val_loss: 1394626865.3881\n",
      "Epoch 7177/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1303001808.9080 - val_loss: 1394879879.0137\n",
      "Epoch 7178/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1303314658.2544 - val_loss: 1395224502.3562\n",
      "Epoch 7179/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1303192936.0783 - val_loss: 1395690222.4658\n",
      "Epoch 7180/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1302757090.5675 - val_loss: 1395023281.3881\n",
      "Epoch 7181/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1303212448.4384 - val_loss: 1395460915.7260\n",
      "Epoch 7182/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1302694814.1840 - val_loss: 1394704693.4795\n",
      "Epoch 7183/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 39us/step - loss: 1302501219.0685 - val_loss: 1394857288.1826\n",
      "Epoch 7184/15000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1302617382.1996 - val_loss: 1393893314.6301\n",
      "Epoch 7185/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1302396970.8337 - val_loss: 1394214779.6164\n",
      "Epoch 7186/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1302372474.6145 - val_loss: 1394761470.2466\n",
      "Epoch 7187/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1302338250.2074 - val_loss: 1395019267.7991\n",
      "Epoch 7188/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1302178126.5284 - val_loss: 1394458598.2831\n",
      "Epoch 7189/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1302351924.7280 - val_loss: 1393009919.7078\n",
      "Epoch 7190/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1302312735.5616 - val_loss: 1393356629.9178\n",
      "Epoch 7191/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1302093807.7182 - val_loss: 1393483378.5571\n",
      "Epoch 7192/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1302370106.8650 - val_loss: 1394637010.1187\n",
      "Epoch 7193/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1302062165.5421 - val_loss: 1394457928.4749\n",
      "Epoch 7194/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1302162668.9628 - val_loss: 1393000316.7854\n",
      "Epoch 7195/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1302381656.5479 - val_loss: 1394696582.1370\n",
      "Epoch 7196/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1301684233.3307 - val_loss: 1393436831.5616\n",
      "Epoch 7197/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1301699049.7065 - val_loss: 1393068882.1187\n",
      "Epoch 7198/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1301725344.6888 - val_loss: 1393674050.0457\n",
      "Epoch 7199/15000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1301501140.9159 - val_loss: 1393279844.8219\n",
      "Epoch 7200/15000\n",
      "1022/1022 [==============================] - 0s 72us/step - loss: 1302220684.0235 - val_loss: 1394356871.0137\n",
      "Epoch 7201/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1301366450.6614 - val_loss: 1392300628.7489\n",
      "Epoch 7202/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1301373942.8571 - val_loss: 1392545485.7352\n",
      "Epoch 7203/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1301501953.0020 - val_loss: 1392682474.3744\n",
      "Epoch 7204/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1301245845.5421 - val_loss: 1392266985.7900\n",
      "Epoch 7205/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1301293774.7789 - val_loss: 1392434290.5571\n",
      "Epoch 7206/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1301371056.2192 - val_loss: 1391253037.5890\n",
      "Epoch 7207/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1301162986.9589 - val_loss: 1392184829.6621\n",
      "Epoch 7208/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1301400780.9002 - val_loss: 1392212861.0776\n",
      "Epoch 7209/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1301912708.9472 - val_loss: 1390937618.9954\n",
      "Epoch 7210/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1300932571.4912 - val_loss: 1392738146.1918\n",
      "Epoch 7211/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1301094283.1468 - val_loss: 1392678076.4932\n",
      "Epoch 7212/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1300861005.5264 - val_loss: 1391907364.2374\n",
      "Epoch 7213/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1300814508.3366 - val_loss: 1392374148.6758\n",
      "Epoch 7214/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1300830625.6908 - val_loss: 1391780778.9589\n",
      "Epoch 7215/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1300780050.9119 - val_loss: 1390683999.5616\n",
      "Epoch 7216/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1301104658.0352 - val_loss: 1391626944.8767\n",
      "Epoch 7217/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1300699462.1370 - val_loss: 1390283537.2420\n",
      "Epoch 7218/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1300679591.3268 - val_loss: 1390484150.3562\n",
      "Epoch 7219/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1300633305.1742 - val_loss: 1391883520.5845\n",
      "Epoch 7220/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1300460009.9569 - val_loss: 1391181065.6438\n",
      "Epoch 7221/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1300696938.3327 - val_loss: 1391300747.9817\n",
      "Epoch 7222/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1300196902.0744 - val_loss: 1390922294.6484\n",
      "Epoch 7223/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1300350112.0626 - val_loss: 1391694701.5890\n",
      "Epoch 7224/15000\n",
      "1022/1022 [==============================] - 0s 70us/step - loss: 1300094617.4247 - val_loss: 1391206903.5251\n",
      "Epoch 7225/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1300122951.3894 - val_loss: 1390194065.2420\n",
      "Epoch 7226/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1299940503.7965 - val_loss: 1390568292.2374\n",
      "Epoch 7227/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1300096333.4012 - val_loss: 1389880649.9361\n",
      "Epoch 7228/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1299811516.1174 - val_loss: 1390169317.4064\n",
      "Epoch 7229/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1299906587.8043 - val_loss: 1390130185.0594\n",
      "Epoch 7230/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1299725738.0822 - val_loss: 1389431319.0868\n",
      "Epoch 7231/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1300280722.1605 - val_loss: 1388727529.2055\n",
      "Epoch 7232/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1299546075.1781 - val_loss: 1389933794.7763\n",
      "Epoch 7233/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1299724393.0802 - val_loss: 1390543898.0091\n",
      "Epoch 7234/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1299673392.9706 - val_loss: 1389797765.8447\n",
      "Epoch 7235/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1299545180.8063 - val_loss: 1389360741.6986\n",
      "Epoch 7236/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1299362848.8767 - val_loss: 1389629441.1689\n",
      "Epoch 7237/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1299527632.9080 - val_loss: 1388699018.5205\n",
      "Epoch 7238/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1299937293.7769 - val_loss: 1389625588.3105\n",
      "Epoch 7239/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1299232122.2387 - val_loss: 1388996216.6941\n",
      "Epoch 7240/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1299287681.6282 - val_loss: 1389370733.0046\n",
      "Epoch 7241/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1299170098.9746 - val_loss: 1388947476.1644\n",
      "Epoch 7242/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1299234149.1977 - val_loss: 1388004445.8082\n",
      "Epoch 7243/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1299461185.8787 - val_loss: 1389455360.0000\n",
      "Epoch 7244/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1299111949.6517 - val_loss: 1388574125.2968\n",
      "Epoch 7245/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1299024026.0509 - val_loss: 1388118068.6027\n",
      "Epoch 7246/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1299291232.0626 - val_loss: 1389273152.5845\n",
      "Epoch 7247/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1299006244.5714 - val_loss: 1388019636.8950\n",
      "Epoch 7248/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1298603828.6027 - val_loss: 1388299696.2192\n",
      "Epoch 7249/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1299275282.2857 - val_loss: 1389657890.7763\n",
      "Epoch 7250/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1298666953.8943 - val_loss: 1388405253.2603\n",
      "Epoch 7251/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1298468529.3464 - val_loss: 1388389640.1826\n",
      "Epoch 7252/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1298696712.8924 - val_loss: 1387571666.4110\n",
      "Epoch 7253/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1298499549.1820 - val_loss: 1388401924.6758\n",
      "Epoch 7254/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1298595779.7573 - val_loss: 1387297153.1689\n",
      "Epoch 7255/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1298853893.5108 - val_loss: 1388956949.3333\n",
      "Epoch 7256/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1298318406.7632 - val_loss: 1387304515.5068\n",
      "Epoch 7257/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1299087209.7065 - val_loss: 1389188054.7945\n",
      "Epoch 7258/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1298219265.8787 - val_loss: 1386913262.4658\n",
      "Epoch 7259/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1298101903.2798 - val_loss: 1386993196.4201\n",
      "Epoch 7260/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1298151848.3288 - val_loss: 1386738448.9498\n",
      "Epoch 7261/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1298036633.5499 - val_loss: 1387460482.9224\n",
      "Epoch 7262/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1298078137.8630 - val_loss: 1387525263.4886\n",
      "Epoch 7263/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1298343101.3699 - val_loss: 1388205571.7991\n",
      "Epoch 7264/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1297827537.1585 - val_loss: 1386522868.6027\n",
      "Epoch 7265/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1298137591.4834 - val_loss: 1388022461.9543\n",
      "Epoch 7266/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1298000277.7926 - val_loss: 1385378983.7443\n",
      "Epoch 7267/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1298163925.5421 - val_loss: 1386909390.6119\n",
      "Epoch 7268/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1297647040.8767 - val_loss: 1386847648.7306\n",
      "Epoch 7269/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1297818816.8141 - val_loss: 1386618642.4110\n",
      "Epoch 7270/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1297668931.2564 - val_loss: 1385474405.1142\n",
      "Epoch 7271/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1297334448.3444 - val_loss: 1386169795.2146\n",
      "Epoch 7272/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1297542713.8630 - val_loss: 1385173652.7489\n",
      "Epoch 7273/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1297445066.3327 - val_loss: 1386189886.2466\n",
      "Epoch 7274/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1297265192.3288 - val_loss: 1386351848.6210\n",
      "Epoch 7275/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1297210339.0685 - val_loss: 1385789323.9817\n",
      "Epoch 7276/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1297199528.0783 - val_loss: 1385800536.5479\n",
      "Epoch 7277/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1297510244.1957 - val_loss: 1386387045.4064\n",
      "Epoch 7278/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1297122798.5910 - val_loss: 1385727106.0457\n",
      "Epoch 7279/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1297317324.1487 - val_loss: 1384949236.3105\n",
      "Epoch 7280/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1296894899.8513 - val_loss: 1385139012.3836\n",
      "Epoch 7281/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1297036220.7436 - val_loss: 1384364102.4292\n",
      "Epoch 7282/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1297580915.7260 - val_loss: 1385216054.3562\n",
      "Epoch 7283/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1296725606.9511 - val_loss: 1385023622.4292\n",
      "Epoch 7284/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1297327983.2172 - val_loss: 1386432010.5205\n",
      "Epoch 7285/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1296949598.5597 - val_loss: 1385670352.9498\n",
      "Epoch 7286/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1297096863.3738 - val_loss: 1385119343.0502\n",
      "Epoch 7287/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1296931645.3072 - val_loss: 1383715516.4932\n",
      "Epoch 7288/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1297162063.4051 - val_loss: 1382600852.1644\n",
      "Epoch 7289/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1297075467.7730 - val_loss: 1385474404.2374\n",
      "Epoch 7290/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1297354133.9178 - val_loss: 1384437039.3425\n",
      "Epoch 7291/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1296679649.3151 - val_loss: 1383682954.5205\n",
      "Epoch 7292/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1296518319.7182 - val_loss: 1384892838.2831\n",
      "Epoch 7293/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1296333408.5636 - val_loss: 1383917020.3470\n",
      "Epoch 7294/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1296294915.8826 - val_loss: 1384601088.8767\n",
      "Epoch 7295/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1296037081.8004 - val_loss: 1383959998.5388\n",
      "Epoch 7296/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1296329579.5851 - val_loss: 1383858782.3927\n",
      "Epoch 7297/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1296155617.3151 - val_loss: 1383625976.6941\n",
      "Epoch 7298/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1295977039.7808 - val_loss: 1383466447.7808\n",
      "Epoch 7299/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1296172068.0705 - val_loss: 1383877703.3059\n",
      "Epoch 7300/15000\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 1296270320.2818 - val_loss: 1384353136.8037\n",
      "Epoch 7301/15000\n",
      "1022/1022 [==============================] - 0s 87us/step - loss: 1296286739.9139 - val_loss: 1384115212.8584\n",
      "Epoch 7302/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1296221056.6262 - val_loss: 1382790149.8447\n",
      "Epoch 7303/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1295720909.9022 - val_loss: 1383729559.6712\n",
      "Epoch 7304/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1295805590.5440 - val_loss: 1382826702.9041\n",
      "Epoch 7305/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1295579798.7945 - val_loss: 1382636216.9863\n",
      "Epoch 7306/15000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1295566415.7808 - val_loss: 1382182596.9680\n",
      "Epoch 7307/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1296339305.5186 - val_loss: 1383307669.3333\n",
      "Epoch 7308/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1295739943.8278 - val_loss: 1383750917.2603\n",
      "Epoch 7309/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1295802378.6458 - val_loss: 1382886846.5388\n",
      "Epoch 7310/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1295501836.7750 - val_loss: 1382774234.3014\n",
      "Epoch 7311/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 28us/step - loss: 1295606499.9452 - val_loss: 1383122063.1963\n",
      "Epoch 7312/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1295329429.7926 - val_loss: 1381445555.4338\n",
      "Epoch 7313/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1295311006.4971 - val_loss: 1381529042.7032\n",
      "Epoch 7314/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1295348787.7260 - val_loss: 1381249076.0183\n",
      "Epoch 7315/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1295041927.8904 - val_loss: 1381966599.0137\n",
      "Epoch 7316/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1295325118.9980 - val_loss: 1380873899.8356\n",
      "Epoch 7317/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1295020752.6575 - val_loss: 1381437066.5205\n",
      "Epoch 7318/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1294928609.8160 - val_loss: 1381877433.8630\n",
      "Epoch 7319/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1294953159.3894 - val_loss: 1381195432.3288\n",
      "Epoch 7320/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1295414791.0137 - val_loss: 1383541252.9680\n",
      "Epoch 7321/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1294605425.4716 - val_loss: 1382545488.6575\n",
      "Epoch 7322/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1294946600.4540 - val_loss: 1381582661.2603\n",
      "Epoch 7323/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1294796426.7710 - val_loss: 1380469926.2831\n",
      "Epoch 7324/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1294513798.6380 - val_loss: 1380969837.8813\n",
      "Epoch 7325/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1294456637.2446 - val_loss: 1380945857.1689\n",
      "Epoch 7326/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1294626074.3014 - val_loss: 1381302693.1142\n",
      "Epoch 7327/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1294589243.1155 - val_loss: 1381224016.3653\n",
      "Epoch 7328/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1294666379.3973 - val_loss: 1381660988.4932\n",
      "Epoch 7329/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1294466668.2114 - val_loss: 1380010359.2329\n",
      "Epoch 7330/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1294247040.6888 - val_loss: 1380779230.9772\n",
      "Epoch 7331/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1294325362.2231 - val_loss: 1380818935.8174\n",
      "Epoch 7332/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1294347932.5558 - val_loss: 1381488913.5342\n",
      "Epoch 7333/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1294003513.2368 - val_loss: 1380821710.6119\n",
      "Epoch 7334/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1294389486.9667 - val_loss: 1380739540.7489\n",
      "Epoch 7335/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1294369063.2016 - val_loss: 1379488978.9954\n",
      "Epoch 7336/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1294282777.9256 - val_loss: 1379462903.8174\n",
      "Epoch 7337/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1294052819.1624 - val_loss: 1379216296.0365\n",
      "Epoch 7338/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1294841861.6360 - val_loss: 1381508845.0046\n",
      "Epoch 7339/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1294203258.9902 - val_loss: 1380036520.3288\n",
      "Epoch 7340/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1294148640.3131 - val_loss: 1378914472.6210\n",
      "Epoch 7341/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1293380621.5264 - val_loss: 1379828100.6758\n",
      "Epoch 7342/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1293577161.8943 - val_loss: 1379735550.5388\n",
      "Epoch 7343/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1294752295.7025 - val_loss: 1380812373.6256\n",
      "Epoch 7344/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1293547012.7593 - val_loss: 1379987168.4384\n",
      "Epoch 7345/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1293389168.8454 - val_loss: 1379763355.7626\n",
      "Epoch 7346/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1293630375.3268 - val_loss: 1378989734.5753\n",
      "Epoch 7347/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1293761905.2211 - val_loss: 1380319050.5205\n",
      "Epoch 7348/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1293338026.3327 - val_loss: 1379571444.3105\n",
      "Epoch 7349/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1293552458.8963 - val_loss: 1379396498.7032\n",
      "Epoch 7350/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1293604332.9628 - val_loss: 1379324660.0183\n",
      "Epoch 7351/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1293157189.6360 - val_loss: 1379390968.1096\n",
      "Epoch 7352/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1293399994.6145 - val_loss: 1379535281.6804\n",
      "Epoch 7353/15000\n",
      "1022/1022 [==============================] - 0s 77us/step - loss: 1293308107.7730 - val_loss: 1377821359.0502\n",
      "Epoch 7354/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1292865349.6360 - val_loss: 1378357239.5251\n",
      "Epoch 7355/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1293023725.2133 - val_loss: 1377924939.6895\n",
      "Epoch 7356/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1293155951.4677 - val_loss: 1379169108.1644\n",
      "Epoch 7357/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1293062248.2035 - val_loss: 1378424870.5753\n",
      "Epoch 7358/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1293042417.9726 - val_loss: 1378400355.0685\n",
      "Epoch 7359/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1292776671.6869 - val_loss: 1377972247.0868\n",
      "Epoch 7360/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1292689153.0020 - val_loss: 1378806468.0913\n",
      "Epoch 7361/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1292880544.5636 - val_loss: 1377441729.1689\n",
      "Epoch 7362/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1292701565.4951 - val_loss: 1378600747.5434\n",
      "Epoch 7363/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1292606878.8102 - val_loss: 1378125359.6347\n",
      "Epoch 7364/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1292501178.1761 - val_loss: 1377838305.0228\n",
      "Epoch 7365/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1292737897.5812 - val_loss: 1378808779.3973\n",
      "Epoch 7366/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1292925023.6869 - val_loss: 1376957529.1324\n",
      "Epoch 7367/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1292597902.9980 - val_loss: 1376384699.9087\n",
      "Epoch 7368/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1293011016.3914 - val_loss: 1378731856.3653\n",
      "Epoch 7369/15000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1292515051.9609 - val_loss: 1378541001.6438\n",
      "Epoch 7370/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1292348744.5166 - val_loss: 1378010111.4155\n",
      "Epoch 7371/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1292528436.9472 - val_loss: 1375939815.7443\n",
      "Epoch 7372/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1292118703.5930 - val_loss: 1377118940.6393\n",
      "Epoch 7373/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1292063021.7143 - val_loss: 1376845856.4384\n",
      "Epoch 7374/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1292665584.5949 - val_loss: 1377638330.7397\n",
      "Epoch 7375/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 29us/step - loss: 1292106041.1115 - val_loss: 1377054151.5982\n",
      "Epoch 7376/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1292058331.3033 - val_loss: 1376629617.3881\n",
      "Epoch 7377/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1291862395.4912 - val_loss: 1377274443.9817\n",
      "Epoch 7378/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1291742380.1487 - val_loss: 1376472511.7078\n",
      "Epoch 7379/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1291851573.3542 - val_loss: 1377258407.4521\n",
      "Epoch 7380/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1291976385.3777 - val_loss: 1375964627.2877\n",
      "Epoch 7381/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1291940380.8063 - val_loss: 1376681307.4703\n",
      "Epoch 7382/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1291735094.7945 - val_loss: 1376733854.6849\n",
      "Epoch 7383/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1291954996.8532 - val_loss: 1376518571.2511\n",
      "Epoch 7384/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1291708071.4521 - val_loss: 1376835993.1324\n",
      "Epoch 7385/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1292056541.3072 - val_loss: 1376913645.5890\n",
      "Epoch 7386/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1291367333.6986 - val_loss: 1376157737.7900\n",
      "Epoch 7387/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1291372749.5264 - val_loss: 1375455665.6804\n",
      "Epoch 7388/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1291581251.8826 - val_loss: 1374692773.9909\n",
      "Epoch 7389/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1291405862.7006 - val_loss: 1375429511.5982\n",
      "Epoch 7390/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1291157790.0587 - val_loss: 1375603121.9726\n",
      "Epoch 7391/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1291528089.6751 - val_loss: 1375083446.0639\n",
      "Epoch 7392/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1291828349.8708 - val_loss: 1374491441.9726\n",
      "Epoch 7393/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1291164898.0665 - val_loss: 1375972059.7626\n",
      "Epoch 7394/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1291063537.4716 - val_loss: 1376429653.3333\n",
      "Epoch 7395/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1291550299.5538 - val_loss: 1374778249.9361\n",
      "Epoch 7396/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1291138207.6869 - val_loss: 1375840147.2877\n",
      "Epoch 7397/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1290906411.5851 - val_loss: 1375638943.2694\n",
      "Epoch 7398/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1290849440.5636 - val_loss: 1375103892.7489\n",
      "Epoch 7399/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1291180730.4892 - val_loss: 1373968148.1644\n",
      "Epoch 7400/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1290657732.5088 - val_loss: 1374756934.1370\n",
      "Epoch 7401/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1291001943.1703 - val_loss: 1375751828.4566\n",
      "Epoch 7402/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1290725807.5930 - val_loss: 1374354016.7306\n",
      "Epoch 7403/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1290470871.5460 - val_loss: 1374927930.7397\n",
      "Epoch 7404/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1290592825.6751 - val_loss: 1374498977.8995\n",
      "Epoch 7405/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1290500904.2035 - val_loss: 1374139582.5388\n",
      "Epoch 7406/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1290359347.6008 - val_loss: 1374862532.3836\n",
      "Epoch 7407/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1290483893.7299 - val_loss: 1374672631.8174\n",
      "Epoch 7408/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1290499155.9139 - val_loss: 1374452707.6530\n",
      "Epoch 7409/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1290589673.2055 - val_loss: 1375162504.4749\n",
      "Epoch 7410/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1290265505.8160 - val_loss: 1374258562.9224\n",
      "Epoch 7411/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1290335208.9550 - val_loss: 1374273225.9361\n",
      "Epoch 7412/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1290432855.3581 - val_loss: 1373659354.5936\n",
      "Epoch 7413/15000\n",
      "1022/1022 [==============================] - 0s 65us/step - loss: 1290129505.8160 - val_loss: 1373746368.5845\n",
      "Epoch 7414/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1290768989.0568 - val_loss: 1374530353.6804\n",
      "Epoch 7415/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1290204938.7710 - val_loss: 1373995865.1324\n",
      "Epoch 7416/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1289941849.4247 - val_loss: 1373173714.9954\n",
      "Epoch 7417/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1289970688.6262 - val_loss: 1373350117.9909\n",
      "Epoch 7418/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1289940597.1037 - val_loss: 1372595029.0411\n",
      "Epoch 7419/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1289884932.7593 - val_loss: 1373510357.9178\n",
      "Epoch 7420/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1289952906.2701 - val_loss: 1372594059.6895\n",
      "Epoch 7421/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1289704520.1409 - val_loss: 1373231089.6804\n",
      "Epoch 7422/15000\n",
      "1022/1022 [==============================] - 0s 80us/step - loss: 1290023518.0587 - val_loss: 1372766667.1050\n",
      "Epoch 7423/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1289722542.9667 - val_loss: 1373464883.1416\n",
      "Epoch 7424/15000\n",
      "1022/1022 [==============================] - 0s 90us/step - loss: 1289749546.5832 - val_loss: 1373272313.2785\n",
      "Epoch 7425/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1289588041.7691 - val_loss: 1373019761.6804\n",
      "Epoch 7426/15000\n",
      "1022/1022 [==============================] - 0s 65us/step - loss: 1289816680.7045 - val_loss: 1372055532.1279\n",
      "Epoch 7427/15000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1291309948.4932 - val_loss: 1374173183.7078\n",
      "Epoch 7428/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1289435349.7926 - val_loss: 1372400404.7489\n",
      "Epoch 7429/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1289422901.2290 - val_loss: 1372688649.3516\n",
      "Epoch 7430/15000\n",
      "1022/1022 [==============================] - 0s 67us/step - loss: 1289402487.1703 - val_loss: 1371898692.0913\n",
      "Epoch 7431/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1289228643.5695 - val_loss: 1371582367.2694\n",
      "Epoch 7432/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1289642075.3033 - val_loss: 1372589955.2146\n",
      "Epoch 7433/15000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1289196691.0372 - val_loss: 1372651313.0959\n",
      "Epoch 7434/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1289548895.4364 - val_loss: 1371500605.3699\n",
      "Epoch 7435/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1289552029.3072 - val_loss: 1371095484.2009\n",
      "Epoch 7436/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1289378663.2016 - val_loss: 1372528793.1324\n",
      "Epoch 7437/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1288895066.9902 - val_loss: 1371796316.6393\n",
      "Epoch 7438/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1289029084.9315 - val_loss: 1372185918.8311\n",
      "Epoch 7439/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 32us/step - loss: 1289073851.9922 - val_loss: 1372115158.5023\n",
      "Epoch 7440/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1288958045.0568 - val_loss: 1371494737.5342\n",
      "Epoch 7441/15000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1289038637.0881 - val_loss: 1372263448.2557\n",
      "Epoch 7442/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1288901977.4247 - val_loss: 1370703101.3699\n",
      "Epoch 7443/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1288768624.7202 - val_loss: 1371580374.5023\n",
      "Epoch 7444/15000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1289073653.3542 - val_loss: 1370665167.4886\n",
      "Epoch 7445/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1289028103.1389 - val_loss: 1371553533.6621\n",
      "Epoch 7446/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1288499525.1350 - val_loss: 1370745254.2831\n",
      "Epoch 7447/15000\n",
      "1022/1022 [==============================] - 0s 63us/step - loss: 1288556887.9843 - val_loss: 1371430663.3059\n",
      "Epoch 7448/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1288928027.8043 - val_loss: 1370885687.5251\n",
      "Epoch 7449/15000\n",
      "1022/1022 [==============================] - 0s 82us/step - loss: 1288703250.5362 - val_loss: 1371768989.8082\n",
      "Epoch 7450/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1288454701.7143 - val_loss: 1370466431.7078\n",
      "Epoch 7451/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1288635014.7632 - val_loss: 1371566950.8676\n",
      "Epoch 7452/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1288378162.5988 - val_loss: 1370180990.5388\n",
      "Epoch 7453/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1288470665.0176 - val_loss: 1370943196.6393\n",
      "Epoch 7454/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1288206431.6869 - val_loss: 1370045317.8447\n",
      "Epoch 7455/15000\n",
      "1022/1022 [==============================] - 0s 72us/step - loss: 1288359286.3562 - val_loss: 1370933368.6941\n",
      "Epoch 7456/15000\n",
      "1022/1022 [==============================] - 0s 75us/step - loss: 1288359869.8708 - val_loss: 1370203746.7763\n",
      "Epoch 7457/15000\n",
      "1022/1022 [==============================] - 0s 95us/step - loss: 1288156429.0254 - val_loss: 1369470590.2466\n",
      "Epoch 7458/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1288045973.8552 - val_loss: 1369898525.2237\n",
      "Epoch 7459/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1287888635.9295 - val_loss: 1370456941.0046\n",
      "Epoch 7460/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1288290610.3483 - val_loss: 1369506868.8950\n",
      "Epoch 7461/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1288000340.1644 - val_loss: 1370528644.6758\n",
      "Epoch 7462/15000\n",
      "1022/1022 [==============================] - 0s 68us/step - loss: 1288003014.3875 - val_loss: 1370371770.1553\n",
      "Epoch 7463/15000\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 1288112398.7789 - val_loss: 1370001054.3927\n",
      "Epoch 7464/15000\n",
      "1022/1022 [==============================] - 0s 93us/step - loss: 1287881514.6458 - val_loss: 1370233337.8630\n",
      "Epoch 7465/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1288653674.3327 - val_loss: 1371074591.5616\n",
      "Epoch 7466/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1288426329.1742 - val_loss: 1369574791.8904\n",
      "Epoch 7467/15000\n",
      "1022/1022 [==============================] - 0s 119us/step - loss: 1289322377.5186 - val_loss: 1367267546.5936\n",
      "Epoch 7468/15000\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 1288164593.9726 - val_loss: 1368987295.8539\n",
      "Epoch 7469/15000\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 1287684377.6751 - val_loss: 1368589405.2237\n",
      "Epoch 7470/15000\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 1287345550.5284 - val_loss: 1369088615.4521\n",
      "Epoch 7471/15000\n",
      "1022/1022 [==============================] - 0s 87us/step - loss: 1288278995.6634 - val_loss: 1368572875.6895\n",
      "Epoch 7472/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1287355125.9804 - val_loss: 1368885893.8447\n",
      "Epoch 7473/15000\n",
      "1022/1022 [==============================] - 0s 80us/step - loss: 1287716808.7671 - val_loss: 1370196605.3699\n",
      "Epoch 7474/15000\n",
      "1022/1022 [==============================] - 0s 69us/step - loss: 1287600156.0548 - val_loss: 1368393768.9132\n",
      "Epoch 7475/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1287576741.3229 - val_loss: 1370074979.9452\n",
      "Epoch 7476/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1287149665.9413 - val_loss: 1369136294.8676\n",
      "Epoch 7477/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1287099280.5949 - val_loss: 1368614612.4566\n",
      "Epoch 7478/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1287159705.0489 - val_loss: 1368055606.3562\n",
      "Epoch 7479/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1287825996.3992 - val_loss: 1367606288.9498\n",
      "Epoch 7480/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1287110965.2290 - val_loss: 1369320502.9406\n",
      "Epoch 7481/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1287292223.3738 - val_loss: 1368070260.8950\n",
      "Epoch 7482/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1287082977.9413 - val_loss: 1369120634.1553\n",
      "Epoch 7483/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1286928407.7339 - val_loss: 1368809162.2283\n",
      "Epoch 7484/15000\n",
      "1022/1022 [==============================] - 0s 86us/step - loss: 1286780608.8141 - val_loss: 1368737310.3927\n",
      "Epoch 7485/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1286772633.8004 - val_loss: 1367853688.4018\n",
      "Epoch 7486/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1286828399.5930 - val_loss: 1368620472.4018\n",
      "Epoch 7487/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1287362849.9413 - val_loss: 1369132204.7123\n",
      "Epoch 7488/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1286549557.6047 - val_loss: 1368174122.6667\n",
      "Epoch 7489/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1286863013.5734 - val_loss: 1366650084.8219\n",
      "Epoch 7490/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1286922189.9022 - val_loss: 1368282031.0502\n",
      "Epoch 7491/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1287035698.4736 - val_loss: 1367160459.9817\n",
      "Epoch 7492/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1287110839.6086 - val_loss: 1366556422.4292\n",
      "Epoch 7493/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1286440174.3405 - val_loss: 1367148487.8904\n",
      "Epoch 7494/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1286374797.7769 - val_loss: 1367588591.9269\n",
      "Epoch 7495/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1287348828.1800 - val_loss: 1368293899.9817\n",
      "Epoch 7496/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1286395772.7436 - val_loss: 1367095035.6164\n",
      "Epoch 7497/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1287235334.3875 - val_loss: 1366046103.6712\n",
      "Epoch 7498/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1286068882.1605 - val_loss: 1367087574.7945\n",
      "Epoch 7499/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1286436238.0274 - val_loss: 1367636878.0274\n",
      "Epoch 7500/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1286393765.5734 - val_loss: 1367522731.8356\n",
      "Epoch 7501/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1285936602.9276 - val_loss: 1366768206.3196\n",
      "Epoch 7502/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1286047260.8063 - val_loss: 1366781342.9772\n",
      "Epoch 7503/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 34us/step - loss: 1285951775.3112 - val_loss: 1366939941.1142\n",
      "Epoch 7504/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1286192877.7143 - val_loss: 1365755521.1689\n",
      "Epoch 7505/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1286613050.4892 - val_loss: 1366760891.3242\n",
      "Epoch 7506/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1285872054.8571 - val_loss: 1366575987.4338\n",
      "Epoch 7507/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1285823405.3386 - val_loss: 1366472391.5982\n",
      "Epoch 7508/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1286084576.1879 - val_loss: 1367175234.3379\n",
      "Epoch 7509/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1286088709.5108 - val_loss: 1366062724.0913\n",
      "Epoch 7510/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1286584648.6419 - val_loss: 1366973622.0639\n",
      "Epoch 7511/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1285649637.3229 - val_loss: 1365306219.5434\n",
      "Epoch 7512/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1285811873.3151 - val_loss: 1366455828.4566\n",
      "Epoch 7513/15000\n",
      "1022/1022 [==============================] - 0s 89us/step - loss: 1285457039.0294 - val_loss: 1366113223.0137\n",
      "Epoch 7514/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1285728939.8982 - val_loss: 1365468868.0913\n",
      "Epoch 7515/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1285444201.3933 - val_loss: 1365197504.2922\n",
      "Epoch 7516/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1285565553.3464 - val_loss: 1364411052.4201\n",
      "Epoch 7517/15000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1285253068.3366 - val_loss: 1365102759.1598\n",
      "Epoch 7518/15000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1285488891.8669 - val_loss: 1365663368.7671\n",
      "Epoch 7519/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1285678850.6928 - val_loss: 1366310910.8311\n",
      "Epoch 7520/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1285407421.6204 - val_loss: 1365561034.2283\n",
      "Epoch 7521/15000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1285392654.2779 - val_loss: 1364672003.5068\n",
      "Epoch 7522/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1285456686.5910 - val_loss: 1366213702.1370\n",
      "Epoch 7523/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1285191059.1624 - val_loss: 1364722057.9361\n",
      "Epoch 7524/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1285131988.9159 - val_loss: 1365542219.6895\n",
      "Epoch 7525/15000\n",
      "1022/1022 [==============================] - 0s 87us/step - loss: 1285098323.1624 - val_loss: 1364561785.2785\n",
      "Epoch 7526/15000\n",
      "1022/1022 [==============================] - 0s 69us/step - loss: 1285078198.7319 - val_loss: 1364657996.2740\n",
      "Epoch 7527/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1285494737.5342 - val_loss: 1363528040.9132\n",
      "Epoch 7528/15000\n",
      "1022/1022 [==============================] - 0s 126us/step - loss: 1284863182.9041 - val_loss: 1364853101.8813\n",
      "Epoch 7529/15000\n",
      "1022/1022 [==============================] - 0s 112us/step - loss: 1285215757.5264 - val_loss: 1364375070.9772\n",
      "Epoch 7530/15000\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 1284920336.9080 - val_loss: 1364891660.5662\n",
      "Epoch 7531/15000\n",
      "1022/1022 [==============================] - 0s 125us/step - loss: 1284870207.4990 - val_loss: 1364750426.0091\n",
      "Epoch 7532/15000\n",
      "1022/1022 [==============================] - 0s 71us/step - loss: 1285186847.5616 - val_loss: 1363598908.4932\n",
      "Epoch 7533/15000\n",
      "1022/1022 [==============================] - 0s 107us/step - loss: 1285409978.8650 - val_loss: 1366311057.5342\n",
      "Epoch 7534/15000\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 1285184216.5479 - val_loss: 1364030091.6895\n",
      "Epoch 7535/15000\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 1284566955.3346 - val_loss: 1364593827.9452\n",
      "Epoch 7536/15000\n",
      "1022/1022 [==============================] - 0s 89us/step - loss: 1284527240.7671 - val_loss: 1364593369.1324\n",
      "Epoch 7537/15000\n",
      "1022/1022 [==============================] - 0s 124us/step - loss: 1284622657.6282 - val_loss: 1365066540.7123\n",
      "Epoch 7538/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1285249364.1644 - val_loss: 1362580311.6712\n",
      "Epoch 7539/15000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1284455150.7162 - val_loss: 1364380266.0822\n",
      "Epoch 7540/15000\n",
      "1022/1022 [==============================] - 0s 81us/step - loss: 1284638668.9002 - val_loss: 1363775115.6895\n",
      "Epoch 7541/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1284617604.8845 - val_loss: 1362820137.2055\n",
      "Epoch 7542/15000\n",
      "1022/1022 [==============================] - 0s 67us/step - loss: 1284267643.0528 - val_loss: 1364366340.9680\n",
      "Epoch 7543/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1284675297.1898 - val_loss: 1364576016.0731\n",
      "Epoch 7544/15000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1284168623.9687 - val_loss: 1364097225.9361\n",
      "Epoch 7545/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1284318570.7084 - val_loss: 1363485844.7489\n",
      "Epoch 7546/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1284121953.8160 - val_loss: 1363795373.2968\n",
      "Epoch 7547/15000\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 1284540684.5245 - val_loss: 1362740008.0365\n",
      "Epoch 7548/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1283984891.4912 - val_loss: 1363498043.0320\n",
      "Epoch 7549/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1284031233.7534 - val_loss: 1362753563.7626\n",
      "Epoch 7550/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1283932817.2838 - val_loss: 1362645440.0000\n",
      "Epoch 7551/15000\n",
      "1022/1022 [==============================] - 0s 85us/step - loss: 1284206557.4325 - val_loss: 1362990836.6027\n",
      "Epoch 7552/15000\n",
      "1022/1022 [==============================] - 0s 82us/step - loss: 1283727372.7123 - val_loss: 1363037241.2785\n",
      "Epoch 7553/15000\n",
      "1022/1022 [==============================] - 0s 82us/step - loss: 1283771239.0763 - val_loss: 1362647555.2146\n",
      "Epoch 7554/15000\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 1284141719.0450 - val_loss: 1363762290.8493\n",
      "Epoch 7555/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1283575721.3307 - val_loss: 1362965356.1279\n",
      "Epoch 7556/15000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1283789786.6771 - val_loss: 1363141202.1187\n",
      "Epoch 7557/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1284247460.8219 - val_loss: 1361838476.5662\n",
      "Epoch 7558/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1284479129.4247 - val_loss: 1361806410.5205\n",
      "Epoch 7559/15000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1283537369.4247 - val_loss: 1362381587.5799\n",
      "Epoch 7560/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1284469230.4658 - val_loss: 1360642126.9041\n",
      "Epoch 7561/15000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1284202595.6947 - val_loss: 1363478037.9178\n",
      "Epoch 7562/15000\n",
      "1022/1022 [==============================] - 0s 92us/step - loss: 1283795470.7789 - val_loss: 1362087717.9909\n",
      "Epoch 7563/15000\n",
      "1022/1022 [==============================] - 0s 89us/step - loss: 1284022253.4638 - val_loss: 1363395272.1826\n",
      "Epoch 7564/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1283339935.8121 - val_loss: 1361781123.2146\n",
      "Epoch 7565/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1283213057.1272 - val_loss: 1361939230.3927\n",
      "Epoch 7566/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1283576135.6399 - val_loss: 1360970083.0685\n",
      "Epoch 7567/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 60us/step - loss: 1283788915.2250 - val_loss: 1363223214.4658\n",
      "Epoch 7568/15000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1283845263.6556 - val_loss: 1360695373.1507\n",
      "Epoch 7569/15000\n",
      "1022/1022 [==============================] - 0s 105us/step - loss: 1283379967.3738 - val_loss: 1362146357.1872\n",
      "Epoch 7570/15000\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 1283513667.5068 - val_loss: 1361301954.3379\n",
      "Epoch 7571/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1283166292.4149 - val_loss: 1361477164.4201\n",
      "Epoch 7572/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1282896428.8376 - val_loss: 1361674443.9817\n",
      "Epoch 7573/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1282926263.8591 - val_loss: 1361155903.4155\n",
      "Epoch 7574/15000\n",
      "1022/1022 [==============================] - 0s 69us/step - loss: 1283157074.9119 - val_loss: 1361590319.3425\n",
      "Epoch 7575/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1283348492.0235 - val_loss: 1362193515.2511\n",
      "Epoch 7576/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1283977347.5068 - val_loss: 1360590875.7626\n",
      "Epoch 7577/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1283015804.9941 - val_loss: 1360755928.5479\n",
      "Epoch 7578/15000\n",
      "1022/1022 [==============================] - 0s 69us/step - loss: 1282847847.2016 - val_loss: 1360844779.5434\n",
      "Epoch 7579/15000\n",
      "1022/1022 [==============================] - 0s 83us/step - loss: 1282669426.8493 - val_loss: 1360653106.8493\n",
      "Epoch 7580/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1282953449.3307 - val_loss: 1361463971.9452\n",
      "Epoch 7581/15000\n",
      "1022/1022 [==============================] - 0s 80us/step - loss: 1282735655.2642 - val_loss: 1360333290.9589\n",
      "Epoch 7582/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1282940511.0607 - val_loss: 1360412204.4201\n",
      "Epoch 7583/15000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1282778731.7730 - val_loss: 1360485449.9361\n",
      "Epoch 7584/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1282473273.3620 - val_loss: 1361132477.0776\n",
      "Epoch 7585/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1282469576.1409 - val_loss: 1360481874.9954\n",
      "Epoch 7586/15000\n",
      "1022/1022 [==============================] - 0s 74us/step - loss: 1282554922.5832 - val_loss: 1361302667.1050\n",
      "Epoch 7587/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1282775297.0020 - val_loss: 1359514981.9909\n",
      "Epoch 7588/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1282497750.4814 - val_loss: 1360695940.0913\n",
      "Epoch 7589/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1283637561.6751 - val_loss: 1358682887.5982\n",
      "Epoch 7590/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1282869407.5616 - val_loss: 1361001744.3653\n",
      "Epoch 7591/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1282164030.6223 - val_loss: 1359689114.5936\n",
      "Epoch 7592/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1282113321.4560 - val_loss: 1360321672.4749\n",
      "Epoch 7593/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1282023542.4814 - val_loss: 1360177849.5708\n",
      "Epoch 7594/15000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1282271343.2172 - val_loss: 1360830705.0959\n",
      "Epoch 7595/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1282435043.6947 - val_loss: 1359355105.6073\n",
      "Epoch 7596/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1282035709.9961 - val_loss: 1359683718.7215\n",
      "Epoch 7597/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1282277325.4012 - val_loss: 1359123904.2922\n",
      "Epoch 7598/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1281896618.8337 - val_loss: 1359774880.4384\n",
      "Epoch 7599/15000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1281782900.6027 - val_loss: 1359894126.7580\n",
      "Epoch 7600/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1281992285.8708 - val_loss: 1359242070.2100\n",
      "Epoch 7601/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1281787278.0274 - val_loss: 1359631486.2466\n",
      "Epoch 7602/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1281690605.2133 - val_loss: 1359537201.6804\n",
      "Epoch 7603/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1281822786.5362 - val_loss: 1359385193.4977\n",
      "Epoch 7604/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1281790192.7202 - val_loss: 1358462462.5388\n",
      "Epoch 7605/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1281620918.8571 - val_loss: 1359262456.9863\n",
      "Epoch 7606/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1282164129.3151 - val_loss: 1357519029.7717\n",
      "Epoch 7607/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1281854493.3072 - val_loss: 1358540277.4795\n",
      "Epoch 7608/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1281477844.6654 - val_loss: 1359354894.0274\n",
      "Epoch 7609/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1281506527.3112 - val_loss: 1359548210.2648\n",
      "Epoch 7610/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1282077326.2779 - val_loss: 1358906804.6027\n",
      "Epoch 7611/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1281957015.2955 - val_loss: 1357159033.5708\n",
      "Epoch 7612/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1281360596.0391 - val_loss: 1358792015.1963\n",
      "Epoch 7613/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1282286473.8943 - val_loss: 1359744122.7397\n",
      "Epoch 7614/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1281336771.8826 - val_loss: 1358187804.3470\n",
      "Epoch 7615/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1281119491.1311 - val_loss: 1358103126.5023\n",
      "Epoch 7616/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1281515066.8023 - val_loss: 1357528144.0731\n",
      "Epoch 7617/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1281040692.1018 - val_loss: 1358353071.0502\n",
      "Epoch 7618/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1281084578.8180 - val_loss: 1358115728.6575\n",
      "Epoch 7619/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1281256263.7652 - val_loss: 1358772554.2283\n",
      "Epoch 7620/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1281206927.6556 - val_loss: 1357936131.5068\n",
      "Epoch 7621/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1281453676.7123 - val_loss: 1358117849.7169\n",
      "Epoch 7622/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1280994496.7515 - val_loss: 1358318121.2055\n",
      "Epoch 7623/15000\n",
      "1022/1022 [==============================] - 0s 88us/step - loss: 1280957208.5479 - val_loss: 1357129979.6164\n",
      "Epoch 7624/15000\n",
      "1022/1022 [==============================] - 0s 72us/step - loss: 1281383136.5636 - val_loss: 1357031876.6758\n",
      "Epoch 7625/15000\n",
      "1022/1022 [==============================] - 0s 66us/step - loss: 1281390131.0998 - val_loss: 1357618794.3744\n",
      "Epoch 7626/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1280911160.4853 - val_loss: 1357820721.0959\n",
      "Epoch 7627/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1280912722.1605 - val_loss: 1357999717.9909\n",
      "Epoch 7628/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1281162876.2427 - val_loss: 1358458726.5753\n",
      "Epoch 7629/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1281131632.2192 - val_loss: 1356767200.7306\n",
      "Epoch 7630/15000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1281238139.7417 - val_loss: 1358007954.9954\n",
      "Epoch 7631/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 36us/step - loss: 1280496433.0959 - val_loss: 1357305260.7123\n",
      "Epoch 7632/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1280600532.6654 - val_loss: 1357700083.4338\n",
      "Epoch 7633/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1280410722.1918 - val_loss: 1357299245.8813\n",
      "Epoch 7634/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1280443226.4266 - val_loss: 1356946658.4840\n",
      "Epoch 7635/15000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1280379788.1487 - val_loss: 1357195482.8858\n",
      "Epoch 7636/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1280635216.0313 - val_loss: 1357603358.3927\n",
      "Epoch 7637/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1280644653.8395 - val_loss: 1357183664.2192\n",
      "Epoch 7638/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1280483479.9217 - val_loss: 1355876282.7397\n",
      "Epoch 7639/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1280427990.7945 - val_loss: 1355066902.2100\n",
      "Epoch 7640/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1280747278.9667 - val_loss: 1356664091.7626\n",
      "Epoch 7641/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1280303730.3483 - val_loss: 1356557515.3973\n",
      "Epoch 7642/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1280018457.0489 - val_loss: 1356156759.6712\n",
      "Epoch 7643/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1280335877.3855 - val_loss: 1356478420.7489\n",
      "Epoch 7644/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1280879783.2016 - val_loss: 1355069008.6575\n",
      "Epoch 7645/15000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1280043631.8434 - val_loss: 1356130642.7032\n",
      "Epoch 7646/15000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1280350198.7945 - val_loss: 1356563026.7032\n",
      "Epoch 7647/15000\n",
      "1022/1022 [==============================] - 0s 94us/step - loss: 1280109903.5930 - val_loss: 1355875585.7534\n",
      "Epoch 7648/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1279868185.2994 - val_loss: 1356189182.5388\n",
      "Epoch 7649/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1280167028.4775 - val_loss: 1355280025.1324\n",
      "Epoch 7650/15000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1280026805.4168 - val_loss: 1355309664.4384\n",
      "Epoch 7651/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1279737123.7573 - val_loss: 1355268240.9498\n",
      "Epoch 7652/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1280590838.0431 - val_loss: 1356375691.1050\n",
      "Epoch 7653/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1279654962.4110 - val_loss: 1355970849.8995\n",
      "Epoch 7654/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1279705825.3151 - val_loss: 1355418806.6484\n",
      "Epoch 7655/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1280534002.7241 - val_loss: 1356727359.4155\n",
      "Epoch 7656/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1279792329.3933 - val_loss: 1356965213.5160\n",
      "Epoch 7657/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1279445654.1683 - val_loss: 1355055762.1187\n",
      "Epoch 7658/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1279731479.0450 - val_loss: 1354839900.6393\n",
      "Epoch 7659/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1279497823.4364 - val_loss: 1354264348.9315\n",
      "Epoch 7660/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1279647095.2329 - val_loss: 1355774995.2877\n",
      "Epoch 7661/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1279208773.8865 - val_loss: 1355686261.1872\n",
      "Epoch 7662/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1280046264.8611 - val_loss: 1353437404.9315\n",
      "Epoch 7663/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1279156938.1448 - val_loss: 1354640769.7534\n",
      "Epoch 7664/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1279311549.2446 - val_loss: 1354912746.3744\n",
      "Epoch 7665/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1279607956.7906 - val_loss: 1355721185.8995\n",
      "Epoch 7666/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1279236878.4031 - val_loss: 1354832644.3836\n",
      "Epoch 7667/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1279182596.7593 - val_loss: 1355006071.8174\n",
      "Epoch 7668/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1279561179.9295 - val_loss: 1353027795.2877\n",
      "Epoch 7669/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1280053588.0391 - val_loss: 1355704222.6849\n",
      "Epoch 7670/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1279211317.9804 - val_loss: 1353606481.8265\n",
      "Epoch 7671/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1279427055.4677 - val_loss: 1354123588.3836\n",
      "Epoch 7672/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1279210463.1859 - val_loss: 1354764550.7215\n",
      "Epoch 7673/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1278868723.4755 - val_loss: 1353679539.4338\n",
      "Epoch 7674/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1278792019.6634 - val_loss: 1353968796.9315\n",
      "Epoch 7675/15000\n",
      "1022/1022 [==============================] - 0s 65us/step - loss: 1278950453.4795 - val_loss: 1353834631.5982\n",
      "Epoch 7676/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1278634813.2446 - val_loss: 1353989371.0320\n",
      "Epoch 7677/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1278721717.3542 - val_loss: 1354238053.1142\n",
      "Epoch 7678/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1278676884.6654 - val_loss: 1354007756.2740\n",
      "Epoch 7679/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1279023354.7397 - val_loss: 1353593172.1644\n",
      "Epoch 7680/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1278724249.0489 - val_loss: 1353282908.9315\n",
      "Epoch 7681/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1278524550.7632 - val_loss: 1354201337.5708\n",
      "Epoch 7682/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1278996619.7730 - val_loss: 1352758729.9361\n",
      "Epoch 7683/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1278453898.0196 - val_loss: 1354419286.5023\n",
      "Epoch 7684/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1278470903.6712 - val_loss: 1353843118.1735\n",
      "Epoch 7685/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1278296024.4227 - val_loss: 1353759207.4521\n",
      "Epoch 7686/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1278491573.6047 - val_loss: 1353310582.3562\n",
      "Epoch 7687/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1278539486.5597 - val_loss: 1352785751.3790\n",
      "Epoch 7688/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1278200005.5108 - val_loss: 1353149858.1918\n",
      "Epoch 7689/15000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1278433901.8395 - val_loss: 1354366291.5799\n",
      "Epoch 7690/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1278766106.4266 - val_loss: 1352289991.0137\n",
      "Epoch 7691/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1278459271.6399 - val_loss: 1353345701.6986\n",
      "Epoch 7692/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1278083554.8180 - val_loss: 1352706259.8721\n",
      "Epoch 7693/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1278113880.3601 - val_loss: 1352532842.6667\n",
      "Epoch 7694/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1277968413.0568 - val_loss: 1352424656.9498\n",
      "Epoch 7695/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 46us/step - loss: 1278165119.8748 - val_loss: 1353799477.7717\n",
      "Epoch 7696/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1277984996.1957 - val_loss: 1353814009.5708\n",
      "Epoch 7697/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1278144546.0665 - val_loss: 1352836623.1963\n",
      "Epoch 7698/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1277985745.5342 - val_loss: 1351999831.9635\n",
      "Epoch 7699/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1277935626.0196 - val_loss: 1351293805.8813\n",
      "Epoch 7700/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1277843670.9198 - val_loss: 1352621004.5662\n",
      "Epoch 7701/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1277670366.8102 - val_loss: 1352895913.7900\n",
      "Epoch 7702/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1278421561.5499 - val_loss: 1351675858.4110\n",
      "Epoch 7703/15000\n",
      "1022/1022 [==============================] - 0s 68us/step - loss: 1277661403.5538 - val_loss: 1351779418.5936\n",
      "Epoch 7704/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1277540691.7886 - val_loss: 1352008236.4201\n",
      "Epoch 7705/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1277610700.5871 - val_loss: 1352712732.3470\n",
      "Epoch 7706/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1278307275.6477 - val_loss: 1351736265.3516\n",
      "Epoch 7707/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1277439726.4658 - val_loss: 1352531373.2968\n",
      "Epoch 7708/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1277559800.6106 - val_loss: 1352332285.0776\n",
      "Epoch 7709/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1277751376.1566 - val_loss: 1352709165.0046\n",
      "Epoch 7710/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1277630598.0117 - val_loss: 1351793421.7352\n",
      "Epoch 7711/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1277402171.6164 - val_loss: 1351563517.6621\n",
      "Epoch 7712/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1277392532.7906 - val_loss: 1352096907.3973\n",
      "Epoch 7713/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1277556315.4286 - val_loss: 1351020851.1416\n",
      "Epoch 7714/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1277273233.2838 - val_loss: 1351854943.5616\n",
      "Epoch 7715/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1277190798.5284 - val_loss: 1351156913.0959\n",
      "Epoch 7716/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1277261286.7006 - val_loss: 1351416286.3927\n",
      "Epoch 7717/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1277513199.1546 - val_loss: 1351997188.3836\n",
      "Epoch 7718/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1276978673.3464 - val_loss: 1351059067.9087\n",
      "Epoch 7719/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1277154447.1546 - val_loss: 1350257183.8539\n",
      "Epoch 7720/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1277647402.7084 - val_loss: 1351444160.8767\n",
      "Epoch 7721/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1277332723.2877 - val_loss: 1349741570.6301\n",
      "Epoch 7722/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1277110752.3131 - val_loss: 1351635861.6256\n",
      "Epoch 7723/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1277212024.8611 - val_loss: 1351608122.4475\n",
      "Epoch 7724/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1276905665.6282 - val_loss: 1350163342.0274\n",
      "Epoch 7725/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1277234672.7202 - val_loss: 1351369371.7626\n",
      "Epoch 7726/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1277170364.3679 - val_loss: 1350545878.5023\n",
      "Epoch 7727/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1276919956.1644 - val_loss: 1350189654.7945\n",
      "Epoch 7728/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1276848088.6732 - val_loss: 1350284002.1918\n",
      "Epoch 7729/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1276632145.9100 - val_loss: 1350109605.6986\n",
      "Epoch 7730/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1276789537.3151 - val_loss: 1351283236.5297\n",
      "Epoch 7731/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1276429853.1820 - val_loss: 1350377359.4886\n",
      "Epoch 7732/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1276784983.1703 - val_loss: 1351349082.3014\n",
      "Epoch 7733/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1276460570.6771 - val_loss: 1350046295.9635\n",
      "Epoch 7734/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1276541305.2368 - val_loss: 1350657016.1096\n",
      "Epoch 7735/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1276845666.3796 - val_loss: 1350730813.9543\n",
      "Epoch 7736/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1276941720.5479 - val_loss: 1348738771.2877\n",
      "Epoch 7737/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1276325216.2505 - val_loss: 1349806528.0000\n",
      "Epoch 7738/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1276530413.5890 - val_loss: 1349457756.9315\n",
      "Epoch 7739/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1277293059.5068 - val_loss: 1350235908.0913\n",
      "Epoch 7740/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1276335173.0098 - val_loss: 1350120446.5388\n",
      "Epoch 7741/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1276242287.2172 - val_loss: 1349799967.2694\n",
      "Epoch 7742/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1276404575.6869 - val_loss: 1349372609.7534\n",
      "Epoch 7743/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1276211214.0274 - val_loss: 1349957238.0639\n",
      "Epoch 7744/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1276393324.4618 - val_loss: 1348618860.7123\n",
      "Epoch 7745/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1277160136.5793 - val_loss: 1350353823.2694\n",
      "Epoch 7746/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1276299589.9491 - val_loss: 1348076923.6164\n",
      "Epoch 7747/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1276257072.5949 - val_loss: 1348153735.3059\n",
      "Epoch 7748/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1276304680.9550 - val_loss: 1349308598.9406\n",
      "Epoch 7749/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1275917669.5734 - val_loss: 1349802707.5799\n",
      "Epoch 7750/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1275782806.4188 - val_loss: 1349115891.4338\n",
      "Epoch 7751/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1276001785.9883 - val_loss: 1347925979.1781\n",
      "Epoch 7752/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1276120714.7710 - val_loss: 1349374745.1324\n",
      "Epoch 7753/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1275677233.3464 - val_loss: 1348841094.7215\n",
      "Epoch 7754/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1275734327.1076 - val_loss: 1348615679.4155\n",
      "Epoch 7755/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1275880762.3640 - val_loss: 1347997214.3927\n",
      "Epoch 7756/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1275931320.1096 - val_loss: 1348249021.0776\n",
      "Epoch 7757/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1275733442.8806 - val_loss: 1349673756.6393\n",
      "Epoch 7758/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1275761881.5499 - val_loss: 1348953597.0776\n",
      "Epoch 7759/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 40us/step - loss: 1275484591.7182 - val_loss: 1348325250.6301\n",
      "Epoch 7760/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1275616976.9080 - val_loss: 1348760506.1553\n",
      "Epoch 7761/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1275491453.6204 - val_loss: 1348679680.8767\n",
      "Epoch 7762/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1276445733.6360 - val_loss: 1349523160.8402\n",
      "Epoch 7763/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1275388541.2446 - val_loss: 1347510473.9361\n",
      "Epoch 7764/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1275387171.5695 - val_loss: 1348190380.7123\n",
      "Epoch 7765/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1275388525.0881 - val_loss: 1348783769.4247\n",
      "Epoch 7766/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1275821352.9550 - val_loss: 1347093173.4795\n",
      "Epoch 7767/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1275598635.0841 - val_loss: 1347445395.5799\n",
      "Epoch 7768/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1275070243.3190 - val_loss: 1348107402.8128\n",
      "Epoch 7769/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1275117910.1683 - val_loss: 1347786742.3562\n",
      "Epoch 7770/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1275343967.0607 - val_loss: 1347962424.1096\n",
      "Epoch 7771/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1276504392.8924 - val_loss: 1346929915.3242\n",
      "Epoch 7772/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1275610219.8356 - val_loss: 1348607933.3699\n",
      "Epoch 7773/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1275495095.9843 - val_loss: 1348218123.1050\n",
      "Epoch 7774/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1275948013.9648 - val_loss: 1346474268.3470\n",
      "Epoch 7775/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1275212222.0587 - val_loss: 1346809632.7306\n",
      "Epoch 7776/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1275069800.2035 - val_loss: 1347297918.5388\n",
      "Epoch 7777/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1275578210.6928 - val_loss: 1346158118.2831\n",
      "Epoch 7778/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1274783940.3836 - val_loss: 1347970293.7717\n",
      "Epoch 7779/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1275014524.2427 - val_loss: 1347724373.6256\n",
      "Epoch 7780/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1275168426.9589 - val_loss: 1346232791.3790\n",
      "Epoch 7781/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1274864816.3444 - val_loss: 1347177838.1735\n",
      "Epoch 7782/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1275036562.1605 - val_loss: 1347210037.7717\n",
      "Epoch 7783/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1274521961.9569 - val_loss: 1347643933.5160\n",
      "Epoch 7784/15000\n",
      "1022/1022 [==============================] - 0s 78us/step - loss: 1274958153.5812 - val_loss: 1346765350.5753\n",
      "Epoch 7785/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1274608845.1507 - val_loss: 1347319713.6073\n",
      "Epoch 7786/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1274600338.2857 - val_loss: 1347419318.6484\n",
      "Epoch 7787/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1274412999.5773 - val_loss: 1347156381.5160\n",
      "Epoch 7788/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1274552388.3836 - val_loss: 1346667029.6256\n",
      "Epoch 7789/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1274592571.1155 - val_loss: 1347472309.1872\n",
      "Epoch 7790/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1274541236.1018 - val_loss: 1347008768.0000\n",
      "Epoch 7791/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1274419097.9256 - val_loss: 1346981907.8721\n",
      "Epoch 7792/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1274366886.1683 - val_loss: 1346398064.5114\n",
      "Epoch 7793/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1274592600.1722 - val_loss: 1346904041.7900\n",
      "Epoch 7794/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1274485253.0098 - val_loss: 1347600172.7123\n",
      "Epoch 7795/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1274353036.6497 - val_loss: 1345882667.5434\n",
      "Epoch 7796/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1274369569.1898 - val_loss: 1345064092.3470\n",
      "Epoch 7797/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1274161509.1977 - val_loss: 1345293637.8447\n",
      "Epoch 7798/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1275279322.4892 - val_loss: 1346702578.8493\n",
      "Epoch 7799/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1274192230.1370 - val_loss: 1345514736.5114\n",
      "Epoch 7800/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1274016618.4579 - val_loss: 1346219166.9772\n",
      "Epoch 7801/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1274209478.6380 - val_loss: 1346289576.3288\n",
      "Epoch 7802/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1273973103.0920 - val_loss: 1345554040.6941\n",
      "Epoch 7803/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1273906256.1566 - val_loss: 1345179279.4886\n",
      "Epoch 7804/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1274140841.5812 - val_loss: 1346593740.5662\n",
      "Epoch 7805/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1273821890.3796 - val_loss: 1345844880.3653\n",
      "Epoch 7806/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1273844629.1663 - val_loss: 1345477914.0091\n",
      "Epoch 7807/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1274088902.5127 - val_loss: 1344607473.6804\n",
      "Epoch 7808/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1273640015.5930 - val_loss: 1345048926.3927\n",
      "Epoch 7809/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1274105555.2877 - val_loss: 1345985139.4338\n",
      "Epoch 7810/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1274051790.4031 - val_loss: 1344636337.0959\n",
      "Epoch 7811/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1273650582.0431 - val_loss: 1345433026.0457\n",
      "Epoch 7812/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1273718786.3796 - val_loss: 1345608784.6575\n",
      "Epoch 7813/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1274179987.0372 - val_loss: 1345587271.8904\n",
      "Epoch 7814/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1273697715.8513 - val_loss: 1345090575.4886\n",
      "Epoch 7815/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1273577657.8630 - val_loss: 1345399967.8539\n",
      "Epoch 7816/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1273687500.6497 - val_loss: 1344618091.2511\n",
      "Epoch 7817/15000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1273630721.8787 - val_loss: 1344885635.2146\n",
      "Epoch 7818/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1273652187.1781 - val_loss: 1343563478.5023\n",
      "Epoch 7819/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1273314668.3992 - val_loss: 1345354444.5662\n",
      "Epoch 7820/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1273805784.5479 - val_loss: 1343344049.3881\n",
      "Epoch 7821/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1273993015.4834 - val_loss: 1345547861.0411\n",
      "Epoch 7822/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1273632103.2016 - val_loss: 1345134916.0913\n",
      "Epoch 7823/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 33us/step - loss: 1273162239.4990 - val_loss: 1345255817.3516\n",
      "Epoch 7824/15000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1273287681.3777 - val_loss: 1344956744.1826\n",
      "Epoch 7825/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1273064922.6771 - val_loss: 1344666190.6119\n",
      "Epoch 7826/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1273220329.3307 - val_loss: 1343764551.3059\n",
      "Epoch 7827/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1272973011.4129 - val_loss: 1343962603.8356\n",
      "Epoch 7828/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1273131302.1996 - val_loss: 1344801809.8265\n",
      "Epoch 7829/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1272907724.9002 - val_loss: 1344545949.8082\n",
      "Epoch 7830/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1273469899.8982 - val_loss: 1343852418.9224\n",
      "Epoch 7831/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1273853312.0626 - val_loss: 1345403248.8037\n",
      "Epoch 7832/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1272790366.9354 - val_loss: 1344288719.7808\n",
      "Epoch 7833/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1273068538.4892 - val_loss: 1344433109.6256\n",
      "Epoch 7834/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1272768057.2368 - val_loss: 1343123567.6347\n",
      "Epoch 7835/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1272877661.6830 - val_loss: 1343933047.2329\n",
      "Epoch 7836/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1272672833.3151 - val_loss: 1343528115.1416\n",
      "Epoch 7837/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1272753378.7554 - val_loss: 1343156692.7489\n",
      "Epoch 7838/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1272666209.6908 - val_loss: 1343571467.1050\n",
      "Epoch 7839/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1272545293.2759 - val_loss: 1343640380.7854\n",
      "Epoch 7840/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1272527660.7123 - val_loss: 1343140495.4886\n",
      "Epoch 7841/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1272575287.1076 - val_loss: 1343731161.4247\n",
      "Epoch 7842/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1272665423.4051 - val_loss: 1343741595.1781\n",
      "Epoch 7843/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1272605910.2935 - val_loss: 1343312233.4977\n",
      "Epoch 7844/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1272666115.0059 - val_loss: 1343591390.3927\n",
      "Epoch 7845/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1273011549.0568 - val_loss: 1343973611.5434\n",
      "Epoch 7846/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1272207926.9824 - val_loss: 1343200257.7534\n",
      "Epoch 7847/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1272513019.6164 - val_loss: 1342797275.4703\n",
      "Epoch 7848/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1272769728.3757 - val_loss: 1343641638.2831\n",
      "Epoch 7849/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1272112636.7436 - val_loss: 1342964766.9772\n",
      "Epoch 7850/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1272136167.7025 - val_loss: 1342945294.9041\n",
      "Epoch 7851/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1272642501.8865 - val_loss: 1342451172.8219\n",
      "Epoch 7852/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1272190135.3581 - val_loss: 1343320819.4338\n",
      "Epoch 7853/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1272374131.0372 - val_loss: 1343870352.6575\n",
      "Epoch 7854/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1272146292.3523 - val_loss: 1342480396.8584\n",
      "Epoch 7855/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1272114554.9902 - val_loss: 1343028762.0091\n",
      "Epoch 7856/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1272116207.7182 - val_loss: 1341957243.0320\n",
      "Epoch 7857/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1272166760.3288 - val_loss: 1342608722.4110\n",
      "Epoch 7858/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1272148939.8982 - val_loss: 1342867259.3242\n",
      "Epoch 7859/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1272055752.1409 - val_loss: 1341807705.7169\n",
      "Epoch 7860/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1271732905.0802 - val_loss: 1342660716.7123\n",
      "Epoch 7861/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1271864136.6419 - val_loss: 1341919190.2100\n",
      "Epoch 7862/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1271717515.3973 - val_loss: 1342654445.5890\n",
      "Epoch 7863/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1271593614.0900 - val_loss: 1342456606.3927\n",
      "Epoch 7864/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1271773061.3855 - val_loss: 1342077118.5388\n",
      "Epoch 7865/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1272333735.9530 - val_loss: 1340773708.5662\n",
      "Epoch 7866/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1271819574.1057 - val_loss: 1342596103.8904\n",
      "Epoch 7867/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1271638430.6849 - val_loss: 1342007473.9726\n",
      "Epoch 7868/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1271721245.8082 - val_loss: 1342917211.7626\n",
      "Epoch 7869/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1271545081.9883 - val_loss: 1342268325.1142\n",
      "Epoch 7870/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1271763002.1135 - val_loss: 1340617560.2557\n",
      "Epoch 7871/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1271305681.1585 - val_loss: 1341754547.1416\n",
      "Epoch 7872/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1271672031.5616 - val_loss: 1341623296.5845\n",
      "Epoch 7873/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1271678568.5793 - val_loss: 1342815284.3105\n",
      "Epoch 7874/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1271351329.3151 - val_loss: 1342043779.5068\n",
      "Epoch 7875/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1272206453.2290 - val_loss: 1342509157.4064\n",
      "Epoch 7876/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1271392870.3249 - val_loss: 1340938166.0639\n",
      "Epoch 7877/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1271667621.6986 - val_loss: 1342151326.6849\n",
      "Epoch 7878/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1271126540.0235 - val_loss: 1341446182.8676\n",
      "Epoch 7879/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1271823422.1213 - val_loss: 1340348258.7763\n",
      "Epoch 7880/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1272179157.4168 - val_loss: 1342152265.3516\n",
      "Epoch 7881/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1271860052.9785 - val_loss: 1341154672.2192\n",
      "Epoch 7882/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1271390387.9765 - val_loss: 1341600577.7534\n",
      "Epoch 7883/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1271168417.5656 - val_loss: 1340426907.1781\n",
      "Epoch 7884/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1271108237.9022 - val_loss: 1341526852.3836\n",
      "Epoch 7885/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1271164492.0235 - val_loss: 1342049508.2374\n",
      "Epoch 7886/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1270895969.6908 - val_loss: 1340654087.8904\n",
      "Epoch 7887/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 31us/step - loss: 1271046396.7436 - val_loss: 1340063583.8539\n",
      "Epoch 7888/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1270869143.5460 - val_loss: 1341092985.2785\n",
      "Epoch 7889/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1270789129.7691 - val_loss: 1340654749.5160\n",
      "Epoch 7890/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1270675108.1331 - val_loss: 1340963682.4840\n",
      "Epoch 7891/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1270890800.2192 - val_loss: 1340687595.2511\n",
      "Epoch 7892/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1270876478.3718 - val_loss: 1340781696.5845\n",
      "Epoch 7893/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1271223011.3190 - val_loss: 1340852806.4292\n",
      "Epoch 7894/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1271219561.8317 - val_loss: 1338774902.3562\n",
      "Epoch 7895/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1270407790.5910 - val_loss: 1339955107.9452\n",
      "Epoch 7896/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1270926081.3777 - val_loss: 1341282810.4475\n",
      "Epoch 7897/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1271523139.8200 - val_loss: 1339827942.5753\n",
      "Epoch 7898/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1271573115.7417 - val_loss: 1341984378.7397\n",
      "Epoch 7899/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1270514441.5186 - val_loss: 1341308038.4292\n",
      "Epoch 7900/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1270526929.6595 - val_loss: 1339641031.5982\n",
      "Epoch 7901/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1270808944.5949 - val_loss: 1340515630.7580\n",
      "Epoch 7902/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1271368047.9061 - val_loss: 1338348887.9635\n",
      "Epoch 7903/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1271755728.7828 - val_loss: 1340980017.9726\n",
      "Epoch 7904/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1270385348.8845 - val_loss: 1340666982.2831\n",
      "Epoch 7905/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1271042750.1213 - val_loss: 1339555514.1553\n",
      "Epoch 7906/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1270789990.7006 - val_loss: 1339987296.7306\n",
      "Epoch 7907/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1270181686.9824 - val_loss: 1340129673.0594\n",
      "Epoch 7908/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1270509382.8885 - val_loss: 1340506959.4886\n",
      "Epoch 7909/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1270052802.0039 - val_loss: 1339346648.2557\n",
      "Epoch 7910/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1270283671.4207 - val_loss: 1339772405.4795\n",
      "Epoch 7911/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1270150876.5558 - val_loss: 1339677105.6804\n",
      "Epoch 7912/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1269977141.6047 - val_loss: 1338872826.1553\n",
      "Epoch 7913/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1270220273.3464 - val_loss: 1339950036.1644\n",
      "Epoch 7914/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1270344723.1624 - val_loss: 1340165675.2511\n",
      "Epoch 7915/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1270021098.6771 - val_loss: 1338956076.1279\n",
      "Epoch 7916/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1269845187.5695 - val_loss: 1339015699.8721\n",
      "Epoch 7917/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1269742460.6184 - val_loss: 1339324317.8082\n",
      "Epoch 7918/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1269992767.3738 - val_loss: 1338106454.5023\n",
      "Epoch 7919/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1270073222.0117 - val_loss: 1339875833.2785\n",
      "Epoch 7920/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1269747845.7613 - val_loss: 1339527442.4110\n",
      "Epoch 7921/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1270309194.5205 - val_loss: 1339578422.9406\n",
      "Epoch 7922/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1270201016.1096 - val_loss: 1340090998.6484\n",
      "Epoch 7923/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1270318615.0450 - val_loss: 1339137847.8174\n",
      "Epoch 7924/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1269797018.5519 - val_loss: 1337953829.6986\n",
      "Epoch 7925/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1269916184.0470 - val_loss: 1337478133.1872\n",
      "Epoch 7926/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1269423831.1703 - val_loss: 1337923856.3653\n",
      "Epoch 7927/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1270464504.4853 - val_loss: 1338792381.0776\n",
      "Epoch 7928/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1269782290.4110 - val_loss: 1338685347.9452\n",
      "Epoch 7929/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1269692631.9217 - val_loss: 1339473373.8082\n",
      "Epoch 7930/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1269590128.7202 - val_loss: 1338036417.4612\n",
      "Epoch 7931/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1269647804.8689 - val_loss: 1337807601.6804\n",
      "Epoch 7932/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1269317131.7730 - val_loss: 1338706935.2329\n",
      "Epoch 7933/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1269549327.0294 - val_loss: 1339201261.2968\n",
      "Epoch 7934/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1269199482.4892 - val_loss: 1338884396.7123\n",
      "Epoch 7935/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1271165645.5890 - val_loss: 1336335730.8493\n",
      "Epoch 7936/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1269257777.8474 - val_loss: 1338850081.8995\n",
      "Epoch 7937/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1269120292.8219 - val_loss: 1338507772.4932\n",
      "Epoch 7938/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1269352820.2270 - val_loss: 1339313139.7260\n",
      "Epoch 7939/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1269006870.1683 - val_loss: 1338240870.8676\n",
      "Epoch 7940/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1269180228.3836 - val_loss: 1338136502.6484\n",
      "Epoch 7941/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1269078064.0939 - val_loss: 1337077501.6621\n",
      "Epoch 7942/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1268964242.9119 - val_loss: 1337888728.8402\n",
      "Epoch 7943/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1268971677.1820 - val_loss: 1338397173.7717\n",
      "Epoch 7944/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1268993127.2016 - val_loss: 1338520081.8265\n",
      "Epoch 7945/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1268999261.1820 - val_loss: 1337251674.3014\n",
      "Epoch 7946/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1269341826.5049 - val_loss: 1338445133.1507\n",
      "Epoch 7947/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1268878025.1429 - val_loss: 1336967905.6073\n",
      "Epoch 7948/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1269021465.9883 - val_loss: 1336558697.4977\n",
      "Epoch 7949/15000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1268957036.3366 - val_loss: 1336941142.7945\n",
      "Epoch 7950/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1268668973.0881 - val_loss: 1336883371.2511\n",
      "Epoch 7951/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 39us/step - loss: 1268671015.8278 - val_loss: 1337883787.1050\n",
      "Epoch 7952/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1268775057.2838 - val_loss: 1338355381.1872\n",
      "Epoch 7953/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1268695267.1937 - val_loss: 1337961038.6119\n",
      "Epoch 7954/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1269183716.4462 - val_loss: 1338137776.8037\n",
      "Epoch 7955/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1268523212.3992 - val_loss: 1337140281.5708\n",
      "Epoch 7956/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1268582194.5988 - val_loss: 1337373693.0776\n",
      "Epoch 7957/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1268515384.3601 - val_loss: 1336999313.5342\n",
      "Epoch 7958/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1268607362.2544 - val_loss: 1337087343.9269\n",
      "Epoch 7959/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1268547655.7652 - val_loss: 1336777142.0639\n",
      "Epoch 7960/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1268544072.1409 - val_loss: 1336345130.3744\n",
      "Epoch 7961/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1268485550.0900 - val_loss: 1336571391.4155\n",
      "Epoch 7962/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1268272228.5714 - val_loss: 1336550738.7032\n",
      "Epoch 7963/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1268522622.2466 - val_loss: 1337129829.1142\n",
      "Epoch 7964/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1268493361.5969 - val_loss: 1336769287.8904\n",
      "Epoch 7965/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1268519899.5538 - val_loss: 1337370513.2420\n",
      "Epoch 7966/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1268230000.2192 - val_loss: 1336920027.4703\n",
      "Epoch 7967/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1268151202.3170 - val_loss: 1335699453.9543\n",
      "Epoch 7968/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1268185387.2094 - val_loss: 1335203358.9772\n",
      "Epoch 7969/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1268499327.4990 - val_loss: 1337301655.0868\n",
      "Epoch 7970/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1268108875.5225 - val_loss: 1335897285.8447\n",
      "Epoch 7971/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1268103714.3170 - val_loss: 1336102511.6347\n",
      "Epoch 7972/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1267848463.7808 - val_loss: 1336203837.9543\n",
      "Epoch 7973/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1268258674.7241 - val_loss: 1335404410.1553\n",
      "Epoch 7974/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1267839884.7750 - val_loss: 1335943442.9954\n",
      "Epoch 7975/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1267920734.6849 - val_loss: 1336481383.4521\n",
      "Epoch 7976/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1267971319.9843 - val_loss: 1335202623.7078\n",
      "Epoch 7977/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1268005225.5812 - val_loss: 1335512528.9498\n",
      "Epoch 7978/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1267770638.9041 - val_loss: 1335186722.7763\n",
      "Epoch 7979/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1267849771.8356 - val_loss: 1336225107.5799\n",
      "Epoch 7980/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1268597334.6693 - val_loss: 1336150856.1826\n",
      "Epoch 7981/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1267713999.5303 - val_loss: 1335151664.8037\n",
      "Epoch 7982/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1267871169.6908 - val_loss: 1334665808.3653\n",
      "Epoch 7983/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1267631413.2916 - val_loss: 1335859896.6941\n",
      "Epoch 7984/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1267528682.4579 - val_loss: 1335801586.2648\n",
      "Epoch 7985/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1267574623.9374 - val_loss: 1335735092.3105\n",
      "Epoch 7986/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1267825197.8395 - val_loss: 1335898986.9589\n",
      "Epoch 7987/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1267926629.9491 - val_loss: 1334746195.5799\n",
      "Epoch 7988/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1267339315.0998 - val_loss: 1334946218.3744\n",
      "Epoch 7989/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1267538870.4814 - val_loss: 1335609556.7489\n",
      "Epoch 7990/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1267562595.4442 - val_loss: 1335741469.2237\n",
      "Epoch 7991/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1267485710.9041 - val_loss: 1336075867.1781\n",
      "Epoch 7992/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1267523625.4560 - val_loss: 1336238751.5616\n",
      "Epoch 7993/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1267349091.1937 - val_loss: 1334424593.5342\n",
      "Epoch 7994/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1267472946.3483 - val_loss: 1334771972.6758\n",
      "Epoch 7995/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1267155246.8415 - val_loss: 1334799971.6530\n",
      "Epoch 7996/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1267136730.1761 - val_loss: 1334825445.4064\n",
      "Epoch 7997/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1267311755.2720 - val_loss: 1335769476.9680\n",
      "Epoch 7998/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1267429017.2994 - val_loss: 1334326667.9817\n",
      "Epoch 7999/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1267045320.7671 - val_loss: 1334830365.5160\n",
      "Epoch 8000/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1267376468.9159 - val_loss: 1334418596.5297\n",
      "Epoch 8001/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1267134017.8787 - val_loss: 1334629951.7078\n",
      "Epoch 8002/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1266840937.9569 - val_loss: 1334904533.9178\n",
      "Epoch 8003/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1267243685.3229 - val_loss: 1334456363.2511\n",
      "Epoch 8004/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1267060157.8708 - val_loss: 1335114715.4703\n",
      "Epoch 8005/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1267139274.4579 - val_loss: 1335674796.1279\n",
      "Epoch 8006/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1267359057.1585 - val_loss: 1333981906.9954\n",
      "Epoch 8007/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1267543931.3659 - val_loss: 1335972098.3379\n",
      "Epoch 8008/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1267615901.0568 - val_loss: 1333170741.7717\n",
      "Epoch 8009/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1267251309.4638 - val_loss: 1334952755.4338\n",
      "Epoch 8010/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1267106286.0900 - val_loss: 1334291788.2740\n",
      "Epoch 8011/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1266874304.8767 - val_loss: 1334382745.1324\n",
      "Epoch 8012/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1266637939.9765 - val_loss: 1334621337.1324\n",
      "Epoch 8013/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1266729095.2642 - val_loss: 1333786060.2740\n",
      "Epoch 8014/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1266728971.5225 - val_loss: 1333726107.7626\n",
      "Epoch 8015/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 29us/step - loss: 1266592235.8356 - val_loss: 1334632934.5753\n",
      "Epoch 8016/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1266769301.9178 - val_loss: 1333274393.7169\n",
      "Epoch 8017/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1266748901.9491 - val_loss: 1332484176.6575\n",
      "Epoch 8018/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1266975198.3092 - val_loss: 1334542566.5753\n",
      "Epoch 8019/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1266853590.9198 - val_loss: 1335333136.6575\n",
      "Epoch 8020/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1266539049.0802 - val_loss: 1332678656.8767\n",
      "Epoch 8021/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1266698882.2544 - val_loss: 1333698078.3927\n",
      "Epoch 8022/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1266340448.0626 - val_loss: 1333292899.3607\n",
      "Epoch 8023/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1266264123.9922 - val_loss: 1333949979.4703\n",
      "Epoch 8024/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1266548786.7867 - val_loss: 1332897648.2192\n",
      "Epoch 8025/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1266565076.9159 - val_loss: 1334753369.4247\n",
      "Epoch 8026/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1266396976.5949 - val_loss: 1332699590.7215\n",
      "Epoch 8027/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1266556754.2857 - val_loss: 1334055294.2466\n",
      "Epoch 8028/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1266280175.4051 - val_loss: 1333176372.3105\n",
      "Epoch 8029/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1266076070.4501 - val_loss: 1334087575.9635\n",
      "Epoch 8030/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1266200038.4501 - val_loss: 1332923584.8767\n",
      "Epoch 8031/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1266456822.8571 - val_loss: 1331841632.1461\n",
      "Epoch 8032/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1266085807.9687 - val_loss: 1333500969.2055\n",
      "Epoch 8033/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1265970522.6771 - val_loss: 1333564114.1187\n",
      "Epoch 8034/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1266233692.9315 - val_loss: 1333150210.3379\n",
      "Epoch 8035/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1266088257.8787 - val_loss: 1333118472.7671\n",
      "Epoch 8036/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1266181584.6575 - val_loss: 1333401568.7306\n",
      "Epoch 8037/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1266273426.0352 - val_loss: 1333848748.4201\n",
      "Epoch 8038/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1265961849.2368 - val_loss: 1333320637.6621\n",
      "Epoch 8039/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1265740321.6908 - val_loss: 1333572677.2603\n",
      "Epoch 8040/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1266095476.0391 - val_loss: 1333503839.8539\n",
      "Epoch 8041/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1267319317.0411 - val_loss: 1331372705.3151\n",
      "Epoch 8042/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1266281438.0587 - val_loss: 1332340590.7580\n",
      "Epoch 8043/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1266197216.9393 - val_loss: 1331363055.3425\n",
      "Epoch 8044/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1265682878.9980 - val_loss: 1333126263.8174\n",
      "Epoch 8045/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1265890904.6106 - val_loss: 1332565115.9087\n",
      "Epoch 8046/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1266062158.1526 - val_loss: 1331401074.5571\n",
      "Epoch 8047/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1265525348.1957 - val_loss: 1332290601.2055\n",
      "Epoch 8048/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1266192403.4755 - val_loss: 1332501893.2603\n",
      "Epoch 8049/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1265898492.9941 - val_loss: 1332878622.9772\n",
      "Epoch 8050/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1265418900.7906 - val_loss: 1332495088.2192\n",
      "Epoch 8051/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1266400800.0626 - val_loss: 1331997781.9178\n",
      "Epoch 8052/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1265691979.3973 - val_loss: 1333830249.7900\n",
      "Epoch 8053/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1265737291.6477 - val_loss: 1331552073.6438\n",
      "Epoch 8054/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1265691901.1194 - val_loss: 1332803133.3699\n",
      "Epoch 8055/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1265601402.6771 - val_loss: 1333343588.8219\n",
      "Epoch 8056/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1265433375.9374 - val_loss: 1331910632.3288\n",
      "Epoch 8057/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1265455573.3542 - val_loss: 1331818029.2968\n",
      "Epoch 8058/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1265184785.4090 - val_loss: 1332407821.1507\n",
      "Epoch 8059/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1265116430.0274 - val_loss: 1332411873.3151\n",
      "Epoch 8060/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1265096047.7182 - val_loss: 1330877256.1826\n",
      "Epoch 8061/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1264960053.2290 - val_loss: 1331649419.3973\n",
      "Epoch 8062/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1265375141.8239 - val_loss: 1330462673.2420\n",
      "Epoch 8063/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1265389332.5401 - val_loss: 1330716775.1598\n",
      "Epoch 8064/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1265363049.5812 - val_loss: 1332624019.8721\n",
      "Epoch 8065/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1265298942.2466 - val_loss: 1332406473.3516\n",
      "Epoch 8066/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1265970055.8278 - val_loss: 1330452167.0137\n",
      "Epoch 8067/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1264976909.7769 - val_loss: 1332220269.5890\n",
      "Epoch 8068/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1265369227.7730 - val_loss: 1330910504.0365\n",
      "Epoch 8069/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1264993103.9061 - val_loss: 1332587201.7534\n",
      "Epoch 8070/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1264921664.3757 - val_loss: 1332253122.0457\n",
      "Epoch 8071/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1265052267.2094 - val_loss: 1332436359.5982\n",
      "Epoch 8072/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1264900728.1096 - val_loss: 1331977226.8128\n",
      "Epoch 8073/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1264901644.9628 - val_loss: 1331060655.6347\n",
      "Epoch 8074/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1264936255.4990 - val_loss: 1331914752.8767\n",
      "Epoch 8075/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1264568923.8043 - val_loss: 1331048738.7763\n",
      "Epoch 8076/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1264824860.0548 - val_loss: 1330949335.9635\n",
      "Epoch 8077/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1264845478.7006 - val_loss: 1329635010.0457\n",
      "Epoch 8078/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1265813264.6575 - val_loss: 1331261991.7443\n",
      "Epoch 8079/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 32us/step - loss: 1264665054.9354 - val_loss: 1331379354.8858\n",
      "Epoch 8080/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1264904853.2916 - val_loss: 1329772400.8037\n",
      "Epoch 8081/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1264507904.9393 - val_loss: 1330311599.3425\n",
      "Epoch 8082/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1265836498.3483 - val_loss: 1328795141.2603\n",
      "Epoch 8083/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1264466837.5421 - val_loss: 1331092192.7306\n",
      "Epoch 8084/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1264460980.8532 - val_loss: 1331370946.9224\n",
      "Epoch 8085/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1264595089.7847 - val_loss: 1331888578.3379\n",
      "Epoch 8086/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1264793912.5479 - val_loss: 1329286323.7260\n",
      "Epoch 8087/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1264331659.7730 - val_loss: 1330755575.5251\n",
      "Epoch 8088/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1264487427.3816 - val_loss: 1330905123.6530\n",
      "Epoch 8089/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1264249517.5890 - val_loss: 1329559918.1735\n",
      "Epoch 8090/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1264441491.2877 - val_loss: 1328872223.5616\n",
      "Epoch 8091/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1264681705.7065 - val_loss: 1331039499.9817\n",
      "Epoch 8092/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1264062819.0685 - val_loss: 1330570688.2922\n",
      "Epoch 8093/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1263985591.3581 - val_loss: 1330233468.7854\n",
      "Epoch 8094/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1264332112.6575 - val_loss: 1330122934.3562\n",
      "Epoch 8095/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1264723834.6145 - val_loss: 1328067968.0000\n",
      "Epoch 8096/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1263962457.4247 - val_loss: 1328915237.1142\n",
      "Epoch 8097/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1264731186.7241 - val_loss: 1330951208.0365\n",
      "Epoch 8098/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1265103819.7730 - val_loss: 1328796745.6438\n",
      "Epoch 8099/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1264011405.2759 - val_loss: 1329379844.6758\n",
      "Epoch 8100/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1263926304.3131 - val_loss: 1330547279.7808\n",
      "Epoch 8101/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1263800396.0235 - val_loss: 1329640460.8584\n",
      "Epoch 8102/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1264777752.5479 - val_loss: 1331508135.4521\n",
      "Epoch 8103/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1263857945.1742 - val_loss: 1328992893.0776\n",
      "Epoch 8104/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1263976179.2250 - val_loss: 1329200277.6256\n",
      "Epoch 8105/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1263808887.6086 - val_loss: 1330351591.1598\n",
      "Epoch 8106/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1264055526.9511 - val_loss: 1328755211.3973\n",
      "Epoch 8107/15000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1263512242.8493 - val_loss: 1329651522.0457\n",
      "Epoch 8108/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1263921395.6008 - val_loss: 1330104556.1279\n",
      "Epoch 8109/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1263736776.6419 - val_loss: 1328808640.0000\n",
      "Epoch 8110/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1263344585.7065 - val_loss: 1329170812.2009\n",
      "Epoch 8111/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1264235168.3131 - val_loss: 1330668937.3516\n",
      "Epoch 8112/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1263437033.2055 - val_loss: 1329100076.1279\n",
      "Epoch 8113/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1263315964.4932 - val_loss: 1329429706.2283\n",
      "Epoch 8114/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1263634750.2466 - val_loss: 1329776476.3470\n",
      "Epoch 8115/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1263385001.8317 - val_loss: 1328837091.9452\n",
      "Epoch 8116/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1263683751.4521 - val_loss: 1328399707.7626\n",
      "Epoch 8117/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1263315882.0822 - val_loss: 1329093633.1689\n",
      "Epoch 8118/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1263979927.4207 - val_loss: 1328746301.9543\n",
      "Epoch 8119/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1263679292.8689 - val_loss: 1328151360.0000\n",
      "Epoch 8120/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1264860939.8982 - val_loss: 1330400066.0457\n",
      "Epoch 8121/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1263324869.3229 - val_loss: 1328358929.8265\n",
      "Epoch 8122/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1263177322.8337 - val_loss: 1328325698.9224\n",
      "Epoch 8123/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1263355527.2642 - val_loss: 1329244904.3288\n",
      "Epoch 8124/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1263556259.9452 - val_loss: 1328850276.2374\n",
      "Epoch 8125/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1262894284.5871 - val_loss: 1328769666.9224\n",
      "Epoch 8126/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1264324288.0000 - val_loss: 1329370344.9132\n",
      "Epoch 8127/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1263221086.1840 - val_loss: 1327123939.0685\n",
      "Epoch 8128/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1263174746.1761 - val_loss: 1327941255.3059\n",
      "Epoch 8129/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1263079974.0744 - val_loss: 1327049225.0594\n",
      "Epoch 8130/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1263163143.6399 - val_loss: 1328871817.6438\n",
      "Epoch 8131/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1263401732.7593 - val_loss: 1327856164.2374\n",
      "Epoch 8132/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1263093538.3170 - val_loss: 1328701064.7671\n",
      "Epoch 8133/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1263324283.1155 - val_loss: 1328699441.0959\n",
      "Epoch 8134/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1264516704.6888 - val_loss: 1326266198.5023\n",
      "Epoch 8135/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1262696618.7084 - val_loss: 1328031366.4292\n",
      "Epoch 8136/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1262627313.9726 - val_loss: 1327995337.0594\n",
      "Epoch 8137/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1262914242.5675 - val_loss: 1328180119.9635\n",
      "Epoch 8138/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1263784677.8239 - val_loss: 1327295472.5114\n",
      "Epoch 8139/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1263004821.3542 - val_loss: 1329088296.6210\n",
      "Epoch 8140/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1262731489.9413 - val_loss: 1327843513.5708\n",
      "Epoch 8141/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1262790621.6830 - val_loss: 1328508613.2603\n",
      "Epoch 8142/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1262561225.3933 - val_loss: 1327670485.9178\n",
      "Epoch 8143/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 29us/step - loss: 1263427468.8376 - val_loss: 1326560170.3744\n",
      "Epoch 8144/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1262357485.2133 - val_loss: 1327436126.1005\n",
      "Epoch 8145/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1262653397.2916 - val_loss: 1327639836.3470\n",
      "Epoch 8146/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1262524827.4286 - val_loss: 1328208370.2648\n",
      "Epoch 8147/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1262309037.8395 - val_loss: 1327480137.9361\n",
      "Epoch 8148/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1262567083.0841 - val_loss: 1327621816.1096\n",
      "Epoch 8149/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1262857784.1096 - val_loss: 1328230668.2740\n",
      "Epoch 8150/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1262822765.2133 - val_loss: 1327172981.4795\n",
      "Epoch 8151/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1262327316.5401 - val_loss: 1328021621.1872\n",
      "Epoch 8152/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1262700317.0568 - val_loss: 1326309122.6301\n",
      "Epoch 8153/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1262356709.5734 - val_loss: 1326649469.6621\n",
      "Epoch 8154/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1262262157.9022 - val_loss: 1327116552.1826\n",
      "Epoch 8155/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1262139610.0509 - val_loss: 1327672555.2511\n",
      "Epoch 8156/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1262317162.8337 - val_loss: 1328222922.8128\n",
      "Epoch 8157/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1262286839.5460 - val_loss: 1327405898.8128\n",
      "Epoch 8158/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1263166289.9726 - val_loss: 1325654739.5799\n",
      "Epoch 8159/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1262319236.5088 - val_loss: 1326797968.0731\n",
      "Epoch 8160/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1262064654.9041 - val_loss: 1326296052.3105\n",
      "Epoch 8161/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1262287221.6673 - val_loss: 1326766583.2329\n",
      "Epoch 8162/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1262213954.3796 - val_loss: 1327479417.8630\n",
      "Epoch 8163/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1262146621.4325 - val_loss: 1327487144.9132\n",
      "Epoch 8164/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1262223303.3894 - val_loss: 1326464115.1416\n",
      "Epoch 8165/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1261876955.4286 - val_loss: 1326474719.5616\n",
      "Epoch 8166/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1262212318.6849 - val_loss: 1327710150.4292\n",
      "Epoch 8167/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1261890932.4775 - val_loss: 1325758681.7169\n",
      "Epoch 8168/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1261750241.9413 - val_loss: 1327042707.5799\n",
      "Epoch 8169/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1262154082.8806 - val_loss: 1325243237.4064\n",
      "Epoch 8170/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1261720195.8826 - val_loss: 1326903673.5708\n",
      "Epoch 8171/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1261953563.0528 - val_loss: 1325557377.4612\n",
      "Epoch 8172/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1261873330.8493 - val_loss: 1326186164.8950\n",
      "Epoch 8173/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1261790157.7769 - val_loss: 1325879330.1918\n",
      "Epoch 8174/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1261693205.1663 - val_loss: 1326478094.6119\n",
      "Epoch 8175/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1262002647.2955 - val_loss: 1327401014.3562\n",
      "Epoch 8176/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1261515266.0039 - val_loss: 1325778057.3516\n",
      "Epoch 8177/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1261679617.6282 - val_loss: 1326532622.0274\n",
      "Epoch 8178/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1261482205.8082 - val_loss: 1325577360.6575\n",
      "Epoch 8179/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1261644378.0509 - val_loss: 1325911457.6073\n",
      "Epoch 8180/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1261638966.2935 - val_loss: 1326650386.7032\n",
      "Epoch 8181/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1261779028.6654 - val_loss: 1325658359.8174\n",
      "Epoch 8182/15000\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 1261804004.1957 - val_loss: 1326927371.3973\n",
      "Epoch 8183/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1261260208.0939 - val_loss: 1325665442.1918\n",
      "Epoch 8184/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1261322473.4560 - val_loss: 1325691114.6667\n",
      "Epoch 8185/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1261246219.1468 - val_loss: 1325707366.2831\n",
      "Epoch 8186/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1261465882.6771 - val_loss: 1326607811.5068\n",
      "Epoch 8187/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1261749439.8748 - val_loss: 1324464729.1324\n",
      "Epoch 8188/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1261831471.4677 - val_loss: 1324442628.3836\n",
      "Epoch 8189/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1261706061.6517 - val_loss: 1326103724.1279\n",
      "Epoch 8190/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1261291658.2701 - val_loss: 1326713813.9178\n",
      "Epoch 8191/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1261391158.4814 - val_loss: 1326291508.6027\n",
      "Epoch 8192/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1261116868.8845 - val_loss: 1325413875.4338\n",
      "Epoch 8193/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1261038375.7025 - val_loss: 1325108159.7078\n",
      "Epoch 8194/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1260880923.8043 - val_loss: 1325375468.1279\n",
      "Epoch 8195/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1261068857.1115 - val_loss: 1324750347.6895\n",
      "Epoch 8196/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1261181428.8845 - val_loss: 1324936402.4110\n",
      "Epoch 8197/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1261058966.0431 - val_loss: 1325074128.3653\n",
      "Epoch 8198/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1260754353.2211 - val_loss: 1325321664.2922\n",
      "Epoch 8199/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1260847183.4051 - val_loss: 1325990415.7808\n",
      "Epoch 8200/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1261410442.9589 - val_loss: 1324617562.5936\n",
      "Epoch 8201/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1260928719.6556 - val_loss: 1325540348.4932\n",
      "Epoch 8202/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1260806004.2270 - val_loss: 1325494139.9087\n",
      "Epoch 8203/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1261422511.8434 - val_loss: 1323433250.7763\n",
      "Epoch 8204/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1261162221.7143 - val_loss: 1325261619.1416\n",
      "Epoch 8205/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1260922977.0646 - val_loss: 1325689524.8950\n",
      "Epoch 8206/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1260810958.2153 - val_loss: 1324690337.0228\n",
      "Epoch 8207/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 33us/step - loss: 1261389420.9628 - val_loss: 1326040299.5434\n",
      "Epoch 8208/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1261252869.7613 - val_loss: 1323542549.9178\n",
      "Epoch 8209/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1261385991.1389 - val_loss: 1325050487.8174\n",
      "Epoch 8210/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1260631270.9511 - val_loss: 1324446600.7671\n",
      "Epoch 8211/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1260863327.5616 - val_loss: 1323877843.5799\n",
      "Epoch 8212/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1260830146.7554 - val_loss: 1325479192.2557\n",
      "Epoch 8213/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1260527914.5832 - val_loss: 1325472121.8630\n",
      "Epoch 8214/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1260363243.7104 - val_loss: 1324049570.7763\n",
      "Epoch 8215/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1260729994.7710 - val_loss: 1325371521.7534\n",
      "Epoch 8216/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1260851281.0333 - val_loss: 1324630526.5388\n",
      "Epoch 8217/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1260667643.2407 - val_loss: 1324458990.4658\n",
      "Epoch 8218/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1260551996.4932 - val_loss: 1324539503.0502\n",
      "Epoch 8219/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1261077426.3483 - val_loss: 1322484785.9726\n",
      "Epoch 8220/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1260109644.1487 - val_loss: 1324683819.8356\n",
      "Epoch 8221/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1260313690.8023 - val_loss: 1324710352.0731\n",
      "Epoch 8222/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1260339939.6947 - val_loss: 1324728402.4110\n",
      "Epoch 8223/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1260383667.3503 - val_loss: 1324204416.8767\n",
      "Epoch 8224/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1260188408.4853 - val_loss: 1323942508.7123\n",
      "Epoch 8225/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1260557994.8337 - val_loss: 1323682557.6621\n",
      "Epoch 8226/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1260021389.5890 - val_loss: 1323771314.5571\n",
      "Epoch 8227/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1260527232.2505 - val_loss: 1323583070.9772\n",
      "Epoch 8228/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1260159345.8474 - val_loss: 1323267395.7991\n",
      "Epoch 8229/15000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1260104867.0685 - val_loss: 1324506027.2511\n",
      "Epoch 8230/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1260268687.2798 - val_loss: 1322681238.2100\n",
      "Epoch 8231/15000\n",
      "1022/1022 [==============================] - 0s 115us/step - loss: 1260184543.9374 - val_loss: 1323910347.1050\n",
      "Epoch 8232/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1259991475.1624 - val_loss: 1323533582.9041\n",
      "Epoch 8233/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1259828282.8650 - val_loss: 1324092536.1096\n",
      "Epoch 8234/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1259900822.9198 - val_loss: 1323330187.1050\n",
      "Epoch 8235/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1260428651.4599 - val_loss: 1324449372.9315\n",
      "Epoch 8236/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1259767789.9648 - val_loss: 1323318953.2055\n",
      "Epoch 8237/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1259801674.8963 - val_loss: 1324014814.9772\n",
      "Epoch 8238/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1259819216.0313 - val_loss: 1323343098.7397\n",
      "Epoch 8239/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1260397233.3464 - val_loss: 1322355119.0502\n",
      "Epoch 8240/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1260361831.2016 - val_loss: 1324824530.4110\n",
      "Epoch 8241/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1259976910.3405 - val_loss: 1324035354.0091\n",
      "Epoch 8242/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1259661801.7691 - val_loss: 1323100188.9315\n",
      "Epoch 8243/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1259859555.2564 - val_loss: 1323180349.6621\n",
      "Epoch 8244/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1260335013.4481 - val_loss: 1321921962.6667\n",
      "Epoch 8245/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1259983620.6967 - val_loss: 1321788892.9315\n",
      "Epoch 8246/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1259543948.3992 - val_loss: 1323798468.6758\n",
      "Epoch 8247/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1259661037.0881 - val_loss: 1322297734.4292\n",
      "Epoch 8248/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1259528488.8924 - val_loss: 1323448054.3562\n",
      "Epoch 8249/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1259500776.0783 - val_loss: 1322494605.4429\n",
      "Epoch 8250/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1259689290.6458 - val_loss: 1322833268.8950\n",
      "Epoch 8251/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1259481338.9902 - val_loss: 1323883775.7078\n",
      "Epoch 8252/15000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1259365128.7671 - val_loss: 1323114476.4201\n",
      "Epoch 8253/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1259315399.1389 - val_loss: 1322633611.6895\n",
      "Epoch 8254/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1259242739.8513 - val_loss: 1322805043.7260\n",
      "Epoch 8255/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1259229147.8043 - val_loss: 1322865014.6484\n",
      "Epoch 8256/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1259675205.6360 - val_loss: 1322362748.4932\n",
      "Epoch 8257/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1259575347.4755 - val_loss: 1323840116.0183\n",
      "Epoch 8258/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1260145897.5812 - val_loss: 1322112081.2420\n",
      "Epoch 8259/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1259225905.3464 - val_loss: 1323424682.9589\n",
      "Epoch 8260/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1259167870.1213 - val_loss: 1323378044.2009\n",
      "Epoch 8261/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1259075580.4932 - val_loss: 1322378107.6164\n",
      "Epoch 8262/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1259218275.6947 - val_loss: 1321840387.2146\n",
      "Epoch 8263/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1259240726.5440 - val_loss: 1322801176.5479\n",
      "Epoch 8264/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1259425220.1957 - val_loss: 1320995063.5251\n",
      "Epoch 8265/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1259239891.0372 - val_loss: 1321597615.9269\n",
      "Epoch 8266/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1258877314.6301 - val_loss: 1321930230.6484\n",
      "Epoch 8267/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1259112297.2055 - val_loss: 1323031461.6986\n",
      "Epoch 8268/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1259342073.2368 - val_loss: 1322484187.1781\n",
      "Epoch 8269/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1259093310.4971 - val_loss: 1323029601.3151\n",
      "Epoch 8270/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1258853043.3503 - val_loss: 1321152971.1050\n",
      "Epoch 8271/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1259458470.7006 - val_loss: 1320488488.0365\n",
      "Epoch 8272/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1259377084.9941 - val_loss: 1322466291.4338\n",
      "Epoch 8273/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1258705499.1781 - val_loss: 1322062990.0274\n",
      "Epoch 8274/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1259006845.6204 - val_loss: 1321471645.8082\n",
      "Epoch 8275/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1259042194.5362 - val_loss: 1322383529.7900\n",
      "Epoch 8276/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1259106968.9863 - val_loss: 1321654935.0868\n",
      "Epoch 8277/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1258822716.0548 - val_loss: 1321127039.7078\n",
      "Epoch 8278/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1258700172.0235 - val_loss: 1322480418.7763\n",
      "Epoch 8279/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1258756334.2153 - val_loss: 1322664230.2831\n",
      "Epoch 8280/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1259413453.7769 - val_loss: 1320587768.4018\n",
      "Epoch 8281/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1258869988.4462 - val_loss: 1321315467.9817\n",
      "Epoch 8282/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1258504907.3973 - val_loss: 1321925982.3927\n",
      "Epoch 8283/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1258681072.0939 - val_loss: 1320862948.8219\n",
      "Epoch 8284/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1258745678.4031 - val_loss: 1321700389.1142\n",
      "Epoch 8285/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1258443609.0489 - val_loss: 1321944069.2603\n",
      "Epoch 8286/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1258456733.3072 - val_loss: 1320189648.3653\n",
      "Epoch 8287/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1258897099.8982 - val_loss: 1322035947.8356\n",
      "Epoch 8288/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1258672575.1233 - val_loss: 1321315217.8265\n",
      "Epoch 8289/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1258645240.8611 - val_loss: 1319995463.5982\n",
      "Epoch 8290/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1258191639.2955 - val_loss: 1321013852.3470\n",
      "Epoch 8291/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1258202754.4423 - val_loss: 1320603243.8356\n",
      "Epoch 8292/15000\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 1258568322.0039 - val_loss: 1322299821.2968\n",
      "Epoch 8293/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1258043222.6693 - val_loss: 1321549572.6758\n",
      "Epoch 8294/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1258356281.8630 - val_loss: 1321558878.1005\n",
      "Epoch 8295/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1258382094.7789 - val_loss: 1320365664.7306\n",
      "Epoch 8296/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1258173884.3679 - val_loss: 1320398530.3379\n",
      "Epoch 8297/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1258811728.4070 - val_loss: 1321660514.7763\n",
      "Epoch 8298/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1258477431.9843 - val_loss: 1320436249.7169\n",
      "Epoch 8299/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1258297252.5714 - val_loss: 1321614639.0502\n",
      "Epoch 8300/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1258316439.4834 - val_loss: 1321643756.4201\n",
      "Epoch 8301/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1257865719.8591 - val_loss: 1320144848.3653\n",
      "Epoch 8302/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1258078953.8317 - val_loss: 1320447617.4612\n",
      "Epoch 8303/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1258199547.7417 - val_loss: 1319524628.7489\n",
      "Epoch 8304/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1257768261.6360 - val_loss: 1320143638.7945\n",
      "Epoch 8305/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1258183210.4579 - val_loss: 1321488913.8265\n",
      "Epoch 8306/15000\n",
      "1022/1022 [==============================] - 0s 74us/step - loss: 1258410653.5577 - val_loss: 1322189878.0639\n",
      "Epoch 8307/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1258054450.3483 - val_loss: 1319789819.6164\n",
      "Epoch 8308/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1258257244.6184 - val_loss: 1320818475.5434\n",
      "Epoch 8309/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1257851532.2740 - val_loss: 1319887925.7717\n",
      "Epoch 8310/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1258030768.5949 - val_loss: 1320995504.2192\n",
      "Epoch 8311/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1258577415.5147 - val_loss: 1320462580.0183\n",
      "Epoch 8312/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1257587568.3444 - val_loss: 1320585730.6301\n",
      "Epoch 8313/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1257726681.4247 - val_loss: 1320117494.3562\n",
      "Epoch 8314/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1257625682.4110 - val_loss: 1320091434.9589\n",
      "Epoch 8315/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1257898910.0587 - val_loss: 1319998102.5023\n",
      "Epoch 8316/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1257616438.8571 - val_loss: 1319641768.0365\n",
      "Epoch 8317/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1257753537.5029 - val_loss: 1321089390.4658\n",
      "Epoch 8318/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1257578217.8943 - val_loss: 1319671998.8311\n",
      "Epoch 8319/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1257460805.2603 - val_loss: 1320557032.0365\n",
      "Epoch 8320/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1257704950.2309 - val_loss: 1321102741.3333\n",
      "Epoch 8321/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1257749081.9256 - val_loss: 1320658746.7397\n",
      "Epoch 8322/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1257605443.6321 - val_loss: 1319046037.6256\n",
      "Epoch 8323/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1258374816.4384 - val_loss: 1319939294.3927\n",
      "Epoch 8324/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1257479364.5088 - val_loss: 1320185455.3425\n",
      "Epoch 8325/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1257677830.7632 - val_loss: 1320804755.2877\n",
      "Epoch 8326/15000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1257282272.4384 - val_loss: 1320291909.5525\n",
      "Epoch 8327/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1257222130.7241 - val_loss: 1319063898.5936\n",
      "Epoch 8328/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1257276857.9883 - val_loss: 1319507186.8493\n",
      "Epoch 8329/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1257429223.4521 - val_loss: 1319751409.6804\n",
      "Epoch 8330/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1257718219.6477 - val_loss: 1318448933.9909\n",
      "Epoch 8331/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1257176270.9041 - val_loss: 1319121631.5616\n",
      "Epoch 8332/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1257325575.0137 - val_loss: 1320182645.1872\n",
      "Epoch 8333/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1258148742.2622 - val_loss: 1318937628.0548\n",
      "Epoch 8334/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1256979776.5010 - val_loss: 1319317612.4201\n",
      "Epoch 8335/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 36us/step - loss: 1257341680.9706 - val_loss: 1318332319.2694\n",
      "Epoch 8336/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1257605439.3738 - val_loss: 1320596219.3242\n",
      "Epoch 8337/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1257604884.0391 - val_loss: 1318524363.9817\n",
      "Epoch 8338/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1257027823.9687 - val_loss: 1318661653.6256\n",
      "Epoch 8339/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1256832655.4051 - val_loss: 1319312078.9041\n",
      "Epoch 8340/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1257186089.2055 - val_loss: 1319730555.9087\n",
      "Epoch 8341/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1256775333.9491 - val_loss: 1318968039.7443\n",
      "Epoch 8342/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1257893297.0959 - val_loss: 1318653614.7580\n",
      "Epoch 8343/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1257984187.7417 - val_loss: 1320491404.2740\n",
      "Epoch 8344/15000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1256863795.9139 - val_loss: 1319205411.6530\n",
      "Epoch 8345/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1257216965.1350 - val_loss: 1318877318.1370\n",
      "Epoch 8346/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1257063883.8982 - val_loss: 1319153324.7123\n",
      "Epoch 8347/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1257324394.8337 - val_loss: 1319480832.8767\n",
      "Epoch 8348/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1256673203.4755 - val_loss: 1319622776.4018\n",
      "Epoch 8349/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1256968556.7123 - val_loss: 1318568852.4566\n",
      "Epoch 8350/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1256939465.8943 - val_loss: 1317098513.5342\n",
      "Epoch 8351/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1256928038.4501 - val_loss: 1318340045.7352\n",
      "Epoch 8352/15000\n",
      "1022/1022 [==============================] - 0s 72us/step - loss: 1256640260.2583 - val_loss: 1319259088.6575\n",
      "Epoch 8353/15000\n",
      "1022/1022 [==============================] - 0s 97us/step - loss: 1256814424.6732 - val_loss: 1319078104.5479\n",
      "Epoch 8354/15000\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 1256882255.2798 - val_loss: 1317661572.6758\n",
      "Epoch 8355/15000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1256506713.2994 - val_loss: 1318007203.6530\n",
      "Epoch 8356/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1256425829.6986 - val_loss: 1318064455.5982\n",
      "Epoch 8357/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1256988349.6204 - val_loss: 1318216660.1644\n",
      "Epoch 8358/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1256575000.9237 - val_loss: 1318662850.3379\n",
      "Epoch 8359/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1256414472.5166 - val_loss: 1318864627.1416\n",
      "Epoch 8360/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1256761180.4305 - val_loss: 1319793221.2603\n",
      "Epoch 8361/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1256688525.9022 - val_loss: 1318196923.9087\n",
      "Epoch 8362/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1256417015.4834 - val_loss: 1319026597.6986\n",
      "Epoch 8363/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1256160768.5010 - val_loss: 1318453760.8767\n",
      "Epoch 8364/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1256092642.0039 - val_loss: 1318288286.9772\n",
      "Epoch 8365/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1256269144.4227 - val_loss: 1318715741.2237\n",
      "Epoch 8366/15000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1256426109.8082 - val_loss: 1317643182.7580\n",
      "Epoch 8367/15000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1256638696.0783 - val_loss: 1318227495.4521\n",
      "Epoch 8368/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1256214395.6164 - val_loss: 1318396043.3973\n",
      "Epoch 8369/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1256799186.6614 - val_loss: 1319202234.4475\n",
      "Epoch 8370/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1256171730.6614 - val_loss: 1316955609.1324\n",
      "Epoch 8371/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1256156101.7613 - val_loss: 1317529017.8630\n",
      "Epoch 8372/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1256020328.8297 - val_loss: 1318132020.6027\n",
      "Epoch 8373/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1256093717.6047 - val_loss: 1317487517.8082\n",
      "Epoch 8374/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1256145961.0802 - val_loss: 1316442368.5845\n",
      "Epoch 8375/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1256290943.7495 - val_loss: 1317537813.0411\n",
      "Epoch 8376/15000\n",
      "1022/1022 [==============================] - 0s 79us/step - loss: 1256736925.1820 - val_loss: 1316701692.7854\n",
      "Epoch 8377/15000\n",
      "1022/1022 [==============================] - 0s 73us/step - loss: 1255918800.0313 - val_loss: 1318273194.3744\n",
      "Epoch 8378/15000\n",
      "1022/1022 [==============================] - 0s 67us/step - loss: 1256235045.3229 - val_loss: 1317722098.2648\n",
      "Epoch 8379/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1256741371.8669 - val_loss: 1317460679.5982\n",
      "Epoch 8380/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1255890712.7984 - val_loss: 1318306410.3744\n",
      "Epoch 8381/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1255745420.5245 - val_loss: 1318465156.0913\n",
      "Epoch 8382/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1255980160.5010 - val_loss: 1317179640.6941\n",
      "Epoch 8383/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1255774884.4462 - val_loss: 1316864764.7854\n",
      "Epoch 8384/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1256993654.6067 - val_loss: 1318227735.0868\n",
      "Epoch 8385/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1255850941.4951 - val_loss: 1316944269.7352\n",
      "Epoch 8386/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1255735572.7906 - val_loss: 1317177467.3242\n",
      "Epoch 8387/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1256174249.5812 - val_loss: 1317180599.2329\n",
      "Epoch 8388/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1256052884.4149 - val_loss: 1318520574.8311\n",
      "Epoch 8389/15000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1255778376.3914 - val_loss: 1317078504.9132\n",
      "Epoch 8390/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1255592238.4031 - val_loss: 1317667020.5662\n",
      "Epoch 8391/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1255705991.4521 - val_loss: 1317261606.8676\n",
      "Epoch 8392/15000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1256279366.7632 - val_loss: 1318688554.3744\n",
      "Epoch 8393/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1255372991.8748 - val_loss: 1316943328.7306\n",
      "Epoch 8394/15000\n",
      "1022/1022 [==============================] - 0s 67us/step - loss: 1255536903.3268 - val_loss: 1317377663.4155\n",
      "Epoch 8395/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1255437163.4599 - val_loss: 1316600606.6849\n",
      "Epoch 8396/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1255438363.5538 - val_loss: 1317137079.5251\n",
      "Epoch 8397/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1255771458.5675 - val_loss: 1317605733.6986\n",
      "Epoch 8398/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1255539960.3601 - val_loss: 1316846420.4566\n",
      "Epoch 8399/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 59us/step - loss: 1255232876.2114 - val_loss: 1316875811.9452\n",
      "Epoch 8400/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1255512211.0372 - val_loss: 1316455372.8584\n",
      "Epoch 8401/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1255681396.2270 - val_loss: 1317837343.8539\n",
      "Epoch 8402/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1255184974.6536 - val_loss: 1316888090.5936\n",
      "Epoch 8403/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1255525635.5068 - val_loss: 1315685347.0685\n",
      "Epoch 8404/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1255210433.7534 - val_loss: 1315718551.9635\n",
      "Epoch 8405/15000\n",
      "1022/1022 [==============================] - 0s 75us/step - loss: 1255330394.6771 - val_loss: 1317204968.6210\n",
      "Epoch 8406/15000\n",
      "1022/1022 [==============================] - 0s 66us/step - loss: 1254976638.9980 - val_loss: 1316783622.1370\n",
      "Epoch 8407/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1255151729.7221 - val_loss: 1316281438.9772\n",
      "Epoch 8408/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1255362853.8239 - val_loss: 1315770359.5251\n",
      "Epoch 8409/15000\n",
      "1022/1022 [==============================] - 0s 77us/step - loss: 1255514930.0978 - val_loss: 1317558784.0000\n",
      "Epoch 8410/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1255090096.5949 - val_loss: 1316821218.4840\n",
      "Epoch 8411/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1255138299.2407 - val_loss: 1316919155.1416\n",
      "Epoch 8412/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1255056991.4364 - val_loss: 1316141885.0776\n",
      "Epoch 8413/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1255031751.3894 - val_loss: 1315381962.2283\n",
      "Epoch 8414/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1255300747.7730 - val_loss: 1316215998.8311\n",
      "Epoch 8415/15000\n",
      "1022/1022 [==============================] - 0s 75us/step - loss: 1255113469.1194 - val_loss: 1315780256.4384\n",
      "Epoch 8416/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1255008134.7632 - val_loss: 1316575335.7443\n",
      "Epoch 8417/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1254924896.9393 - val_loss: 1316606747.7626\n",
      "Epoch 8418/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1255076513.0020 - val_loss: 1316965192.7671\n",
      "Epoch 8419/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1254730880.0626 - val_loss: 1316639865.5708\n",
      "Epoch 8420/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1254896625.9726 - val_loss: 1315142406.7215\n",
      "Epoch 8421/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1255280388.1331 - val_loss: 1317262854.4292\n",
      "Epoch 8422/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1255483461.0098 - val_loss: 1314890281.2055\n",
      "Epoch 8423/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1254688546.0665 - val_loss: 1315773502.2466\n",
      "Epoch 8424/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1254743660.4618 - val_loss: 1316038839.2329\n",
      "Epoch 8425/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1255304776.0157 - val_loss: 1316854495.5616\n",
      "Epoch 8426/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1254775263.0607 - val_loss: 1315518864.6575\n",
      "Epoch 8427/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1254652825.2994 - val_loss: 1314858428.7854\n",
      "Epoch 8428/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1254611538.1605 - val_loss: 1314633589.7717\n",
      "Epoch 8429/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1254767911.5773 - val_loss: 1316676727.2329\n",
      "Epoch 8430/15000\n",
      "1022/1022 [==============================] - 0s 80us/step - loss: 1255408940.3366 - val_loss: 1314898454.5023\n",
      "Epoch 8431/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1254383349.9804 - val_loss: 1315901314.9224\n",
      "Epoch 8432/15000\n",
      "1022/1022 [==============================] - 0s 68us/step - loss: 1254797677.4638 - val_loss: 1316917281.0228\n",
      "Epoch 8433/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1254977124.3209 - val_loss: 1315239207.4521\n",
      "Epoch 8434/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1254746875.1155 - val_loss: 1316257450.6667\n",
      "Epoch 8435/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1254710452.4149 - val_loss: 1316548475.6164\n",
      "Epoch 8436/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1254538517.1037 - val_loss: 1315836357.8447\n",
      "Epoch 8437/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1254366307.5695 - val_loss: 1316027678.9772\n",
      "Epoch 8438/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1254642070.4188 - val_loss: 1315587647.4155\n",
      "Epoch 8439/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1254590773.3542 - val_loss: 1315945182.3927\n",
      "Epoch 8440/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1255306388.5401 - val_loss: 1314102597.8447\n",
      "Epoch 8441/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1254221414.0744 - val_loss: 1315976420.2374\n",
      "Epoch 8442/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1255545010.2231 - val_loss: 1316193361.2420\n",
      "Epoch 8443/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1254156465.2838 - val_loss: 1314775717.9909\n",
      "Epoch 8444/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1254412697.4247 - val_loss: 1314786857.7900\n",
      "Epoch 8445/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1254340909.5890 - val_loss: 1315295340.1279\n",
      "Epoch 8446/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1254381791.4364 - val_loss: 1316391177.6438\n",
      "Epoch 8447/15000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1254633014.6067 - val_loss: 1315618752.0000\n",
      "Epoch 8448/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1254565479.8278 - val_loss: 1313460183.0868\n",
      "Epoch 8449/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1254293606.5753 - val_loss: 1314855060.4566\n",
      "Epoch 8450/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1254210719.9374 - val_loss: 1315599361.4612\n",
      "Epoch 8451/15000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1254573888.6262 - val_loss: 1313291595.9817\n",
      "Epoch 8452/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1253953414.6380 - val_loss: 1314870366.9772\n",
      "Epoch 8453/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1254370017.6908 - val_loss: 1316110734.9041\n",
      "Epoch 8454/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1254253810.9746 - val_loss: 1315627640.4018\n",
      "Epoch 8455/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1253852492.0861 - val_loss: 1314523149.4429\n",
      "Epoch 8456/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1253850278.5753 - val_loss: 1314587167.5616\n",
      "Epoch 8457/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1254026998.9824 - val_loss: 1314901267.8721\n",
      "Epoch 8458/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1254383912.3288 - val_loss: 1315482179.5068\n",
      "Epoch 8459/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1253970687.6243 - val_loss: 1315200485.4064\n",
      "Epoch 8460/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1253685480.9550 - val_loss: 1314503860.6027\n",
      "Epoch 8461/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1253884069.8239 - val_loss: 1314776185.2785\n",
      "Epoch 8462/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1253656066.3796 - val_loss: 1314753767.4521\n",
      "Epoch 8463/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 49us/step - loss: 1253641992.7671 - val_loss: 1314807953.8265\n",
      "Epoch 8464/15000\n",
      "1022/1022 [==============================] - 0s 116us/step - loss: 1253744225.5656 - val_loss: 1314050963.2877\n",
      "Epoch 8465/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1254132459.2094 - val_loss: 1314338698.2283\n",
      "Epoch 8466/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1253615799.8591 - val_loss: 1314506996.3105\n",
      "Epoch 8467/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1253828085.6047 - val_loss: 1313281962.6667\n",
      "Epoch 8468/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1253460191.9374 - val_loss: 1314310493.2237\n",
      "Epoch 8469/15000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1253579427.0685 - val_loss: 1314875573.4795\n",
      "Epoch 8470/15000\n",
      "1022/1022 [==============================] - 0s 83us/step - loss: 1253748947.5382 - val_loss: 1313613237.4795\n",
      "Epoch 8471/15000\n",
      "1022/1022 [==============================] - 0s 67us/step - loss: 1253315929.9256 - val_loss: 1313975840.1461\n",
      "Epoch 8472/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1253503137.8160 - val_loss: 1315191405.5890\n",
      "Epoch 8473/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1253464897.0646 - val_loss: 1313808608.7306\n",
      "Epoch 8474/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1253356890.0509 - val_loss: 1313804005.9909\n",
      "Epoch 8475/15000\n",
      "1022/1022 [==============================] - 0s 101us/step - loss: 1253695883.7730 - val_loss: 1314720270.9041\n",
      "Epoch 8476/15000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1253707925.0411 - val_loss: 1313581868.7123\n",
      "Epoch 8477/15000\n",
      "1022/1022 [==============================] - 0s 68us/step - loss: 1253437237.6047 - val_loss: 1313702799.1963\n",
      "Epoch 8478/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1253775157.6047 - val_loss: 1314747407.7808\n",
      "Epoch 8479/15000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1253820560.5949 - val_loss: 1314534380.4201\n",
      "Epoch 8480/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1253551921.5969 - val_loss: 1314238951.7443\n",
      "Epoch 8481/15000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1253405762.3796 - val_loss: 1313903883.3973\n",
      "Epoch 8482/15000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1253315524.5088 - val_loss: 1313467575.2329\n",
      "Epoch 8483/15000\n",
      "1022/1022 [==============================] - 0s 66us/step - loss: 1253334277.7613 - val_loss: 1314191980.7123\n",
      "Epoch 8484/15000\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 1253234359.8904 - val_loss: 1314457817.4247\n",
      "Epoch 8485/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1253217524.6027 - val_loss: 1313236707.9452\n",
      "Epoch 8486/15000\n",
      "1022/1022 [==============================] - 0s 63us/step - loss: 1253702273.2524 - val_loss: 1314436625.2420\n",
      "Epoch 8487/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1253137265.7847 - val_loss: 1313103093.7717\n",
      "Epoch 8488/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1253786342.5753 - val_loss: 1313111647.8539\n",
      "Epoch 8489/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1253235829.9804 - val_loss: 1312778428.2009\n",
      "Epoch 8490/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1253518551.1703 - val_loss: 1313744251.0320\n",
      "Epoch 8491/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1253132919.6086 - val_loss: 1313104064.8767\n",
      "Epoch 8492/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1253424602.1761 - val_loss: 1314316470.0639\n",
      "Epoch 8493/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1252925276.6810 - val_loss: 1313554302.5388\n",
      "Epoch 8494/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1252933752.2348 - val_loss: 1313824403.2877\n",
      "Epoch 8495/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1252844248.9237 - val_loss: 1313278023.5982\n",
      "Epoch 8496/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1252817491.0372 - val_loss: 1313561844.3105\n",
      "Epoch 8497/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1252839572.6027 - val_loss: 1313027658.2283\n",
      "Epoch 8498/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1253109263.7808 - val_loss: 1314154252.2740\n",
      "Epoch 8499/15000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1252986633.0176 - val_loss: 1313747783.3059\n",
      "Epoch 8500/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1253205399.4207 - val_loss: 1311584507.6164\n",
      "Epoch 8501/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1252806424.5479 - val_loss: 1312966034.9954\n",
      "Epoch 8502/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1252941794.4423 - val_loss: 1313757502.8311\n",
      "Epoch 8503/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1252943041.0020 - val_loss: 1313401136.8037\n",
      "Epoch 8504/15000\n",
      "1022/1022 [==============================] - 0s 74us/step - loss: 1252799549.8708 - val_loss: 1313474497.7534\n",
      "Epoch 8505/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1252825480.0783 - val_loss: 1312843304.6210\n",
      "Epoch 8506/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1252645181.8082 - val_loss: 1312913287.3059\n",
      "Epoch 8507/15000\n",
      "1022/1022 [==============================] - 0s 84us/step - loss: 1252923346.5362 - val_loss: 1312380025.2785\n",
      "Epoch 8508/15000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1252931353.8004 - val_loss: 1313641721.2785\n",
      "Epoch 8509/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1252745896.9550 - val_loss: 1311506216.6210\n",
      "Epoch 8510/15000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1252467987.1624 - val_loss: 1312782346.5205\n",
      "Epoch 8511/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1252934558.3092 - val_loss: 1313442692.3836\n",
      "Epoch 8512/15000\n",
      "1022/1022 [==============================] - 0s 71us/step - loss: 1252519344.9706 - val_loss: 1312320188.2009\n",
      "Epoch 8513/15000\n",
      "1022/1022 [==============================] - 0s 84us/step - loss: 1252533713.2211 - val_loss: 1311590346.2283\n",
      "Epoch 8514/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1252508300.2740 - val_loss: 1312940861.0776\n",
      "Epoch 8515/15000\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 1252859128.8611 - val_loss: 1311531159.6712\n",
      "Epoch 8516/15000\n",
      "1022/1022 [==============================] - 0s 92us/step - loss: 1252923381.8552 - val_loss: 1313871043.5068\n",
      "Epoch 8517/15000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1253092896.8141 - val_loss: 1312279903.5616\n",
      "Epoch 8518/15000\n",
      "1022/1022 [==============================] - 0s 85us/step - loss: 1253292291.6321 - val_loss: 1311262613.9178\n",
      "Epoch 8519/15000\n",
      "1022/1022 [==============================] - 0s 79us/step - loss: 1252188689.5342 - val_loss: 1311815295.1233\n",
      "Epoch 8520/15000\n",
      "1022/1022 [==============================] - 0s 69us/step - loss: 1252547398.3875 - val_loss: 1312373354.6667\n",
      "Epoch 8521/15000\n",
      "1022/1022 [==============================] - 0s 79us/step - loss: 1252369591.4834 - val_loss: 1312755900.4932\n",
      "Epoch 8522/15000\n",
      "1022/1022 [==============================] - 0s 90us/step - loss: 1252323432.2035 - val_loss: 1311901175.5251\n",
      "Epoch 8523/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1252210625.3777 - val_loss: 1312342873.7169\n",
      "Epoch 8524/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1252557586.4110 - val_loss: 1313140345.2785\n",
      "Epoch 8525/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1252137975.9843 - val_loss: 1312857364.7489\n",
      "Epoch 8526/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1252480221.4325 - val_loss: 1312868166.1370\n",
      "Epoch 8527/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 43us/step - loss: 1252197475.1937 - val_loss: 1311924670.8311\n",
      "Epoch 8528/15000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1252794806.9824 - val_loss: 1312484247.9635\n",
      "Epoch 8529/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1252021688.4227 - val_loss: 1312134519.8174\n",
      "Epoch 8530/15000\n",
      "1022/1022 [==============================] - 0s 68us/step - loss: 1252627826.2231 - val_loss: 1313405426.5571\n",
      "Epoch 8531/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1252134721.1272 - val_loss: 1312090501.8447\n",
      "Epoch 8532/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1252014642.3483 - val_loss: 1312523535.7808\n",
      "Epoch 8533/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1252388535.2329 - val_loss: 1313103588.5297\n",
      "Epoch 8534/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1252331623.8278 - val_loss: 1311705364.7489\n",
      "Epoch 8535/15000\n",
      "1022/1022 [==============================] - 0s 91us/step - loss: 1252160246.3562 - val_loss: 1312685866.3744\n",
      "Epoch 8536/15000\n",
      "1022/1022 [==============================] - 0s 88us/step - loss: 1252477278.5597 - val_loss: 1311163014.7215\n",
      "Epoch 8537/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1252071053.0254 - val_loss: 1310932155.9087\n",
      "Epoch 8538/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1251927897.9256 - val_loss: 1310823185.5342\n",
      "Epoch 8539/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1252014466.3796 - val_loss: 1312542991.7808\n",
      "Epoch 8540/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1251929458.0978 - val_loss: 1311079983.9269\n",
      "Epoch 8541/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1252379671.4207 - val_loss: 1312418933.7717\n",
      "Epoch 8542/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1251795677.4325 - val_loss: 1312425847.2329\n",
      "Epoch 8543/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1251670622.1840 - val_loss: 1311563344.3653\n",
      "Epoch 8544/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1252038023.2016 - val_loss: 1311514421.4795\n",
      "Epoch 8545/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1252289107.1624 - val_loss: 1312028800.2922\n",
      "Epoch 8546/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1252014161.0333 - val_loss: 1310470898.2648\n",
      "Epoch 8547/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1251804460.7750 - val_loss: 1311996698.0091\n",
      "Epoch 8548/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1251812572.0548 - val_loss: 1311256677.9909\n",
      "Epoch 8549/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1251715195.6164 - val_loss: 1311196282.4475\n",
      "Epoch 8550/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1251485695.2485 - val_loss: 1311261998.7580\n",
      "Epoch 8551/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1251739923.5382 - val_loss: 1310876151.5251\n",
      "Epoch 8552/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1251867527.0137 - val_loss: 1311115472.0731\n",
      "Epoch 8553/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1252154775.1703 - val_loss: 1312801096.4749\n",
      "Epoch 8554/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1251499830.8571 - val_loss: 1311769271.5251\n",
      "Epoch 8555/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1251420950.4188 - val_loss: 1311282875.9087\n",
      "Epoch 8556/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1252307308.3366 - val_loss: 1312925701.5525\n",
      "Epoch 8557/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1251288016.4070 - val_loss: 1311066798.1735\n",
      "Epoch 8558/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1251516398.2779 - val_loss: 1310422866.1187\n",
      "Epoch 8559/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1251837570.3796 - val_loss: 1311450679.2329\n",
      "Epoch 8560/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1251683139.0059 - val_loss: 1309348591.6347\n",
      "Epoch 8561/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1251537497.9256 - val_loss: 1310576899.5068\n",
      "Epoch 8562/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1251501473.3151 - val_loss: 1311645662.1005\n",
      "Epoch 8563/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1251207080.3288 - val_loss: 1310553567.2694\n",
      "Epoch 8564/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1251521208.8611 - val_loss: 1310073935.7808\n",
      "Epoch 8565/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1251261613.6517 - val_loss: 1311428912.8037\n",
      "Epoch 8566/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1252173894.3249 - val_loss: 1308948106.8128\n",
      "Epoch 8567/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1252039958.6067 - val_loss: 1311172600.9863\n",
      "Epoch 8568/15000\n",
      "1022/1022 [==============================] - 0s 69us/step - loss: 1251141777.7847 - val_loss: 1310162304.5845\n",
      "Epoch 8569/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1251301869.0254 - val_loss: 1311265823.2694\n",
      "Epoch 8570/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1251245930.2074 - val_loss: 1310330865.0959\n",
      "Epoch 8571/15000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1251084983.9217 - val_loss: 1310419930.3014\n",
      "Epoch 8572/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1251497046.7945 - val_loss: 1309856802.1918\n",
      "Epoch 8573/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1251054471.2642 - val_loss: 1310781261.1507\n",
      "Epoch 8574/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1250901436.4932 - val_loss: 1310426459.1781\n",
      "Epoch 8575/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1251195903.2485 - val_loss: 1309882704.3653\n",
      "Epoch 8576/15000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1251234853.6986 - val_loss: 1309881562.8858\n",
      "Epoch 8577/15000\n",
      "1022/1022 [==============================] - 0s 83us/step - loss: 1250855138.1918 - val_loss: 1310872832.0000\n",
      "Epoch 8578/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1250805293.5890 - val_loss: 1310580198.8676\n",
      "Epoch 8579/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1251119558.6380 - val_loss: 1310427782.7215\n",
      "Epoch 8580/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1250880053.3542 - val_loss: 1310986848.4384\n",
      "Epoch 8581/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1251427743.1859 - val_loss: 1308996488.1826\n",
      "Epoch 8582/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1250911337.0802 - val_loss: 1309786209.3151\n",
      "Epoch 8583/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1250626010.1761 - val_loss: 1310521666.6301\n",
      "Epoch 8584/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1250709846.5440 - val_loss: 1310286498.1918\n",
      "Epoch 8585/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1250938936.2348 - val_loss: 1310160102.8676\n",
      "Epoch 8586/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1251504308.9785 - val_loss: 1311656922.8858\n",
      "Epoch 8587/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1250983107.3816 - val_loss: 1308692857.8630\n",
      "Epoch 8588/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1250756352.7515 - val_loss: 1310197578.2283\n",
      "Epoch 8589/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1250622284.1487 - val_loss: 1309807412.3105\n",
      "Epoch 8590/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1250792355.6947 - val_loss: 1310061487.3425\n",
      "Epoch 8591/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 36us/step - loss: 1251090261.2916 - val_loss: 1309296199.3059\n",
      "Epoch 8592/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1250868089.4873 - val_loss: 1310820137.7900\n",
      "Epoch 8593/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1250922542.4031 - val_loss: 1310871265.6073\n",
      "Epoch 8594/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1250775073.8160 - val_loss: 1310250462.1005\n",
      "Epoch 8595/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1250800686.3405 - val_loss: 1308369598.5388\n",
      "Epoch 8596/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1250553004.5871 - val_loss: 1308719476.8950\n",
      "Epoch 8597/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1250265236.9785 - val_loss: 1309669490.5571\n",
      "Epoch 8598/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1250464232.4540 - val_loss: 1309287607.8174\n",
      "Epoch 8599/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1250379873.6908 - val_loss: 1309809261.0046\n",
      "Epoch 8600/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1250564127.1859 - val_loss: 1310318927.4886\n",
      "Epoch 8601/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1250468724.9785 - val_loss: 1310041599.1233\n",
      "Epoch 8602/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1250431786.2074 - val_loss: 1309370613.4795\n",
      "Epoch 8603/15000\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 1250845290.2074 - val_loss: 1309330362.1553\n",
      "Epoch 8604/15000\n",
      "1022/1022 [==============================] - 0s 71us/step - loss: 1250340426.0196 - val_loss: 1310178700.2740\n",
      "Epoch 8605/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1250268202.5832 - val_loss: 1308764354.6301\n",
      "Epoch 8606/15000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1250890301.9961 - val_loss: 1309698972.6393\n",
      "Epoch 8607/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1250248510.6223 - val_loss: 1310300516.2374\n",
      "Epoch 8608/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1250157585.8474 - val_loss: 1308893040.5114\n",
      "Epoch 8609/15000\n",
      "1022/1022 [==============================] - 0s 83us/step - loss: 1250456292.5714 - val_loss: 1309862176.4384\n",
      "Epoch 8610/15000\n",
      "1022/1022 [==============================] - 0s 84us/step - loss: 1250201118.5597 - val_loss: 1308327824.9498\n",
      "Epoch 8611/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1250392721.2838 - val_loss: 1308870538.2283\n",
      "Epoch 8612/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1250316555.2720 - val_loss: 1309894902.3562\n",
      "Epoch 8613/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1250208818.0978 - val_loss: 1309172913.3881\n",
      "Epoch 8614/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1250348866.6301 - val_loss: 1308227620.2374\n",
      "Epoch 8615/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1250105254.4501 - val_loss: 1309302863.1963\n",
      "Epoch 8616/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1249909168.3444 - val_loss: 1308733295.9269\n",
      "Epoch 8617/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1249939597.1507 - val_loss: 1308273564.0548\n",
      "Epoch 8618/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1250006177.6908 - val_loss: 1308589957.8447\n",
      "Epoch 8619/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1250122402.3170 - val_loss: 1308778892.8584\n",
      "Epoch 8620/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1249998812.6810 - val_loss: 1309047292.7854\n",
      "Epoch 8621/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1249880801.6908 - val_loss: 1308238430.3927\n",
      "Epoch 8622/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1250018846.5597 - val_loss: 1309160419.3607\n",
      "Epoch 8623/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1250457580.9628 - val_loss: 1307131076.9680\n",
      "Epoch 8624/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1249622213.3855 - val_loss: 1308606952.9132\n",
      "Epoch 8625/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1249924473.6125 - val_loss: 1309123277.1507\n",
      "Epoch 8626/15000\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 1249776974.4031 - val_loss: 1308678932.4566\n",
      "Epoch 8627/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1249994698.6458 - val_loss: 1308976872.3288\n",
      "Epoch 8628/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1250615249.4090 - val_loss: 1309982313.7900\n",
      "Epoch 8629/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1250342630.8258 - val_loss: 1308260154.7397\n",
      "Epoch 8630/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1250112221.7456 - val_loss: 1308446316.4201\n",
      "Epoch 8631/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1249567051.3973 - val_loss: 1308539025.8265\n",
      "Epoch 8632/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1249772606.8728 - val_loss: 1309014603.6895\n",
      "Epoch 8633/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1249566584.3601 - val_loss: 1308759603.4338\n",
      "Epoch 8634/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1249830829.7143 - val_loss: 1308152008.1826\n",
      "Epoch 8635/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1249829064.1409 - val_loss: 1307618938.7397\n",
      "Epoch 8636/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1249695763.2877 - val_loss: 1308092793.5708\n",
      "Epoch 8637/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1249898779.1781 - val_loss: 1308390492.0548\n",
      "Epoch 8638/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1249704124.6184 - val_loss: 1308733176.4018\n",
      "Epoch 8639/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1250016050.2231 - val_loss: 1308357488.5114\n",
      "Epoch 8640/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1249605675.3346 - val_loss: 1308661262.6119\n",
      "Epoch 8641/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1249586755.3816 - val_loss: 1308476731.0320\n",
      "Epoch 8642/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1249341194.9589 - val_loss: 1308612355.5068\n",
      "Epoch 8643/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1249776209.7847 - val_loss: 1309047661.8813\n",
      "Epoch 8644/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1249316466.2231 - val_loss: 1307554481.9726\n",
      "Epoch 8645/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1249394522.3014 - val_loss: 1307875857.8265\n",
      "Epoch 8646/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1249245917.0568 - val_loss: 1308473541.2603\n",
      "Epoch 8647/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1249245131.5851 - val_loss: 1308057395.4338\n",
      "Epoch 8648/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1249279120.4070 - val_loss: 1307816650.2283\n",
      "Epoch 8649/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1249252673.6282 - val_loss: 1307745437.8082\n",
      "Epoch 8650/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1249265788.1174 - val_loss: 1307110235.4703\n",
      "Epoch 8651/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1249478052.9472 - val_loss: 1307444005.1142\n",
      "Epoch 8652/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1250440681.7065 - val_loss: 1309544283.4703\n",
      "Epoch 8653/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1248941394.6614 - val_loss: 1308001389.0046\n",
      "Epoch 8654/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1249261172.3523 - val_loss: 1307481765.6986\n",
      "Epoch 8655/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 37us/step - loss: 1249198307.5695 - val_loss: 1307360666.0091\n",
      "Epoch 8656/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1249069524.9159 - val_loss: 1307291492.2374\n",
      "Epoch 8657/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1249150321.2211 - val_loss: 1308132250.5936\n",
      "Epoch 8658/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1249329704.9550 - val_loss: 1308929335.5251\n",
      "Epoch 8659/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1248910890.8963 - val_loss: 1307807120.0731\n",
      "Epoch 8660/15000\n",
      "1022/1022 [==============================] - 0s 72us/step - loss: 1249029366.4814 - val_loss: 1307105779.4338\n",
      "Epoch 8661/15000\n",
      "1022/1022 [==============================] - 0s 75us/step - loss: 1248997316.8845 - val_loss: 1307911641.1324\n",
      "Epoch 8662/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1249534117.8239 - val_loss: 1306085064.1826\n",
      "Epoch 8663/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1250032627.3503 - val_loss: 1308317493.7717\n",
      "Epoch 8664/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1249085085.4325 - val_loss: 1307422096.6575\n",
      "Epoch 8665/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1248805335.4207 - val_loss: 1307140389.4064\n",
      "Epoch 8666/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1248763864.6732 - val_loss: 1307298998.0639\n",
      "Epoch 8667/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1249252577.3151 - val_loss: 1305859996.3470\n",
      "Epoch 8668/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1248713094.6380 - val_loss: 1306983303.3059\n",
      "Epoch 8669/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1249127346.5988 - val_loss: 1308237381.8447\n",
      "Epoch 8670/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1249445464.7984 - val_loss: 1306509422.7580\n",
      "Epoch 8671/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1248810064.6575 - val_loss: 1306819038.1005\n",
      "Epoch 8672/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1249752205.4012 - val_loss: 1308411747.3607\n",
      "Epoch 8673/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1248804691.9139 - val_loss: 1307779059.4338\n",
      "Epoch 8674/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1248669115.8669 - val_loss: 1307682605.5890\n",
      "Epoch 8675/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1249430799.7808 - val_loss: 1308799462.5753\n",
      "Epoch 8676/15000\n",
      "1022/1022 [==============================] - 0s 72us/step - loss: 1248678988.6497 - val_loss: 1306348242.4110\n",
      "Epoch 8677/15000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1249441798.8258 - val_loss: 1306066677.1872\n",
      "Epoch 8678/15000\n",
      "1022/1022 [==============================] - 0s 86us/step - loss: 1248442979.9452 - val_loss: 1306753906.5571\n",
      "Epoch 8679/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1248728748.9628 - val_loss: 1307129301.9178\n",
      "Epoch 8680/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1249333499.4912 - val_loss: 1308452460.7123\n",
      "Epoch 8681/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1248919307.3973 - val_loss: 1307610863.3425\n",
      "Epoch 8682/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1248924038.7632 - val_loss: 1305320428.7123\n",
      "Epoch 8683/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1248581913.6751 - val_loss: 1306078305.6073\n",
      "Epoch 8684/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1248355068.4932 - val_loss: 1306948969.2055\n",
      "Epoch 8685/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1249424268.2740 - val_loss: 1305436799.4155\n",
      "Epoch 8686/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1248455592.7671 - val_loss: 1307792551.4521\n",
      "Epoch 8687/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1248482413.2133 - val_loss: 1307841347.7991\n",
      "Epoch 8688/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1248363497.2055 - val_loss: 1307563434.9589\n",
      "Epoch 8689/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1248229741.4638 - val_loss: 1306936957.6621\n",
      "Epoch 8690/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1248275553.3151 - val_loss: 1307472714.5205\n",
      "Epoch 8691/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1248415179.6477 - val_loss: 1305995010.3379\n",
      "Epoch 8692/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1248539467.6477 - val_loss: 1307519821.7352\n",
      "Epoch 8693/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1248244304.7828 - val_loss: 1306926481.8265\n",
      "Epoch 8694/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1248335702.1683 - val_loss: 1306078776.9863\n",
      "Epoch 8695/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1248753844.8532 - val_loss: 1307539354.0091\n",
      "Epoch 8696/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1248521857.2524 - val_loss: 1307149446.4292\n",
      "Epoch 8697/15000\n",
      "1022/1022 [==============================] - 0s 109us/step - loss: 1248057199.7182 - val_loss: 1306510550.2100\n",
      "Epoch 8698/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1248168054.9198 - val_loss: 1306665587.4338\n",
      "Epoch 8699/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1248078072.4853 - val_loss: 1306767466.0822\n",
      "Epoch 8700/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1248027363.8200 - val_loss: 1306216425.2055\n",
      "Epoch 8701/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1248031884.6497 - val_loss: 1306484648.9132\n",
      "Epoch 8702/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1248763263.2485 - val_loss: 1304102399.1233\n",
      "Epoch 8703/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1248158531.2564 - val_loss: 1306225065.4977\n",
      "Epoch 8704/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1249341326.0274 - val_loss: 1305086137.5708\n",
      "Epoch 8705/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1248098241.3777 - val_loss: 1305590260.3105\n",
      "Epoch 8706/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1247813210.0509 - val_loss: 1306798598.7215\n",
      "Epoch 8707/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1247954470.5753 - val_loss: 1306616678.8676\n",
      "Epoch 8708/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1248057777.4090 - val_loss: 1306684711.1598\n",
      "Epoch 8709/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1248186147.1937 - val_loss: 1307602257.2420\n",
      "Epoch 8710/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1247911226.2387 - val_loss: 1306879593.4977\n",
      "Epoch 8711/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1247813533.8082 - val_loss: 1306438824.0365\n",
      "Epoch 8712/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1247927987.3503 - val_loss: 1304833845.7717\n",
      "Epoch 8713/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1248102937.1742 - val_loss: 1306702383.6347\n",
      "Epoch 8714/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1248082025.9569 - val_loss: 1307163696.2192\n",
      "Epoch 8715/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1247963609.9256 - val_loss: 1305948673.7534\n",
      "Epoch 8716/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1247727360.7515 - val_loss: 1306164918.9406\n",
      "Epoch 8717/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1247663255.2955 - val_loss: 1306212364.8584\n",
      "Epoch 8718/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1247634791.0763 - val_loss: 1305750934.2100\n",
      "Epoch 8719/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 29us/step - loss: 1248059148.7750 - val_loss: 1306927593.4977\n",
      "Epoch 8720/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1247795491.9452 - val_loss: 1305713314.7763\n",
      "Epoch 8721/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1247739065.8630 - val_loss: 1306391526.5753\n",
      "Epoch 8722/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1247471668.3523 - val_loss: 1305605752.1096\n",
      "Epoch 8723/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1247716508.5558 - val_loss: 1305382712.4018\n",
      "Epoch 8724/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1247810978.8180 - val_loss: 1304000470.7945\n",
      "Epoch 8725/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1247370821.1350 - val_loss: 1305249488.9498\n",
      "Epoch 8726/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1247469802.3327 - val_loss: 1305242148.2374\n",
      "Epoch 8727/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1247785017.6125 - val_loss: 1304181038.4658\n",
      "Epoch 8728/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1247761021.7456 - val_loss: 1305299600.0731\n",
      "Epoch 8729/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1247631462.0744 - val_loss: 1305252282.7397\n",
      "Epoch 8730/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1247411874.3170 - val_loss: 1306274326.2100\n",
      "Epoch 8731/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1247314164.9785 - val_loss: 1305419954.8493\n",
      "Epoch 8732/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1247240465.1585 - val_loss: 1305895562.2283\n",
      "Epoch 8733/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1247564784.3444 - val_loss: 1305040948.3105\n",
      "Epoch 8734/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1247376611.9452 - val_loss: 1305994293.7717\n",
      "Epoch 8735/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1247373532.3053 - val_loss: 1305531221.3333\n",
      "Epoch 8736/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1247339630.1526 - val_loss: 1305859989.3333\n",
      "Epoch 8737/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1247803840.4384 - val_loss: 1303958900.0183\n",
      "Epoch 8738/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1247786229.4795 - val_loss: 1303403543.0868\n",
      "Epoch 8739/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1247238087.3894 - val_loss: 1306502051.9452\n",
      "Epoch 8740/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1248285456.2818 - val_loss: 1307123069.6621\n",
      "Epoch 8741/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1248738350.3405 - val_loss: 1303978303.7078\n",
      "Epoch 8742/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1247156162.5049 - val_loss: 1306084085.7717\n",
      "Epoch 8743/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1247164002.8180 - val_loss: 1306607975.1598\n",
      "Epoch 8744/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1247147543.0450 - val_loss: 1305476861.9543\n",
      "Epoch 8745/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1247056089.4247 - val_loss: 1305043244.7123\n",
      "Epoch 8746/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1247312274.2857 - val_loss: 1306674939.0320\n",
      "Epoch 8747/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1247115539.0372 - val_loss: 1306175280.8037\n",
      "Epoch 8748/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1246984634.6145 - val_loss: 1305339982.6119\n",
      "Epoch 8749/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1247305471.5616 - val_loss: 1304395297.6073\n",
      "Epoch 8750/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1247156024.3601 - val_loss: 1305283342.3196\n",
      "Epoch 8751/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1247147012.2583 - val_loss: 1306177735.5982\n",
      "Epoch 8752/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1247537858.7554 - val_loss: 1305125397.9178\n",
      "Epoch 8753/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1246826208.9393 - val_loss: 1305453678.1735\n",
      "Epoch 8754/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1247168268.9002 - val_loss: 1304456820.6027\n",
      "Epoch 8755/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1246975743.4990 - val_loss: 1305558160.9498\n",
      "Epoch 8756/15000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1246804546.5049 - val_loss: 1305067869.8082\n",
      "Epoch 8757/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1247098829.2133 - val_loss: 1305266465.3151\n",
      "Epoch 8758/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1246920295.9530 - val_loss: 1305552636.7854\n",
      "Epoch 8759/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1246801422.0900 - val_loss: 1304118660.9680\n",
      "Epoch 8760/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1246882985.4560 - val_loss: 1303916143.6347\n",
      "Epoch 8761/15000\n",
      "1022/1022 [==============================] - 0s 81us/step - loss: 1246638840.7358 - val_loss: 1304888853.0411\n",
      "Epoch 8762/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1246766578.4736 - val_loss: 1306009568.4384\n",
      "Epoch 8763/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1246927025.9726 - val_loss: 1305479936.2922\n",
      "Epoch 8764/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1247359012.0078 - val_loss: 1305439427.5068\n",
      "Epoch 8765/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1246934951.8278 - val_loss: 1303499655.5982\n",
      "Epoch 8766/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1247221443.0059 - val_loss: 1305533931.2511\n",
      "Epoch 8767/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1246840850.1605 - val_loss: 1305418797.8813\n",
      "Epoch 8768/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1246782487.6086 - val_loss: 1303757818.4475\n",
      "Epoch 8769/15000\n",
      "1022/1022 [==============================] - 0s 63us/step - loss: 1247116141.7143 - val_loss: 1304899364.2374\n",
      "Epoch 8770/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1246593976.7358 - val_loss: 1304931466.2283\n",
      "Epoch 8771/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1246572478.8728 - val_loss: 1303898304.0000\n",
      "Epoch 8772/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1246388313.1742 - val_loss: 1304058026.9589\n",
      "Epoch 8773/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1247378839.5460 - val_loss: 1306072572.4932\n",
      "Epoch 8774/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1246415077.9491 - val_loss: 1304266063.1963\n",
      "Epoch 8775/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1246577777.7221 - val_loss: 1304803347.8721\n",
      "Epoch 8776/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1247166180.6967 - val_loss: 1302763236.2374\n",
      "Epoch 8777/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1246654693.1977 - val_loss: 1302642507.6895\n",
      "Epoch 8778/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1246428607.8748 - val_loss: 1304726415.7808\n",
      "Epoch 8779/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1246745175.5460 - val_loss: 1303721457.0959\n",
      "Epoch 8780/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1246668922.7397 - val_loss: 1305385873.5342\n",
      "Epoch 8781/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1246281342.9980 - val_loss: 1305034357.7717\n",
      "Epoch 8782/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1246412177.6595 - val_loss: 1304462033.2420\n",
      "Epoch 8783/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1246593892.1957 - val_loss: 1303284835.9452\n",
      "Epoch 8784/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1246176155.0528 - val_loss: 1304926586.7397\n",
      "Epoch 8785/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1246265410.6301 - val_loss: 1303942484.7489\n",
      "Epoch 8786/15000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1246460654.9667 - val_loss: 1304741166.1735\n",
      "Epoch 8787/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1246290949.5108 - val_loss: 1303241040.9498\n",
      "Epoch 8788/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1246670848.0000 - val_loss: 1304127407.6347\n",
      "Epoch 8789/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1246313599.3738 - val_loss: 1304656048.5114\n",
      "Epoch 8790/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1246880706.6301 - val_loss: 1302595082.5205\n",
      "Epoch 8791/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1246228096.0000 - val_loss: 1303018076.0548\n",
      "Epoch 8792/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1246774173.0568 - val_loss: 1304362081.8995\n",
      "Epoch 8793/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1246956086.4188 - val_loss: 1304199717.1142\n",
      "Epoch 8794/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1246041922.1292 - val_loss: 1304326114.4840\n",
      "Epoch 8795/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1246048701.3699 - val_loss: 1303270050.1918\n",
      "Epoch 8796/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1246602858.2074 - val_loss: 1304583006.3927\n",
      "Epoch 8797/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1246164613.0098 - val_loss: 1304292346.4475\n",
      "Epoch 8798/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1245853874.8493 - val_loss: 1304168222.1005\n",
      "Epoch 8799/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1247292744.0157 - val_loss: 1302742483.2877\n",
      "Epoch 8800/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1245757818.4892 - val_loss: 1303694490.0091\n",
      "Epoch 8801/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1246305979.4912 - val_loss: 1304732457.4977\n",
      "Epoch 8802/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1245886394.7397 - val_loss: 1304060707.0685\n",
      "Epoch 8803/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1245830156.7750 - val_loss: 1303894068.8950\n",
      "Epoch 8804/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1246163092.6654 - val_loss: 1304283509.7717\n",
      "Epoch 8805/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1245643738.6771 - val_loss: 1303380980.8950\n",
      "Epoch 8806/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1245722750.3718 - val_loss: 1303341957.2603\n",
      "Epoch 8807/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1245948978.8493 - val_loss: 1304118485.0411\n",
      "Epoch 8808/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1245637201.4090 - val_loss: 1303495725.2968\n",
      "Epoch 8809/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1245873653.9804 - val_loss: 1302482065.2420\n",
      "Epoch 8810/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1246987526.2622 - val_loss: 1304061565.3699\n",
      "Epoch 8811/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1245789964.0235 - val_loss: 1303867858.4110\n",
      "Epoch 8812/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1245571335.5147 - val_loss: 1302633075.1416\n",
      "Epoch 8813/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1245640013.1507 - val_loss: 1302863223.8174\n",
      "Epoch 8814/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1245505488.4070 - val_loss: 1303004389.4064\n",
      "Epoch 8815/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1246775649.0646 - val_loss: 1301455189.0411\n",
      "Epoch 8816/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1245413935.9687 - val_loss: 1303336237.8813\n",
      "Epoch 8817/15000\n",
      "1022/1022 [==============================] - 0s 93us/step - loss: 1245566589.6204 - val_loss: 1303831377.5342\n",
      "Epoch 8818/15000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1245498151.6399 - val_loss: 1303716285.3699\n",
      "Epoch 8819/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1245434260.7906 - val_loss: 1303562680.4018\n",
      "Epoch 8820/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1245565001.9569 - val_loss: 1302546792.6210\n",
      "Epoch 8821/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1245534422.1683 - val_loss: 1303223811.5068\n",
      "Epoch 8822/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1246082141.8082 - val_loss: 1301818123.3973\n",
      "Epoch 8823/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1245521486.6536 - val_loss: 1303214293.0411\n",
      "Epoch 8824/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1245378506.3953 - val_loss: 1303702565.6986\n",
      "Epoch 8825/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1245395592.2661 - val_loss: 1303608686.1735\n",
      "Epoch 8826/15000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1245308914.5362 - val_loss: 1302846013.0776\n",
      "Epoch 8827/15000\n",
      "1022/1022 [==============================] - 0s 66us/step - loss: 1245414375.4521 - val_loss: 1303302459.9087\n",
      "Epoch 8828/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1245685529.5499 - val_loss: 1301513207.8174\n",
      "Epoch 8829/15000\n",
      "1022/1022 [==============================] - 0s 65us/step - loss: 1245437550.7162 - val_loss: 1303612585.2055\n",
      "Epoch 8830/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1245553842.8493 - val_loss: 1303083818.0822\n",
      "Epoch 8831/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1245415757.5264 - val_loss: 1303025379.3607\n",
      "Epoch 8832/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1245639676.1174 - val_loss: 1302956848.8037\n",
      "Epoch 8833/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1245522222.5910 - val_loss: 1304026674.8493\n",
      "Epoch 8834/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1245694390.1057 - val_loss: 1303850291.1416\n",
      "Epoch 8835/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1245135169.7534 - val_loss: 1302803626.6667\n",
      "Epoch 8836/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1245385481.6438 - val_loss: 1302704840.1826\n",
      "Epoch 8837/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1245368607.1859 - val_loss: 1301762549.1872\n",
      "Epoch 8838/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1244978818.5675 - val_loss: 1302392594.9954\n",
      "Epoch 8839/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1245256961.7534 - val_loss: 1302752495.6347\n",
      "Epoch 8840/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1245564545.7534 - val_loss: 1302766717.3699\n",
      "Epoch 8841/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1245943361.7534 - val_loss: 1302423674.7397\n",
      "Epoch 8842/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1246025056.3131 - val_loss: 1304341345.8995\n",
      "Epoch 8843/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1245141828.6341 - val_loss: 1301707593.9361\n",
      "Epoch 8844/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1245030624.3131 - val_loss: 1302195109.9909\n",
      "Epoch 8845/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1245041575.0763 - val_loss: 1302125120.5845\n",
      "Epoch 8846/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1245202203.8043 - val_loss: 1302565394.9954\n",
      "Epoch 8847/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 39us/step - loss: 1245200416.3131 - val_loss: 1301845454.0274\n",
      "Epoch 8848/15000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1244762431.8748 - val_loss: 1302145892.8219\n",
      "Epoch 8849/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1244761326.2153 - val_loss: 1303152496.2192\n",
      "Epoch 8850/15000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1244977317.3229 - val_loss: 1302758821.1142\n",
      "Epoch 8851/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1244840895.7495 - val_loss: 1303284173.4429\n",
      "Epoch 8852/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1245400028.2427 - val_loss: 1302046169.4247\n",
      "Epoch 8853/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1245000446.2466 - val_loss: 1303253449.3516\n",
      "Epoch 8854/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1245046698.2074 - val_loss: 1302760383.7078\n",
      "Epoch 8855/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1244581516.3992 - val_loss: 1301983567.1963\n",
      "Epoch 8856/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1244661611.8356 - val_loss: 1302087655.1598\n",
      "Epoch 8857/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1244753933.1507 - val_loss: 1301904624.5114\n",
      "Epoch 8858/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1244778990.4658 - val_loss: 1301825683.5799\n",
      "Epoch 8859/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1244918811.3033 - val_loss: 1302195082.8128\n",
      "Epoch 8860/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1244858728.4540 - val_loss: 1302349350.2831\n",
      "Epoch 8861/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1244863967.6869 - val_loss: 1302140627.8721\n",
      "Epoch 8862/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1244677244.2427 - val_loss: 1302241743.7808\n",
      "Epoch 8863/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1245501880.6106 - val_loss: 1302367764.4566\n",
      "Epoch 8864/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1245026315.1468 - val_loss: 1300480132.3836\n",
      "Epoch 8865/15000\n",
      "1022/1022 [==============================] - 0s 69us/step - loss: 1244530231.2329 - val_loss: 1302043463.8904\n",
      "Epoch 8866/15000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1244726680.2975 - val_loss: 1303073866.5205\n",
      "Epoch 8867/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1244558118.8258 - val_loss: 1302344946.5571\n",
      "Epoch 8868/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1244947260.8689 - val_loss: 1302405622.6484\n",
      "Epoch 8869/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1245694732.0235 - val_loss: 1301381105.0959\n",
      "Epoch 8870/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1245187952.2192 - val_loss: 1303720657.5342\n",
      "Epoch 8871/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1244513438.0587 - val_loss: 1303085115.3242\n",
      "Epoch 8872/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1244375465.4560 - val_loss: 1301396375.6712\n",
      "Epoch 8873/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1244934253.3386 - val_loss: 1302383439.7808\n",
      "Epoch 8874/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1244346783.8121 - val_loss: 1301392391.5982\n",
      "Epoch 8875/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1244493984.0626 - val_loss: 1301591940.0913\n",
      "Epoch 8876/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1244559024.2192 - val_loss: 1301141310.2466\n",
      "Epoch 8877/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1244357472.0626 - val_loss: 1301631660.7123\n",
      "Epoch 8878/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1244457549.0254 - val_loss: 1300589854.9772\n",
      "Epoch 8879/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1244258023.3268 - val_loss: 1301753283.5068\n",
      "Epoch 8880/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1244520506.7397 - val_loss: 1301451230.9772\n",
      "Epoch 8881/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1244322273.9413 - val_loss: 1302535288.6941\n",
      "Epoch 8882/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1244215497.3933 - val_loss: 1301300907.2511\n",
      "Epoch 8883/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1244302653.1194 - val_loss: 1302446261.1872\n",
      "Epoch 8884/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1244413423.1546 - val_loss: 1300625631.5616\n",
      "Epoch 8885/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1244385187.5695 - val_loss: 1302405324.8584\n",
      "Epoch 8886/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1244057921.1272 - val_loss: 1301494883.0685\n",
      "Epoch 8887/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1245197961.2681 - val_loss: 1301093677.5890\n",
      "Epoch 8888/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1244246621.6830 - val_loss: 1302373430.6484\n",
      "Epoch 8889/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1244919446.0431 - val_loss: 1300166965.4795\n",
      "Epoch 8890/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1244270152.3288 - val_loss: 1300087976.3288\n",
      "Epoch 8891/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1244596329.2055 - val_loss: 1301585467.3242\n",
      "Epoch 8892/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1244063736.3601 - val_loss: 1302021321.6438\n",
      "Epoch 8893/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1243935781.0098 - val_loss: 1300836086.0639\n",
      "Epoch 8894/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1244469375.8121 - val_loss: 1300272267.6895\n",
      "Epoch 8895/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1243842397.1820 - val_loss: 1301886204.7854\n",
      "Epoch 8896/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1243775683.6321 - val_loss: 1301708111.7808\n",
      "Epoch 8897/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1244064711.8904 - val_loss: 1300528730.8858\n",
      "Epoch 8898/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1243967993.9883 - val_loss: 1300710164.4566\n",
      "Epoch 8899/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1244002596.1957 - val_loss: 1300683718.7215\n",
      "Epoch 8900/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1244389429.7299 - val_loss: 1299918692.2374\n",
      "Epoch 8901/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1244124410.6145 - val_loss: 1301687874.6301\n",
      "Epoch 8902/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1244177257.2055 - val_loss: 1302361600.8767\n",
      "Epoch 8903/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1243931730.7867 - val_loss: 1301931651.2146\n",
      "Epoch 8904/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1243841791.6243 - val_loss: 1301485115.9087\n",
      "Epoch 8905/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1245117670.4501 - val_loss: 1302688893.0776\n",
      "Epoch 8906/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1244410391.5460 - val_loss: 1298874983.4521\n",
      "Epoch 8907/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1244003526.8258 - val_loss: 1301117509.5525\n",
      "Epoch 8908/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1243831083.9609 - val_loss: 1299385102.3196\n",
      "Epoch 8909/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1243828220.7436 - val_loss: 1300062844.7854\n",
      "Epoch 8910/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1244052180.7906 - val_loss: 1299699966.5388\n",
      "Epoch 8911/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 29us/step - loss: 1243809650.8493 - val_loss: 1300452717.2968\n",
      "Epoch 8912/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1243638932.6654 - val_loss: 1301300866.0457\n",
      "Epoch 8913/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1243567125.7299 - val_loss: 1300610889.3516\n",
      "Epoch 8914/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1243696447.0607 - val_loss: 1301020658.8493\n",
      "Epoch 8915/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1243517147.4286 - val_loss: 1300516866.0457\n",
      "Epoch 8916/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1243969525.2290 - val_loss: 1301766286.9041\n",
      "Epoch 8917/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1244786407.0763 - val_loss: 1298871941.8447\n",
      "Epoch 8918/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1243284938.8963 - val_loss: 1300253201.5342\n",
      "Epoch 8919/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1243428485.2603 - val_loss: 1301047265.0228\n",
      "Epoch 8920/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1243772630.5440 - val_loss: 1299739585.4612\n",
      "Epoch 8921/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1243522980.9472 - val_loss: 1301572899.0685\n",
      "Epoch 8922/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1243327516.6810 - val_loss: 1301171261.9543\n",
      "Epoch 8923/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1243393301.2916 - val_loss: 1300464921.1324\n",
      "Epoch 8924/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1243363666.6614 - val_loss: 1300894629.4064\n",
      "Epoch 8925/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1243334629.8865 - val_loss: 1300419832.6941\n",
      "Epoch 8926/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1243512506.4892 - val_loss: 1300932380.3470\n",
      "Epoch 8927/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1243370092.5871 - val_loss: 1300575016.0365\n",
      "Epoch 8928/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1243670531.5068 - val_loss: 1299613653.9178\n",
      "Epoch 8929/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1243456950.3562 - val_loss: 1301219766.3562\n",
      "Epoch 8930/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1243325418.7397 - val_loss: 1299993780.3105\n",
      "Epoch 8931/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1243273210.3640 - val_loss: 1300364386.4840\n",
      "Epoch 8932/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1243265193.5812 - val_loss: 1300952387.2146\n",
      "Epoch 8933/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1243027811.6947 - val_loss: 1299596707.6530\n",
      "Epoch 8934/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1243847159.9843 - val_loss: 1299379645.6621\n",
      "Epoch 8935/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1243866647.4207 - val_loss: 1301178912.4384\n",
      "Epoch 8936/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1243258230.7319 - val_loss: 1300107440.2192\n",
      "Epoch 8937/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1243201518.4658 - val_loss: 1299459133.0776\n",
      "Epoch 8938/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1243144054.4814 - val_loss: 1299388717.8813\n",
      "Epoch 8939/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1243852431.9687 - val_loss: 1299975966.3927\n",
      "Epoch 8940/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1243367825.6595 - val_loss: 1300053398.5023\n",
      "Epoch 8941/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1243227598.9041 - val_loss: 1300960088.8402\n",
      "Epoch 8942/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1243322554.7397 - val_loss: 1299306796.4201\n",
      "Epoch 8943/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1243211745.0646 - val_loss: 1299709783.9635\n",
      "Epoch 8944/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1243705848.1096 - val_loss: 1300261590.7945\n",
      "Epoch 8945/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1242945314.5675 - val_loss: 1300244930.0457\n",
      "Epoch 8946/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1243737999.8434 - val_loss: 1300393396.0183\n",
      "Epoch 8947/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1242952926.1840 - val_loss: 1298689182.3927\n",
      "Epoch 8948/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1243057233.7847 - val_loss: 1299426605.0046\n",
      "Epoch 8949/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1242940320.5636 - val_loss: 1299578159.3425\n",
      "Epoch 8950/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1243073625.9256 - val_loss: 1299016252.7854\n",
      "Epoch 8951/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1243110763.7104 - val_loss: 1299403282.7032\n",
      "Epoch 8952/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1242898253.4012 - val_loss: 1298933362.5571\n",
      "Epoch 8953/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1242837205.9178 - val_loss: 1299430073.8630\n",
      "Epoch 8954/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1243049481.5186 - val_loss: 1298829731.9452\n",
      "Epoch 8955/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1242923122.7241 - val_loss: 1298653281.0228\n",
      "Epoch 8956/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1242892333.5890 - val_loss: 1299079870.5388\n",
      "Epoch 8957/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1243151396.6967 - val_loss: 1300378891.6895\n",
      "Epoch 8958/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1242962131.9139 - val_loss: 1300521238.5023\n",
      "Epoch 8959/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1242573969.7847 - val_loss: 1299377663.7078\n",
      "Epoch 8960/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1243424894.5597 - val_loss: 1297361694.3927\n",
      "Epoch 8961/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1242528959.2485 - val_loss: 1299105269.1872\n",
      "Epoch 8962/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1242658450.1605 - val_loss: 1299770618.1553\n",
      "Epoch 8963/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1243525855.4364 - val_loss: 1301205715.2877\n",
      "Epoch 8964/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1242817010.4736 - val_loss: 1298963645.9543\n",
      "Epoch 8965/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1242681481.1429 - val_loss: 1299545293.7352\n",
      "Epoch 8966/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1242849589.9804 - val_loss: 1298550360.2557\n",
      "Epoch 8967/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1243164415.6243 - val_loss: 1298659108.2374\n",
      "Epoch 8968/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1242951086.4658 - val_loss: 1299317816.1096\n",
      "Epoch 8969/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1242573835.1468 - val_loss: 1298410914.7763\n",
      "Epoch 8970/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1242762506.7710 - val_loss: 1299912686.4658\n",
      "Epoch 8971/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1242714326.7945 - val_loss: 1299273322.3744\n",
      "Epoch 8972/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1242748322.8806 - val_loss: 1298569511.4521\n",
      "Epoch 8973/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1242529826.0665 - val_loss: 1300028172.5662\n",
      "Epoch 8974/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1242326752.9393 - val_loss: 1299064713.3516\n",
      "Epoch 8975/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1242359182.0274 - val_loss: 1299261243.6164\n",
      "Epoch 8976/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1242322541.3386 - val_loss: 1298870267.6164\n",
      "Epoch 8977/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1242598027.8982 - val_loss: 1298908131.6530\n",
      "Epoch 8978/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1242391473.0959 - val_loss: 1299631266.1918\n",
      "Epoch 8979/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1242501599.9374 - val_loss: 1297944389.5525\n",
      "Epoch 8980/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1242425505.1898 - val_loss: 1297569947.1781\n",
      "Epoch 8981/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1242478851.5695 - val_loss: 1299434127.4886\n",
      "Epoch 8982/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1242244710.0744 - val_loss: 1299354704.9498\n",
      "Epoch 8983/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1242659060.3523 - val_loss: 1299611343.1963\n",
      "Epoch 8984/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1243029015.4207 - val_loss: 1298553146.1553\n",
      "Epoch 8985/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1242379048.9550 - val_loss: 1298946293.4795\n",
      "Epoch 8986/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1242308199.2016 - val_loss: 1298743088.5114\n",
      "Epoch 8987/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1242502827.2094 - val_loss: 1298938203.1781\n",
      "Epoch 8988/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1242109889.5029 - val_loss: 1298486941.5160\n",
      "Epoch 8989/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1242185048.7984 - val_loss: 1298066361.5708\n",
      "Epoch 8990/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1242489980.9941 - val_loss: 1299865069.5890\n",
      "Epoch 8991/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1242459621.1977 - val_loss: 1299261400.8402\n",
      "Epoch 8992/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1241958744.0470 - val_loss: 1298576096.7306\n",
      "Epoch 8993/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1242018641.6595 - val_loss: 1298358840.9863\n",
      "Epoch 8994/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1242518730.2701 - val_loss: 1296923490.4840\n",
      "Epoch 8995/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1242784295.0763 - val_loss: 1299820126.3927\n",
      "Epoch 8996/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1242439965.0568 - val_loss: 1298101331.8721\n",
      "Epoch 8997/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1242339324.3679 - val_loss: 1298974420.7489\n",
      "Epoch 8998/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1242068968.7045 - val_loss: 1297583198.3927\n",
      "Epoch 8999/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1241860017.8474 - val_loss: 1298278259.7260\n",
      "Epoch 9000/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1242140933.2603 - val_loss: 1299222806.2100\n",
      "Epoch 9001/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1242095007.8121 - val_loss: 1299386046.5388\n",
      "Epoch 9002/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1242089497.5499 - val_loss: 1299124444.9315\n",
      "Epoch 9003/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1241790036.6654 - val_loss: 1298922155.8356\n",
      "Epoch 9004/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1242052196.0078 - val_loss: 1297581844.1644\n",
      "Epoch 9005/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1241790707.4129 - val_loss: 1297775442.4110\n",
      "Epoch 9006/15000\n",
      "1022/1022 [==============================] - ETA: 0s - loss: 1104774784.00 - 0s 29us/step - loss: 1241922687.7495 - val_loss: 1298384548.8219\n",
      "Epoch 9007/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1242027873.6908 - val_loss: 1297374028.8584\n",
      "Epoch 9008/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1241971875.3190 - val_loss: 1298607862.9406\n",
      "Epoch 9009/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1242556040.7671 - val_loss: 1299362678.0639\n",
      "Epoch 9010/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1241710695.9530 - val_loss: 1298685416.9132\n",
      "Epoch 9011/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1241697918.9980 - val_loss: 1298860684.5662\n",
      "Epoch 9012/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1242342273.2524 - val_loss: 1298641273.8630\n",
      "Epoch 9013/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1242081469.1194 - val_loss: 1297449488.3653\n",
      "Epoch 9014/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1242714462.1840 - val_loss: 1299536432.2192\n",
      "Epoch 9015/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1241874829.5890 - val_loss: 1297049880.2557\n",
      "Epoch 9016/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1241815578.8023 - val_loss: 1296439042.6301\n",
      "Epoch 9017/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1242115495.1389 - val_loss: 1299242577.2420\n",
      "Epoch 9018/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1241584551.4521 - val_loss: 1298043078.4292\n",
      "Epoch 9019/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1241790049.1898 - val_loss: 1296745656.4018\n",
      "Epoch 9020/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1241856061.1194 - val_loss: 1298740265.7900\n",
      "Epoch 9021/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1241644487.8904 - val_loss: 1298900718.4658\n",
      "Epoch 9022/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1241413711.4051 - val_loss: 1297826393.7169\n",
      "Epoch 9023/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1241449276.6184 - val_loss: 1296899531.9817\n",
      "Epoch 9024/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1241626029.8395 - val_loss: 1296252410.1553\n",
      "Epoch 9025/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1241660335.0920 - val_loss: 1297308111.7808\n",
      "Epoch 9026/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1241606668.7750 - val_loss: 1297291802.5936\n",
      "Epoch 9027/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1241417205.1037 - val_loss: 1298965174.6484\n",
      "Epoch 9028/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1241650500.7593 - val_loss: 1297754533.9909\n",
      "Epoch 9029/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1241500847.0920 - val_loss: 1297069033.4977\n",
      "Epoch 9030/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1241377905.4716 - val_loss: 1297751059.8721\n",
      "Epoch 9031/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1241270557.9335 - val_loss: 1298697743.7808\n",
      "Epoch 9032/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1241988354.5049 - val_loss: 1296706797.2968\n",
      "Epoch 9033/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1241251280.3444 - val_loss: 1297436114.7032\n",
      "Epoch 9034/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1241394244.8845 - val_loss: 1296872714.5205\n",
      "Epoch 9035/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1241470930.3483 - val_loss: 1297227218.9954\n",
      "Epoch 9036/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1241794198.4188 - val_loss: 1298560544.7306\n",
      "Epoch 9037/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1241154603.7104 - val_loss: 1298270006.0639\n",
      "Epoch 9038/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1241211510.0431 - val_loss: 1297583933.0776\n",
      "Epoch 9039/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 28us/step - loss: 1241800635.4912 - val_loss: 1298441626.5936\n",
      "Epoch 9040/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1241729216.3757 - val_loss: 1296301747.7260\n",
      "Epoch 9041/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1241373158.1996 - val_loss: 1297839618.0457\n",
      "Epoch 9042/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1241088645.2603 - val_loss: 1297112315.0320\n",
      "Epoch 9043/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1241142547.8513 - val_loss: 1297084385.6073\n",
      "Epoch 9044/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1241189514.1448 - val_loss: 1297691540.4566\n",
      "Epoch 9045/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1242008863.8121 - val_loss: 1298123770.1553\n",
      "Epoch 9046/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1240984928.5636 - val_loss: 1297919587.3607\n",
      "Epoch 9047/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1241380438.4188 - val_loss: 1298227758.4658\n",
      "Epoch 9048/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1241202348.2114 - val_loss: 1297215386.5936\n",
      "Epoch 9049/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1241344992.5636 - val_loss: 1298284872.1826\n",
      "Epoch 9050/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1241490286.0900 - val_loss: 1297697548.2740\n",
      "Epoch 9051/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1241262070.4188 - val_loss: 1295953554.9954\n",
      "Epoch 9052/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1241114696.3914 - val_loss: 1297180115.8721\n",
      "Epoch 9053/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1240808233.0802 - val_loss: 1297777487.7808\n",
      "Epoch 9054/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1240898331.1781 - val_loss: 1297597027.3607\n",
      "Epoch 9055/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1241135605.2290 - val_loss: 1295929936.6575\n",
      "Epoch 9056/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1240889173.1663 - val_loss: 1297053396.1644\n",
      "Epoch 9057/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1240901377.0020 - val_loss: 1297456262.1370\n",
      "Epoch 9058/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1241370933.8552 - val_loss: 1298064298.6667\n",
      "Epoch 9059/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1240802702.9667 - val_loss: 1296297265.0959\n",
      "Epoch 9060/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1240731461.2603 - val_loss: 1297036750.9041\n",
      "Epoch 9061/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1240688854.7945 - val_loss: 1296920224.1461\n",
      "Epoch 9062/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1240928216.9237 - val_loss: 1295688451.2146\n",
      "Epoch 9063/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1240996941.2759 - val_loss: 1297463291.9087\n",
      "Epoch 9064/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1240978770.9119 - val_loss: 1296138437.8447\n",
      "Epoch 9065/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1240939855.2798 - val_loss: 1297963576.9863\n",
      "Epoch 9066/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1241052239.1546 - val_loss: 1295557853.2237\n",
      "Epoch 9067/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1240667212.9002 - val_loss: 1296541033.2055\n",
      "Epoch 9068/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1240564007.4521 - val_loss: 1297415320.8402\n",
      "Epoch 9069/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1240580152.6106 - val_loss: 1297445210.8858\n",
      "Epoch 9070/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1240790805.0411 - val_loss: 1297745502.6849\n",
      "Epoch 9071/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1240562913.9413 - val_loss: 1296839562.5205\n",
      "Epoch 9072/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1240705072.9706 - val_loss: 1297763881.7900\n",
      "Epoch 9073/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1240685427.4755 - val_loss: 1296617014.6484\n",
      "Epoch 9074/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1240403517.1194 - val_loss: 1296229937.9726\n",
      "Epoch 9075/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1240611618.4423 - val_loss: 1296770175.7078\n",
      "Epoch 9076/15000\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 1240689268.6654 - val_loss: 1295730484.0183\n",
      "Epoch 9077/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1240833921.0020 - val_loss: 1296533070.0274\n",
      "Epoch 9078/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1241112255.1233 - val_loss: 1297292682.5205\n",
      "Epoch 9079/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1240804640.3131 - val_loss: 1296916057.4247\n",
      "Epoch 9080/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1240318578.7241 - val_loss: 1296011423.8539\n",
      "Epoch 9081/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1240670341.2603 - val_loss: 1296406744.8402\n",
      "Epoch 9082/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1240400787.2250 - val_loss: 1296789631.7078\n",
      "Epoch 9083/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1240851929.9256 - val_loss: 1295738874.1553\n",
      "Epoch 9084/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1240326351.6556 - val_loss: 1296318001.9726\n",
      "Epoch 9085/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1240934416.0313 - val_loss: 1297768114.2648\n",
      "Epoch 9086/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1240332847.7808 - val_loss: 1296494716.4932\n",
      "Epoch 9087/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1240284777.3307 - val_loss: 1295816451.7991\n",
      "Epoch 9088/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1240375788.6497 - val_loss: 1296387865.4247\n",
      "Epoch 9089/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1240255951.0294 - val_loss: 1296176320.5845\n",
      "Epoch 9090/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1240242967.7339 - val_loss: 1296304630.9406\n",
      "Epoch 9091/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1240696606.0587 - val_loss: 1296389321.3516\n",
      "Epoch 9092/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1240922481.2211 - val_loss: 1297781528.8402\n",
      "Epoch 9093/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1239928604.5558 - val_loss: 1296314763.3973\n",
      "Epoch 9094/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1241018006.0431 - val_loss: 1294693029.6986\n",
      "Epoch 9095/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1240927900.6810 - val_loss: 1297764790.3562\n",
      "Epoch 9096/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1240396223.8748 - val_loss: 1297159512.5479\n",
      "Epoch 9097/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1239831410.2231 - val_loss: 1296060910.4658\n",
      "Epoch 9098/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1240305109.6673 - val_loss: 1294931929.1324\n",
      "Epoch 9099/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1240259343.1546 - val_loss: 1296292233.9361\n",
      "Epoch 9100/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1240574941.6830 - val_loss: 1295179072.0000\n",
      "Epoch 9101/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1240066771.2877 - val_loss: 1295351306.5205\n",
      "Epoch 9102/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1240201121.5029 - val_loss: 1296905926.7215\n",
      "Epoch 9103/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1240508816.0313 - val_loss: 1295439223.2329\n",
      "Epoch 9104/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1240404361.7691 - val_loss: 1295066725.4064\n",
      "Epoch 9105/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1240728557.4638 - val_loss: 1297435626.0822\n",
      "Epoch 9106/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1240265073.9726 - val_loss: 1295787313.3881\n",
      "Epoch 9107/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1240116171.0215 - val_loss: 1295872986.5936\n",
      "Epoch 9108/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1240212297.7691 - val_loss: 1296867014.7215\n",
      "Epoch 9109/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1239741100.4618 - val_loss: 1296355492.5297\n",
      "Epoch 9110/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1240332968.4540 - val_loss: 1294727328.7306\n",
      "Epoch 9111/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1240265320.1409 - val_loss: 1296851098.0091\n",
      "Epoch 9112/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1239939703.7339 - val_loss: 1294968721.2420\n",
      "Epoch 9113/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1240106208.6262 - val_loss: 1295307844.9680\n",
      "Epoch 9114/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1239836203.3346 - val_loss: 1296393791.1233\n",
      "Epoch 9115/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1240012901.0724 - val_loss: 1296051956.3105\n",
      "Epoch 9116/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1240170778.3014 - val_loss: 1295768540.6393\n",
      "Epoch 9117/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1239761709.3386 - val_loss: 1296946088.0365\n",
      "Epoch 9118/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1240017560.4227 - val_loss: 1296138478.7580\n",
      "Epoch 9119/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1239820361.0176 - val_loss: 1295900430.0274\n",
      "Epoch 9120/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1239589903.1546 - val_loss: 1296545522.2648\n",
      "Epoch 9121/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1239936788.2896 - val_loss: 1295346232.9863\n",
      "Epoch 9122/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1239937796.7593 - val_loss: 1296638274.9224\n",
      "Epoch 9123/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1239607567.0294 - val_loss: 1296148721.6804\n",
      "Epoch 9124/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1239491680.4384 - val_loss: 1295435760.8037\n",
      "Epoch 9125/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1239559258.8023 - val_loss: 1296812140.7123\n",
      "Epoch 9126/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1239640857.8004 - val_loss: 1296322781.8082\n",
      "Epoch 9127/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1239574588.8689 - val_loss: 1295304840.4749\n",
      "Epoch 9128/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1240295245.9022 - val_loss: 1296457665.7534\n",
      "Epoch 9129/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1239684442.4266 - val_loss: 1296274457.1324\n",
      "Epoch 9130/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1239377088.6262 - val_loss: 1295713883.7626\n",
      "Epoch 9131/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1239487473.8474 - val_loss: 1295968775.5982\n",
      "Epoch 9132/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1239720628.7280 - val_loss: 1296211585.4612\n",
      "Epoch 9133/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1239897882.8023 - val_loss: 1296094030.6119\n",
      "Epoch 9134/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1239285408.8141 - val_loss: 1295204669.9543\n",
      "Epoch 9135/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1239332757.8552 - val_loss: 1295634493.6621\n",
      "Epoch 9136/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1239288747.9609 - val_loss: 1295896434.8493\n",
      "Epoch 9137/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1239660031.4990 - val_loss: 1294462102.5023\n",
      "Epoch 9138/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1239340460.3366 - val_loss: 1294444784.5114\n",
      "Epoch 9139/15000\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 1239508122.5519 - val_loss: 1296164551.8904\n",
      "Epoch 9140/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1239245862.1996 - val_loss: 1295940694.5023\n",
      "Epoch 9141/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1239707310.4658 - val_loss: 1296251536.0731\n",
      "Epoch 9142/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1239537386.5832 - val_loss: 1296408312.4018\n",
      "Epoch 9143/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1239296385.8787 - val_loss: 1296214926.3196\n",
      "Epoch 9144/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1239292162.0039 - val_loss: 1295098463.2694\n",
      "Epoch 9145/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1239140250.0509 - val_loss: 1295007612.2009\n",
      "Epoch 9146/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1239260982.6067 - val_loss: 1295281918.5388\n",
      "Epoch 9147/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1239643177.0802 - val_loss: 1294120553.2055\n",
      "Epoch 9148/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1239694802.0352 - val_loss: 1296408950.9406\n",
      "Epoch 9149/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1239960361.3307 - val_loss: 1294450632.7671\n",
      "Epoch 9150/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1239090718.3092 - val_loss: 1294806622.6849\n",
      "Epoch 9151/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1239082114.1292 - val_loss: 1295516916.0183\n",
      "Epoch 9152/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1239002958.2779 - val_loss: 1294915491.6530\n",
      "Epoch 9153/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1239001497.4247 - val_loss: 1295579059.7260\n",
      "Epoch 9154/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1239292863.4990 - val_loss: 1294470898.8493\n",
      "Epoch 9155/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1239080916.6654 - val_loss: 1296221232.2192\n",
      "Epoch 9156/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1238892845.4638 - val_loss: 1295369179.7626\n",
      "Epoch 9157/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1239701646.5284 - val_loss: 1296333787.7626\n",
      "Epoch 9158/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1238742514.9119 - val_loss: 1294845079.0868\n",
      "Epoch 9159/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1239070235.6791 - val_loss: 1294528415.8539\n",
      "Epoch 9160/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1238922209.0646 - val_loss: 1294396136.9132\n",
      "Epoch 9161/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1238869518.9667 - val_loss: 1295333300.0183\n",
      "Epoch 9162/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1238798958.9667 - val_loss: 1294901665.3151\n",
      "Epoch 9163/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1238826333.9335 - val_loss: 1294239626.2283\n",
      "Epoch 9164/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1239351910.4501 - val_loss: 1296319743.4155\n",
      "Epoch 9165/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1238853673.3307 - val_loss: 1295613707.3973\n",
      "Epoch 9166/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1238687035.0528 - val_loss: 1294204449.6073\n",
      "Epoch 9167/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 28us/step - loss: 1238812477.1194 - val_loss: 1295191936.2922\n",
      "Epoch 9168/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1238857694.5597 - val_loss: 1294569462.9406\n",
      "Epoch 9169/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1238735085.9648 - val_loss: 1294074804.0183\n",
      "Epoch 9170/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1238798936.2975 - val_loss: 1294252075.5434\n",
      "Epoch 9171/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1238947756.2114 - val_loss: 1295057336.4018\n",
      "Epoch 9172/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1238556374.1683 - val_loss: 1294334093.7352\n",
      "Epoch 9173/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1238801895.0763 - val_loss: 1293036410.4475\n",
      "Epoch 9174/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1239836553.5186 - val_loss: 1296143571.8721\n",
      "Epoch 9175/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1238883793.9100 - val_loss: 1292519331.6530\n",
      "Epoch 9176/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1239480951.3581 - val_loss: 1294884623.4886\n",
      "Epoch 9177/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1238610002.0352 - val_loss: 1294038393.2785\n",
      "Epoch 9178/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1238491299.4442 - val_loss: 1293906555.0320\n",
      "Epoch 9179/15000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1238561577.8317 - val_loss: 1294194997.4795\n",
      "Epoch 9180/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1238807236.3836 - val_loss: 1294290737.0959\n",
      "Epoch 9181/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1238965756.7436 - val_loss: 1293870937.1324\n",
      "Epoch 9182/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1238589192.8924 - val_loss: 1293619392.8767\n",
      "Epoch 9183/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1238888268.0235 - val_loss: 1294853827.2146\n",
      "Epoch 9184/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1238829605.8239 - val_loss: 1294895946.8128\n",
      "Epoch 9185/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1238479101.6204 - val_loss: 1294309508.6758\n",
      "Epoch 9186/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1238858934.6067 - val_loss: 1295283102.6849\n",
      "Epoch 9187/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1238458876.4305 - val_loss: 1293391798.0639\n",
      "Epoch 9188/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1238497987.6321 - val_loss: 1293782193.6804\n",
      "Epoch 9189/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1238511214.4658 - val_loss: 1293254172.0548\n",
      "Epoch 9190/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1238744097.4403 - val_loss: 1295194298.1553\n",
      "Epoch 9191/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1238711255.2329 - val_loss: 1294995459.7991\n",
      "Epoch 9192/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1238856545.4403 - val_loss: 1293212743.3059\n",
      "Epoch 9193/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1238180975.9687 - val_loss: 1293429385.9361\n",
      "Epoch 9194/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1238275361.0646 - val_loss: 1293685001.3516\n",
      "Epoch 9195/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1238604204.0861 - val_loss: 1294554285.2968\n",
      "Epoch 9196/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1239119811.3816 - val_loss: 1293267632.8037\n",
      "Epoch 9197/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1238640308.8532 - val_loss: 1294775935.1233\n",
      "Epoch 9198/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1238980663.7339 - val_loss: 1291824654.9041\n",
      "Epoch 9199/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1239382631.9530 - val_loss: 1295031212.4201\n",
      "Epoch 9200/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1238676704.1879 - val_loss: 1294765793.6073\n",
      "Epoch 9201/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1238049537.4403 - val_loss: 1293031085.5890\n",
      "Epoch 9202/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1237949735.9530 - val_loss: 1293087841.3151\n",
      "Epoch 9203/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1238984437.9178 - val_loss: 1294496224.1461\n",
      "Epoch 9204/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1238532928.3757 - val_loss: 1293032578.3379\n",
      "Epoch 9205/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1238079847.4521 - val_loss: 1293443288.5479\n",
      "Epoch 9206/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1238061130.0196 - val_loss: 1292897909.7717\n",
      "Epoch 9207/15000\n",
      "1022/1022 [==============================] - 0s 70us/step - loss: 1238434303.2485 - val_loss: 1294098540.1279\n",
      "Epoch 9208/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1238247026.3483 - val_loss: 1294271147.5434\n",
      "Epoch 9209/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1237870104.7984 - val_loss: 1292516492.5662\n",
      "Epoch 9210/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1238138886.3875 - val_loss: 1292803129.5708\n",
      "Epoch 9211/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1238027293.9335 - val_loss: 1291987391.7078\n",
      "Epoch 9212/15000\n",
      "1022/1022 [==============================] - 0s 76us/step - loss: 1238097159.2642 - val_loss: 1293651671.0868\n",
      "Epoch 9213/15000\n",
      "1022/1022 [==============================] - 0s 65us/step - loss: 1238074132.9785 - val_loss: 1293166011.6164\n",
      "Epoch 9214/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1238213980.8063 - val_loss: 1294139126.0639\n",
      "Epoch 9215/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1237701226.4579 - val_loss: 1293677835.6895\n",
      "Epoch 9216/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1238051824.4697 - val_loss: 1291991625.3516\n",
      "Epoch 9217/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1238251214.8415 - val_loss: 1293482633.0594\n",
      "Epoch 9218/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1238169209.3620 - val_loss: 1292537066.3744\n",
      "Epoch 9219/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1237757868.9628 - val_loss: 1292499106.1918\n",
      "Epoch 9220/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1237785499.8043 - val_loss: 1293477721.1324\n",
      "Epoch 9221/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1237668238.9041 - val_loss: 1293254442.6667\n",
      "Epoch 9222/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1239001038.0274 - val_loss: 1290475517.3699\n",
      "Epoch 9223/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1238814572.3366 - val_loss: 1293684135.4521\n",
      "Epoch 9224/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1237491866.5519 - val_loss: 1293250444.5662\n",
      "Epoch 9225/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1237728019.9139 - val_loss: 1292169835.2511\n",
      "Epoch 9226/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1238082310.8885 - val_loss: 1292836498.1187\n",
      "Epoch 9227/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1237556436.5401 - val_loss: 1293155485.8082\n",
      "Epoch 9228/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1237810624.8767 - val_loss: 1291627021.1507\n",
      "Epoch 9229/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1237493022.0587 - val_loss: 1292816875.2511\n",
      "Epoch 9230/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1237582449.7221 - val_loss: 1293722382.9041\n",
      "Epoch 9231/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1237507741.0568 - val_loss: 1292034699.3973\n",
      "Epoch 9232/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1237809008.5949 - val_loss: 1292889742.0274\n",
      "Epoch 9233/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1237816326.0117 - val_loss: 1291222933.3333\n",
      "Epoch 9234/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1237493023.0607 - val_loss: 1292203653.5525\n",
      "Epoch 9235/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1238292151.3581 - val_loss: 1290712393.6438\n",
      "Epoch 9236/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1237685685.7299 - val_loss: 1292825515.2511\n",
      "Epoch 9237/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1237754969.8004 - val_loss: 1292699076.6758\n",
      "Epoch 9238/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1237731551.6869 - val_loss: 1293850370.3379\n",
      "Epoch 9239/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1237627131.2407 - val_loss: 1293462051.6530\n",
      "Epoch 9240/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1237399774.4344 - val_loss: 1291661231.3425\n",
      "Epoch 9241/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1237412321.7221 - val_loss: 1292673239.6712\n",
      "Epoch 9242/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1237838485.7926 - val_loss: 1291945597.3699\n",
      "Epoch 9243/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1237592727.9217 - val_loss: 1293203392.0000\n",
      "Epoch 9244/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1237824910.1526 - val_loss: 1291237513.0594\n",
      "Epoch 9245/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1237494755.1937 - val_loss: 1291478636.4201\n",
      "Epoch 9246/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1237335100.8689 - val_loss: 1293241181.8082\n",
      "Epoch 9247/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1237427864.4227 - val_loss: 1292317459.8721\n",
      "Epoch 9248/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1237121023.1233 - val_loss: 1292636615.0137\n",
      "Epoch 9249/15000\n",
      "1022/1022 [==============================] - 0s 63us/step - loss: 1237372531.9765 - val_loss: 1292152835.7991\n",
      "Epoch 9250/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1237124801.1272 - val_loss: 1292258539.2511\n",
      "Epoch 9251/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1237454046.1840 - val_loss: 1292794583.3790\n",
      "Epoch 9252/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1237248326.2622 - val_loss: 1291705931.6895\n",
      "Epoch 9253/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1237138247.0763 - val_loss: 1291262931.8721\n",
      "Epoch 9254/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1237235792.4070 - val_loss: 1291811938.4840\n",
      "Epoch 9255/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1237796671.1233 - val_loss: 1292070532.6758\n",
      "Epoch 9256/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1236905832.7045 - val_loss: 1291641609.3516\n",
      "Epoch 9257/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1237033899.7730 - val_loss: 1291435633.6804\n",
      "Epoch 9258/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1237025334.7319 - val_loss: 1292363738.3014\n",
      "Epoch 9259/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1236880563.4755 - val_loss: 1291459872.7306\n",
      "Epoch 9260/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1236989796.0705 - val_loss: 1291672187.3242\n",
      "Epoch 9261/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1237302127.3425 - val_loss: 1291212471.8174\n",
      "Epoch 9262/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1237376669.4325 - val_loss: 1291853869.2968\n",
      "Epoch 9263/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1236819093.1663 - val_loss: 1291967906.4840\n",
      "Epoch 9264/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1237326296.9237 - val_loss: 1290374872.5479\n",
      "Epoch 9265/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1236784785.9100 - val_loss: 1291860793.8630\n",
      "Epoch 9266/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1237152264.1409 - val_loss: 1292818489.8630\n",
      "Epoch 9267/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1237072193.8787 - val_loss: 1291771752.3288\n",
      "Epoch 9268/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1236804901.0724 - val_loss: 1291970137.7169\n",
      "Epoch 9269/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1236860003.8200 - val_loss: 1292083841.7534\n",
      "Epoch 9270/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1236810979.1937 - val_loss: 1291386460.6393\n",
      "Epoch 9271/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1236857966.2153 - val_loss: 1291472482.4840\n",
      "Epoch 9272/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1237407491.1311 - val_loss: 1291447187.2877\n",
      "Epoch 9273/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1236825410.6301 - val_loss: 1291413451.6895\n",
      "Epoch 9274/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1236805517.7143 - val_loss: 1290554840.5479\n",
      "Epoch 9275/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1236757764.8845 - val_loss: 1291709577.9361\n",
      "Epoch 9276/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1236776192.6262 - val_loss: 1290818561.1689\n",
      "Epoch 9277/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1236616774.7632 - val_loss: 1290766136.9863\n",
      "Epoch 9278/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1236690154.5205 - val_loss: 1292251676.9315\n",
      "Epoch 9279/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1236588314.5519 - val_loss: 1291705017.5708\n",
      "Epoch 9280/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1236708272.5323 - val_loss: 1291727276.4201\n",
      "Epoch 9281/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1237296796.0548 - val_loss: 1292573710.0274\n",
      "Epoch 9282/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1237096064.1252 - val_loss: 1290689864.1826\n",
      "Epoch 9283/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1236604363.6477 - val_loss: 1291377845.4795\n",
      "Epoch 9284/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1236565547.5225 - val_loss: 1290724211.7260\n",
      "Epoch 9285/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1236768677.6986 - val_loss: 1290812438.7945\n",
      "Epoch 9286/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1236613759.1233 - val_loss: 1291758268.7854\n",
      "Epoch 9287/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1236866515.7886 - val_loss: 1290745647.0502\n",
      "Epoch 9288/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1236407995.6164 - val_loss: 1291547996.9315\n",
      "Epoch 9289/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1237088485.9491 - val_loss: 1291869881.5708\n",
      "Epoch 9290/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1236898243.3816 - val_loss: 1290881312.4384\n",
      "Epoch 9291/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1236463887.2798 - val_loss: 1291351978.0822\n",
      "Epoch 9292/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1236255512.3601 - val_loss: 1290879913.4977\n",
      "Epoch 9293/15000\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 1236499855.4677 - val_loss: 1290098424.9863\n",
      "Epoch 9294/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1236767672.8611 - val_loss: 1291311077.1142\n",
      "Epoch 9295/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 45us/step - loss: 1236953488.0313 - val_loss: 1289471079.1598\n",
      "Epoch 9296/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1236390211.6321 - val_loss: 1289230245.1142\n",
      "Epoch 9297/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1236916163.0685 - val_loss: 1292163648.5845\n",
      "Epoch 9298/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1236569362.5362 - val_loss: 1290138974.3927\n",
      "Epoch 9299/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1236708589.3386 - val_loss: 1291609193.2055\n",
      "Epoch 9300/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1236431925.2290 - val_loss: 1291551341.0046\n",
      "Epoch 9301/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1236537609.2681 - val_loss: 1291255905.0228\n",
      "Epoch 9302/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1236586289.3464 - val_loss: 1290268126.9772\n",
      "Epoch 9303/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1236228040.8924 - val_loss: 1291515827.7260\n",
      "Epoch 9304/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1236276902.8258 - val_loss: 1291310890.3744\n",
      "Epoch 9305/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1236011474.3483 - val_loss: 1290204233.9361\n",
      "Epoch 9306/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1236117402.0509 - val_loss: 1290255712.1461\n",
      "Epoch 9307/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1236049318.5753 - val_loss: 1290520030.3927\n",
      "Epoch 9308/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1236133715.2877 - val_loss: 1290647026.8493\n",
      "Epoch 9309/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1236187162.3014 - val_loss: 1290491142.7215\n",
      "Epoch 9310/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1236297093.8239 - val_loss: 1290107955.4338\n",
      "Epoch 9311/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1236044672.1252 - val_loss: 1290645655.0868\n",
      "Epoch 9312/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1236058311.6399 - val_loss: 1290085414.5753\n",
      "Epoch 9313/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1236016138.4579 - val_loss: 1290405963.3973\n",
      "Epoch 9314/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1235980760.4227 - val_loss: 1289922465.0228\n",
      "Epoch 9315/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1236245210.6771 - val_loss: 1290760436.8950\n",
      "Epoch 9316/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1236191433.7691 - val_loss: 1291436229.5525\n",
      "Epoch 9317/15000\n",
      "1022/1022 [==============================] - 0s 70us/step - loss: 1236023313.2838 - val_loss: 1290247665.0959\n",
      "Epoch 9318/15000\n",
      "1022/1022 [==============================] - 0s 76us/step - loss: 1236840354.5675 - val_loss: 1291822374.5753\n",
      "Epoch 9319/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1236208792.9863 - val_loss: 1289270086.1370\n",
      "Epoch 9320/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1235878243.8513 - val_loss: 1290031444.1644\n",
      "Epoch 9321/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1236006897.2211 - val_loss: 1290874242.3379\n",
      "Epoch 9322/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1236724595.4755 - val_loss: 1290128628.0183\n",
      "Epoch 9323/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1236330665.0802 - val_loss: 1290890753.1689\n",
      "Epoch 9324/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1235905590.9198 - val_loss: 1290050052.3836\n",
      "Epoch 9325/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1235885344.1252 - val_loss: 1290213325.4429\n",
      "Epoch 9326/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1235814095.4051 - val_loss: 1290175575.3790\n",
      "Epoch 9327/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1235739303.2016 - val_loss: 1289581650.9954\n",
      "Epoch 9328/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1235798897.8474 - val_loss: 1289661749.7717\n",
      "Epoch 9329/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1235963510.2309 - val_loss: 1289643626.0822\n",
      "Epoch 9330/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1235909209.4247 - val_loss: 1289987663.4886\n",
      "Epoch 9331/15000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1236044823.7965 - val_loss: 1290952358.2831\n",
      "Epoch 9332/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1235782053.5734 - val_loss: 1289940343.2329\n",
      "Epoch 9333/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1236312916.1644 - val_loss: 1290873351.8904\n",
      "Epoch 9334/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1236204574.6849 - val_loss: 1289665452.7123\n",
      "Epoch 9335/15000\n",
      "1022/1022 [==============================] - 0s 75us/step - loss: 1235615539.9765 - val_loss: 1289477652.7489\n",
      "Epoch 9336/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1235979236.1957 - val_loss: 1289317048.9863\n",
      "Epoch 9337/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1235745888.0000 - val_loss: 1289225414.7215\n",
      "Epoch 9338/15000\n",
      "1022/1022 [==============================] - 0s 76us/step - loss: 1235414581.8552 - val_loss: 1290328202.2283\n",
      "Epoch 9339/15000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1235970956.9002 - val_loss: 1291489193.4977\n",
      "Epoch 9340/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1235821916.5558 - val_loss: 1290475963.0320\n",
      "Epoch 9341/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1235680255.4990 - val_loss: 1289588589.8813\n",
      "Epoch 9342/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1235945079.8591 - val_loss: 1288629051.9087\n",
      "Epoch 9343/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1235438206.8728 - val_loss: 1289187363.6530\n",
      "Epoch 9344/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1235830715.9922 - val_loss: 1288905107.2877\n",
      "Epoch 9345/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1235970214.8258 - val_loss: 1291763586.6301\n",
      "Epoch 9346/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1235718958.8415 - val_loss: 1288835390.8311\n",
      "Epoch 9347/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1235415768.6732 - val_loss: 1289717330.7032\n",
      "Epoch 9348/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1235383623.7652 - val_loss: 1290170995.4338\n",
      "Epoch 9349/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1235590847.3738 - val_loss: 1290450236.4932\n",
      "Epoch 9350/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1235567310.9041 - val_loss: 1289280663.6712\n",
      "Epoch 9351/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1235662759.0137 - val_loss: 1288523858.4110\n",
      "Epoch 9352/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1235143024.4697 - val_loss: 1289276516.8219\n",
      "Epoch 9353/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1235927774.4344 - val_loss: 1288918428.6393\n",
      "Epoch 9354/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1235214536.1409 - val_loss: 1289232869.9909\n",
      "Epoch 9355/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1235970459.8043 - val_loss: 1287658862.7580\n",
      "Epoch 9356/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1235551303.8904 - val_loss: 1288620509.8082\n",
      "Epoch 9357/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1236266762.1448 - val_loss: 1291540430.6119\n",
      "Epoch 9358/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1235765536.6888 - val_loss: 1289589737.2055\n",
      "Epoch 9359/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 32us/step - loss: 1235264395.8982 - val_loss: 1289791058.1187\n",
      "Epoch 9360/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1235449727.3738 - val_loss: 1289084655.0502\n",
      "Epoch 9361/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1235972511.8121 - val_loss: 1287813020.6393\n",
      "Epoch 9362/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1235945802.8963 - val_loss: 1290964492.8584\n",
      "Epoch 9363/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1235453318.7632 - val_loss: 1290223537.9726\n",
      "Epoch 9364/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1235304940.0861 - val_loss: 1289641512.0365\n",
      "Epoch 9365/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1235332460.2114 - val_loss: 1288235588.0913\n",
      "Epoch 9366/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1235674072.7984 - val_loss: 1289174282.5205\n",
      "Epoch 9367/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1235099895.3581 - val_loss: 1289372750.6119\n",
      "Epoch 9368/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1236951065.2994 - val_loss: 1291240886.3562\n",
      "Epoch 9369/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1235065586.9746 - val_loss: 1289946083.3607\n",
      "Epoch 9370/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1234931598.5910 - val_loss: 1288545218.3379\n",
      "Epoch 9371/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1235052599.2329 - val_loss: 1287917693.6621\n",
      "Epoch 9372/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1234973633.8787 - val_loss: 1288611724.8584\n",
      "Epoch 9373/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1235556905.5812 - val_loss: 1289626984.9132\n",
      "Epoch 9374/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1235619187.2250 - val_loss: 1290002511.4886\n",
      "Epoch 9375/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1235623445.9178 - val_loss: 1288214538.5205\n",
      "Epoch 9376/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1235051538.0352 - val_loss: 1287955818.0822\n",
      "Epoch 9377/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1234962519.2329 - val_loss: 1288404306.1187\n",
      "Epoch 9378/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1235380954.4266 - val_loss: 1288930103.8174\n",
      "Epoch 9379/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1234817295.5303 - val_loss: 1289576921.4247\n",
      "Epoch 9380/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1234898427.4912 - val_loss: 1289535297.1689\n",
      "Epoch 9381/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1234834518.7945 - val_loss: 1288855539.4338\n",
      "Epoch 9382/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1234764060.5558 - val_loss: 1288879965.8082\n",
      "Epoch 9383/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1234962898.7867 - val_loss: 1289539556.8219\n",
      "Epoch 9384/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1234892698.0509 - val_loss: 1289003399.5982\n",
      "Epoch 9385/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1234827769.6125 - val_loss: 1288553637.1142\n",
      "Epoch 9386/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1234860300.2740 - val_loss: 1288739807.8539\n",
      "Epoch 9387/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1234814497.5656 - val_loss: 1287898400.1461\n",
      "Epoch 9388/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1234965336.4227 - val_loss: 1287715301.1142\n",
      "Epoch 9389/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1234999278.4658 - val_loss: 1289642429.3699\n",
      "Epoch 9390/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1235341890.8806 - val_loss: 1287918048.7306\n",
      "Epoch 9391/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1234640105.8317 - val_loss: 1288315915.3973\n",
      "Epoch 9392/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1235131628.2114 - val_loss: 1290331141.8447\n",
      "Epoch 9393/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1235709887.1233 - val_loss: 1288336037.1142\n",
      "Epoch 9394/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1235047626.2701 - val_loss: 1288976065.1689\n",
      "Epoch 9395/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1234893074.0352 - val_loss: 1288031149.5890\n",
      "Epoch 9396/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1234861852.4305 - val_loss: 1289096606.1005\n",
      "Epoch 9397/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1234592798.6849 - val_loss: 1289351056.6575\n",
      "Epoch 9398/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1234449244.9315 - val_loss: 1289023364.9680\n",
      "Epoch 9399/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1234695708.8063 - val_loss: 1289253529.7169\n",
      "Epoch 9400/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1234667845.7613 - val_loss: 1288896695.8174\n",
      "Epoch 9401/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1234546318.2779 - val_loss: 1287070070.9406\n",
      "Epoch 9402/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1234745586.9746 - val_loss: 1288050803.1416\n",
      "Epoch 9403/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1234672202.2074 - val_loss: 1288143625.9361\n",
      "Epoch 9404/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1234549483.0841 - val_loss: 1288883867.1781\n",
      "Epoch 9405/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1234320557.6517 - val_loss: 1288520857.1324\n",
      "Epoch 9406/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1234638802.1605 - val_loss: 1288572596.3105\n",
      "Epoch 9407/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1234400182.6067 - val_loss: 1288427238.2831\n",
      "Epoch 9408/15000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1235057468.1174 - val_loss: 1289399771.4703\n",
      "Epoch 9409/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1234181803.3346 - val_loss: 1288531943.4521\n",
      "Epoch 9410/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1234525008.2818 - val_loss: 1287357850.0091\n",
      "Epoch 9411/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1234568122.2387 - val_loss: 1287065416.4749\n",
      "Epoch 9412/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1234331159.6712 - val_loss: 1288276779.5434\n",
      "Epoch 9413/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1234822686.8102 - val_loss: 1288382556.3470\n",
      "Epoch 9414/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1234768877.2133 - val_loss: 1289317414.2831\n",
      "Epoch 9415/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1234537130.5832 - val_loss: 1288949080.5479\n",
      "Epoch 9416/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1234152090.5519 - val_loss: 1287654211.7991\n",
      "Epoch 9417/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1234381092.5714 - val_loss: 1287792599.6712\n",
      "Epoch 9418/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1234612434.5988 - val_loss: 1289250109.9543\n",
      "Epoch 9419/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1234379208.4540 - val_loss: 1287946196.4566\n",
      "Epoch 9420/15000\n",
      "1022/1022 [==============================] - 0s 70us/step - loss: 1234282338.4423 - val_loss: 1288309642.2283\n",
      "Epoch 9421/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1234101948.4305 - val_loss: 1287826141.2237\n",
      "Epoch 9422/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1234450208.5636 - val_loss: 1288070243.3607\n",
      "Epoch 9423/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 36us/step - loss: 1234791890.2857 - val_loss: 1287573902.3196\n",
      "Epoch 9424/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1234095343.9687 - val_loss: 1287366170.8858\n",
      "Epoch 9425/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1233946710.5440 - val_loss: 1287823066.5936\n",
      "Epoch 9426/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1234144064.5010 - val_loss: 1288571606.2100\n",
      "Epoch 9427/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1234243714.0039 - val_loss: 1288911393.6073\n",
      "Epoch 9428/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1235056364.5871 - val_loss: 1287465850.1553\n",
      "Epoch 9429/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1234000814.4658 - val_loss: 1288100853.1872\n",
      "Epoch 9430/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1234042966.0431 - val_loss: 1288356514.4840\n",
      "Epoch 9431/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1234849188.5714 - val_loss: 1288970904.5479\n",
      "Epoch 9432/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1234313153.0646 - val_loss: 1288707094.5023\n",
      "Epoch 9433/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1233973864.7045 - val_loss: 1288169425.2420\n",
      "Epoch 9434/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1234215338.7084 - val_loss: 1286402009.4247\n",
      "Epoch 9435/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1234010891.2720 - val_loss: 1286907600.0731\n",
      "Epoch 9436/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1234061770.7710 - val_loss: 1287556938.8128\n",
      "Epoch 9437/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1234441113.0489 - val_loss: 1286121227.9817\n",
      "Epoch 9438/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1235100797.4325 - val_loss: 1287977979.9087\n",
      "Epoch 9439/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1233726915.6321 - val_loss: 1288141154.1918\n",
      "Epoch 9440/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1234338048.6262 - val_loss: 1287213744.2192\n",
      "Epoch 9441/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1233850161.1585 - val_loss: 1287094444.1279\n",
      "Epoch 9442/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1234215228.8689 - val_loss: 1287722025.4977\n",
      "Epoch 9443/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1233809090.5675 - val_loss: 1287401999.1963\n",
      "Epoch 9444/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1235345227.5225 - val_loss: 1289666079.2694\n",
      "Epoch 9445/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1233789242.2387 - val_loss: 1287243707.9087\n",
      "Epoch 9446/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1233855946.2701 - val_loss: 1288387287.9635\n",
      "Epoch 9447/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1233945870.0274 - val_loss: 1288144168.0365\n",
      "Epoch 9448/15000\n",
      "1022/1022 [==============================] - 0s 68us/step - loss: 1234236426.2701 - val_loss: 1286179484.6393\n",
      "Epoch 9449/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1234352002.7554 - val_loss: 1287568159.2694\n",
      "Epoch 9450/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1233629425.8474 - val_loss: 1287530649.7169\n",
      "Epoch 9451/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1233671586.0665 - val_loss: 1287381446.7215\n",
      "Epoch 9452/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1233596924.9941 - val_loss: 1286663910.2831\n",
      "Epoch 9453/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1233593456.5949 - val_loss: 1287107610.5936\n",
      "Epoch 9454/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1233680292.8219 - val_loss: 1287116974.7580\n",
      "Epoch 9455/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1233641900.9628 - val_loss: 1287240137.3516\n",
      "Epoch 9456/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1233762731.0841 - val_loss: 1287006077.0776\n",
      "Epoch 9457/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1233565651.4129 - val_loss: 1287577787.3242\n",
      "Epoch 9458/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1234015153.2211 - val_loss: 1286257300.1644\n",
      "Epoch 9459/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1233850821.6360 - val_loss: 1288804336.5114\n",
      "Epoch 9460/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1233520593.5342 - val_loss: 1287603598.9041\n",
      "Epoch 9461/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1233836431.7808 - val_loss: 1286035611.4703\n",
      "Epoch 9462/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1233883719.8904 - val_loss: 1288332453.1142\n",
      "Epoch 9463/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1233496793.4247 - val_loss: 1287002842.8858\n",
      "Epoch 9464/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1234042185.8943 - val_loss: 1288189027.9452\n",
      "Epoch 9465/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1233482244.0078 - val_loss: 1288571734.5023\n",
      "Epoch 9466/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1233407433.8943 - val_loss: 1287808714.2283\n",
      "Epoch 9467/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1233359962.3014 - val_loss: 1286383198.3927\n",
      "Epoch 9468/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1233401994.0196 - val_loss: 1286381425.3881\n",
      "Epoch 9469/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1233492964.5714 - val_loss: 1285737915.0320\n",
      "Epoch 9470/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1233743598.2153 - val_loss: 1286950770.5571\n",
      "Epoch 9471/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1233536422.8258 - val_loss: 1286531384.4018\n",
      "Epoch 9472/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1233487112.3914 - val_loss: 1287213849.7169\n",
      "Epoch 9473/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1233462857.8943 - val_loss: 1288233714.5571\n",
      "Epoch 9474/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1233313354.1448 - val_loss: 1287189726.9772\n",
      "Epoch 9475/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1233339700.0391 - val_loss: 1287788292.6758\n",
      "Epoch 9476/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1233273890.8180 - val_loss: 1287159425.7534\n",
      "Epoch 9477/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1233449294.7789 - val_loss: 1286607990.0639\n",
      "Epoch 9478/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1233069611.3346 - val_loss: 1286982080.5845\n",
      "Epoch 9479/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1233495560.5166 - val_loss: 1286180461.8813\n",
      "Epoch 9480/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1233534965.7926 - val_loss: 1286070413.4429\n",
      "Epoch 9481/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1233204077.4012 - val_loss: 1286819799.9635\n",
      "Epoch 9482/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1233837597.3072 - val_loss: 1288406340.6758\n",
      "Epoch 9483/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1233011126.2935 - val_loss: 1287278834.8493\n",
      "Epoch 9484/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1233221444.3836 - val_loss: 1287737042.1187\n",
      "Epoch 9485/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1233062780.2427 - val_loss: 1286928184.1096\n",
      "Epoch 9486/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1233453882.8650 - val_loss: 1285490286.7580\n",
      "Epoch 9487/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 29us/step - loss: 1233199642.1761 - val_loss: 1286767823.7808\n",
      "Epoch 9488/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1233091253.3542 - val_loss: 1286342881.6073\n",
      "Epoch 9489/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1233504253.4951 - val_loss: 1288024396.8584\n",
      "Epoch 9490/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1233136422.0744 - val_loss: 1287402223.3425\n",
      "Epoch 9491/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1233486968.2348 - val_loss: 1285300907.2511\n",
      "Epoch 9492/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1233282734.4658 - val_loss: 1286145228.8584\n",
      "Epoch 9493/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1232902569.5186 - val_loss: 1286984900.0913\n",
      "Epoch 9494/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1233002355.9765 - val_loss: 1287185891.6530\n",
      "Epoch 9495/15000\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 1233006919.8904 - val_loss: 1286419713.4612\n",
      "Epoch 9496/15000\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 1232834107.6164 - val_loss: 1286908888.8402\n",
      "Epoch 9497/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1233035871.5616 - val_loss: 1286154685.0776\n",
      "Epoch 9498/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1232809718.4188 - val_loss: 1286777560.8402\n",
      "Epoch 9499/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1232833221.5108 - val_loss: 1286497373.8082\n",
      "Epoch 9500/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1233243277.6517 - val_loss: 1286207710.9772\n",
      "Epoch 9501/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1232928711.3894 - val_loss: 1286263025.9726\n",
      "Epoch 9502/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1232863088.9706 - val_loss: 1286606612.1644\n",
      "Epoch 9503/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1232691733.4168 - val_loss: 1286901077.9178\n",
      "Epoch 9504/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1233504286.9354 - val_loss: 1286894138.1553\n",
      "Epoch 9505/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1233391066.4266 - val_loss: 1287313137.9726\n",
      "Epoch 9506/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1233281838.9041 - val_loss: 1285615684.6758\n",
      "Epoch 9507/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1233172239.7808 - val_loss: 1285390169.4247\n",
      "Epoch 9508/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1232622202.7397 - val_loss: 1286360130.3379\n",
      "Epoch 9509/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1232667682.5675 - val_loss: 1287153722.7397\n",
      "Epoch 9510/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1232925973.0411 - val_loss: 1286987743.5616\n",
      "Epoch 9511/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1232770580.2896 - val_loss: 1285517444.3836\n",
      "Epoch 9512/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1232930513.4090 - val_loss: 1286702780.4932\n",
      "Epoch 9513/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1232865463.3581 - val_loss: 1286504605.8082\n",
      "Epoch 9514/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1233139152.9080 - val_loss: 1284341015.6712\n",
      "Epoch 9515/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1232533379.1311 - val_loss: 1285979911.0137\n",
      "Epoch 9516/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1232734993.2838 - val_loss: 1287262078.8311\n",
      "Epoch 9517/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1232455981.8395 - val_loss: 1285739417.4247\n",
      "Epoch 9518/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1232858043.8669 - val_loss: 1286482853.9909\n",
      "Epoch 9519/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1232655029.6047 - val_loss: 1286149954.0457\n",
      "Epoch 9520/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1232715525.0098 - val_loss: 1285867287.9635\n",
      "Epoch 9521/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1232765348.8219 - val_loss: 1286314513.2420\n",
      "Epoch 9522/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1232715922.1605 - val_loss: 1286223232.8767\n",
      "Epoch 9523/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1232565696.6262 - val_loss: 1285965251.5068\n",
      "Epoch 9524/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1232916712.8297 - val_loss: 1285010152.0365\n",
      "Epoch 9525/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1232531457.0020 - val_loss: 1284755031.3790\n",
      "Epoch 9526/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1232722288.9706 - val_loss: 1286381237.4795\n",
      "Epoch 9527/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1232857813.3542 - val_loss: 1286613807.3425\n",
      "Epoch 9528/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1232844214.1057 - val_loss: 1287246904.4018\n",
      "Epoch 9529/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1232622032.7828 - val_loss: 1285591326.3927\n",
      "Epoch 9530/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1232598974.3718 - val_loss: 1286479644.6393\n",
      "Epoch 9531/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1232559657.0802 - val_loss: 1285010232.1096\n",
      "Epoch 9532/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1233173055.2485 - val_loss: 1287054028.2740\n",
      "Epoch 9533/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1232138712.0470 - val_loss: 1285500437.0411\n",
      "Epoch 9534/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1232318021.8865 - val_loss: 1285262909.9543\n",
      "Epoch 9535/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1232472884.6027 - val_loss: 1284264116.6027\n",
      "Epoch 9536/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1232431971.9452 - val_loss: 1286287363.7991\n",
      "Epoch 9537/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1232603279.7808 - val_loss: 1285836660.8950\n",
      "Epoch 9538/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1233413316.6341 - val_loss: 1284100253.2237\n",
      "Epoch 9539/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1232334831.5930 - val_loss: 1284991772.0548\n",
      "Epoch 9540/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1232992570.8650 - val_loss: 1286836887.9635\n",
      "Epoch 9541/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1232115866.3014 - val_loss: 1286228345.8630\n",
      "Epoch 9542/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1232078833.2211 - val_loss: 1285631093.1872\n",
      "Epoch 9543/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1232426595.2564 - val_loss: 1286276146.8493\n",
      "Epoch 9544/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1232030180.4462 - val_loss: 1285329009.6804\n",
      "Epoch 9545/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1232055805.2446 - val_loss: 1285131956.8950\n",
      "Epoch 9546/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1232684513.4403 - val_loss: 1286701069.1507\n",
      "Epoch 9547/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1231968978.9119 - val_loss: 1285056590.6119\n",
      "Epoch 9548/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1232524919.3581 - val_loss: 1284708629.3333\n",
      "Epoch 9549/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1231973435.1155 - val_loss: 1285519690.5205\n",
      "Epoch 9550/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1232078195.7260 - val_loss: 1285907223.9635\n",
      "Epoch 9551/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 38us/step - loss: 1232260184.2975 - val_loss: 1285111492.9680\n",
      "Epoch 9552/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1232848923.8043 - val_loss: 1286381792.4384\n",
      "Epoch 9553/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1232198276.5088 - val_loss: 1285707557.1142\n",
      "Epoch 9554/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1232657581.5890 - val_loss: 1283625298.1187\n",
      "Epoch 9555/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1232042205.8082 - val_loss: 1284613993.2055\n",
      "Epoch 9556/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1231902865.4090 - val_loss: 1285044648.6210\n",
      "Epoch 9557/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1232156224.3757 - val_loss: 1284138560.2922\n",
      "Epoch 9558/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1232261156.4462 - val_loss: 1284539491.3607\n",
      "Epoch 9559/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1231895605.8552 - val_loss: 1284973531.7626\n",
      "Epoch 9560/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1232479211.0841 - val_loss: 1286370125.4429\n",
      "Epoch 9561/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1231955549.0568 - val_loss: 1284861414.5753\n",
      "Epoch 9562/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1232182916.9472 - val_loss: 1284887971.6530\n",
      "Epoch 9563/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1231723108.3209 - val_loss: 1285171829.7717\n",
      "Epoch 9564/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1231830170.4266 - val_loss: 1284576665.7169\n",
      "Epoch 9565/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1231693727.4364 - val_loss: 1285198048.4384\n",
      "Epoch 9566/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1231739211.2720 - val_loss: 1285127856.5114\n",
      "Epoch 9567/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1231792895.1233 - val_loss: 1285541862.5753\n",
      "Epoch 9568/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1232000056.4853 - val_loss: 1284079725.0046\n",
      "Epoch 9569/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1232326155.0215 - val_loss: 1286619376.2192\n",
      "Epoch 9570/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1231565429.4795 - val_loss: 1284859107.6530\n",
      "Epoch 9571/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1231738314.6458 - val_loss: 1284185959.1598\n",
      "Epoch 9572/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1232023677.3699 - val_loss: 1285600085.9178\n",
      "Epoch 9573/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1231894419.5382 - val_loss: 1284400426.0822\n",
      "Epoch 9574/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1231990826.5832 - val_loss: 1283709740.1279\n",
      "Epoch 9575/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1231638604.6497 - val_loss: 1285176899.5068\n",
      "Epoch 9576/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1231978043.6164 - val_loss: 1284666998.3562\n",
      "Epoch 9577/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1231801652.2896 - val_loss: 1285413980.3470\n",
      "Epoch 9578/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1231841742.4031 - val_loss: 1284499562.9589\n",
      "Epoch 9579/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1232215395.6947 - val_loss: 1284222345.9361\n",
      "Epoch 9580/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1231456043.2094 - val_loss: 1284621790.1005\n",
      "Epoch 9581/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1231554032.2192 - val_loss: 1284502029.1507\n",
      "Epoch 9582/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1231747711.2485 - val_loss: 1284383262.1005\n",
      "Epoch 9583/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1231639864.7358 - val_loss: 1284781898.8128\n",
      "Epoch 9584/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1231819858.5362 - val_loss: 1284123574.6484\n",
      "Epoch 9585/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1231623772.1800 - val_loss: 1284252306.4110\n",
      "Epoch 9586/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1231916190.3092 - val_loss: 1285261377.7534\n",
      "Epoch 9587/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1231960107.8356 - val_loss: 1285734595.5068\n",
      "Epoch 9588/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1231564389.6986 - val_loss: 1283374244.2374\n",
      "Epoch 9589/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1232169822.7476 - val_loss: 1283023023.6347\n",
      "Epoch 9590/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1231807564.3366 - val_loss: 1283616225.3151\n",
      "Epoch 9591/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1232176311.8591 - val_loss: 1282871547.6164\n",
      "Epoch 9592/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1231966670.5284 - val_loss: 1285546250.2283\n",
      "Epoch 9593/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1231372421.9491 - val_loss: 1284809523.4338\n",
      "Epoch 9594/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1231843931.1781 - val_loss: 1284963485.8082\n",
      "Epoch 9595/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1231278625.0646 - val_loss: 1284101724.6393\n",
      "Epoch 9596/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1231556501.5421 - val_loss: 1285169954.4840\n",
      "Epoch 9597/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1231561851.3659 - val_loss: 1284126081.7534\n",
      "Epoch 9598/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1231302250.4579 - val_loss: 1284371179.8356\n",
      "Epoch 9599/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1231939603.5382 - val_loss: 1284718045.5160\n",
      "Epoch 9600/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1231340395.4599 - val_loss: 1284276508.9315\n",
      "Epoch 9601/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1231529344.5010 - val_loss: 1285100778.3744\n",
      "Epoch 9602/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1231285237.9804 - val_loss: 1284099061.4795\n",
      "Epoch 9603/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1231543927.3581 - val_loss: 1283655043.2146\n",
      "Epoch 9604/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1231451357.4325 - val_loss: 1283171416.8402\n",
      "Epoch 9605/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1232494620.3053 - val_loss: 1285936974.6119\n",
      "Epoch 9606/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1231374673.1585 - val_loss: 1283545527.8174\n",
      "Epoch 9607/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1231123377.0959 - val_loss: 1284177233.5342\n",
      "Epoch 9608/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1231193514.5832 - val_loss: 1284436458.6667\n",
      "Epoch 9609/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1231219417.8004 - val_loss: 1284252892.6393\n",
      "Epoch 9610/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1231437580.1487 - val_loss: 1282914957.4429\n",
      "Epoch 9611/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1231335997.0568 - val_loss: 1284070464.2922\n",
      "Epoch 9612/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1231469725.6830 - val_loss: 1282760520.1826\n",
      "Epoch 9613/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1231772004.9472 - val_loss: 1284816325.2603\n",
      "Epoch 9614/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1231473397.6047 - val_loss: 1285896704.8767\n",
      "Epoch 9615/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 33us/step - loss: 1230927091.6008 - val_loss: 1284290488.1096\n",
      "Epoch 9616/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1231146675.9765 - val_loss: 1284077402.8858\n",
      "Epoch 9617/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1230923028.0391 - val_loss: 1283558388.6027\n",
      "Epoch 9618/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1231512083.5382 - val_loss: 1284468730.1553\n",
      "Epoch 9619/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1231038316.0861 - val_loss: 1282993916.4932\n",
      "Epoch 9620/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1231249185.5656 - val_loss: 1283845796.5297\n",
      "Epoch 9621/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1231709429.9804 - val_loss: 1284672729.7169\n",
      "Epoch 9622/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1231222118.0744 - val_loss: 1283963917.7352\n",
      "Epoch 9623/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1230996081.0333 - val_loss: 1283130170.4475\n",
      "Epoch 9624/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1230963484.3053 - val_loss: 1283496909.4429\n",
      "Epoch 9625/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1230827274.3953 - val_loss: 1283220919.5251\n",
      "Epoch 9626/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1231082299.6164 - val_loss: 1282855490.6301\n",
      "Epoch 9627/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1231669492.4775 - val_loss: 1281905975.8174\n",
      "Epoch 9628/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1230679446.7945 - val_loss: 1283932807.8904\n",
      "Epoch 9629/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1231106890.7084 - val_loss: 1283319180.5662\n",
      "Epoch 9630/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1230932762.0509 - val_loss: 1283293193.6438\n",
      "Epoch 9631/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1231838393.8630 - val_loss: 1282805332.7489\n",
      "Epoch 9632/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1230970099.1624 - val_loss: 1283274011.4703\n",
      "Epoch 9633/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1230880265.4560 - val_loss: 1283229231.9269\n",
      "Epoch 9634/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1230618903.1703 - val_loss: 1283868839.4521\n",
      "Epoch 9635/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1231071751.0137 - val_loss: 1284758190.1735\n",
      "Epoch 9636/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1230784259.0059 - val_loss: 1284058979.3607\n",
      "Epoch 9637/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1231009310.1840 - val_loss: 1284968345.4247\n",
      "Epoch 9638/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1230557898.5205 - val_loss: 1283521497.1324\n",
      "Epoch 9639/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1230938142.8102 - val_loss: 1282638029.4429\n",
      "Epoch 9640/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1231264564.6027 - val_loss: 1284890078.1005\n",
      "Epoch 9641/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1231888088.8611 - val_loss: 1281930484.0183\n",
      "Epoch 9642/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1230585319.6399 - val_loss: 1283517229.8813\n",
      "Epoch 9643/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1231718118.1996 - val_loss: 1281616267.9817\n",
      "Epoch 9644/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1231216237.7143 - val_loss: 1284120976.3653\n",
      "Epoch 9645/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1230579383.1076 - val_loss: 1283310151.5982\n",
      "Epoch 9646/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1230573671.0763 - val_loss: 1283294523.6164\n",
      "Epoch 9647/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1230713215.4990 - val_loss: 1284192534.7945\n",
      "Epoch 9648/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1230862275.6321 - val_loss: 1282271309.1507\n",
      "Epoch 9649/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1230503131.4286 - val_loss: 1283974044.3470\n",
      "Epoch 9650/15000\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 1230867830.9824 - val_loss: 1283166350.6119\n",
      "Epoch 9651/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1230869328.5323 - val_loss: 1281756851.7260\n",
      "Epoch 9652/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1230591323.9295 - val_loss: 1283494591.7078\n",
      "Epoch 9653/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1230677973.4168 - val_loss: 1282859250.8493\n",
      "Epoch 9654/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1230575569.2211 - val_loss: 1283541753.2785\n",
      "Epoch 9655/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1231119744.0000 - val_loss: 1282427922.7032\n",
      "Epoch 9656/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1230420745.5186 - val_loss: 1282774898.5571\n",
      "Epoch 9657/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1230883101.9335 - val_loss: 1283607153.0959\n",
      "Epoch 9658/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1230418043.7417 - val_loss: 1283234036.6027\n",
      "Epoch 9659/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1230434476.7123 - val_loss: 1282432680.6210\n",
      "Epoch 9660/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1230959636.6654 - val_loss: 1281911153.9726\n",
      "Epoch 9661/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1230479837.1820 - val_loss: 1283490905.7169\n",
      "Epoch 9662/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1230358441.7691 - val_loss: 1283020848.5114\n",
      "Epoch 9663/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1230726138.7397 - val_loss: 1282266599.4521\n",
      "Epoch 9664/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1230460884.1644 - val_loss: 1282799489.1689\n",
      "Epoch 9665/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1230655461.9491 - val_loss: 1281952731.4703\n",
      "Epoch 9666/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1230452696.9863 - val_loss: 1283141499.3242\n",
      "Epoch 9667/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1230688269.0254 - val_loss: 1283509750.3562\n",
      "Epoch 9668/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1230245288.7671 - val_loss: 1283197052.7854\n",
      "Epoch 9669/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1230357039.9687 - val_loss: 1283758953.2055\n",
      "Epoch 9670/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1230303371.3973 - val_loss: 1282942917.8447\n",
      "Epoch 9671/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1230272606.6849 - val_loss: 1282681812.7489\n",
      "Epoch 9672/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1230389756.4932 - val_loss: 1283311333.1142\n",
      "Epoch 9673/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1230292240.2818 - val_loss: 1282537943.3790\n",
      "Epoch 9674/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1230757321.1429 - val_loss: 1283469951.7078\n",
      "Epoch 9675/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1230514013.4951 - val_loss: 1282059876.2374\n",
      "Epoch 9676/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1230465076.7906 - val_loss: 1282285678.7580\n",
      "Epoch 9677/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1230375396.4462 - val_loss: 1282025559.3790\n",
      "Epoch 9678/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1230576744.4540 - val_loss: 1282536270.3196\n",
      "Epoch 9679/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1230880231.9530 - val_loss: 1280903931.9087\n",
      "Epoch 9680/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1230457257.7691 - val_loss: 1283676367.7808\n",
      "Epoch 9681/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1230248038.6380 - val_loss: 1284190435.0685\n",
      "Epoch 9682/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1230099362.8180 - val_loss: 1283231649.6073\n",
      "Epoch 9683/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1230049634.4423 - val_loss: 1282713344.0000\n",
      "Epoch 9684/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1230183813.8865 - val_loss: 1282076058.0091\n",
      "Epoch 9685/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1230908789.1037 - val_loss: 1283654198.6484\n",
      "Epoch 9686/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1230047880.3914 - val_loss: 1282257019.9087\n",
      "Epoch 9687/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1230224126.3092 - val_loss: 1282433083.9087\n",
      "Epoch 9688/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1230417524.6027 - val_loss: 1282782068.8950\n",
      "Epoch 9689/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1229928664.1722 - val_loss: 1282557469.8082\n",
      "Epoch 9690/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1230588841.8317 - val_loss: 1281570345.7900\n",
      "Epoch 9691/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1229891897.1115 - val_loss: 1282765751.8174\n",
      "Epoch 9692/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1230246492.9315 - val_loss: 1283615603.4338\n",
      "Epoch 9693/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1229981766.3875 - val_loss: 1282143409.9726\n",
      "Epoch 9694/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1229770985.0176 - val_loss: 1282288846.9041\n",
      "Epoch 9695/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1230063273.8317 - val_loss: 1281763761.9726\n",
      "Epoch 9696/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1229792106.4579 - val_loss: 1282210520.5479\n",
      "Epoch 9697/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1229968428.8376 - val_loss: 1281811705.8630\n",
      "Epoch 9698/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1229939773.3699 - val_loss: 1282641782.9406\n",
      "Epoch 9699/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1229846258.7867 - val_loss: 1282568496.2192\n",
      "Epoch 9700/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1230488507.3659 - val_loss: 1283729222.7215\n",
      "Epoch 9701/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1230435150.0274 - val_loss: 1280733800.0365\n",
      "Epoch 9702/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1230076674.5049 - val_loss: 1280247963.7626\n",
      "Epoch 9703/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1230734105.0489 - val_loss: 1281660074.0822\n",
      "Epoch 9704/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1229739236.4462 - val_loss: 1282456297.2055\n",
      "Epoch 9705/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1229763715.2564 - val_loss: 1282477309.6621\n",
      "Epoch 9706/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1229633648.2192 - val_loss: 1282265683.2877\n",
      "Epoch 9707/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1229748432.9080 - val_loss: 1283430004.0183\n",
      "Epoch 9708/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1229816298.2074 - val_loss: 1281834170.1553\n",
      "Epoch 9709/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1230083274.0822 - val_loss: 1281515262.5388\n",
      "Epoch 9710/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1230424851.1624 - val_loss: 1280745767.7443\n",
      "Epoch 9711/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1229990668.2740 - val_loss: 1283507544.5479\n",
      "Epoch 9712/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1229966721.3151 - val_loss: 1281216654.0274\n",
      "Epoch 9713/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1229642694.5127 - val_loss: 1281586062.6119\n",
      "Epoch 9714/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1229836227.1311 - val_loss: 1283541025.8995\n",
      "Epoch 9715/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1229562780.8689 - val_loss: 1282491600.9498\n",
      "Epoch 9716/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1229608949.2290 - val_loss: 1281965956.9680\n",
      "Epoch 9717/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1230019405.9022 - val_loss: 1282463565.1507\n",
      "Epoch 9718/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1229596801.0020 - val_loss: 1282361250.1918\n",
      "Epoch 9719/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1229685619.2250 - val_loss: 1281681069.8813\n",
      "Epoch 9720/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1230199101.6204 - val_loss: 1282017008.8037\n",
      "Epoch 9721/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1230375058.3483 - val_loss: 1279988973.2968\n",
      "Epoch 9722/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1229667385.6125 - val_loss: 1282492450.1918\n",
      "Epoch 9723/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1229518304.1879 - val_loss: 1282198992.9498\n",
      "Epoch 9724/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1229466859.7104 - val_loss: 1282440178.5571\n",
      "Epoch 9725/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1229810238.4971 - val_loss: 1282283851.6895\n",
      "Epoch 9726/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1230089141.9804 - val_loss: 1282562098.5571\n",
      "Epoch 9727/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1230103934.9980 - val_loss: 1280757031.7443\n",
      "Epoch 9728/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1230318189.7143 - val_loss: 1281252752.0731\n",
      "Epoch 9729/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1229541319.0137 - val_loss: 1280856625.9726\n",
      "Epoch 9730/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1229301365.5421 - val_loss: 1281789493.1872\n",
      "Epoch 9731/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1229630842.8650 - val_loss: 1281860891.7626\n",
      "Epoch 9732/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1229298805.6673 - val_loss: 1282061831.5982\n",
      "Epoch 9733/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1229333360.4697 - val_loss: 1282380445.5160\n",
      "Epoch 9734/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1229652641.3151 - val_loss: 1280790045.5160\n",
      "Epoch 9735/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1229228104.6419 - val_loss: 1282253299.4338\n",
      "Epoch 9736/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1229430976.6262 - val_loss: 1281557320.4749\n",
      "Epoch 9737/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1229974890.2074 - val_loss: 1281351433.0594\n",
      "Epoch 9738/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1229684731.2407 - val_loss: 1282437788.3470\n",
      "Epoch 9739/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1229271971.9452 - val_loss: 1282132538.7397\n",
      "Epoch 9740/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1229706548.4775 - val_loss: 1280499136.0000\n",
      "Epoch 9741/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1230766026.5205 - val_loss: 1283944359.4521\n",
      "Epoch 9742/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1229420352.0000 - val_loss: 1281310913.7534\n",
      "Epoch 9743/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 28us/step - loss: 1229159959.2955 - val_loss: 1281766792.7671\n",
      "Epoch 9744/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1229300804.8845 - val_loss: 1281485790.1005\n",
      "Epoch 9745/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1229279026.0978 - val_loss: 1281809635.0685\n",
      "Epoch 9746/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1229353562.5519 - val_loss: 1282614130.2648\n",
      "Epoch 9747/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1229093625.9883 - val_loss: 1282042838.7945\n",
      "Epoch 9748/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1229470075.7417 - val_loss: 1280442084.5297\n",
      "Epoch 9749/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1229357887.1233 - val_loss: 1281468561.8265\n",
      "Epoch 9750/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1229232587.8982 - val_loss: 1280622911.1233\n",
      "Epoch 9751/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1229021034.1448 - val_loss: 1281255197.5160\n",
      "Epoch 9752/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1229151608.0470 - val_loss: 1282324399.6347\n",
      "Epoch 9753/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1229139388.8689 - val_loss: 1282309510.1370\n",
      "Epoch 9754/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1229150390.9824 - val_loss: 1282371222.7945\n",
      "Epoch 9755/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1228897838.0900 - val_loss: 1281006673.5342\n",
      "Epoch 9756/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1229124122.8023 - val_loss: 1281091596.2740\n",
      "Epoch 9757/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1229346867.3503 - val_loss: 1281159094.3562\n",
      "Epoch 9758/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1229330743.8591 - val_loss: 1281420615.5982\n",
      "Epoch 9759/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1229438260.4775 - val_loss: 1280291114.0822\n",
      "Epoch 9760/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1228952739.3816 - val_loss: 1281313394.2648\n",
      "Epoch 9761/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1228933544.0157 - val_loss: 1281567250.7032\n",
      "Epoch 9762/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1228945126.4501 - val_loss: 1280966072.6941\n",
      "Epoch 9763/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1229012062.6849 - val_loss: 1282113918.2466\n",
      "Epoch 9764/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1229335539.2250 - val_loss: 1281376909.4429\n",
      "Epoch 9765/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1229733297.8474 - val_loss: 1283325059.2146\n",
      "Epoch 9766/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1229167406.0274 - val_loss: 1280488431.3425\n",
      "Epoch 9767/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1228909063.7652 - val_loss: 1281848946.8493\n",
      "Epoch 9768/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1229014030.2779 - val_loss: 1281568997.4064\n",
      "Epoch 9769/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1229502730.3953 - val_loss: 1279763396.0913\n",
      "Epoch 9770/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1229157689.9883 - val_loss: 1279631020.4201\n",
      "Epoch 9771/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1228792845.5890 - val_loss: 1281274719.5616\n",
      "Epoch 9772/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1229619325.7456 - val_loss: 1283134693.1142\n",
      "Epoch 9773/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1229374811.4286 - val_loss: 1280143916.1279\n",
      "Epoch 9774/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1229544045.7143 - val_loss: 1282921799.3059\n",
      "Epoch 9775/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1228855696.4697 - val_loss: 1280741281.0228\n",
      "Epoch 9776/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1228716271.3425 - val_loss: 1280567306.2283\n",
      "Epoch 9777/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1229585841.9726 - val_loss: 1282010696.7671\n",
      "Epoch 9778/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1229100034.8806 - val_loss: 1280753365.3333\n",
      "Epoch 9779/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1229254533.0098 - val_loss: 1280670157.7352\n",
      "Epoch 9780/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1229213405.9335 - val_loss: 1281500698.0091\n",
      "Epoch 9781/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1228739588.0078 - val_loss: 1281623944.4749\n",
      "Epoch 9782/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1228860857.9883 - val_loss: 1279931325.0776\n",
      "Epoch 9783/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1228819622.1996 - val_loss: 1281406165.0411\n",
      "Epoch 9784/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1228887301.5734 - val_loss: 1280440538.5936\n",
      "Epoch 9785/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1228603800.5479 - val_loss: 1280132670.8311\n",
      "Epoch 9786/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1228581758.2466 - val_loss: 1280428614.1370\n",
      "Epoch 9787/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1228684122.1135 - val_loss: 1281093123.5068\n",
      "Epoch 9788/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1228635450.9902 - val_loss: 1281166056.6210\n",
      "Epoch 9789/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1229326512.6888 - val_loss: 1281911729.0959\n",
      "Epoch 9790/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1229230124.2740 - val_loss: 1280497700.2374\n",
      "Epoch 9791/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1228754874.9902 - val_loss: 1278879273.2055\n",
      "Epoch 9792/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1228971211.7730 - val_loss: 1279034326.7945\n",
      "Epoch 9793/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1229641789.3699 - val_loss: 1281549636.9680\n",
      "Epoch 9794/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1228548009.7065 - val_loss: 1280834010.5936\n",
      "Epoch 9795/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1228793013.7299 - val_loss: 1281126970.7397\n",
      "Epoch 9796/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1228595685.5734 - val_loss: 1280243196.7854\n",
      "Epoch 9797/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1228813062.5127 - val_loss: 1280001079.5251\n",
      "Epoch 9798/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1229059529.1429 - val_loss: 1281598898.5571\n",
      "Epoch 9799/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1228785430.2309 - val_loss: 1280733565.3699\n",
      "Epoch 9800/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1228491505.9726 - val_loss: 1279870631.7443\n",
      "Epoch 9801/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1228568585.8943 - val_loss: 1280331424.4384\n",
      "Epoch 9802/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1228614800.1566 - val_loss: 1279213470.1005\n",
      "Epoch 9803/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1228901218.4423 - val_loss: 1279918884.8219\n",
      "Epoch 9804/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1228522510.5284 - val_loss: 1280190165.0411\n",
      "Epoch 9805/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1228490152.0783 - val_loss: 1280351168.5845\n",
      "Epoch 9806/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1228566378.7084 - val_loss: 1281118681.4247\n",
      "Epoch 9807/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 29us/step - loss: 1228655397.6360 - val_loss: 1280740598.3562\n",
      "Epoch 9808/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1228390276.0078 - val_loss: 1280367186.9954\n",
      "Epoch 9809/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1228297677.4012 - val_loss: 1280466870.3562\n",
      "Epoch 9810/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1228563534.5284 - val_loss: 1281463463.4521\n",
      "Epoch 9811/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1228372139.9609 - val_loss: 1280924724.3105\n",
      "Epoch 9812/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1228706250.3953 - val_loss: 1281372239.7808\n",
      "Epoch 9813/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1228564532.8532 - val_loss: 1279321214.8311\n",
      "Epoch 9814/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1229232024.2975 - val_loss: 1282045848.2557\n",
      "Epoch 9815/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1228306328.7984 - val_loss: 1279610694.4292\n",
      "Epoch 9816/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1229060189.4325 - val_loss: 1279249621.6256\n",
      "Epoch 9817/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1228292324.1331 - val_loss: 1280783431.3059\n",
      "Epoch 9818/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1228500181.4168 - val_loss: 1279761135.3425\n",
      "Epoch 9819/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1228393530.8650 - val_loss: 1281172289.7534\n",
      "Epoch 9820/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1228290499.1311 - val_loss: 1281324930.3379\n",
      "Epoch 9821/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1228936732.8063 - val_loss: 1280468486.7215\n",
      "Epoch 9822/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1228138655.4364 - val_loss: 1280315015.0137\n",
      "Epoch 9823/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1228315659.8982 - val_loss: 1279555056.2192\n",
      "Epoch 9824/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1228446600.7671 - val_loss: 1280963795.2877\n",
      "Epoch 9825/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1228129205.4795 - val_loss: 1280651905.7534\n",
      "Epoch 9826/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1228175992.2348 - val_loss: 1279768626.5571\n",
      "Epoch 9827/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1228077153.9413 - val_loss: 1280357893.5525\n",
      "Epoch 9828/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1228122761.9569 - val_loss: 1280192420.5297\n",
      "Epoch 9829/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1228507633.9726 - val_loss: 1278994710.2100\n",
      "Epoch 9830/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1228170007.5460 - val_loss: 1280153744.0731\n",
      "Epoch 9831/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1227888276.1644 - val_loss: 1280365464.2557\n",
      "Epoch 9832/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1228061906.1605 - val_loss: 1280350035.5799\n",
      "Epoch 9833/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1228105275.1155 - val_loss: 1280119360.0000\n",
      "Epoch 9834/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1228277778.0352 - val_loss: 1280110659.2146\n",
      "Epoch 9835/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1228472187.7417 - val_loss: 1281653286.2831\n",
      "Epoch 9836/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1228844043.6477 - val_loss: 1279355720.1826\n",
      "Epoch 9837/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1228532639.4364 - val_loss: 1280593576.3288\n",
      "Epoch 9838/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1227887639.4207 - val_loss: 1280435968.2922\n",
      "Epoch 9839/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1228359141.9491 - val_loss: 1278722120.1826\n",
      "Epoch 9840/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1227821982.4344 - val_loss: 1280032469.0411\n",
      "Epoch 9841/15000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1228149500.3679 - val_loss: 1280564757.9178\n",
      "Epoch 9842/15000\n",
      "1022/1022 [==============================] - 0s 75us/step - loss: 1228424359.5773 - val_loss: 1279142052.8219\n",
      "Epoch 9843/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1227874122.7710 - val_loss: 1279997088.1461\n",
      "Epoch 9844/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1228273764.6967 - val_loss: 1281059849.0594\n",
      "Epoch 9845/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1227956384.5636 - val_loss: 1279601443.9452\n",
      "Epoch 9846/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1228515743.1859 - val_loss: 1280866289.6804\n",
      "Epoch 9847/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1228167780.9472 - val_loss: 1279838604.5662\n",
      "Epoch 9848/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1227848188.1174 - val_loss: 1279216301.8813\n",
      "Epoch 9849/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1227713822.5597 - val_loss: 1279563371.2511\n",
      "Epoch 9850/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1227920277.0411 - val_loss: 1279494175.5616\n",
      "Epoch 9851/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1227831522.5675 - val_loss: 1281152599.9635\n",
      "Epoch 9852/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1227640429.0254 - val_loss: 1280224523.1050\n",
      "Epoch 9853/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1227814263.6086 - val_loss: 1280534708.8950\n",
      "Epoch 9854/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1227726787.8826 - val_loss: 1280106301.9543\n",
      "Epoch 9855/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1227835364.1331 - val_loss: 1280091457.7534\n",
      "Epoch 9856/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1227841079.9843 - val_loss: 1279300275.7260\n",
      "Epoch 9857/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1228034181.0724 - val_loss: 1280699620.2374\n",
      "Epoch 9858/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1227776354.0665 - val_loss: 1280240538.0091\n",
      "Epoch 9859/15000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1227929811.4129 - val_loss: 1280340819.8721\n",
      "Epoch 9860/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1227660475.6164 - val_loss: 1279912969.0594\n",
      "Epoch 9861/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1227663542.7319 - val_loss: 1280085134.6119\n",
      "Epoch 9862/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1227811690.2074 - val_loss: 1279870193.0959\n",
      "Epoch 9863/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1227546755.1311 - val_loss: 1279421993.7900\n",
      "Epoch 9864/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1227645700.5714 - val_loss: 1279434074.8858\n",
      "Epoch 9865/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1227599178.6458 - val_loss: 1279543625.0594\n",
      "Epoch 9866/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1227728384.5010 - val_loss: 1278764604.4932\n",
      "Epoch 9867/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1227667784.0157 - val_loss: 1279593822.9772\n",
      "Epoch 9868/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1228247134.5597 - val_loss: 1279934871.9635\n",
      "Epoch 9869/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1227477844.5401 - val_loss: 1279619814.5753\n",
      "Epoch 9870/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1227806005.6673 - val_loss: 1279786580.4566\n",
      "Epoch 9871/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 29us/step - loss: 1227463648.5636 - val_loss: 1280117105.0959\n",
      "Epoch 9872/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1227538767.7808 - val_loss: 1280333988.2374\n",
      "Epoch 9873/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1227873878.7945 - val_loss: 1279002059.6895\n",
      "Epoch 9874/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1228028801.7534 - val_loss: 1279970882.9224\n",
      "Epoch 9875/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1227800144.9080 - val_loss: 1278259092.4566\n",
      "Epoch 9876/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1227980930.5049 - val_loss: 1279932191.8539\n",
      "Epoch 9877/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1227671574.9198 - val_loss: 1279786979.6530\n",
      "Epoch 9878/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1227676733.8708 - val_loss: 1278689605.2603\n",
      "Epoch 9879/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1227408155.5538 - val_loss: 1278733071.4886\n",
      "Epoch 9880/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1227674871.7339 - val_loss: 1278160626.2648\n",
      "Epoch 9881/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1227846946.2544 - val_loss: 1280694056.3288\n",
      "Epoch 9882/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1227300565.1663 - val_loss: 1279223942.4292\n",
      "Epoch 9883/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1227391660.5871 - val_loss: 1278788177.2420\n",
      "Epoch 9884/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1227426812.4932 - val_loss: 1279112141.4429\n",
      "Epoch 9885/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1227817934.1526 - val_loss: 1280951691.9817\n",
      "Epoch 9886/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1227634495.1859 - val_loss: 1280105789.0776\n",
      "Epoch 9887/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1227609143.6086 - val_loss: 1278624335.7808\n",
      "Epoch 9888/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1227286051.0685 - val_loss: 1279246862.6119\n",
      "Epoch 9889/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1227909945.3620 - val_loss: 1277462934.2100\n",
      "Epoch 9890/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1227181783.5460 - val_loss: 1279759224.6941\n",
      "Epoch 9891/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1227456287.4364 - val_loss: 1280101495.5251\n",
      "Epoch 9892/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1227417950.9354 - val_loss: 1279817280.5845\n",
      "Epoch 9893/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1227312439.1076 - val_loss: 1279838805.0411\n",
      "Epoch 9894/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1227486888.3288 - val_loss: 1279874585.1324\n",
      "Epoch 9895/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1227146073.4247 - val_loss: 1279116199.1598\n",
      "Epoch 9896/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1227190128.9706 - val_loss: 1279279496.7671\n",
      "Epoch 9897/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1227864394.6458 - val_loss: 1280694964.3105\n",
      "Epoch 9898/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1227134351.1546 - val_loss: 1279066516.4566\n",
      "Epoch 9899/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1227876073.2055 - val_loss: 1280159997.6621\n",
      "Epoch 9900/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1226913657.4873 - val_loss: 1279120544.4384\n",
      "Epoch 9901/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1227678280.3914 - val_loss: 1279670572.1279\n",
      "Epoch 9902/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1227056752.2192 - val_loss: 1278204073.2055\n",
      "Epoch 9903/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1227087216.3444 - val_loss: 1278482244.3836\n",
      "Epoch 9904/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1227016548.6967 - val_loss: 1277984378.1553\n",
      "Epoch 9905/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1227157159.1389 - val_loss: 1279458911.5616\n",
      "Epoch 9906/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1227947972.1331 - val_loss: 1277642837.6256\n",
      "Epoch 9907/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1226939895.2329 - val_loss: 1279539820.7123\n",
      "Epoch 9908/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1227264342.1683 - val_loss: 1279465454.1735\n",
      "Epoch 9909/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1227138137.4247 - val_loss: 1279852351.7078\n",
      "Epoch 9910/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1227133255.7652 - val_loss: 1277884370.7032\n",
      "Epoch 9911/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1226970733.8395 - val_loss: 1278900085.7717\n",
      "Epoch 9912/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1227220441.6751 - val_loss: 1279878176.7306\n",
      "Epoch 9913/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1227035470.9041 - val_loss: 1279499657.6438\n",
      "Epoch 9914/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1227118926.5284 - val_loss: 1279276173.7352\n",
      "Epoch 9915/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1227002752.0000 - val_loss: 1279400233.2055\n",
      "Epoch 9916/15000\n",
      "1022/1022 [==============================] - 0s 84us/step - loss: 1228084339.7260 - val_loss: 1276275243.5434\n",
      "Epoch 9917/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1227494837.1037 - val_loss: 1278742821.6986\n",
      "Epoch 9918/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1227276061.3072 - val_loss: 1277809778.8493\n",
      "Epoch 9919/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1227098161.5969 - val_loss: 1278400907.1050\n",
      "Epoch 9920/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1227355311.2172 - val_loss: 1280600045.5890\n",
      "Epoch 9921/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1227068769.4403 - val_loss: 1278141205.9178\n",
      "Epoch 9922/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1226860968.8297 - val_loss: 1278300966.5753\n",
      "Epoch 9923/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1228207572.2896 - val_loss: 1280437801.4977\n",
      "Epoch 9924/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1226839528.4540 - val_loss: 1279400530.1187\n",
      "Epoch 9925/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1227380940.3992 - val_loss: 1277589591.3790\n",
      "Epoch 9926/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1226823937.6282 - val_loss: 1277845543.4521\n",
      "Epoch 9927/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1226698898.5362 - val_loss: 1278412499.2877\n",
      "Epoch 9928/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1226729289.2055 - val_loss: 1278826281.7900\n",
      "Epoch 9929/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1226810401.0646 - val_loss: 1279004394.9589\n",
      "Epoch 9930/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1227011861.1663 - val_loss: 1279529096.4749\n",
      "Epoch 9931/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1226823271.7025 - val_loss: 1278977380.5297\n",
      "Epoch 9932/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1226719782.9511 - val_loss: 1279539060.8950\n",
      "Epoch 9933/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1226737384.0783 - val_loss: 1279748592.8037\n",
      "Epoch 9934/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1227520600.4227 - val_loss: 1278805086.3927\n",
      "Epoch 9935/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1227015602.3483 - val_loss: 1279409623.3790\n",
      "Epoch 9936/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1227137367.9217 - val_loss: 1277422090.5205\n",
      "Epoch 9937/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1226978923.9609 - val_loss: 1278818392.2557\n",
      "Epoch 9938/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1226888068.7593 - val_loss: 1279571889.9726\n",
      "Epoch 9939/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1227255061.2916 - val_loss: 1278286893.0046\n",
      "Epoch 9940/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1226659243.7104 - val_loss: 1278039552.2922\n",
      "Epoch 9941/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1226518449.5342 - val_loss: 1278337216.8767\n",
      "Epoch 9942/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1226927008.1879 - val_loss: 1279839087.9269\n",
      "Epoch 9943/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1227073985.8160 - val_loss: 1278168310.3562\n",
      "Epoch 9944/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1226600204.7750 - val_loss: 1278346651.1781\n",
      "Epoch 9945/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1226744721.4090 - val_loss: 1278919518.9772\n",
      "Epoch 9946/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1226416426.9589 - val_loss: 1278228637.2237\n",
      "Epoch 9947/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1226808398.1526 - val_loss: 1278275655.8904\n",
      "Epoch 9948/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1227658198.4188 - val_loss: 1278601396.0183\n",
      "Epoch 9949/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1226746504.5166 - val_loss: 1278300624.0731\n",
      "Epoch 9950/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1226712443.9922 - val_loss: 1279644020.8950\n",
      "Epoch 9951/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1227094075.8669 - val_loss: 1280216663.9635\n",
      "Epoch 9952/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1226665852.3053 - val_loss: 1278242205.2237\n",
      "Epoch 9953/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1226808768.3757 - val_loss: 1278968854.2100\n",
      "Epoch 9954/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1226394964.3523 - val_loss: 1277819710.8311\n",
      "Epoch 9955/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1226708336.2192 - val_loss: 1277849089.4612\n",
      "Epoch 9956/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1226544153.9256 - val_loss: 1277472751.6347\n",
      "Epoch 9957/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1226719114.7710 - val_loss: 1276967354.7397\n",
      "Epoch 9958/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1226614737.4090 - val_loss: 1278098069.3333\n",
      "Epoch 9959/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1226422995.9765 - val_loss: 1277776114.2648\n",
      "Epoch 9960/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1226970256.1566 - val_loss: 1279306645.3333\n",
      "Epoch 9961/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1226327406.4658 - val_loss: 1278731157.6256\n",
      "Epoch 9962/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1226552257.1272 - val_loss: 1279201404.2009\n",
      "Epoch 9963/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1226745276.1800 - val_loss: 1278556978.2648\n",
      "Epoch 9964/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1226389420.3366 - val_loss: 1277921458.8493\n",
      "Epoch 9965/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1226705858.2544 - val_loss: 1277295780.5297\n",
      "Epoch 9966/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1226331253.9804 - val_loss: 1278699505.3881\n",
      "Epoch 9967/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1226596753.6595 - val_loss: 1279144594.7032\n",
      "Epoch 9968/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1226238946.8180 - val_loss: 1278404430.0274\n",
      "Epoch 9969/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1226920822.8571 - val_loss: 1276790045.5160\n",
      "Epoch 9970/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1226596062.8102 - val_loss: 1279002762.5205\n",
      "Epoch 9971/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1226182467.2564 - val_loss: 1278226961.8265\n",
      "Epoch 9972/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1226192102.4501 - val_loss: 1277888454.7215\n",
      "Epoch 9973/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1226415895.0450 - val_loss: 1277838190.7580\n",
      "Epoch 9974/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1226548417.8787 - val_loss: 1276726582.9406\n",
      "Epoch 9975/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1226412295.2642 - val_loss: 1279242256.9498\n",
      "Epoch 9976/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1226865437.6204 - val_loss: 1277155463.8904\n",
      "Epoch 9977/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1226406763.4599 - val_loss: 1279150508.1279\n",
      "Epoch 9978/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1226513332.7593 - val_loss: 1279088484.8219\n",
      "Epoch 9979/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1226488689.5969 - val_loss: 1277108830.9772\n",
      "Epoch 9980/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1226104265.3933 - val_loss: 1278207767.9635\n",
      "Epoch 9981/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1226361356.7750 - val_loss: 1278350412.8584\n",
      "Epoch 9982/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1226227041.6908 - val_loss: 1278397750.9406\n",
      "Epoch 9983/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1226510727.0137 - val_loss: 1277763664.9498\n",
      "Epoch 9984/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1226637534.1840 - val_loss: 1279329627.4703\n",
      "Epoch 9985/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1226896346.2387 - val_loss: 1276770611.7260\n",
      "Epoch 9986/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1225986702.2779 - val_loss: 1278402606.4658\n",
      "Epoch 9987/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1226454037.0411 - val_loss: 1276480511.1233\n",
      "Epoch 9988/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1228043673.6751 - val_loss: 1279075505.9726\n",
      "Epoch 9989/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1225972368.7202 - val_loss: 1278228783.9269\n",
      "Epoch 9990/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1226054919.6399 - val_loss: 1277581885.3699\n",
      "Epoch 9991/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1226506652.8063 - val_loss: 1278333204.7489\n",
      "Epoch 9992/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1226118944.5636 - val_loss: 1277485330.7032\n",
      "Epoch 9993/15000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1226531341.5264 - val_loss: 1277770861.8813\n",
      "Epoch 9994/15000\n",
      "1022/1022 [==============================] - 0s 70us/step - loss: 1225861358.3405 - val_loss: 1277771552.4384\n",
      "Epoch 9995/15000\n",
      "1022/1022 [==============================] - 0s 75us/step - loss: 1226369965.2133 - val_loss: 1276763862.5023\n",
      "Epoch 9996/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1226655373.9022 - val_loss: 1278568347.1781\n",
      "Epoch 9997/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1225810617.3620 - val_loss: 1278257057.8995\n",
      "Epoch 9998/15000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1226123863.1703 - val_loss: 1278980616.4749\n",
      "Epoch 9999/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 49us/step - loss: 1226104667.9295 - val_loss: 1276720338.7032\n",
      "Epoch 10000/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1225850233.8630 - val_loss: 1277321565.2237\n",
      "Epoch 10001/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1226547172.9472 - val_loss: 1278517655.9635\n",
      "Epoch 10002/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1225907839.0607 - val_loss: 1277745237.6256\n",
      "Epoch 10003/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1226054558.4344 - val_loss: 1277823859.7260\n",
      "Epoch 10004/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1226370949.3229 - val_loss: 1277888333.7352\n",
      "Epoch 10005/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1225924402.3483 - val_loss: 1277039058.7032\n",
      "Epoch 10006/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1226040936.2661 - val_loss: 1278032371.1416\n",
      "Epoch 10007/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1226071611.6164 - val_loss: 1278156046.0274\n",
      "Epoch 10008/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1225734470.4501 - val_loss: 1277626315.3973\n",
      "Epoch 10009/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1226458329.0489 - val_loss: 1278284328.9132\n",
      "Epoch 10010/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1226551899.1155 - val_loss: 1278140568.8402\n",
      "Epoch 10011/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1225874244.6341 - val_loss: 1276462637.0046\n",
      "Epoch 10012/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1225756016.3444 - val_loss: 1276600779.9817\n",
      "Epoch 10013/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1225658672.5949 - val_loss: 1277323426.7763\n",
      "Epoch 10014/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1226201655.1076 - val_loss: 1276016797.5160\n",
      "Epoch 10015/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1225738549.7299 - val_loss: 1277322124.2740\n",
      "Epoch 10016/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1225556531.8513 - val_loss: 1276724119.3790\n",
      "Epoch 10017/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1225645113.7378 - val_loss: 1277310597.5525\n",
      "Epoch 10018/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1225865170.4110 - val_loss: 1278051978.8128\n",
      "Epoch 10019/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1225716354.5049 - val_loss: 1277974874.8858\n",
      "Epoch 10020/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1225894145.0020 - val_loss: 1277854144.0000\n",
      "Epoch 10021/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1225819695.4677 - val_loss: 1277924526.4658\n",
      "Epoch 10022/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1225582067.0998 - val_loss: 1277594013.2237\n",
      "Epoch 10023/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1225538857.0802 - val_loss: 1277222826.6667\n",
      "Epoch 10024/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1225626379.3973 - val_loss: 1277026924.7123\n",
      "Epoch 10025/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1225672146.6614 - val_loss: 1277647421.0776\n",
      "Epoch 10026/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1225484821.5421 - val_loss: 1277094755.0685\n",
      "Epoch 10027/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1225659512.3601 - val_loss: 1277804446.9772\n",
      "Epoch 10028/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1225705529.8004 - val_loss: 1276904656.3653\n",
      "Epoch 10029/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1225552085.4168 - val_loss: 1277317355.2511\n",
      "Epoch 10030/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1226355209.7691 - val_loss: 1276825471.4155\n",
      "Epoch 10031/15000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1225491758.7162 - val_loss: 1277711116.8584\n",
      "Epoch 10032/15000\n",
      "1022/1022 [==============================] - 0s 71us/step - loss: 1225660999.3894 - val_loss: 1278031555.5068\n",
      "Epoch 10033/15000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1225970931.0372 - val_loss: 1276096123.3242\n",
      "Epoch 10034/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1225974266.8023 - val_loss: 1277821488.2192\n",
      "Epoch 10035/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1225352271.1546 - val_loss: 1277538306.6301\n",
      "Epoch 10036/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1225795443.8513 - val_loss: 1276280491.5434\n",
      "Epoch 10037/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1225378990.7162 - val_loss: 1277404392.3288\n",
      "Epoch 10038/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1225546024.2035 - val_loss: 1276571310.7580\n",
      "Epoch 10039/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1225270385.2211 - val_loss: 1276707120.8037\n",
      "Epoch 10040/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1225717760.3757 - val_loss: 1278373368.4018\n",
      "Epoch 10041/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1225607045.7613 - val_loss: 1276426945.4612\n",
      "Epoch 10042/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1225608932.8219 - val_loss: 1276965280.7306\n",
      "Epoch 10043/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1225274643.3503 - val_loss: 1277313251.9452\n",
      "Epoch 10044/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1225514751.3738 - val_loss: 1276841415.5982\n",
      "Epoch 10045/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1225435073.6282 - val_loss: 1277050373.8447\n",
      "Epoch 10046/15000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1225575213.0881 - val_loss: 1278235582.5388\n",
      "Epoch 10047/15000\n",
      "1022/1022 [==============================] - 0s 65us/step - loss: 1225177409.8787 - val_loss: 1277720772.9680\n",
      "Epoch 10048/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1225308923.7417 - val_loss: 1277595834.1553\n",
      "Epoch 10049/15000\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 1225474137.4247 - val_loss: 1276268280.1096\n",
      "Epoch 10050/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1225823426.6301 - val_loss: 1275700728.9863\n",
      "Epoch 10051/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1225380442.1761 - val_loss: 1277740741.5525\n",
      "Epoch 10052/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1225494997.9178 - val_loss: 1275849211.3242\n",
      "Epoch 10053/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1225090008.1722 - val_loss: 1277049245.2237\n",
      "Epoch 10054/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1225531200.4384 - val_loss: 1277769617.5342\n",
      "Epoch 10055/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1225053720.9863 - val_loss: 1277220727.8174\n",
      "Epoch 10056/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1225877469.3699 - val_loss: 1276585870.3196\n",
      "Epoch 10057/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1225383601.0959 - val_loss: 1276846934.5023\n",
      "Epoch 10058/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1225388812.8376 - val_loss: 1276501628.4932\n",
      "Epoch 10059/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1225153152.6262 - val_loss: 1277694638.4658\n",
      "Epoch 10060/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1225485251.2564 - val_loss: 1276879619.2146\n",
      "Epoch 10061/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1225178964.0391 - val_loss: 1276835714.0457\n",
      "Epoch 10062/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1225203579.4912 - val_loss: 1277334406.7215\n",
      "Epoch 10063/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 28us/step - loss: 1225177060.9472 - val_loss: 1276130955.3973\n",
      "Epoch 10064/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1224872408.5479 - val_loss: 1276914158.7580\n",
      "Epoch 10065/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1225475874.4423 - val_loss: 1276134854.7215\n",
      "Epoch 10066/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1224953978.4892 - val_loss: 1277241785.2785\n",
      "Epoch 10067/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1225471884.3992 - val_loss: 1276403429.4064\n",
      "Epoch 10068/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1225051756.6497 - val_loss: 1276894841.2785\n",
      "Epoch 10069/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1225188977.9726 - val_loss: 1276813135.1963\n",
      "Epoch 10070/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1224981496.9863 - val_loss: 1276363921.8265\n",
      "Epoch 10071/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1225130846.1840 - val_loss: 1276412770.7763\n",
      "Epoch 10072/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1225778292.7280 - val_loss: 1278989664.4384\n",
      "Epoch 10073/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1225331254.6067 - val_loss: 1276995213.7352\n",
      "Epoch 10074/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1225065302.6693 - val_loss: 1277709046.6484\n",
      "Epoch 10075/15000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1225342089.0176 - val_loss: 1278002215.1598\n",
      "Epoch 10076/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1225165919.0607 - val_loss: 1276872931.6530\n",
      "Epoch 10077/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1224907724.1487 - val_loss: 1276825976.6941\n",
      "Epoch 10078/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1224904180.7280 - val_loss: 1276374973.3699\n",
      "Epoch 10079/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1225095675.9922 - val_loss: 1275556080.5114\n",
      "Epoch 10080/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1224750268.3679 - val_loss: 1276262690.4840\n",
      "Epoch 10081/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1224956310.2935 - val_loss: 1276752272.9498\n",
      "Epoch 10082/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1225327293.1194 - val_loss: 1278257480.4749\n",
      "Epoch 10083/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1224973737.9569 - val_loss: 1276636882.1187\n",
      "Epoch 10084/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1224897755.4286 - val_loss: 1275866183.5982\n",
      "Epoch 10085/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1224907637.8552 - val_loss: 1276605216.4384\n",
      "Epoch 10086/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1224883541.6673 - val_loss: 1276108424.4749\n",
      "Epoch 10087/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1224898245.8865 - val_loss: 1276920643.5068\n",
      "Epoch 10088/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1224890628.4462 - val_loss: 1277221064.4749\n",
      "Epoch 10089/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1224991277.2133 - val_loss: 1277365165.0046\n",
      "Epoch 10090/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1224740013.3386 - val_loss: 1276563840.0000\n",
      "Epoch 10091/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1225208774.2622 - val_loss: 1276834776.2557\n",
      "Epoch 10092/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1225177788.8689 - val_loss: 1277095801.8630\n",
      "Epoch 10093/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1224953441.1898 - val_loss: 1275616649.0594\n",
      "Epoch 10094/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1225579788.3366 - val_loss: 1277024137.6438\n",
      "Epoch 10095/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1224835518.3718 - val_loss: 1277254757.9909\n",
      "Epoch 10096/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1225260026.1135 - val_loss: 1276935532.7123\n",
      "Epoch 10097/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1224969601.6282 - val_loss: 1275112488.0365\n",
      "Epoch 10098/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1224954295.6086 - val_loss: 1274929178.5936\n",
      "Epoch 10099/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1224638939.4286 - val_loss: 1277027324.2009\n",
      "Epoch 10100/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1225004475.8669 - val_loss: 1277092554.2283\n",
      "Epoch 10101/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1224974550.6693 - val_loss: 1277273303.9635\n",
      "Epoch 10102/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1225126713.6125 - val_loss: 1275834673.0959\n",
      "Epoch 10103/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1224741304.1096 - val_loss: 1276734004.3105\n",
      "Epoch 10104/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1224562048.2505 - val_loss: 1276427687.1598\n",
      "Epoch 10105/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1225010259.7886 - val_loss: 1274865162.5205\n",
      "Epoch 10106/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1224543201.0646 - val_loss: 1275837184.8767\n",
      "Epoch 10107/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1226111415.9843 - val_loss: 1277060760.8402\n",
      "Epoch 10108/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1225050048.8767 - val_loss: 1275019864.8402\n",
      "Epoch 10109/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1224525420.7123 - val_loss: 1276945695.8539\n",
      "Epoch 10110/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1224583937.0020 - val_loss: 1276510274.6301\n",
      "Epoch 10111/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1224650120.6419 - val_loss: 1275713331.4338\n",
      "Epoch 10112/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1224518523.3659 - val_loss: 1275664001.7534\n",
      "Epoch 10113/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1225694831.3425 - val_loss: 1276892306.9954\n",
      "Epoch 10114/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1224625576.3288 - val_loss: 1277242236.4932\n",
      "Epoch 10115/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1224529525.4795 - val_loss: 1276275851.3973\n",
      "Epoch 10116/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1224487875.8826 - val_loss: 1276528585.9361\n",
      "Epoch 10117/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1225228277.9804 - val_loss: 1275152480.4384\n",
      "Epoch 10118/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1224834474.5832 - val_loss: 1276125291.2511\n",
      "Epoch 10119/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1224505801.8943 - val_loss: 1275995740.9315\n",
      "Epoch 10120/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1224562482.0978 - val_loss: 1276990027.6895\n",
      "Epoch 10121/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1224587457.9413 - val_loss: 1277241796.3836\n",
      "Epoch 10122/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1225166674.4736 - val_loss: 1277166530.0457\n",
      "Epoch 10123/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1226266945.1272 - val_loss: 1273507913.0594\n",
      "Epoch 10124/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1224720680.7045 - val_loss: 1276211633.3881\n",
      "Epoch 10125/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1224397742.4658 - val_loss: 1276078506.9589\n",
      "Epoch 10126/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1224558357.4168 - val_loss: 1276433051.4703\n",
      "Epoch 10127/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 28us/step - loss: 1224344122.1135 - val_loss: 1275723309.2968\n",
      "Epoch 10128/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1224525854.9354 - val_loss: 1275978680.6941\n",
      "Epoch 10129/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1224626810.8650 - val_loss: 1276524147.7260\n",
      "Epoch 10130/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1224705591.6086 - val_loss: 1276319075.3607\n",
      "Epoch 10131/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1224875253.6360 - val_loss: 1275977899.8356\n",
      "Epoch 10132/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1224662258.7241 - val_loss: 1275555255.2329\n",
      "Epoch 10133/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1224617721.4873 - val_loss: 1276357207.3790\n",
      "Epoch 10134/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1224647342.0900 - val_loss: 1275332653.2968\n",
      "Epoch 10135/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1224159160.1096 - val_loss: 1275992689.3881\n",
      "Epoch 10136/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1224166338.2544 - val_loss: 1276057124.8219\n",
      "Epoch 10137/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1224601348.5088 - val_loss: 1276051812.8219\n",
      "Epoch 10138/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1224150905.8630 - val_loss: 1275659077.8447\n",
      "Epoch 10139/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1224594537.4560 - val_loss: 1276886701.5890\n",
      "Epoch 10140/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1224157077.3542 - val_loss: 1275841268.6027\n",
      "Epoch 10141/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1224275850.7710 - val_loss: 1275403567.3425\n",
      "Epoch 10142/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1224408701.2446 - val_loss: 1276530711.6712\n",
      "Epoch 10143/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1224728550.2622 - val_loss: 1276179513.2785\n",
      "Epoch 10144/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1224282343.0137 - val_loss: 1276159493.5525\n",
      "Epoch 10145/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1225102587.8669 - val_loss: 1276825193.4977\n",
      "Epoch 10146/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1224589845.3542 - val_loss: 1275435503.0502\n",
      "Epoch 10147/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1224153236.6654 - val_loss: 1275703861.1872\n",
      "Epoch 10148/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1224333356.3366 - val_loss: 1275232351.8539\n",
      "Epoch 10149/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1224288289.6908 - val_loss: 1275827145.0594\n",
      "Epoch 10150/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1224442535.8278 - val_loss: 1275667371.5434\n",
      "Epoch 10151/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1224534982.3875 - val_loss: 1275504581.2603\n",
      "Epoch 10152/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223999010.5675 - val_loss: 1275936289.6073\n",
      "Epoch 10153/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1224203196.6184 - val_loss: 1275931398.4292\n",
      "Epoch 10154/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1224437190.1370 - val_loss: 1276087799.5251\n",
      "Epoch 10155/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1224691489.1898 - val_loss: 1276343324.6393\n",
      "Epoch 10156/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1223884501.3542 - val_loss: 1275945674.2283\n",
      "Epoch 10157/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1224230364.9315 - val_loss: 1274932904.9132\n",
      "Epoch 10158/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1224213442.1292 - val_loss: 1276582968.1096\n",
      "Epoch 10159/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1223961041.6595 - val_loss: 1275562578.4110\n",
      "Epoch 10160/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1224707413.9804 - val_loss: 1274041751.6712\n",
      "Epoch 10161/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1224021079.6712 - val_loss: 1276147664.0731\n",
      "Epoch 10162/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1224334713.2368 - val_loss: 1274770088.6210\n",
      "Epoch 10163/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223914496.7515 - val_loss: 1275725981.2237\n",
      "Epoch 10164/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1224001906.0978 - val_loss: 1275604015.6347\n",
      "Epoch 10165/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1223983772.6184 - val_loss: 1276062141.9543\n",
      "Epoch 10166/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1225481900.8376 - val_loss: 1275859031.9635\n",
      "Epoch 10167/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1224927646.8102 - val_loss: 1276501700.3836\n",
      "Epoch 10168/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1224287041.1272 - val_loss: 1276181019.7626\n",
      "Epoch 10169/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1224438983.5147 - val_loss: 1274832384.8767\n",
      "Epoch 10170/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1224345922.1292 - val_loss: 1275997122.3379\n",
      "Epoch 10171/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1225401446.9511 - val_loss: 1274136355.6530\n",
      "Epoch 10172/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1224276929.1272 - val_loss: 1276352569.2785\n",
      "Epoch 10173/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1223962742.1057 - val_loss: 1275893148.6393\n",
      "Epoch 10174/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1223808820.9785 - val_loss: 1275884689.2420\n",
      "Epoch 10175/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1224016813.0881 - val_loss: 1275425823.8539\n",
      "Epoch 10176/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1223871776.1252 - val_loss: 1276434926.1735\n",
      "Epoch 10177/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1223829232.4697 - val_loss: 1274927152.8037\n",
      "Epoch 10178/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1223912596.5401 - val_loss: 1275862377.2055\n",
      "Epoch 10179/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1223880712.1409 - val_loss: 1275397001.0594\n",
      "Epoch 10180/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1223881555.9139 - val_loss: 1276068016.2192\n",
      "Epoch 10181/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1223700182.0431 - val_loss: 1275787446.9406\n",
      "Epoch 10182/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1223998790.1370 - val_loss: 1274890662.5753\n",
      "Epoch 10183/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1223749772.7750 - val_loss: 1276042489.8630\n",
      "Epoch 10184/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1223709579.0841 - val_loss: 1275588009.2055\n",
      "Epoch 10185/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1223659990.9198 - val_loss: 1275973008.0731\n",
      "Epoch 10186/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1223720461.4012 - val_loss: 1275711274.9589\n",
      "Epoch 10187/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1224659938.9432 - val_loss: 1273287565.1507\n",
      "Epoch 10188/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1224800518.8258 - val_loss: 1276485400.5479\n",
      "Epoch 10189/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1223637298.0978 - val_loss: 1275671338.0822\n",
      "Epoch 10190/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1223808770.3170 - val_loss: 1275132057.4247\n",
      "Epoch 10191/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 28us/step - loss: 1224043551.5616 - val_loss: 1274046832.8037\n",
      "Epoch 10192/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1224151032.9237 - val_loss: 1276195143.0137\n",
      "Epoch 10193/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1223672630.6067 - val_loss: 1274391393.3151\n",
      "Epoch 10194/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1223541897.3933 - val_loss: 1275023595.2511\n",
      "Epoch 10195/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1223911479.9843 - val_loss: 1276013542.2831\n",
      "Epoch 10196/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1224358376.5793 - val_loss: 1276377303.3790\n",
      "Epoch 10197/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223603121.0959 - val_loss: 1275375020.7123\n",
      "Epoch 10198/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223950215.2642 - val_loss: 1276095939.7991\n",
      "Epoch 10199/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223835696.0313 - val_loss: 1274300244.4566\n",
      "Epoch 10200/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1223816004.6341 - val_loss: 1274394433.1689\n",
      "Epoch 10201/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223848030.0587 - val_loss: 1275135818.8128\n",
      "Epoch 10202/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1223743831.6712 - val_loss: 1273837840.3653\n",
      "Epoch 10203/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1223628548.5088 - val_loss: 1274091676.6393\n",
      "Epoch 10204/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223507437.0881 - val_loss: 1275374319.6347\n",
      "Epoch 10205/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223625852.7436 - val_loss: 1276040604.9315\n",
      "Epoch 10206/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223555750.1996 - val_loss: 1275423178.8128\n",
      "Epoch 10207/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1223501896.0157 - val_loss: 1275229257.6438\n",
      "Epoch 10208/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223614446.2153 - val_loss: 1275305038.3196\n",
      "Epoch 10209/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223916583.9530 - val_loss: 1274694793.0594\n",
      "Epoch 10210/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223360543.5616 - val_loss: 1275307764.3105\n",
      "Epoch 10211/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1223921495.9217 - val_loss: 1276457844.3105\n",
      "Epoch 10212/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223423328.5636 - val_loss: 1274323851.3973\n",
      "Epoch 10213/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1224434216.7045 - val_loss: 1275624018.7032\n",
      "Epoch 10214/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1224219102.5597 - val_loss: 1273076356.3836\n",
      "Epoch 10215/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1223390880.3131 - val_loss: 1274841161.6438\n",
      "Epoch 10216/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1223556786.0978 - val_loss: 1274924241.8265\n",
      "Epoch 10217/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1223366228.2896 - val_loss: 1275442428.2009\n",
      "Epoch 10218/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1223292500.9159 - val_loss: 1275279675.3242\n",
      "Epoch 10219/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1223727845.0724 - val_loss: 1274187622.5753\n",
      "Epoch 10220/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223488260.1331 - val_loss: 1274666751.7078\n",
      "Epoch 10221/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223273123.8200 - val_loss: 1274643475.5799\n",
      "Epoch 10222/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1223653288.0783 - val_loss: 1274890320.9498\n",
      "Epoch 10223/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223208221.5577 - val_loss: 1274862651.6164\n",
      "Epoch 10224/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223445999.2172 - val_loss: 1276201024.0000\n",
      "Epoch 10225/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223326221.6517 - val_loss: 1275026078.3927\n",
      "Epoch 10226/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1223319236.6341 - val_loss: 1274979663.1963\n",
      "Epoch 10227/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1223205644.7750 - val_loss: 1275409175.9635\n",
      "Epoch 10228/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1223259989.6047 - val_loss: 1275395912.7671\n",
      "Epoch 10229/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1223299236.6967 - val_loss: 1275223874.0457\n",
      "Epoch 10230/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1223792295.5773 - val_loss: 1275394985.4977\n",
      "Epoch 10231/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223807072.1879 - val_loss: 1272799362.3379\n",
      "Epoch 10232/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223242352.5323 - val_loss: 1274725452.2740\n",
      "Epoch 10233/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1223425353.0176 - val_loss: 1274635397.2603\n",
      "Epoch 10234/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1223124076.3366 - val_loss: 1275229105.3881\n",
      "Epoch 10235/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1223704126.9980 - val_loss: 1276447758.9041\n",
      "Epoch 10236/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1223510893.9648 - val_loss: 1275659732.4566\n",
      "Epoch 10237/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1222948103.0137 - val_loss: 1274772375.6712\n",
      "Epoch 10238/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1223102217.1429 - val_loss: 1274502055.4521\n",
      "Epoch 10239/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1223135284.2270 - val_loss: 1274396103.5982\n",
      "Epoch 10240/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1223387551.3112 - val_loss: 1274656647.3059\n",
      "Epoch 10241/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1223078794.5205 - val_loss: 1274850606.4658\n",
      "Epoch 10242/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223120238.9667 - val_loss: 1275107476.7489\n",
      "Epoch 10243/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223291185.9100 - val_loss: 1275163548.6393\n",
      "Epoch 10244/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1223019216.2818 - val_loss: 1274052579.0685\n",
      "Epoch 10245/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223235744.3757 - val_loss: 1274220161.1689\n",
      "Epoch 10246/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223217984.6262 - val_loss: 1273877104.8037\n",
      "Epoch 10247/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223154922.7084 - val_loss: 1275256602.0091\n",
      "Epoch 10248/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223014039.0450 - val_loss: 1275363308.7123\n",
      "Epoch 10249/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223114492.3679 - val_loss: 1274690157.2968\n",
      "Epoch 10250/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223166780.6184 - val_loss: 1273795245.5890\n",
      "Epoch 10251/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1223307685.6986 - val_loss: 1275342377.2055\n",
      "Epoch 10252/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1223004130.4423 - val_loss: 1274733546.3744\n",
      "Epoch 10253/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1223466321.1585 - val_loss: 1273729429.6256\n",
      "Epoch 10254/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223609451.1468 - val_loss: 1273107915.9817\n",
      "Epoch 10255/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 27us/step - loss: 1222983398.5753 - val_loss: 1273597579.1050\n",
      "Epoch 10256/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223335346.7867 - val_loss: 1275883115.8356\n",
      "Epoch 10257/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1223363871.3738 - val_loss: 1274276287.4155\n",
      "Epoch 10258/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1223070207.1233 - val_loss: 1274687916.7123\n",
      "Epoch 10259/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1223182074.8023 - val_loss: 1274809848.1096\n",
      "Epoch 10260/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223175715.7573 - val_loss: 1274446762.6667\n",
      "Epoch 10261/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223272078.5284 - val_loss: 1275334621.5160\n",
      "Epoch 10262/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1223167706.6771 - val_loss: 1274446404.6758\n",
      "Epoch 10263/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1224034215.3268 - val_loss: 1276245996.1279\n",
      "Epoch 10264/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1223215163.3659 - val_loss: 1275282161.9726\n",
      "Epoch 10265/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1223150459.1155 - val_loss: 1273847884.2740\n",
      "Epoch 10266/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1222979110.3249 - val_loss: 1274164468.3105\n",
      "Epoch 10267/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1222944379.4912 - val_loss: 1274462829.2968\n",
      "Epoch 10268/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1222913629.6830 - val_loss: 1274338625.1689\n",
      "Epoch 10269/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223104887.8591 - val_loss: 1273035418.0091\n",
      "Epoch 10270/15000\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 1222828613.0098 - val_loss: 1274548192.1461\n",
      "Epoch 10271/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1222898450.2857 - val_loss: 1274849651.7260\n",
      "Epoch 10272/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1222766209.7534 - val_loss: 1274307185.3881\n",
      "Epoch 10273/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1222796358.8885 - val_loss: 1274476935.3059\n",
      "Epoch 10274/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223273398.3562 - val_loss: 1276096266.2283\n",
      "Epoch 10275/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1223688658.9119 - val_loss: 1272095343.3425\n",
      "Epoch 10276/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1222600462.6536 - val_loss: 1274049219.2146\n",
      "Epoch 10277/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1222824906.3953 - val_loss: 1275255418.7397\n",
      "Epoch 10278/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1222839952.5323 - val_loss: 1273909248.2922\n",
      "Epoch 10279/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1222716846.5910 - val_loss: 1274254214.7215\n",
      "Epoch 10280/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1222854299.5538 - val_loss: 1273805793.3151\n",
      "Epoch 10281/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1222746607.2172 - val_loss: 1274714647.3790\n",
      "Epoch 10282/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1222799852.3366 - val_loss: 1275289822.1005\n",
      "Epoch 10283/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1223439766.2935 - val_loss: 1275384279.3790\n",
      "Epoch 10284/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1222731180.4618 - val_loss: 1274245326.6119\n",
      "Epoch 10285/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1222871154.2857 - val_loss: 1274753914.4475\n",
      "Epoch 10286/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1222568378.3640 - val_loss: 1274248576.2922\n",
      "Epoch 10287/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223191971.6947 - val_loss: 1272741357.2968\n",
      "Epoch 10288/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1222473025.3777 - val_loss: 1273959519.5616\n",
      "Epoch 10289/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223087925.6047 - val_loss: 1275649645.0046\n",
      "Epoch 10290/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1222832725.0411 - val_loss: 1274008272.9498\n",
      "Epoch 10291/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1222442401.5656 - val_loss: 1273909147.7626\n",
      "Epoch 10292/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1222601243.5538 - val_loss: 1274029875.4338\n",
      "Epoch 10293/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1222464009.0176 - val_loss: 1274340026.4475\n",
      "Epoch 10294/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1222636276.3523 - val_loss: 1273734828.1279\n",
      "Epoch 10295/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1222953270.6067 - val_loss: 1275309803.5434\n",
      "Epoch 10296/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1222346866.9746 - val_loss: 1274215975.1598\n",
      "Epoch 10297/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1222819240.4540 - val_loss: 1274553734.7215\n",
      "Epoch 10298/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1222960244.4149 - val_loss: 1274166635.8356\n",
      "Epoch 10299/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223073483.6477 - val_loss: 1273189795.0685\n",
      "Epoch 10300/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1222502354.8493 - val_loss: 1273661832.1826\n",
      "Epoch 10301/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1222571042.8180 - val_loss: 1274201909.1872\n",
      "Epoch 10302/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1222667312.0939 - val_loss: 1274226323.5799\n",
      "Epoch 10303/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1222421705.9256 - val_loss: 1273744503.5251\n",
      "Epoch 10304/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1222775077.8239 - val_loss: 1274783870.5388\n",
      "Epoch 10305/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1222435441.5969 - val_loss: 1274149826.3379\n",
      "Epoch 10306/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1222734441.7065 - val_loss: 1273537984.0000\n",
      "Epoch 10307/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1222568911.0294 - val_loss: 1273950963.4338\n",
      "Epoch 10308/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1222351845.3229 - val_loss: 1274466240.2922\n",
      "Epoch 10309/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1222895949.1507 - val_loss: 1275524233.3516\n",
      "Epoch 10310/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1223428950.9198 - val_loss: 1272789401.4247\n",
      "Epoch 10311/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1222327109.7613 - val_loss: 1273247737.8630\n",
      "Epoch 10312/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1223426520.9237 - val_loss: 1275241711.3425\n",
      "Epoch 10313/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1222223921.5969 - val_loss: 1273736523.6895\n",
      "Epoch 10314/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1222401455.8434 - val_loss: 1272635097.7169\n",
      "Epoch 10315/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1222544807.8278 - val_loss: 1273242518.7945\n",
      "Epoch 10316/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1222761444.6967 - val_loss: 1274507678.3927\n",
      "Epoch 10317/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1222760084.7906 - val_loss: 1273000781.4429\n",
      "Epoch 10318/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1222593921.8787 - val_loss: 1274562390.7945\n",
      "Epoch 10319/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 26us/step - loss: 1223197563.4912 - val_loss: 1274747807.2694\n",
      "Epoch 10320/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1222244429.6517 - val_loss: 1273702945.3151\n",
      "Epoch 10321/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1222352392.6419 - val_loss: 1274117867.5434\n",
      "Epoch 10322/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1222840761.6125 - val_loss: 1273763403.6895\n",
      "Epoch 10323/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1222564713.7065 - val_loss: 1273491622.8676\n",
      "Epoch 10324/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1222654170.5519 - val_loss: 1273438911.7078\n",
      "Epoch 10325/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1222384227.1937 - val_loss: 1273869114.4475\n",
      "Epoch 10326/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1222239753.5186 - val_loss: 1274372850.5571\n",
      "Epoch 10327/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1222236122.1135 - val_loss: 1273336524.5662\n",
      "Epoch 10328/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1222260985.3620 - val_loss: 1274305773.2968\n",
      "Epoch 10329/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1222242678.8571 - val_loss: 1273433710.4658\n",
      "Epoch 10330/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1222733416.2661 - val_loss: 1273045656.8402\n",
      "Epoch 10331/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1222212104.2661 - val_loss: 1274028722.2648\n",
      "Epoch 10332/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1222274614.2309 - val_loss: 1273827207.3059\n",
      "Epoch 10333/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1222457201.8474 - val_loss: 1272649154.0457\n",
      "Epoch 10334/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1222232576.3757 - val_loss: 1272922894.0274\n",
      "Epoch 10335/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1222563758.9667 - val_loss: 1274803476.1644\n",
      "Epoch 10336/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1222127426.3796 - val_loss: 1273910787.5068\n",
      "Epoch 10337/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1222131030.9198 - val_loss: 1273264012.5662\n",
      "Epoch 10338/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1222139682.8180 - val_loss: 1272630297.4247\n",
      "Epoch 10339/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1222481460.1018 - val_loss: 1274323160.2557\n",
      "Epoch 10340/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1222223743.7495 - val_loss: 1272550873.1324\n",
      "Epoch 10341/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1222029155.6321 - val_loss: 1273503584.1461\n",
      "Epoch 10342/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221984944.5949 - val_loss: 1273834926.4658\n",
      "Epoch 10343/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223175416.7358 - val_loss: 1273170790.8676\n",
      "Epoch 10344/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1222115571.7260 - val_loss: 1273325523.8721\n",
      "Epoch 10345/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1222134063.5930 - val_loss: 1273903585.8995\n",
      "Epoch 10346/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1222618721.3151 - val_loss: 1272833623.6712\n",
      "Epoch 10347/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1221998181.5734 - val_loss: 1274234565.8447\n",
      "Epoch 10348/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1222412831.5616 - val_loss: 1274607042.0457\n",
      "Epoch 10349/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1221971536.4070 - val_loss: 1273266633.0594\n",
      "Epoch 10350/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221978544.0939 - val_loss: 1273896256.8767\n",
      "Epoch 10351/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1222389271.4207 - val_loss: 1272035972.3836\n",
      "Epoch 10352/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1222032359.0763 - val_loss: 1272459908.3836\n",
      "Epoch 10353/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1222135549.7456 - val_loss: 1273246663.0137\n",
      "Epoch 10354/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1222050910.1840 - val_loss: 1274010943.4155\n",
      "Epoch 10355/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1222399208.3288 - val_loss: 1273518008.6941\n",
      "Epoch 10356/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1221973289.8317 - val_loss: 1273359082.6667\n",
      "Epoch 10357/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1221853963.8982 - val_loss: 1273565385.9361\n",
      "Epoch 10358/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1221946059.0215 - val_loss: 1273329657.8630\n",
      "Epoch 10359/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1221910391.7339 - val_loss: 1273043897.2785\n",
      "Epoch 10360/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1222081918.4971 - val_loss: 1273874786.4840\n",
      "Epoch 10361/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1221920570.0509 - val_loss: 1273973462.2100\n",
      "Epoch 10362/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1221996106.6458 - val_loss: 1273427042.4840\n",
      "Epoch 10363/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1221901659.4286 - val_loss: 1272266820.6758\n",
      "Epoch 10364/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1221681759.1859 - val_loss: 1272930355.7260\n",
      "Epoch 10365/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1221836652.7123 - val_loss: 1272601530.4475\n",
      "Epoch 10366/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1222118482.4110 - val_loss: 1273901675.8356\n",
      "Epoch 10367/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1221764533.8552 - val_loss: 1272821172.6027\n",
      "Epoch 10368/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1221819340.8376 - val_loss: 1272172878.0274\n",
      "Epoch 10369/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1222014667.1468 - val_loss: 1273610914.7763\n",
      "Epoch 10370/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1222062401.1272 - val_loss: 1273518418.1187\n",
      "Epoch 10371/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1221871235.5068 - val_loss: 1273539537.8265\n",
      "Epoch 10372/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1221688573.9961 - val_loss: 1272716679.8904\n",
      "Epoch 10373/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1222238638.0900 - val_loss: 1273326652.7854\n",
      "Epoch 10374/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1222179959.6086 - val_loss: 1273374293.0411\n",
      "Epoch 10375/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221893192.6419 - val_loss: 1272883567.9269\n",
      "Epoch 10376/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1221770918.0744 - val_loss: 1272327538.8493\n",
      "Epoch 10377/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1221838318.9667 - val_loss: 1272849246.3927\n",
      "Epoch 10378/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1221661955.7573 - val_loss: 1273810940.4932\n",
      "Epoch 10379/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1222006229.9178 - val_loss: 1274377554.1187\n",
      "Epoch 10380/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1222056606.1840 - val_loss: 1271694578.2648\n",
      "Epoch 10381/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1221669278.3092 - val_loss: 1272834212.2374\n",
      "Epoch 10382/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1221754096.4697 - val_loss: 1273929580.1279\n",
      "Epoch 10383/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 28us/step - loss: 1222556914.7241 - val_loss: 1271354471.1598\n",
      "Epoch 10384/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1221582619.0528 - val_loss: 1273428836.8219\n",
      "Epoch 10385/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1221804383.6243 - val_loss: 1273643517.6621\n",
      "Epoch 10386/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1221619012.7593 - val_loss: 1272921980.4932\n",
      "Epoch 10387/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221625502.6849 - val_loss: 1273396713.4977\n",
      "Epoch 10388/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1221847087.3425 - val_loss: 1273309534.1005\n",
      "Epoch 10389/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1221416704.1252 - val_loss: 1272817352.1826\n",
      "Epoch 10390/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221579879.2016 - val_loss: 1272300554.2283\n",
      "Epoch 10391/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221994833.4090 - val_loss: 1272868314.5936\n",
      "Epoch 10392/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221536842.7710 - val_loss: 1272455844.8219\n",
      "Epoch 10393/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1223150048.9393 - val_loss: 1275180064.7306\n",
      "Epoch 10394/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221614866.9746 - val_loss: 1272376295.4521\n",
      "Epoch 10395/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221783698.4110 - val_loss: 1273050557.0776\n",
      "Epoch 10396/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221717592.9237 - val_loss: 1271464973.7352\n",
      "Epoch 10397/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221560474.4892 - val_loss: 1272793353.0594\n",
      "Epoch 10398/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1221619918.9041 - val_loss: 1272863279.6347\n",
      "Epoch 10399/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1221587293.3072 - val_loss: 1272898454.7945\n",
      "Epoch 10400/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221583969.6908 - val_loss: 1273192386.3379\n",
      "Epoch 10401/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1222032953.9883 - val_loss: 1270853208.8402\n",
      "Epoch 10402/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221387339.8982 - val_loss: 1271366210.6301\n",
      "Epoch 10403/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221411992.9237 - val_loss: 1272623381.6256\n",
      "Epoch 10404/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221650042.3640 - val_loss: 1272995409.8265\n",
      "Epoch 10405/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1221381539.8200 - val_loss: 1271768214.7945\n",
      "Epoch 10406/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1222030948.9472 - val_loss: 1272070720.0000\n",
      "Epoch 10407/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221841294.8415 - val_loss: 1273393927.5982\n",
      "Epoch 10408/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1222078219.8356 - val_loss: 1271857315.9452\n",
      "Epoch 10409/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221325940.9785 - val_loss: 1273020596.6027\n",
      "Epoch 10410/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221555192.8611 - val_loss: 1273383738.1553\n",
      "Epoch 10411/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221333728.2505 - val_loss: 1273238451.7260\n",
      "Epoch 10412/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221851197.6830 - val_loss: 1272138532.2374\n",
      "Epoch 10413/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221285941.4795 - val_loss: 1272736707.7991\n",
      "Epoch 10414/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221207046.8885 - val_loss: 1272932199.7443\n",
      "Epoch 10415/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221674935.2329 - val_loss: 1273183108.9680\n",
      "Epoch 10416/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221245724.8063 - val_loss: 1272418548.0183\n",
      "Epoch 10417/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1221634384.6575 - val_loss: 1273450999.5251\n",
      "Epoch 10418/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1221613484.7123 - val_loss: 1272296420.5297\n",
      "Epoch 10419/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221685865.8317 - val_loss: 1273025535.4155\n",
      "Epoch 10420/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221246214.0117 - val_loss: 1272980956.0548\n",
      "Epoch 10421/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1222267451.6164 - val_loss: 1273623308.5662\n",
      "Epoch 10422/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1221508771.8200 - val_loss: 1272312700.2009\n",
      "Epoch 10423/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1221299140.3836 - val_loss: 1272203524.6758\n",
      "Epoch 10424/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221304417.8160 - val_loss: 1271545841.3881\n",
      "Epoch 10425/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221271573.6673 - val_loss: 1272070381.0046\n",
      "Epoch 10426/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221112330.5205 - val_loss: 1272125928.3288\n",
      "Epoch 10427/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221204456.9550 - val_loss: 1271519155.1416\n",
      "Epoch 10428/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1221292736.1252 - val_loss: 1272643564.1279\n",
      "Epoch 10429/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221330812.8689 - val_loss: 1271855205.9909\n",
      "Epoch 10430/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1221540997.9491 - val_loss: 1272857551.7808\n",
      "Epoch 10431/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1222003911.8904 - val_loss: 1270428865.1689\n",
      "Epoch 10432/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1220883162.6771 - val_loss: 1272286728.4749\n",
      "Epoch 10433/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221216951.6086 - val_loss: 1273424978.9954\n",
      "Epoch 10434/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1221926713.9883 - val_loss: 1271190362.8858\n",
      "Epoch 10435/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1221685541.4481 - val_loss: 1273729497.4247\n",
      "Epoch 10436/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1221545027.9452 - val_loss: 1272129034.5205\n",
      "Epoch 10437/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1221107330.1292 - val_loss: 1272652912.5114\n",
      "Epoch 10438/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1221315825.0959 - val_loss: 1271600948.0183\n",
      "Epoch 10439/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1221004257.6282 - val_loss: 1272409590.6484\n",
      "Epoch 10440/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1221334241.4403 - val_loss: 1271156984.9863\n",
      "Epoch 10441/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1221797472.6888 - val_loss: 1274137149.6621\n",
      "Epoch 10442/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1221422094.0274 - val_loss: 1272224674.7763\n",
      "Epoch 10443/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1221758911.3738 - val_loss: 1273197903.4886\n",
      "Epoch 10444/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1220911246.7789 - val_loss: 1272235842.0457\n",
      "Epoch 10445/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1221115109.6986 - val_loss: 1270905195.2511\n",
      "Epoch 10446/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1221172427.1781 - val_loss: 1271315851.3973\n",
      "Epoch 10447/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 29us/step - loss: 1220797055.3112 - val_loss: 1271738140.6393\n",
      "Epoch 10448/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1220956165.5108 - val_loss: 1272193722.7397\n",
      "Epoch 10449/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1221044282.6145 - val_loss: 1272227984.0731\n",
      "Epoch 10450/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1220795060.5401 - val_loss: 1272491949.5890\n",
      "Epoch 10451/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1220890842.3014 - val_loss: 1272811979.9817\n",
      "Epoch 10452/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1220992309.8552 - val_loss: 1273197359.6347\n",
      "Epoch 10453/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221019773.7456 - val_loss: 1272941260.8584\n",
      "Epoch 10454/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1221117134.5910 - val_loss: 1272708325.1142\n",
      "Epoch 10455/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1220753724.4932 - val_loss: 1272090522.0091\n",
      "Epoch 10456/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1221766363.1781 - val_loss: 1272184074.2283\n",
      "Epoch 10457/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1220943651.0685 - val_loss: 1271142405.5525\n",
      "Epoch 10458/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221280921.9256 - val_loss: 1272416400.3653\n",
      "Epoch 10459/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1220905343.1233 - val_loss: 1271826038.9406\n",
      "Epoch 10460/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1220889221.0098 - val_loss: 1271943278.7580\n",
      "Epoch 10461/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221172496.2818 - val_loss: 1270806940.6393\n",
      "Epoch 10462/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1221080136.8924 - val_loss: 1272915752.3288\n",
      "Epoch 10463/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1220906869.2290 - val_loss: 1272760858.8858\n",
      "Epoch 10464/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1220950947.4442 - val_loss: 1272284861.3699\n",
      "Epoch 10465/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1221082895.1546 - val_loss: 1271007366.4292\n",
      "Epoch 10466/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1221259804.0548 - val_loss: 1270252436.4566\n",
      "Epoch 10467/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1220706276.4462 - val_loss: 1270736630.6484\n",
      "Epoch 10468/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1221376020.2896 - val_loss: 1272749215.2694\n",
      "Epoch 10469/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1220651064.7358 - val_loss: 1272457070.1735\n",
      "Epoch 10470/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1220725776.0313 - val_loss: 1272242573.7352\n",
      "Epoch 10471/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1220967268.1957 - val_loss: 1272991690.8128\n",
      "Epoch 10472/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1220984950.9824 - val_loss: 1270785245.2237\n",
      "Epoch 10473/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1220836740.8219 - val_loss: 1272250436.6758\n",
      "Epoch 10474/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1220720170.2074 - val_loss: 1271864109.5890\n",
      "Epoch 10475/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1221387232.6888 - val_loss: 1270394226.5571\n",
      "Epoch 10476/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1220497009.2211 - val_loss: 1271678946.1918\n",
      "Epoch 10477/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1220694638.2153 - val_loss: 1271895541.4795\n",
      "Epoch 10478/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1220573578.6458 - val_loss: 1271430405.5525\n",
      "Epoch 10479/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1220566500.5714 - val_loss: 1272028301.1507\n",
      "Epoch 10480/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1220753801.3933 - val_loss: 1272331774.8311\n",
      "Epoch 10481/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1220614361.4247 - val_loss: 1272102210.6301\n",
      "Epoch 10482/15000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1221186965.1663 - val_loss: 1273931714.3379\n",
      "Epoch 10483/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1220904005.5108 - val_loss: 1272172468.8950\n",
      "Epoch 10484/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1220577832.5166 - val_loss: 1271505788.7854\n",
      "Epoch 10485/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1220623957.0411 - val_loss: 1272445264.0731\n",
      "Epoch 10486/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1220689360.5323 - val_loss: 1272031116.2740\n",
      "Epoch 10487/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1220996309.3542 - val_loss: 1270920920.8402\n",
      "Epoch 10488/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1220670557.9335 - val_loss: 1272590082.0457\n",
      "Epoch 10489/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1220676825.1742 - val_loss: 1272034526.9772\n",
      "Epoch 10490/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1220614649.9883 - val_loss: 1272248552.9132\n",
      "Epoch 10491/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1220518516.8532 - val_loss: 1271933691.6164\n",
      "Epoch 10492/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1220573530.6771 - val_loss: 1270970518.7945\n",
      "Epoch 10493/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1220509042.7241 - val_loss: 1271694700.1279\n",
      "Epoch 10494/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1220538441.6438 - val_loss: 1271081294.3196\n",
      "Epoch 10495/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1220853503.3112 - val_loss: 1272340595.4338\n",
      "Epoch 10496/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1220412546.6301 - val_loss: 1272361368.2557\n",
      "Epoch 10497/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1220564196.6967 - val_loss: 1271520785.8265\n",
      "Epoch 10498/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1220673929.5186 - val_loss: 1272499003.3242\n",
      "Epoch 10499/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1221373255.5147 - val_loss: 1270405436.4932\n",
      "Epoch 10500/15000\n",
      "1022/1022 [==============================] - 0s 88us/step - loss: 1220634138.4266 - val_loss: 1271016065.1689\n",
      "Epoch 10501/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1220495137.8787 - val_loss: 1271513611.9817\n",
      "Epoch 10502/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1220861644.2114 - val_loss: 1271411188.0183\n",
      "Epoch 10503/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1220482838.5440 - val_loss: 1271739398.7215\n",
      "Epoch 10504/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1220495260.0548 - val_loss: 1272395377.9726\n",
      "Epoch 10505/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1220548506.1761 - val_loss: 1272495248.0731\n",
      "Epoch 10506/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1220834904.4227 - val_loss: 1271143955.5799\n",
      "Epoch 10507/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1220694637.6517 - val_loss: 1270907973.8447\n",
      "Epoch 10508/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1220470827.0841 - val_loss: 1272513115.1781\n",
      "Epoch 10509/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1221053646.7789 - val_loss: 1270996536.6941\n",
      "Epoch 10510/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1220407813.6360 - val_loss: 1271621766.4292\n",
      "Epoch 10511/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 28us/step - loss: 1220206568.4540 - val_loss: 1271876753.8265\n",
      "Epoch 10512/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1220685941.9804 - val_loss: 1272786725.1142\n",
      "Epoch 10513/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1220453067.5851 - val_loss: 1271946566.1370\n",
      "Epoch 10514/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1220350553.9256 - val_loss: 1272360405.9178\n",
      "Epoch 10515/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1220264281.1742 - val_loss: 1271866392.8402\n",
      "Epoch 10516/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1220507721.1429 - val_loss: 1270205157.1142\n",
      "Epoch 10517/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1220450364.4932 - val_loss: 1272158090.8128\n",
      "Epoch 10518/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1220348115.6634 - val_loss: 1270765318.7215\n",
      "Epoch 10519/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1220130070.1057 - val_loss: 1271586685.9543\n",
      "Epoch 10520/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1220631687.3894 - val_loss: 1270994719.2694\n",
      "Epoch 10521/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1220175922.9746 - val_loss: 1271971815.1598\n",
      "Epoch 10522/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1220394980.1957 - val_loss: 1271928997.1142\n",
      "Epoch 10523/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1220392412.1800 - val_loss: 1272280217.1324\n",
      "Epoch 10524/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1220261573.5108 - val_loss: 1271170778.3014\n",
      "Epoch 10525/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1220921494.2935 - val_loss: 1273130525.2237\n",
      "Epoch 10526/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1220496115.3503 - val_loss: 1270685191.8904\n",
      "Epoch 10527/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1220467723.0215 - val_loss: 1272582051.6530\n",
      "Epoch 10528/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1220492248.6106 - val_loss: 1270612695.9635\n",
      "Epoch 10529/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1220227052.3366 - val_loss: 1271474366.8311\n",
      "Epoch 10530/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1220313622.4188 - val_loss: 1271674474.0822\n",
      "Epoch 10531/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1220625798.2622 - val_loss: 1270363192.4018\n",
      "Epoch 10532/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1220385637.1977 - val_loss: 1271790011.3242\n",
      "Epoch 10533/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1220207968.5636 - val_loss: 1271941629.6621\n",
      "Epoch 10534/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1220354733.4638 - val_loss: 1270486334.2466\n",
      "Epoch 10535/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1220210419.8513 - val_loss: 1270995101.8082\n",
      "Epoch 10536/15000\n",
      "1022/1022 [==============================] - 0s 90us/step - loss: 1220311782.0744 - val_loss: 1271986985.7900\n",
      "Epoch 10537/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1220107399.2642 - val_loss: 1270528812.4201\n",
      "Epoch 10538/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1220168806.3562 - val_loss: 1271595076.9680\n",
      "Epoch 10539/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1220445964.0235 - val_loss: 1272147191.8174\n",
      "Epoch 10540/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1219874859.5851 - val_loss: 1271430465.7534\n",
      "Epoch 10541/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1219848768.5010 - val_loss: 1271264259.5068\n",
      "Epoch 10542/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1220200981.0411 - val_loss: 1271208556.4201\n",
      "Epoch 10543/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1220216122.3014 - val_loss: 1272088631.2329\n",
      "Epoch 10544/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1220066983.8278 - val_loss: 1271009697.3151\n",
      "Epoch 10545/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1220002950.8258 - val_loss: 1270547123.1416\n",
      "Epoch 10546/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1220015711.6869 - val_loss: 1269902535.3059\n",
      "Epoch 10547/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1221359984.9706 - val_loss: 1272090073.4247\n",
      "Epoch 10548/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1220446150.7632 - val_loss: 1271293696.0000\n",
      "Epoch 10549/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1220753753.8004 - val_loss: 1271839303.5982\n",
      "Epoch 10550/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1219896475.1781 - val_loss: 1271534924.8584\n",
      "Epoch 10551/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1219984503.7339 - val_loss: 1271105637.6986\n",
      "Epoch 10552/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1219985564.6184 - val_loss: 1271215743.4155\n",
      "Epoch 10553/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1220638887.7025 - val_loss: 1269382295.6712\n",
      "Epoch 10554/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1220266274.0665 - val_loss: 1270962038.9406\n",
      "Epoch 10555/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1219825043.0372 - val_loss: 1271372656.8037\n",
      "Epoch 10556/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1219911184.2818 - val_loss: 1270456369.3881\n",
      "Epoch 10557/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1220069278.5597 - val_loss: 1271675330.0457\n",
      "Epoch 10558/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1219765567.3738 - val_loss: 1270987908.0913\n",
      "Epoch 10559/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1219905106.1605 - val_loss: 1270404741.5525\n",
      "Epoch 10560/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1219771377.0959 - val_loss: 1270767511.3790\n",
      "Epoch 10561/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1219689903.5303 - val_loss: 1271410603.5434\n",
      "Epoch 10562/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1220097745.1585 - val_loss: 1271186274.7763\n",
      "Epoch 10563/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1220197972.7906 - val_loss: 1271993371.7626\n",
      "Epoch 10564/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1219634463.1233 - val_loss: 1271485675.8356\n",
      "Epoch 10565/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1219867034.8023 - val_loss: 1271375270.8676\n",
      "Epoch 10566/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1220074669.2133 - val_loss: 1270758349.4429\n",
      "Epoch 10567/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1219947009.3777 - val_loss: 1270920515.2146\n",
      "Epoch 10568/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1220215031.0450 - val_loss: 1270090853.9909\n",
      "Epoch 10569/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1220636291.1311 - val_loss: 1272680974.9041\n",
      "Epoch 10570/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1221048055.3581 - val_loss: 1269464086.2100\n",
      "Epoch 10571/15000\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 1219609144.2348 - val_loss: 1271337744.3653\n",
      "Epoch 10572/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1219787084.2740 - val_loss: 1271459854.0274\n",
      "Epoch 10573/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1219878032.0313 - val_loss: 1270456877.0046\n",
      "Epoch 10574/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1219692866.6301 - val_loss: 1271285790.1005\n",
      "Epoch 10575/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 33us/step - loss: 1219863100.6184 - val_loss: 1271922179.2146\n",
      "Epoch 10576/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1220323737.6751 - val_loss: 1272234147.9452\n",
      "Epoch 10577/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1219659699.5382 - val_loss: 1271477646.9041\n",
      "Epoch 10578/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1220364638.8102 - val_loss: 1270243534.0274\n",
      "Epoch 10579/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1219782437.1977 - val_loss: 1270684954.0091\n",
      "Epoch 10580/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1219729181.6830 - val_loss: 1270562254.9041\n",
      "Epoch 10581/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1219546093.9022 - val_loss: 1270773821.6621\n",
      "Epoch 10582/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1219649902.9667 - val_loss: 1270578271.2694\n",
      "Epoch 10583/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1220754119.2642 - val_loss: 1272621543.7443\n",
      "Epoch 10584/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1219494129.9726 - val_loss: 1271441336.9863\n",
      "Epoch 10585/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1219620148.1018 - val_loss: 1270408707.5068\n",
      "Epoch 10586/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1219703298.0039 - val_loss: 1270097481.3516\n",
      "Epoch 10587/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1219610769.2838 - val_loss: 1270200763.3242\n",
      "Epoch 10588/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1219430943.7182 - val_loss: 1271017127.7443\n",
      "Epoch 10589/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1219758993.8474 - val_loss: 1271683798.2100\n",
      "Epoch 10590/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1219590995.6008 - val_loss: 1271333487.3425\n",
      "Epoch 10591/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1219678654.9354 - val_loss: 1271805497.2785\n",
      "Epoch 10592/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1219434167.3581 - val_loss: 1271445515.3973\n",
      "Epoch 10593/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1219909035.2094 - val_loss: 1271727030.3562\n",
      "Epoch 10594/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1219394916.8219 - val_loss: 1269911038.8311\n",
      "Epoch 10595/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1220410237.7456 - val_loss: 1268426622.2466\n",
      "Epoch 10596/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1219176463.2798 - val_loss: 1270527739.9087\n",
      "Epoch 10597/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1220113879.6712 - val_loss: 1271999130.0091\n",
      "Epoch 10598/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1219588961.6908 - val_loss: 1271531114.6667\n",
      "Epoch 10599/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1219639031.9843 - val_loss: 1269762076.9315\n",
      "Epoch 10600/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1219456470.2309 - val_loss: 1271173661.2237\n",
      "Epoch 10601/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1219782140.2427 - val_loss: 1271631976.3288\n",
      "Epoch 10602/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1219548286.7476 - val_loss: 1270620091.0320\n",
      "Epoch 10603/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1219970008.4227 - val_loss: 1269580594.2648\n",
      "Epoch 10604/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1219389615.8434 - val_loss: 1271508437.0411\n",
      "Epoch 10605/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1219928673.1898 - val_loss: 1269875189.1872\n",
      "Epoch 10606/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1219642627.7573 - val_loss: 1271762801.6804\n",
      "Epoch 10607/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1219456255.5616 - val_loss: 1270877497.2785\n",
      "Epoch 10608/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1219357830.3249 - val_loss: 1271656343.9635\n",
      "Epoch 10609/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1219287335.8278 - val_loss: 1270992511.4155\n",
      "Epoch 10610/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1219518819.1937 - val_loss: 1271749872.5114\n",
      "Epoch 10611/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1219694520.2348 - val_loss: 1270070368.7306\n",
      "Epoch 10612/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1220118833.4090 - val_loss: 1269175284.3105\n",
      "Epoch 10613/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1219008796.0548 - val_loss: 1271016350.9772\n",
      "Epoch 10614/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1219802376.7671 - val_loss: 1271334887.1598\n",
      "Epoch 10615/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1219580625.7847 - val_loss: 1271583644.9315\n",
      "Epoch 10616/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1219700464.8454 - val_loss: 1271378538.3744\n",
      "Epoch 10617/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1219379881.6438 - val_loss: 1270896587.6895\n",
      "Epoch 10618/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1219362821.7613 - val_loss: 1270868850.5571\n",
      "Epoch 10619/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1219586760.6419 - val_loss: 1271829588.4566\n",
      "Epoch 10620/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1219515713.0020 - val_loss: 1271412655.6347\n",
      "Epoch 10621/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1219326600.9550 - val_loss: 1270889099.6895\n",
      "Epoch 10622/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1220052613.7613 - val_loss: 1268281447.1598\n",
      "Epoch 10623/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1219683517.2133 - val_loss: 1271603737.4247\n",
      "Epoch 10624/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1219174494.4344 - val_loss: 1270638600.4749\n",
      "Epoch 10625/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1220580618.1448 - val_loss: 1270043368.3288\n",
      "Epoch 10626/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1219193085.5577 - val_loss: 1270257396.0183\n",
      "Epoch 10627/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1219515874.6928 - val_loss: 1271791100.7854\n",
      "Epoch 10628/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1219579299.1937 - val_loss: 1270190071.8174\n",
      "Epoch 10629/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1219184984.9863 - val_loss: 1269825995.3973\n",
      "Epoch 10630/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1219440505.9883 - val_loss: 1271161652.0183\n",
      "Epoch 10631/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1219431580.6184 - val_loss: 1271202047.1233\n",
      "Epoch 10632/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1219528165.5734 - val_loss: 1269716403.4338\n",
      "Epoch 10633/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1220004467.6008 - val_loss: 1271236344.6941\n",
      "Epoch 10634/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1219074421.4168 - val_loss: 1271088938.0822\n",
      "Epoch 10635/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1219333939.2250 - val_loss: 1271418877.0776\n",
      "Epoch 10636/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1219426090.8337 - val_loss: 1270959488.5845\n",
      "Epoch 10637/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1219197963.0215 - val_loss: 1270012874.2283\n",
      "Epoch 10638/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1219186471.2016 - val_loss: 1270264040.0365\n",
      "Epoch 10639/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1219087081.2055 - val_loss: 1271141424.2192\n",
      "Epoch 10640/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1219275262.3718 - val_loss: 1271078691.3607\n",
      "Epoch 10641/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1219454094.6536 - val_loss: 1269454472.4749\n",
      "Epoch 10642/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1219349212.6810 - val_loss: 1270087129.7169\n",
      "Epoch 10643/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1219019581.6204 - val_loss: 1269890220.1279\n",
      "Epoch 10644/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1219036685.5264 - val_loss: 1270395675.7626\n",
      "Epoch 10645/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1219259815.8278 - val_loss: 1269409160.4749\n",
      "Epoch 10646/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1219815261.5577 - val_loss: 1270911018.9589\n",
      "Epoch 10647/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1219088566.6067 - val_loss: 1270573983.5616\n",
      "Epoch 10648/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1219268068.3209 - val_loss: 1270266519.6712\n",
      "Epoch 10649/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1219652454.7006 - val_loss: 1268677998.7580\n",
      "Epoch 10650/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1219404522.4579 - val_loss: 1268685991.1598\n",
      "Epoch 10651/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1220112138.8963 - val_loss: 1271261142.5023\n",
      "Epoch 10652/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1219269422.6536 - val_loss: 1270968400.0731\n",
      "Epoch 10653/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1219688566.7319 - val_loss: 1269186109.3699\n",
      "Epoch 10654/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1218963986.7867 - val_loss: 1270529358.9041\n",
      "Epoch 10655/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1219489893.1350 - val_loss: 1271569669.2603\n",
      "Epoch 10656/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1219282039.6712 - val_loss: 1270456772.9680\n",
      "Epoch 10657/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1218988617.3933 - val_loss: 1269752509.9543\n",
      "Epoch 10658/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1219067064.6106 - val_loss: 1271642812.7854\n",
      "Epoch 10659/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1219061180.8063 - val_loss: 1271686377.4977\n",
      "Epoch 10660/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1219345411.7573 - val_loss: 1271790445.2968\n",
      "Epoch 10661/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1219198605.1507 - val_loss: 1269122731.5434\n",
      "Epoch 10662/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1219341285.4481 - val_loss: 1268686293.0411\n",
      "Epoch 10663/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1218793577.7065 - val_loss: 1270679561.0594\n",
      "Epoch 10664/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1219493610.3953 - val_loss: 1269543821.1507\n",
      "Epoch 10665/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1219886796.1487 - val_loss: 1271907976.4749\n",
      "Epoch 10666/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1218844755.7886 - val_loss: 1270069910.2100\n",
      "Epoch 10667/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1218923449.6751 - val_loss: 1269512932.5297\n",
      "Epoch 10668/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1219098604.8376 - val_loss: 1271296388.6758\n",
      "Epoch 10669/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1218719158.1057 - val_loss: 1271203960.4018\n",
      "Epoch 10670/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1218983174.0117 - val_loss: 1270193390.7580\n",
      "Epoch 10671/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1219038488.5479 - val_loss: 1269308332.1279\n",
      "Epoch 10672/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1219313087.3738 - val_loss: 1269903461.4064\n",
      "Epoch 10673/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1219079979.8356 - val_loss: 1270811744.4384\n",
      "Epoch 10674/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1218801257.8317 - val_loss: 1269681548.5662\n",
      "Epoch 10675/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1218871897.4247 - val_loss: 1269305211.9087\n",
      "Epoch 10676/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1219397167.0920 - val_loss: 1269092626.9954\n",
      "Epoch 10677/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1219235292.8063 - val_loss: 1271958915.5068\n",
      "Epoch 10678/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1218976126.7476 - val_loss: 1270664278.7945\n",
      "Epoch 10679/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1218796253.5577 - val_loss: 1271284043.9817\n",
      "Epoch 10680/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1219088573.8708 - val_loss: 1270436556.8584\n",
      "Epoch 10681/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1218832080.5323 - val_loss: 1271091439.3425\n",
      "Epoch 10682/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1218766584.8611 - val_loss: 1271129108.4566\n",
      "Epoch 10683/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1219076054.4188 - val_loss: 1269186997.1872\n",
      "Epoch 10684/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1218762174.4971 - val_loss: 1269410524.6393\n",
      "Epoch 10685/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1218990780.1174 - val_loss: 1271048552.3288\n",
      "Epoch 10686/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1218537241.0489 - val_loss: 1270398072.9863\n",
      "Epoch 10687/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1218697408.2505 - val_loss: 1270981974.2100\n",
      "Epoch 10688/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1218944065.3777 - val_loss: 1270100847.3425\n",
      "Epoch 10689/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1218715049.3307 - val_loss: 1269525345.6073\n",
      "Epoch 10690/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1219392393.8943 - val_loss: 1270975858.8493\n",
      "Epoch 10691/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1218802803.5382 - val_loss: 1269448410.5936\n",
      "Epoch 10692/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1218898434.3796 - val_loss: 1268724345.8630\n",
      "Epoch 10693/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1218438464.0000 - val_loss: 1270040324.3836\n",
      "Epoch 10694/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1219244262.9511 - val_loss: 1271590859.9817\n",
      "Epoch 10695/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1218711835.1781 - val_loss: 1270047523.6530\n",
      "Epoch 10696/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1218746501.0724 - val_loss: 1270006663.8904\n",
      "Epoch 10697/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1218657145.3620 - val_loss: 1269911109.2603\n",
      "Epoch 10698/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1219642275.9452 - val_loss: 1270132620.5662\n",
      "Epoch 10699/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1218664057.7378 - val_loss: 1269353758.9772\n",
      "Epoch 10700/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1218759224.2348 - val_loss: 1269198497.8995\n",
      "Epoch 10701/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1218708608.7515 - val_loss: 1271192045.0046\n",
      "Epoch 10702/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1218433165.2759 - val_loss: 1270194296.6941\n",
      "Epoch 10703/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1218809332.2270 - val_loss: 1269159162.7397\n",
      "Epoch 10704/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1219166824.0783 - val_loss: 1268837685.1872\n",
      "Epoch 10705/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1218967575.0450 - val_loss: 1270615738.4475\n",
      "Epoch 10706/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1218673420.2740 - val_loss: 1269315613.8082\n",
      "Epoch 10707/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1218291561.2055 - val_loss: 1270082633.9361\n",
      "Epoch 10708/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1218281876.6654 - val_loss: 1269728696.6941\n",
      "Epoch 10709/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1218886057.9569 - val_loss: 1270865623.0868\n",
      "Epoch 10710/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1218979002.7397 - val_loss: 1269758371.0685\n",
      "Epoch 10711/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1218702629.9491 - val_loss: 1270419419.4703\n",
      "Epoch 10712/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1218514135.5460 - val_loss: 1269804832.4384\n",
      "Epoch 10713/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1218566100.9159 - val_loss: 1268937308.9315\n",
      "Epoch 10714/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1218458884.0078 - val_loss: 1271233388.1279\n",
      "Epoch 10715/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1218601833.2055 - val_loss: 1270557477.4064\n",
      "Epoch 10716/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1218487628.9628 - val_loss: 1269470694.2831\n",
      "Epoch 10717/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1218739611.3033 - val_loss: 1271091519.1233\n",
      "Epoch 10718/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1218201897.7065 - val_loss: 1270027323.0320\n",
      "Epoch 10719/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1218851459.2564 - val_loss: 1268449779.4338\n",
      "Epoch 10720/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1218399216.5949 - val_loss: 1269042144.1461\n",
      "Epoch 10721/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1218384228.4462 - val_loss: 1270099823.3425\n",
      "Epoch 10722/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1218744833.2524 - val_loss: 1269252504.5479\n",
      "Epoch 10723/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1218219697.3464 - val_loss: 1269884076.7123\n",
      "Epoch 10724/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1218470084.3836 - val_loss: 1271075016.1826\n",
      "Epoch 10725/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1218776608.8141 - val_loss: 1271126177.0228\n",
      "Epoch 10726/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1218371349.9178 - val_loss: 1269161401.5708\n",
      "Epoch 10727/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1218856800.1879 - val_loss: 1270566829.2968\n",
      "Epoch 10728/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1218157175.1076 - val_loss: 1269438598.1370\n",
      "Epoch 10729/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1218192378.1135 - val_loss: 1270206208.2922\n",
      "Epoch 10730/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1218765957.1350 - val_loss: 1268261649.2420\n",
      "Epoch 10731/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1218219795.7886 - val_loss: 1269055832.2557\n",
      "Epoch 10732/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1218421183.4364 - val_loss: 1269780847.0502\n",
      "Epoch 10733/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1218135341.7143 - val_loss: 1269357658.3014\n",
      "Epoch 10734/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1218186630.2622 - val_loss: 1269425160.7671\n",
      "Epoch 10735/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1218847446.9198 - val_loss: 1269731873.8995\n",
      "Epoch 10736/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1218489134.8415 - val_loss: 1269010827.9817\n",
      "Epoch 10737/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1218399033.2368 - val_loss: 1270631607.2329\n",
      "Epoch 10738/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1218330142.5597 - val_loss: 1271342790.7215\n",
      "Epoch 10739/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1218186522.0509 - val_loss: 1269089145.2785\n",
      "Epoch 10740/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1218286939.9295 - val_loss: 1270588286.2466\n",
      "Epoch 10741/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1218622161.9100 - val_loss: 1268116605.6621\n",
      "Epoch 10742/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1217806333.8082 - val_loss: 1269467291.4703\n",
      "Epoch 10743/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1218250397.5577 - val_loss: 1270043548.6393\n",
      "Epoch 10744/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1218081640.7045 - val_loss: 1269481597.6621\n",
      "Epoch 10745/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1218518901.2290 - val_loss: 1270906741.1872\n",
      "Epoch 10746/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1218099530.3953 - val_loss: 1269761334.9406\n",
      "Epoch 10747/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1218999859.0998 - val_loss: 1270211504.8037\n",
      "Epoch 10748/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1218024864.8141 - val_loss: 1269986901.6256\n",
      "Epoch 10749/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1218263591.5773 - val_loss: 1268649234.9954\n",
      "Epoch 10750/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1217968144.2818 - val_loss: 1269912488.9132\n",
      "Epoch 10751/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1218010269.8708 - val_loss: 1270049682.9954\n",
      "Epoch 10752/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1218415861.0411 - val_loss: 1268572399.9269\n",
      "Epoch 10753/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1217887602.4736 - val_loss: 1269640209.2420\n",
      "Epoch 10754/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1218051928.6732 - val_loss: 1270247813.5525\n",
      "Epoch 10755/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1218419948.7123 - val_loss: 1269111029.4795\n",
      "Epoch 10756/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1218576346.1761 - val_loss: 1270748076.4201\n",
      "Epoch 10757/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1218214478.0900 - val_loss: 1270577009.9726\n",
      "Epoch 10758/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1218468785.4090 - val_loss: 1269778809.5708\n",
      "Epoch 10759/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1218790649.8630 - val_loss: 1268698343.7443\n",
      "Epoch 10760/15000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1218193233.1585 - val_loss: 1269890465.3151\n",
      "Epoch 10761/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1217844275.6008 - val_loss: 1269549760.5845\n",
      "Epoch 10762/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1218778662.3249 - val_loss: 1270736770.0457\n",
      "Epoch 10763/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1218022746.2387 - val_loss: 1268953879.3790\n",
      "Epoch 10764/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1218287013.6360 - val_loss: 1270170427.6164\n",
      "Epoch 10765/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1217830098.6614 - val_loss: 1269637835.9817\n",
      "Epoch 10766/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1217775288.1096 - val_loss: 1269607565.7352\n",
      "Epoch 10767/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 27us/step - loss: 1218433615.1546 - val_loss: 1268462153.6438\n",
      "Epoch 10768/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1217999495.7652 - val_loss: 1268341939.7260\n",
      "Epoch 10769/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1217724820.0391 - val_loss: 1269285802.9589\n",
      "Epoch 10770/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1218952464.7828 - val_loss: 1271360142.9041\n",
      "Epoch 10771/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1218559775.8121 - val_loss: 1268317919.2694\n",
      "Epoch 10772/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1217889804.2740 - val_loss: 1268953997.7352\n",
      "Epoch 10773/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1217966455.6086 - val_loss: 1270156274.5571\n",
      "Epoch 10774/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1218128206.7789 - val_loss: 1269057446.8676\n",
      "Epoch 10775/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1218215868.6184 - val_loss: 1269871601.3881\n",
      "Epoch 10776/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1218520231.4834 - val_loss: 1269823378.9954\n",
      "Epoch 10777/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1218008537.2994 - val_loss: 1268059569.6804\n",
      "Epoch 10778/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1217939573.7299 - val_loss: 1268241288.1826\n",
      "Epoch 10779/15000\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 1217597467.5538 - val_loss: 1268983016.9132\n",
      "Epoch 10780/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1217745304.9237 - val_loss: 1270053442.9224\n",
      "Epoch 10781/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1217650497.1272 - val_loss: 1270095184.9498\n",
      "Epoch 10782/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1217895389.9335 - val_loss: 1269795604.1644\n",
      "Epoch 10783/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1218014735.9061 - val_loss: 1268106856.0365\n",
      "Epoch 10784/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1217761844.6027 - val_loss: 1269762517.0411\n",
      "Epoch 10785/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1217818978.1918 - val_loss: 1268942465.7534\n",
      "Epoch 10786/15000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1217619650.3796 - val_loss: 1269000557.2968\n",
      "Epoch 10787/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1218631631.6556 - val_loss: 1270431130.3014\n",
      "Epoch 10788/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1217994848.9393 - val_loss: 1269261978.0091\n",
      "Epoch 10789/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1218019220.7906 - val_loss: 1267853639.5982\n",
      "Epoch 10790/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1218135296.0000 - val_loss: 1269346711.0868\n",
      "Epoch 10791/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1217884683.2094 - val_loss: 1270107102.9772\n",
      "Epoch 10792/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1217625567.6869 - val_loss: 1269385564.0548\n",
      "Epoch 10793/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1217573062.1370 - val_loss: 1269862443.8356\n",
      "Epoch 10794/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1217712526.0274 - val_loss: 1268969979.3242\n",
      "Epoch 10795/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1217684924.8689 - val_loss: 1269452132.2374\n",
      "Epoch 10796/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1217790473.0176 - val_loss: 1268727823.1963\n",
      "Epoch 10797/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1218004752.3444 - val_loss: 1269671472.2192\n",
      "Epoch 10798/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1217934743.7965 - val_loss: 1269713223.8904\n",
      "Epoch 10799/15000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1217477724.8063 - val_loss: 1269100619.9817\n",
      "Epoch 10800/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1217987083.2094 - val_loss: 1267791550.8311\n",
      "Epoch 10801/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1217726948.1957 - val_loss: 1269622986.5205\n",
      "Epoch 10802/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1217578234.9902 - val_loss: 1268510361.1324\n",
      "Epoch 10803/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1217759242.2701 - val_loss: 1270359998.8311\n",
      "Epoch 10804/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1217744271.7808 - val_loss: 1267820646.5753\n",
      "Epoch 10805/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1217520291.1937 - val_loss: 1269513796.3836\n",
      "Epoch 10806/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1217740171.4599 - val_loss: 1269262184.9132\n",
      "Epoch 10807/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1217691634.9746 - val_loss: 1267900259.9452\n",
      "Epoch 10808/15000\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 1217613583.0294 - val_loss: 1269201583.6347\n",
      "Epoch 10809/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1217764427.6477 - val_loss: 1270530935.8174\n",
      "Epoch 10810/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1218165802.5832 - val_loss: 1267812888.5479\n",
      "Epoch 10811/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1217969104.4697 - val_loss: 1270220957.8082\n",
      "Epoch 10812/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1217815739.8669 - val_loss: 1270448872.6210\n",
      "Epoch 10813/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1217522157.7143 - val_loss: 1268908918.6484\n",
      "Epoch 10814/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1217584130.1918 - val_loss: 1268514033.6804\n",
      "Epoch 10815/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1217702697.4560 - val_loss: 1270193696.4384\n",
      "Epoch 10816/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1217415000.6732 - val_loss: 1268754878.8311\n",
      "Epoch 10817/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1217951047.1389 - val_loss: 1268655257.4247\n",
      "Epoch 10818/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1217379701.6047 - val_loss: 1269717765.2603\n",
      "Epoch 10819/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1217496262.1370 - val_loss: 1270245323.9817\n",
      "Epoch 10820/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1217350118.4501 - val_loss: 1269817851.3242\n",
      "Epoch 10821/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1218249400.1722 - val_loss: 1268258166.9406\n",
      "Epoch 10822/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1217966461.2446 - val_loss: 1270105165.7352\n",
      "Epoch 10823/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1217824250.8650 - val_loss: 1268266908.9315\n",
      "Epoch 10824/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1217480825.2368 - val_loss: 1268046888.9132\n",
      "Epoch 10825/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1217389883.6164 - val_loss: 1268008520.7671\n",
      "Epoch 10826/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1217318962.5988 - val_loss: 1269265085.3699\n",
      "Epoch 10827/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1217283833.9883 - val_loss: 1268996695.9635\n",
      "Epoch 10828/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1217277188.1957 - val_loss: 1268684352.0000\n",
      "Epoch 10829/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1217459423.9374 - val_loss: 1269243622.8676\n",
      "Epoch 10830/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1217754415.7182 - val_loss: 1269197986.1918\n",
      "Epoch 10831/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 33us/step - loss: 1217389618.8493 - val_loss: 1268875079.8904\n",
      "Epoch 10832/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1217389827.6947 - val_loss: 1270045975.9635\n",
      "Epoch 10833/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1217691773.6204 - val_loss: 1269911278.4658\n",
      "Epoch 10834/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1217409647.5930 - val_loss: 1270067799.9635\n",
      "Epoch 10835/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1217288006.2622 - val_loss: 1268564394.6667\n",
      "Epoch 10836/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1217442355.3503 - val_loss: 1269013629.6621\n",
      "Epoch 10837/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1217282422.6067 - val_loss: 1268239883.9817\n",
      "Epoch 10838/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1218670720.8141 - val_loss: 1270066409.2055\n",
      "Epoch 10839/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1217243873.1898 - val_loss: 1269034317.1507\n",
      "Epoch 10840/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1217286465.3777 - val_loss: 1268391575.6712\n",
      "Epoch 10841/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1217679196.1800 - val_loss: 1269561235.2877\n",
      "Epoch 10842/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1217090630.5753 - val_loss: 1268597255.0137\n",
      "Epoch 10843/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1217327007.1233 - val_loss: 1268055062.5023\n",
      "Epoch 10844/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1217720520.1409 - val_loss: 1269905154.0457\n",
      "Epoch 10845/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1217161177.4873 - val_loss: 1268101537.6073\n",
      "Epoch 10846/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1217069850.1761 - val_loss: 1268039818.2283\n",
      "Epoch 10847/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1217273992.5166 - val_loss: 1267732681.0594\n",
      "Epoch 10848/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1217586923.3346 - val_loss: 1269795802.5936\n",
      "Epoch 10849/15000\n",
      "1022/1022 [==============================] - 0s 90us/step - loss: 1218399118.1526 - val_loss: 1267867745.3151\n",
      "Epoch 10850/15000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1217490929.7221 - val_loss: 1270093407.5616\n",
      "Epoch 10851/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1217235670.1683 - val_loss: 1269149272.5479\n",
      "Epoch 10852/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1217139113.6438 - val_loss: 1268971536.0731\n",
      "Epoch 10853/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1217323955.9765 - val_loss: 1268504525.4429\n",
      "Epoch 10854/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1217023982.0274 - val_loss: 1268563341.1507\n",
      "Epoch 10855/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1217172351.6243 - val_loss: 1267725226.9589\n",
      "Epoch 10856/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1217163497.2055 - val_loss: 1269668792.4018\n",
      "Epoch 10857/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1216999530.9589 - val_loss: 1269054175.5616\n",
      "Epoch 10858/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1217338582.1683 - val_loss: 1269844909.2968\n",
      "Epoch 10859/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1216996597.1037 - val_loss: 1268518253.5890\n",
      "Epoch 10860/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1217222599.0137 - val_loss: 1267502344.7671\n",
      "Epoch 10861/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1217037903.7808 - val_loss: 1268142423.0868\n",
      "Epoch 10862/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1216980553.1429 - val_loss: 1268696829.0776\n",
      "Epoch 10863/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1217138595.5695 - val_loss: 1268620581.6986\n",
      "Epoch 10864/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1216853515.1468 - val_loss: 1268382562.4840\n",
      "Epoch 10865/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1217179382.9824 - val_loss: 1269538887.5982\n",
      "Epoch 10866/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1217080034.6928 - val_loss: 1268044857.2785\n",
      "Epoch 10867/15000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1217075256.4853 - val_loss: 1269476642.7763\n",
      "Epoch 10868/15000\n",
      "1022/1022 [==============================] - 0s 65us/step - loss: 1216830169.4247 - val_loss: 1268228583.1598\n",
      "Epoch 10869/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1217455970.4423 - val_loss: 1268919687.3059\n",
      "Epoch 10870/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1217249374.9354 - val_loss: 1269264653.1507\n",
      "Epoch 10871/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1216769181.4325 - val_loss: 1268830739.8721\n",
      "Epoch 10872/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1216993775.5930 - val_loss: 1268799484.4932\n",
      "Epoch 10873/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1216803550.3092 - val_loss: 1268631445.6256\n",
      "Epoch 10874/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1217262068.7280 - val_loss: 1269257966.1735\n",
      "Epoch 10875/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1216799747.1311 - val_loss: 1268340657.3881\n",
      "Epoch 10876/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1216979312.7202 - val_loss: 1269434535.1598\n",
      "Epoch 10877/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1217258525.5577 - val_loss: 1266934324.0183\n",
      "Epoch 10878/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1217190871.0450 - val_loss: 1268363407.4886\n",
      "Epoch 10879/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1216962723.0685 - val_loss: 1269177901.2968\n",
      "Epoch 10880/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1217137160.5166 - val_loss: 1267251972.3836\n",
      "Epoch 10881/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1216798037.6673 - val_loss: 1267826992.2192\n",
      "Epoch 10882/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1217392765.4951 - val_loss: 1268892241.8265\n",
      "Epoch 10883/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1217034685.4951 - val_loss: 1267909188.9680\n",
      "Epoch 10884/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1217120553.3307 - val_loss: 1267852289.4612\n",
      "Epoch 10885/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1216928481.5029 - val_loss: 1267654634.0822\n",
      "Epoch 10886/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1216920352.0626 - val_loss: 1268482183.3059\n",
      "Epoch 10887/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1217036715.0841 - val_loss: 1268842772.1644\n",
      "Epoch 10888/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1216959789.8395 - val_loss: 1269540586.6667\n",
      "Epoch 10889/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1216766826.1448 - val_loss: 1269265964.4201\n",
      "Epoch 10890/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1216733084.1800 - val_loss: 1268651711.1233\n",
      "Epoch 10891/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1216970444.9628 - val_loss: 1267143721.7900\n",
      "Epoch 10892/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1216599863.1076 - val_loss: 1268966403.5068\n",
      "Epoch 10893/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1216653821.7456 - val_loss: 1269131050.0822\n",
      "Epoch 10894/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1217432498.9746 - val_loss: 1267105620.1644\n",
      "Epoch 10895/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 29us/step - loss: 1217050230.7319 - val_loss: 1269893044.3105\n",
      "Epoch 10896/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1217125839.9061 - val_loss: 1269332469.4795\n",
      "Epoch 10897/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1216702961.9726 - val_loss: 1267711011.9452\n",
      "Epoch 10898/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1217125941.5421 - val_loss: 1268307199.1233\n",
      "Epoch 10899/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1216628390.5753 - val_loss: 1268270037.0411\n",
      "Epoch 10900/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1217707089.1585 - val_loss: 1266480435.1416\n",
      "Epoch 10901/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1216694028.3992 - val_loss: 1268828176.6575\n",
      "Epoch 10902/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1216709665.4403 - val_loss: 1268123228.0548\n",
      "Epoch 10903/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1216688830.6223 - val_loss: 1269407578.3014\n",
      "Epoch 10904/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1216728512.6262 - val_loss: 1269112011.3973\n",
      "Epoch 10905/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1216618836.6654 - val_loss: 1268571907.2146\n",
      "Epoch 10906/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1216655256.8611 - val_loss: 1268984703.4155\n",
      "Epoch 10907/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1216734405.6360 - val_loss: 1267951525.9909\n",
      "Epoch 10908/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1217450144.0626 - val_loss: 1268341468.9315\n",
      "Epoch 10909/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1216813704.9550 - val_loss: 1268742713.5708\n",
      "Epoch 10910/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1216630593.2524 - val_loss: 1268949900.2740\n",
      "Epoch 10911/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1216842552.4227 - val_loss: 1269204791.8174\n",
      "Epoch 10912/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1216453429.1037 - val_loss: 1268321255.7443\n",
      "Epoch 10913/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1216979279.9061 - val_loss: 1269222918.1370\n",
      "Epoch 10914/15000\n",
      "1022/1022 [==============================] - 0s 95us/step - loss: 1216817257.9569 - val_loss: 1267279680.0000\n",
      "Epoch 10915/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1216707543.5460 - val_loss: 1268218071.6712\n",
      "Epoch 10916/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1216710522.2387 - val_loss: 1268793724.4932\n",
      "Epoch 10917/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1216316194.5675 - val_loss: 1268389408.7306\n",
      "Epoch 10918/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1216744181.2290 - val_loss: 1266920745.7900\n",
      "Epoch 10919/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1217102243.8200 - val_loss: 1269111749.5525\n",
      "Epoch 10920/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1217304544.3131 - val_loss: 1267230398.5388\n",
      "Epoch 10921/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1216608383.4990 - val_loss: 1269137954.4840\n",
      "Epoch 10922/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1216455581.8082 - val_loss: 1267446883.6530\n",
      "Epoch 10923/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1216780496.0313 - val_loss: 1268111113.0594\n",
      "Epoch 10924/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1216360503.7965 - val_loss: 1268036752.0731\n",
      "Epoch 10925/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1216385879.1703 - val_loss: 1267343888.0731\n",
      "Epoch 10926/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1217129273.9883 - val_loss: 1267225741.1507\n",
      "Epoch 10927/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1216452044.7750 - val_loss: 1268460053.9178\n",
      "Epoch 10928/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1216466175.5616 - val_loss: 1268981510.7215\n",
      "Epoch 10929/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1216427698.4736 - val_loss: 1268503386.8858\n",
      "Epoch 10930/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1216942700.2114 - val_loss: 1267771690.6667\n",
      "Epoch 10931/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1216512676.1331 - val_loss: 1268444863.4155\n",
      "Epoch 10932/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1216557752.2348 - val_loss: 1268492457.2055\n",
      "Epoch 10933/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1216420794.9276 - val_loss: 1268693432.1096\n",
      "Epoch 10934/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1216588783.8434 - val_loss: 1267610182.4292\n",
      "Epoch 10935/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1216327000.5479 - val_loss: 1268540093.0776\n",
      "Epoch 10936/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1216742036.5401 - val_loss: 1269110958.4658\n",
      "Epoch 10937/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1216656827.8669 - val_loss: 1266742455.2329\n",
      "Epoch 10938/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1216611381.3542 - val_loss: 1269530494.2466\n",
      "Epoch 10939/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1216414379.8356 - val_loss: 1267622917.5525\n",
      "Epoch 10940/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1216201749.0411 - val_loss: 1268269140.4566\n",
      "Epoch 10941/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1216807186.5362 - val_loss: 1266782974.8311\n",
      "Epoch 10942/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1216987127.6086 - val_loss: 1269015397.6986\n",
      "Epoch 10943/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1216911705.1115 - val_loss: 1267725347.9452\n",
      "Epoch 10944/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1216215168.7515 - val_loss: 1268720247.2329\n",
      "Epoch 10945/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1216447365.7613 - val_loss: 1269007121.2420\n",
      "Epoch 10946/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1216221163.7104 - val_loss: 1268334074.4475\n",
      "Epoch 10947/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1216435522.8806 - val_loss: 1267626289.3881\n",
      "Epoch 10948/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1216418176.8767 - val_loss: 1266783482.7397\n",
      "Epoch 10949/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1216191249.9100 - val_loss: 1267884447.2694\n",
      "Epoch 10950/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1216827606.4188 - val_loss: 1266306176.2922\n",
      "Epoch 10951/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1216388214.2935 - val_loss: 1268164529.9726\n",
      "Epoch 10952/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1216693101.0881 - val_loss: 1266775686.7215\n",
      "Epoch 10953/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1217038515.4755 - val_loss: 1269724425.3516\n",
      "Epoch 10954/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1216041590.4814 - val_loss: 1268980065.6073\n",
      "Epoch 10955/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1216772294.3875 - val_loss: 1270120363.5434\n",
      "Epoch 10956/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1216146647.6712 - val_loss: 1268813553.6804\n",
      "Epoch 10957/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1216150395.1155 - val_loss: 1267475083.1050\n",
      "Epoch 10958/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1216480910.5284 - val_loss: 1267438034.9954\n",
      "Epoch 10959/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1216370386.7867 - val_loss: 1268963497.4977\n",
      "Epoch 10960/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1216132434.4110 - val_loss: 1267855952.9498\n",
      "Epoch 10961/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1216652641.6908 - val_loss: 1267252257.3151\n",
      "Epoch 10962/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1216981202.7867 - val_loss: 1267038087.0137\n",
      "Epoch 10963/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1216320851.1624 - val_loss: 1268712401.8265\n",
      "Epoch 10964/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1216278322.5988 - val_loss: 1267309301.4795\n",
      "Epoch 10965/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1216355189.2290 - val_loss: 1269508755.5799\n",
      "Epoch 10966/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1216032803.9452 - val_loss: 1267565927.1598\n",
      "Epoch 10967/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1216122505.0176 - val_loss: 1268569482.8128\n",
      "Epoch 10968/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1216211307.7104 - val_loss: 1267878987.6895\n",
      "Epoch 10969/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1216311481.2368 - val_loss: 1267146268.6393\n",
      "Epoch 10970/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1216181633.7534 - val_loss: 1267979745.6073\n",
      "Epoch 10971/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1216435825.7847 - val_loss: 1269549354.0822\n",
      "Epoch 10972/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1216454234.6771 - val_loss: 1268891111.7443\n",
      "Epoch 10973/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1216061267.9139 - val_loss: 1269047536.5114\n",
      "Epoch 10974/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1216151649.6908 - val_loss: 1268946099.4338\n",
      "Epoch 10975/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1215778395.9295 - val_loss: 1268091671.0868\n",
      "Epoch 10976/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1216120320.1879 - val_loss: 1267361447.1598\n",
      "Epoch 10977/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1216296944.3444 - val_loss: 1267709176.6941\n",
      "Epoch 10978/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1215857707.3346 - val_loss: 1267599932.7854\n",
      "Epoch 10979/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1216233817.5499 - val_loss: 1269009448.9132\n",
      "Epoch 10980/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1216109996.3366 - val_loss: 1266902150.4292\n",
      "Epoch 10981/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1215905541.1350 - val_loss: 1267078137.5708\n",
      "Epoch 10982/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1216117227.9609 - val_loss: 1269162244.3836\n",
      "Epoch 10983/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1216977462.7319 - val_loss: 1267234864.5114\n",
      "Epoch 10984/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1216177624.6732 - val_loss: 1267352534.7945\n",
      "Epoch 10985/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1215860736.6262 - val_loss: 1268699539.2877\n",
      "Epoch 10986/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1216061549.9022 - val_loss: 1268198355.2877\n",
      "Epoch 10987/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1215764983.7339 - val_loss: 1268673894.5753\n",
      "Epoch 10988/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1215967827.1624 - val_loss: 1267372491.6895\n",
      "Epoch 10989/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1216184326.7632 - val_loss: 1268052351.7078\n",
      "Epoch 10990/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1216050743.3581 - val_loss: 1267582522.1553\n",
      "Epoch 10991/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1215894443.9609 - val_loss: 1267746150.8676\n",
      "Epoch 10992/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1215729657.2368 - val_loss: 1268579646.8311\n",
      "Epoch 10993/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1215891485.5577 - val_loss: 1268506126.6119\n",
      "Epoch 10994/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1215790655.1233 - val_loss: 1267844401.6804\n",
      "Epoch 10995/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1216165776.5323 - val_loss: 1269099886.1735\n",
      "Epoch 10996/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1215855801.8630 - val_loss: 1268393150.5388\n",
      "Epoch 10997/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1215793844.1018 - val_loss: 1267333084.9315\n",
      "Epoch 10998/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1215758107.6791 - val_loss: 1268363685.9909\n",
      "Epoch 10999/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1215664801.6908 - val_loss: 1268036396.4201\n",
      "Epoch 11000/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1215902546.7867 - val_loss: 1268168956.4932\n",
      "Epoch 11001/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1215973839.5303 - val_loss: 1267623276.1279\n",
      "Epoch 11002/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1215752855.0450 - val_loss: 1267704631.8174\n",
      "Epoch 11003/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1215681294.7789 - val_loss: 1267597771.9817\n",
      "Epoch 11004/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1215648722.6614 - val_loss: 1267811031.6712\n",
      "Epoch 11005/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1215933164.0861 - val_loss: 1267559375.1963\n",
      "Epoch 11006/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1215985101.8708 - val_loss: 1267149593.7169\n",
      "Epoch 11007/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1216449149.7456 - val_loss: 1269903507.5799\n",
      "Epoch 11008/15000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1215850533.8865 - val_loss: 1268177944.5479\n",
      "Epoch 11009/15000\n",
      "1022/1022 [==============================] - 0s 77us/step - loss: 1215698203.0528 - val_loss: 1267030265.2785\n",
      "Epoch 11010/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1215658442.6458 - val_loss: 1268041488.6575\n",
      "Epoch 11011/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1215721409.6282 - val_loss: 1268651733.9178\n",
      "Epoch 11012/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1215800688.2192 - val_loss: 1267721092.9680\n",
      "Epoch 11013/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1215806837.9804 - val_loss: 1267372267.8356\n",
      "Epoch 11014/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1215858024.4540 - val_loss: 1266967704.5479\n",
      "Epoch 11015/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1215642955.9609 - val_loss: 1268386537.7900\n",
      "Epoch 11016/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1215678649.9883 - val_loss: 1268343104.5845\n",
      "Epoch 11017/15000\n",
      "1022/1022 [==============================] - 0s 24us/step - loss: 1215612209.0959 - val_loss: 1268161710.1735\n",
      "Epoch 11018/15000\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 1215734568.3288 - val_loss: 1267322593.6073\n",
      "Epoch 11019/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1215581474.1918 - val_loss: 1268051598.6119\n",
      "Epoch 11020/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1215940707.1937 - val_loss: 1267655486.8311\n",
      "Epoch 11021/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1216117296.7828 - val_loss: 1266726042.0091\n",
      "Epoch 11022/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1216676821.1663 - val_loss: 1269265991.3059\n",
      "Epoch 11023/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 39us/step - loss: 1215993127.7025 - val_loss: 1267959396.2374\n",
      "Epoch 11024/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1215963848.5166 - val_loss: 1269131803.1781\n",
      "Epoch 11025/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1215974183.9530 - val_loss: 1266969310.9772\n",
      "Epoch 11026/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1215631943.0137 - val_loss: 1267971508.8950\n",
      "Epoch 11027/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1215591226.9902 - val_loss: 1267257286.4292\n",
      "Epoch 11028/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1215865440.8141 - val_loss: 1267076124.9315\n",
      "Epoch 11029/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1216257002.5832 - val_loss: 1268966938.8858\n",
      "Epoch 11030/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1216186090.2074 - val_loss: 1266425886.3927\n",
      "Epoch 11031/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1215378474.3953 - val_loss: 1267596878.6119\n",
      "Epoch 11032/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1215783902.9354 - val_loss: 1266783745.7534\n",
      "Epoch 11033/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1215895694.7789 - val_loss: 1268030470.1370\n",
      "Epoch 11034/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1215883215.4051 - val_loss: 1269208777.9361\n",
      "Epoch 11035/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1215365959.0137 - val_loss: 1268330111.7078\n",
      "Epoch 11036/15000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1215775114.6458 - val_loss: 1268111915.5434\n",
      "Epoch 11037/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1215519715.5068 - val_loss: 1267348809.9361\n",
      "Epoch 11038/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1216037459.6634 - val_loss: 1269155740.0548\n",
      "Epoch 11039/15000\n",
      "1022/1022 [==============================] - 0s 102us/step - loss: 1215303116.2114 - val_loss: 1267440947.7260\n",
      "Epoch 11040/15000\n",
      "1022/1022 [==============================] - 0s 66us/step - loss: 1215573877.2290 - val_loss: 1267632291.3607\n",
      "Epoch 11041/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1215469817.7378 - val_loss: 1266765841.2420\n",
      "Epoch 11042/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1215489253.4481 - val_loss: 1266319731.4338\n",
      "Epoch 11043/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1215306750.3718 - val_loss: 1267971117.5890\n",
      "Epoch 11044/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1215638216.8924 - val_loss: 1266987147.1050\n",
      "Epoch 11045/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1215292351.8748 - val_loss: 1268388024.9863\n",
      "Epoch 11046/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1215785787.8669 - val_loss: 1266910166.2100\n",
      "Epoch 11047/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1215532202.8337 - val_loss: 1268405977.4247\n",
      "Epoch 11048/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1215587919.4051 - val_loss: 1268875198.5388\n",
      "Epoch 11049/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1215489350.7632 - val_loss: 1267345392.5114\n",
      "Epoch 11050/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1215598677.6673 - val_loss: 1268056724.4566\n",
      "Epoch 11051/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1215846580.7280 - val_loss: 1267177704.3288\n",
      "Epoch 11052/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1215473291.5851 - val_loss: 1268657036.8584\n",
      "Epoch 11053/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1215418413.4638 - val_loss: 1268559434.5205\n",
      "Epoch 11054/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1215509748.4775 - val_loss: 1266691854.9041\n",
      "Epoch 11055/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1215548571.6791 - val_loss: 1268233104.9498\n",
      "Epoch 11056/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1215762788.6967 - val_loss: 1266560156.0548\n",
      "Epoch 11057/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1216040102.8885 - val_loss: 1269240070.1370\n",
      "Epoch 11058/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1215244504.4227 - val_loss: 1268098989.0046\n",
      "Epoch 11059/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1215531402.7710 - val_loss: 1266981711.4886\n",
      "Epoch 11060/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1215131891.4755 - val_loss: 1267493147.7626\n",
      "Epoch 11061/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1215262304.9393 - val_loss: 1267003250.2648\n",
      "Epoch 11062/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1215263100.6184 - val_loss: 1267543116.2740\n",
      "Epoch 11063/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1215450026.8337 - val_loss: 1268793263.0502\n",
      "Epoch 11064/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1215385992.1409 - val_loss: 1267184056.6941\n",
      "Epoch 11065/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1215324934.0117 - val_loss: 1268447623.8904\n",
      "Epoch 11066/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1215323815.9530 - val_loss: 1268327831.9635\n",
      "Epoch 11067/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1215263848.0783 - val_loss: 1267794010.3014\n",
      "Epoch 11068/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1215233283.7573 - val_loss: 1267176518.1370\n",
      "Epoch 11069/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1215506774.4188 - val_loss: 1268189200.0731\n",
      "Epoch 11070/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1215230354.7867 - val_loss: 1267755001.8630\n",
      "Epoch 11071/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1215093826.2544 - val_loss: 1267667723.3973\n",
      "Epoch 11072/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1215125859.5695 - val_loss: 1267817524.0183\n",
      "Epoch 11073/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1215139949.9022 - val_loss: 1268093970.9954\n",
      "Epoch 11074/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1215142540.0235 - val_loss: 1267286015.7078\n",
      "Epoch 11075/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1215321140.9159 - val_loss: 1268444422.4292\n",
      "Epoch 11076/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1215138400.4384 - val_loss: 1266999161.5708\n",
      "Epoch 11077/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1215462392.4853 - val_loss: 1266245336.5479\n",
      "Epoch 11078/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1215020791.2329 - val_loss: 1267130779.1781\n",
      "Epoch 11079/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1215052933.5108 - val_loss: 1267911517.8082\n",
      "Epoch 11080/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1215275592.8924 - val_loss: 1267149214.9772\n",
      "Epoch 11081/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1215765483.4599 - val_loss: 1268144123.6164\n",
      "Epoch 11082/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1215799945.2055 - val_loss: 1269254671.4886\n",
      "Epoch 11083/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1215150183.4521 - val_loss: 1267670931.2877\n",
      "Epoch 11084/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1215486601.6438 - val_loss: 1267315144.7671\n",
      "Epoch 11085/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1215830495.5616 - val_loss: 1266711510.7945\n",
      "Epoch 11086/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1215552646.2622 - val_loss: 1269647597.0046\n",
      "Epoch 11087/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 63us/step - loss: 1215193082.8650 - val_loss: 1267399295.1233\n",
      "Epoch 11088/15000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1214955958.4814 - val_loss: 1267835303.1598\n",
      "Epoch 11089/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1215012703.4364 - val_loss: 1267202974.6849\n",
      "Epoch 11090/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1215943371.2720 - val_loss: 1267849319.4521\n",
      "Epoch 11091/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1214919680.2505 - val_loss: 1267845270.7945\n",
      "Epoch 11092/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1215149402.8023 - val_loss: 1267502358.5023\n",
      "Epoch 11093/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1214982282.5832 - val_loss: 1268136673.8995\n",
      "Epoch 11094/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1215211504.8454 - val_loss: 1267210718.9772\n",
      "Epoch 11095/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1215136506.8650 - val_loss: 1267835165.8082\n",
      "Epoch 11096/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1215033294.3405 - val_loss: 1267917146.5936\n",
      "Epoch 11097/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1214915334.0117 - val_loss: 1268644923.6164\n",
      "Epoch 11098/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1215025886.9354 - val_loss: 1267765800.9132\n",
      "Epoch 11099/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1214927402.2074 - val_loss: 1267913147.0320\n",
      "Epoch 11100/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1215914920.0783 - val_loss: 1265994609.3881\n",
      "Epoch 11101/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1214960509.7456 - val_loss: 1268545801.3516\n",
      "Epoch 11102/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1214771931.0528 - val_loss: 1268492833.6073\n",
      "Epoch 11103/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214949523.1624 - val_loss: 1267256117.4795\n",
      "Epoch 11104/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1215268004.3209 - val_loss: 1268884532.3105\n",
      "Epoch 11105/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1214892635.1781 - val_loss: 1267472419.6530\n",
      "Epoch 11106/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214840640.4697 - val_loss: 1267560167.7443\n",
      "Epoch 11107/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1215025064.8297 - val_loss: 1268264617.2055\n",
      "Epoch 11108/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1214974860.5245 - val_loss: 1268518610.9954\n",
      "Epoch 11109/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1215037343.4364 - val_loss: 1267629889.1689\n",
      "Epoch 11110/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1215084875.1468 - val_loss: 1266134656.0000\n",
      "Epoch 11111/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1214906208.6888 - val_loss: 1267994486.9406\n",
      "Epoch 11112/15000\n",
      "1022/1022 [==============================] - 0s 70us/step - loss: 1214737990.7632 - val_loss: 1267226237.0776\n",
      "Epoch 11113/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1215439018.8337 - val_loss: 1268577760.1461\n",
      "Epoch 11114/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1214992745.0802 - val_loss: 1266680942.1735\n",
      "Epoch 11115/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1214986556.6184 - val_loss: 1266526826.9589\n",
      "Epoch 11116/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1214624448.5010 - val_loss: 1267568798.9772\n",
      "Epoch 11117/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1214783136.3131 - val_loss: 1267984184.9863\n",
      "Epoch 11118/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1215107786.8963 - val_loss: 1267466130.1187\n",
      "Epoch 11119/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1215626418.0978 - val_loss: 1269219411.2877\n",
      "Epoch 11120/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214777072.0939 - val_loss: 1267215543.8174\n",
      "Epoch 11121/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214791602.3483 - val_loss: 1267964952.2557\n",
      "Epoch 11122/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1215381266.9119 - val_loss: 1268367753.9361\n",
      "Epoch 11123/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1215128611.7573 - val_loss: 1266278695.7443\n",
      "Epoch 11124/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1214965397.2916 - val_loss: 1267992757.1872\n",
      "Epoch 11125/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214985342.2466 - val_loss: 1266706202.0091\n",
      "Epoch 11126/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214645744.7828 - val_loss: 1268413177.8630\n",
      "Epoch 11127/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1214641216.1252 - val_loss: 1267577274.4475\n",
      "Epoch 11128/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214577451.2720 - val_loss: 1268305840.8037\n",
      "Epoch 11129/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214957412.7593 - val_loss: 1268977168.3653\n",
      "Epoch 11130/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214932258.8180 - val_loss: 1268446907.0320\n",
      "Epoch 11131/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1215254480.1566 - val_loss: 1268732204.4201\n",
      "Epoch 11132/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1214666714.3014 - val_loss: 1267548961.8995\n",
      "Epoch 11133/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214778289.4716 - val_loss: 1266431316.4566\n",
      "Epoch 11134/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214946761.3933 - val_loss: 1267141785.4247\n",
      "Epoch 11135/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1215083493.9491 - val_loss: 1268300892.3470\n",
      "Epoch 11136/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1215027702.4814 - val_loss: 1266247824.3653\n",
      "Epoch 11137/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1214648181.9804 - val_loss: 1267249008.2192\n",
      "Epoch 11138/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1215010635.5225 - val_loss: 1267353502.6849\n",
      "Epoch 11139/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1214778564.8845 - val_loss: 1268899275.3973\n",
      "Epoch 11140/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1214486117.5734 - val_loss: 1268596094.2466\n",
      "Epoch 11141/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214570783.1859 - val_loss: 1267544009.3516\n",
      "Epoch 11142/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1214535793.0959 - val_loss: 1266879514.8858\n",
      "Epoch 11143/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1215000878.7162 - val_loss: 1267961234.7032\n",
      "Epoch 11144/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1214723170.6928 - val_loss: 1268153684.1644\n",
      "Epoch 11145/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214872372.1644 - val_loss: 1267228055.3790\n",
      "Epoch 11146/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214738443.7730 - val_loss: 1268651247.9269\n",
      "Epoch 11147/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214874943.9374 - val_loss: 1267696273.8265\n",
      "Epoch 11148/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1214809458.0978 - val_loss: 1267550401.1689\n",
      "Epoch 11149/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1214496611.0685 - val_loss: 1266824854.5023\n",
      "Epoch 11150/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1214678087.3894 - val_loss: 1267394122.8128\n",
      "Epoch 11151/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1214763848.1409 - val_loss: 1265832169.2055\n",
      "Epoch 11152/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214858542.3405 - val_loss: 1267797029.1142\n",
      "Epoch 11153/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1215224202.6458 - val_loss: 1267247445.9178\n",
      "Epoch 11154/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1214625254.9511 - val_loss: 1266875881.4977\n",
      "Epoch 11155/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1214431281.2838 - val_loss: 1267115193.8630\n",
      "Epoch 11156/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1214370356.1018 - val_loss: 1268292768.4384\n",
      "Epoch 11157/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1216176820.8532 - val_loss: 1270154903.6712\n",
      "Epoch 11158/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214488463.0294 - val_loss: 1266891910.7215\n",
      "Epoch 11159/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214512417.0646 - val_loss: 1266581973.9178\n",
      "Epoch 11160/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214484670.8728 - val_loss: 1268162225.6804\n",
      "Epoch 11161/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214341022.5597 - val_loss: 1267767830.2100\n",
      "Epoch 11162/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214204920.9863 - val_loss: 1267771229.2237\n",
      "Epoch 11163/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1215267296.4384 - val_loss: 1269301824.0000\n",
      "Epoch 11164/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214981772.2740 - val_loss: 1268270924.5662\n",
      "Epoch 11165/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214458441.7065 - val_loss: 1267301519.7808\n",
      "Epoch 11166/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214539148.3992 - val_loss: 1266492194.7763\n",
      "Epoch 11167/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1214198492.9315 - val_loss: 1267334671.7808\n",
      "Epoch 11168/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214351967.4364 - val_loss: 1267698855.4521\n",
      "Epoch 11169/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214415819.1468 - val_loss: 1267276438.5023\n",
      "Epoch 11170/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214267537.0333 - val_loss: 1267331596.8584\n",
      "Epoch 11171/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214579202.7554 - val_loss: 1267717784.8402\n",
      "Epoch 11172/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214404586.4579 - val_loss: 1268489790.2466\n",
      "Epoch 11173/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214663821.9022 - val_loss: 1267121246.1005\n",
      "Epoch 11174/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214533838.6536 - val_loss: 1268076147.4338\n",
      "Epoch 11175/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214630154.2074 - val_loss: 1266439267.0685\n",
      "Epoch 11176/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214232068.2583 - val_loss: 1267688812.7123\n",
      "Epoch 11177/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214404378.3014 - val_loss: 1268163762.8493\n",
      "Epoch 11178/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214589296.7202 - val_loss: 1266440632.1096\n",
      "Epoch 11179/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214162463.8121 - val_loss: 1267520695.2329\n",
      "Epoch 11180/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1214123541.7926 - val_loss: 1267777798.7215\n",
      "Epoch 11181/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1214342540.9315 - val_loss: 1268571180.4201\n",
      "Epoch 11182/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214144916.0391 - val_loss: 1268493785.7169\n",
      "Epoch 11183/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1214605981.0568 - val_loss: 1268642980.8219\n",
      "Epoch 11184/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214641900.7123 - val_loss: 1267401093.8447\n",
      "Epoch 11185/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214268855.3581 - val_loss: 1267129249.3151\n",
      "Epoch 11186/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214458827.6477 - val_loss: 1267495451.7626\n",
      "Epoch 11187/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214268862.3718 - val_loss: 1268502735.1963\n",
      "Epoch 11188/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1214246427.3033 - val_loss: 1267585383.1598\n",
      "Epoch 11189/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214480931.5695 - val_loss: 1268568796.9315\n",
      "Epoch 11190/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214245037.9648 - val_loss: 1268407518.9772\n",
      "Epoch 11191/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214532582.4501 - val_loss: 1268066135.3790\n",
      "Epoch 11192/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214725438.6223 - val_loss: 1266929143.2329\n",
      "Epoch 11193/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214138190.4031 - val_loss: 1268051868.3470\n",
      "Epoch 11194/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214364403.2250 - val_loss: 1267131512.4018\n",
      "Epoch 11195/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214415632.2818 - val_loss: 1267631647.8539\n",
      "Epoch 11196/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214240267.8982 - val_loss: 1267953794.3379\n",
      "Epoch 11197/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1213919521.8160 - val_loss: 1267608333.4429\n",
      "Epoch 11198/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214460497.4090 - val_loss: 1268036134.2831\n",
      "Epoch 11199/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1214034170.3640 - val_loss: 1267951458.4840\n",
      "Epoch 11200/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214673611.3973 - val_loss: 1266400771.7991\n",
      "Epoch 11201/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214039192.6732 - val_loss: 1266292039.3059\n",
      "Epoch 11202/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214975276.1487 - val_loss: 1267881657.2785\n",
      "Epoch 11203/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214487122.1605 - val_loss: 1268436319.5616\n",
      "Epoch 11204/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214296096.3131 - val_loss: 1267642583.0868\n",
      "Epoch 11205/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214120030.3092 - val_loss: 1268078367.5616\n",
      "Epoch 11206/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1213907457.5029 - val_loss: 1267173851.1781\n",
      "Epoch 11207/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214126344.5166 - val_loss: 1266491400.4749\n",
      "Epoch 11208/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1213944534.9198 - val_loss: 1267805199.1963\n",
      "Epoch 11209/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214375594.3327 - val_loss: 1268194348.4201\n",
      "Epoch 11210/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1213922420.7280 - val_loss: 1267606242.4840\n",
      "Epoch 11211/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214152523.5225 - val_loss: 1268283199.1233\n",
      "Epoch 11212/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214365063.0137 - val_loss: 1265531941.4064\n",
      "Epoch 11213/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214003404.7750 - val_loss: 1267771372.1279\n",
      "Epoch 11214/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214141254.0744 - val_loss: 1267826026.0822\n",
      "Epoch 11215/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1213943895.5460 - val_loss: 1267062203.6164\n",
      "Epoch 11216/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1214067647.2485 - val_loss: 1267930957.4429\n",
      "Epoch 11217/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214169656.8611 - val_loss: 1267796032.0000\n",
      "Epoch 11218/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214482274.4423 - val_loss: 1266664082.4110\n",
      "Epoch 11219/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1213994450.9119 - val_loss: 1267936445.3699\n",
      "Epoch 11220/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1214867141.3855 - val_loss: 1266441106.1187\n",
      "Epoch 11221/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1213821933.8395 - val_loss: 1268517353.4977\n",
      "Epoch 11222/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214068352.6262 - val_loss: 1268558167.0868\n",
      "Epoch 11223/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1213735366.3875 - val_loss: 1267796264.6210\n",
      "Epoch 11224/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1213829180.1174 - val_loss: 1267188885.3333\n",
      "Epoch 11225/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214152975.7182 - val_loss: 1268295584.4384\n",
      "Epoch 11226/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214906441.7691 - val_loss: 1266182016.5845\n",
      "Epoch 11227/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1213842455.7965 - val_loss: 1267634906.3014\n",
      "Epoch 11228/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1213858863.8434 - val_loss: 1267703400.0365\n",
      "Epoch 11229/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214525763.5068 - val_loss: 1266564016.8037\n",
      "Epoch 11230/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214112812.4618 - val_loss: 1266165419.8356\n",
      "Epoch 11231/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1213631440.1566 - val_loss: 1268255725.2968\n",
      "Epoch 11232/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1213748202.8963 - val_loss: 1268487914.9589\n",
      "Epoch 11233/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214005408.6888 - val_loss: 1269032040.0365\n",
      "Epoch 11234/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1213995468.3366 - val_loss: 1267850754.3379\n",
      "Epoch 11235/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1213771272.5166 - val_loss: 1268306720.1461\n",
      "Epoch 11236/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1213606066.4736 - val_loss: 1267759986.2648\n",
      "Epoch 11237/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214063643.1781 - val_loss: 1266015153.6804\n",
      "Epoch 11238/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214121891.0685 - val_loss: 1265794916.2374\n",
      "Epoch 11239/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214814176.0626 - val_loss: 1268745189.4064\n",
      "Epoch 11240/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1214052043.8982 - val_loss: 1266650302.5388\n",
      "Epoch 11241/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1214051802.8023 - val_loss: 1267034574.6119\n",
      "Epoch 11242/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1213730591.3112 - val_loss: 1268051389.3699\n",
      "Epoch 11243/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1213769794.1292 - val_loss: 1267759615.1233\n",
      "Epoch 11244/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1213648339.0372 - val_loss: 1267976150.5023\n",
      "Epoch 11245/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1213523765.6047 - val_loss: 1267726989.1507\n",
      "Epoch 11246/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214038495.4364 - val_loss: 1269154437.8447\n",
      "Epoch 11247/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1213538171.8043 - val_loss: 1268196475.0320\n",
      "Epoch 11248/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1213920182.9824 - val_loss: 1267135465.7900\n",
      "Epoch 11249/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1213616928.5636 - val_loss: 1266017230.9041\n",
      "Epoch 11250/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1213588594.5362 - val_loss: 1267006734.3196\n",
      "Epoch 11251/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1213521576.0157 - val_loss: 1267189148.3470\n",
      "Epoch 11252/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1213454914.6301 - val_loss: 1267444093.9543\n",
      "Epoch 11253/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1213726198.3562 - val_loss: 1267486368.4384\n",
      "Epoch 11254/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1214009462.6067 - val_loss: 1266544838.4292\n",
      "Epoch 11255/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1214050520.1722 - val_loss: 1266526363.1781\n",
      "Epoch 11256/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1213883289.5499 - val_loss: 1268134758.8676\n",
      "Epoch 11257/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1213479323.8043 - val_loss: 1266725790.9772\n",
      "Epoch 11258/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1213400272.4070 - val_loss: 1267434451.5799\n",
      "Epoch 11259/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1213468422.5127 - val_loss: 1267241999.4886\n",
      "Epoch 11260/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1214271457.9413 - val_loss: 1265703454.1005\n",
      "Epoch 11261/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1213243734.4188 - val_loss: 1267690780.0548\n",
      "Epoch 11262/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1213504658.7867 - val_loss: 1268065758.1005\n",
      "Epoch 11263/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1213731413.4168 - val_loss: 1267801576.6210\n",
      "Epoch 11264/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1213370217.3933 - val_loss: 1267742942.9772\n",
      "Epoch 11265/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1213549097.3933 - val_loss: 1267027397.5525\n",
      "Epoch 11266/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1213441901.7769 - val_loss: 1267577559.6712\n",
      "Epoch 11267/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1213585538.3796 - val_loss: 1267905076.8950\n",
      "Epoch 11268/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1213740265.7691 - val_loss: 1267886802.9954\n",
      "Epoch 11269/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1213611822.7789 - val_loss: 1267467092.4566\n",
      "Epoch 11270/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1213686613.1663 - val_loss: 1267600997.4064\n",
      "Epoch 11271/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1213692960.9393 - val_loss: 1266979855.1963\n",
      "Epoch 11272/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1213337764.3209 - val_loss: 1267232757.7717\n",
      "Epoch 11273/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1213538536.4540 - val_loss: 1267067474.4110\n",
      "Epoch 11274/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1213565329.5342 - val_loss: 1267909265.8265\n",
      "Epoch 11275/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1213564039.7652 - val_loss: 1266820546.0457\n",
      "Epoch 11276/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1213213341.6830 - val_loss: 1266741603.3607\n",
      "Epoch 11277/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1213283574.3562 - val_loss: 1267437857.6073\n",
      "Epoch 11278/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1213480611.6321 - val_loss: 1266507602.4110\n",
      "Epoch 11279/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 28us/step - loss: 1213262818.7554 - val_loss: 1266306030.7580\n",
      "Epoch 11280/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1213669516.7750 - val_loss: 1268388846.7580\n",
      "Epoch 11281/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1213295545.4873 - val_loss: 1266909051.6164\n",
      "Epoch 11282/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1213446092.3992 - val_loss: 1267890644.1644\n",
      "Epoch 11283/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1213307049.7691 - val_loss: 1267231632.3653\n",
      "Epoch 11284/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1213245287.2016 - val_loss: 1267400744.6210\n",
      "Epoch 11285/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1213309992.1409 - val_loss: 1267662482.7032\n",
      "Epoch 11286/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1213195790.1526 - val_loss: 1266729660.2009\n",
      "Epoch 11287/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1213221710.1526 - val_loss: 1267742381.8813\n",
      "Epoch 11288/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1213133316.8845 - val_loss: 1267207784.3288\n",
      "Epoch 11289/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1213516111.4051 - val_loss: 1267893219.6530\n",
      "Epoch 11290/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1213721606.7632 - val_loss: 1265628689.2420\n",
      "Epoch 11291/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1213049561.9256 - val_loss: 1267012105.3516\n",
      "Epoch 11292/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1213442429.9961 - val_loss: 1267526397.6621\n",
      "Epoch 11293/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1213421745.0959 - val_loss: 1267316710.5753\n",
      "Epoch 11294/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1213157700.6341 - val_loss: 1267400284.6393\n",
      "Epoch 11295/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1213351734.9824 - val_loss: 1267748578.4840\n",
      "Epoch 11296/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1213078399.3738 - val_loss: 1267156752.0731\n",
      "Epoch 11297/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1213333720.6732 - val_loss: 1267997391.4886\n",
      "Epoch 11298/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1213802531.8200 - val_loss: 1265645849.4247\n",
      "Epoch 11299/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1213417253.5734 - val_loss: 1266684441.1324\n",
      "Epoch 11300/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1213129853.7456 - val_loss: 1267780718.7580\n",
      "Epoch 11301/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1213377630.8102 - val_loss: 1268250959.1963\n",
      "Epoch 11302/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1213074219.0841 - val_loss: 1268253710.9041\n",
      "Epoch 11303/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1213515852.6497 - val_loss: 1266841253.4064\n",
      "Epoch 11304/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1213369885.9335 - val_loss: 1267668720.2192\n",
      "Epoch 11305/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1213700193.6908 - val_loss: 1265784054.6484\n",
      "Epoch 11306/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1213124127.1233 - val_loss: 1267593584.8037\n",
      "Epoch 11307/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1213560792.6106 - val_loss: 1265957035.2511\n",
      "Epoch 11308/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1213568088.1722 - val_loss: 1265558569.7900\n",
      "Epoch 11309/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1214012011.1468 - val_loss: 1267952367.9269\n",
      "Epoch 11310/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1212985545.1429 - val_loss: 1267756861.6621\n",
      "Epoch 11311/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1213541783.5460 - val_loss: 1266763668.4566\n",
      "Epoch 11312/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1212935043.1311 - val_loss: 1267317522.1187\n",
      "Epoch 11313/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1213198792.8924 - val_loss: 1267157859.6530\n",
      "Epoch 11314/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1213064309.2290 - val_loss: 1267025906.8493\n",
      "Epoch 11315/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1213036133.5734 - val_loss: 1266395508.8950\n",
      "Epoch 11316/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1212851043.5695 - val_loss: 1267751348.8950\n",
      "Epoch 11317/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1213166915.6321 - val_loss: 1268290179.5068\n",
      "Epoch 11318/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1213598998.1683 - val_loss: 1266387154.9954\n",
      "Epoch 11319/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1213667088.0313 - val_loss: 1267209415.5982\n",
      "Epoch 11320/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1212948833.1898 - val_loss: 1267553419.1050\n",
      "Epoch 11321/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1212830939.9295 - val_loss: 1267816697.2785\n",
      "Epoch 11322/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1213227986.9746 - val_loss: 1266743795.1416\n",
      "Epoch 11323/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1213050025.0802 - val_loss: 1267887690.2283\n",
      "Epoch 11324/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1213047413.4795 - val_loss: 1268417735.8904\n",
      "Epoch 11325/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1213200494.9667 - val_loss: 1267117015.0868\n",
      "Epoch 11326/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1212892929.7534 - val_loss: 1266829229.0046\n",
      "Epoch 11327/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1213511803.9922 - val_loss: 1268226042.1553\n",
      "Epoch 11328/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1212767960.5479 - val_loss: 1267270452.8950\n",
      "Epoch 11329/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1212837417.3307 - val_loss: 1266377381.6986\n",
      "Epoch 11330/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1213815508.5401 - val_loss: 1268868951.9635\n",
      "Epoch 11331/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1213181595.3033 - val_loss: 1265943819.1050\n",
      "Epoch 11332/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1213083395.7573 - val_loss: 1267417656.1096\n",
      "Epoch 11333/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1212949689.8630 - val_loss: 1268177862.4292\n",
      "Epoch 11334/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1213113430.5440 - val_loss: 1266676194.7763\n",
      "Epoch 11335/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1212920053.7299 - val_loss: 1266971817.7900\n",
      "Epoch 11336/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1213103560.8924 - val_loss: 1265641361.8265\n",
      "Epoch 11337/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1212763231.4364 - val_loss: 1267342050.7763\n",
      "Epoch 11338/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1213192199.0137 - val_loss: 1269274383.7808\n",
      "Epoch 11339/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1215012546.7554 - val_loss: 1266569904.2192\n",
      "Epoch 11340/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1213107396.1331 - val_loss: 1267688349.5160\n",
      "Epoch 11341/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1213037786.4266 - val_loss: 1266718272.8767\n",
      "Epoch 11342/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1213128039.2016 - val_loss: 1268204515.9452\n",
      "Epoch 11343/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 29us/step - loss: 1212857678.9041 - val_loss: 1267517558.3562\n",
      "Epoch 11344/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1212684403.7260 - val_loss: 1267484724.6027\n",
      "Epoch 11345/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1213001067.2094 - val_loss: 1266677421.5890\n",
      "Epoch 11346/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1212938488.1096 - val_loss: 1266466439.5982\n",
      "Epoch 11347/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1212746412.5871 - val_loss: 1267128525.1507\n",
      "Epoch 11348/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1213461980.9315 - val_loss: 1266055844.8219\n",
      "Epoch 11349/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1212719389.5577 - val_loss: 1268216274.1187\n",
      "Epoch 11350/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1212861692.8689 - val_loss: 1266932337.0959\n",
      "Epoch 11351/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1213325805.0254 - val_loss: 1268309613.8813\n",
      "Epoch 11352/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1213349412.6967 - val_loss: 1267140078.1735\n",
      "Epoch 11353/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1212747852.6497 - val_loss: 1267121220.3836\n",
      "Epoch 11354/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1212870631.5147 - val_loss: 1266582513.9726\n",
      "Epoch 11355/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1213095577.5499 - val_loss: 1266305152.8767\n",
      "Epoch 11356/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1212491989.6673 - val_loss: 1267222077.3699\n",
      "Epoch 11357/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1212788969.7691 - val_loss: 1267365460.7489\n",
      "Epoch 11358/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1212732006.6380 - val_loss: 1267777904.8037\n",
      "Epoch 11359/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1212902722.8806 - val_loss: 1266493065.6438\n",
      "Epoch 11360/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1212978431.4990 - val_loss: 1265849232.6575\n",
      "Epoch 11361/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1212975848.4540 - val_loss: 1266063041.1689\n",
      "Epoch 11362/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1212670667.3973 - val_loss: 1267031469.0046\n",
      "Epoch 11363/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1213080381.6204 - val_loss: 1268884759.6712\n",
      "Epoch 11364/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1212675292.1800 - val_loss: 1267293918.9772\n",
      "Epoch 11365/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1212960696.6106 - val_loss: 1267994271.8539\n",
      "Epoch 11366/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1213522190.4031 - val_loss: 1265712306.8493\n",
      "Epoch 11367/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1212495094.4188 - val_loss: 1268155767.2329\n",
      "Epoch 11368/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1212821547.8356 - val_loss: 1268435695.9269\n",
      "Epoch 11369/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1212857189.5734 - val_loss: 1267615833.1324\n",
      "Epoch 11370/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1212654830.9667 - val_loss: 1268585187.9452\n",
      "Epoch 11371/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1212957544.7045 - val_loss: 1266616440.4018\n",
      "Epoch 11372/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1212620179.0372 - val_loss: 1267826988.4201\n",
      "Epoch 11373/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1213111069.5577 - val_loss: 1266563171.3607\n",
      "Epoch 11374/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1212565989.5734 - val_loss: 1267864230.5753\n",
      "Epoch 11375/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1212937662.6223 - val_loss: 1267006851.2146\n",
      "Epoch 11376/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1212618826.6458 - val_loss: 1266905823.5616\n",
      "Epoch 11377/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1212752170.5832 - val_loss: 1266299664.6575\n",
      "Epoch 11378/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1213731598.1526 - val_loss: 1268794025.7900\n",
      "Epoch 11379/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1212416657.0959 - val_loss: 1266994734.4658\n",
      "Epoch 11380/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1212604172.9002 - val_loss: 1268008763.6164\n",
      "Epoch 11381/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1212961673.4560 - val_loss: 1266712548.5297\n",
      "Epoch 11382/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1212342645.9804 - val_loss: 1266939911.3059\n",
      "Epoch 11383/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1212803281.1585 - val_loss: 1266793972.6027\n",
      "Epoch 11384/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1212447876.0078 - val_loss: 1267725172.0183\n",
      "Epoch 11385/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1212879227.2407 - val_loss: 1268675941.9909\n",
      "Epoch 11386/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1212549965.9022 - val_loss: 1267458207.8539\n",
      "Epoch 11387/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1212897068.3366 - val_loss: 1265903762.9954\n",
      "Epoch 11388/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1212354756.1331 - val_loss: 1267464790.5023\n",
      "Epoch 11389/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1212568837.6360 - val_loss: 1266665044.7489\n",
      "Epoch 11390/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1213058208.5636 - val_loss: 1266357819.6164\n",
      "Epoch 11391/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1212596812.6497 - val_loss: 1266532999.0137\n",
      "Epoch 11392/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1212356173.1507 - val_loss: 1267821961.9361\n",
      "Epoch 11393/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1212500116.2896 - val_loss: 1268773392.9498\n",
      "Epoch 11394/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1212789632.0626 - val_loss: 1266973326.6119\n",
      "Epoch 11395/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1212613617.4716 - val_loss: 1268594423.2329\n",
      "Epoch 11396/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1212931063.4834 - val_loss: 1267035927.0868\n",
      "Epoch 11397/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1212337171.2250 - val_loss: 1267594929.9726\n",
      "Epoch 11398/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1212151472.4697 - val_loss: 1267495172.6758\n",
      "Epoch 11399/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1212249129.8317 - val_loss: 1267703542.0639\n",
      "Epoch 11400/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1212147416.4227 - val_loss: 1267073093.2603\n",
      "Epoch 11401/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1212569484.6497 - val_loss: 1265976354.1918\n",
      "Epoch 11402/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1212316046.4031 - val_loss: 1267403310.7580\n",
      "Epoch 11403/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1213087407.9687 - val_loss: 1266839947.1050\n",
      "Epoch 11404/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1212506739.2250 - val_loss: 1267274229.4795\n",
      "Epoch 11405/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1212719502.7789 - val_loss: 1266389256.1826\n",
      "Epoch 11406/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1212159057.1585 - val_loss: 1266764911.3425\n",
      "Epoch 11407/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 29us/step - loss: 1212068836.6967 - val_loss: 1267649370.0091\n",
      "Epoch 11408/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1212251740.5558 - val_loss: 1268393528.6941\n",
      "Epoch 11409/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1212647288.1096 - val_loss: 1266686314.9589\n",
      "Epoch 11410/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1212316199.4521 - val_loss: 1268153928.1826\n",
      "Epoch 11411/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1212052240.0939 - val_loss: 1267934207.1233\n",
      "Epoch 11412/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1212103749.5734 - val_loss: 1267730427.3242\n",
      "Epoch 11413/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1212101580.9002 - val_loss: 1267605219.6530\n",
      "Epoch 11414/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1212023859.8513 - val_loss: 1267289054.3927\n",
      "Epoch 11415/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1212263651.0059 - val_loss: 1266586279.1598\n",
      "Epoch 11416/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1212108631.6712 - val_loss: 1267096082.9954\n",
      "Epoch 11417/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1212137140.3523 - val_loss: 1266850269.5160\n",
      "Epoch 11418/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1212581414.0744 - val_loss: 1269115092.1644\n",
      "Epoch 11419/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1212396148.7280 - val_loss: 1267087494.1370\n",
      "Epoch 11420/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1212425421.5264 - val_loss: 1266407939.7991\n",
      "Epoch 11421/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1211897736.2661 - val_loss: 1266848079.4886\n",
      "Epoch 11422/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1212159589.4481 - val_loss: 1267959913.7900\n",
      "Epoch 11423/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1212532059.8043 - val_loss: 1266429392.3653\n",
      "Epoch 11424/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1212146192.6575 - val_loss: 1268179581.3699\n",
      "Epoch 11425/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1212356085.9804 - val_loss: 1266261525.9178\n",
      "Epoch 11426/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1211927698.7867 - val_loss: 1267197103.0502\n",
      "Epoch 11427/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1212122852.5714 - val_loss: 1268475101.5160\n",
      "Epoch 11428/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1211997446.8885 - val_loss: 1267895597.8813\n",
      "Epoch 11429/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1213133469.9335 - val_loss: 1268122278.2831\n",
      "Epoch 11430/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1212219043.9452 - val_loss: 1266693485.2968\n",
      "Epoch 11431/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1212555610.0509 - val_loss: 1267677001.9361\n",
      "Epoch 11432/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1212068744.8924 - val_loss: 1267527198.6849\n",
      "Epoch 11433/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1212039162.2387 - val_loss: 1266753061.4064\n",
      "Epoch 11434/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1212050537.7065 - val_loss: 1266434498.0457\n",
      "Epoch 11435/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1212188919.3581 - val_loss: 1268087949.7352\n",
      "Epoch 11436/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1211960860.8689 - val_loss: 1266898231.8174\n",
      "Epoch 11437/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1212023421.7456 - val_loss: 1268119499.6895\n",
      "Epoch 11438/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1211914289.3464 - val_loss: 1266831019.8356\n",
      "Epoch 11439/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1212261846.1683 - val_loss: 1267521609.9361\n",
      "Epoch 11440/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1211997592.3601 - val_loss: 1267331451.6164\n",
      "Epoch 11441/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1211967937.3777 - val_loss: 1267672338.7032\n",
      "Epoch 11442/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1211943636.4775 - val_loss: 1266614864.9498\n",
      "Epoch 11443/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1211824710.3875 - val_loss: 1267582971.6164\n",
      "Epoch 11444/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1212700693.5421 - val_loss: 1267841001.7900\n",
      "Epoch 11445/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1211932757.1663 - val_loss: 1267263959.0868\n",
      "Epoch 11446/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1212597225.9569 - val_loss: 1268472677.1142\n",
      "Epoch 11447/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1211988891.0528 - val_loss: 1268371709.6621\n",
      "Epoch 11448/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1212264705.5029 - val_loss: 1266217024.2922\n",
      "Epoch 11449/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1212041440.6888 - val_loss: 1266885754.4475\n",
      "Epoch 11450/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1212030889.3307 - val_loss: 1266316022.9406\n",
      "Epoch 11451/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1212082670.8415 - val_loss: 1266964636.0548\n",
      "Epoch 11452/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1212058028.7123 - val_loss: 1268023736.6941\n",
      "Epoch 11453/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1212180927.8748 - val_loss: 1265958190.7580\n",
      "Epoch 11454/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1212466007.1703 - val_loss: 1268787977.6438\n",
      "Epoch 11455/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1212207044.6341 - val_loss: 1268638571.2511\n",
      "Epoch 11456/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1212240166.1370 - val_loss: 1266592843.6895\n",
      "Epoch 11457/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1211910737.7847 - val_loss: 1267085340.9315\n",
      "Epoch 11458/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1211951501.2759 - val_loss: 1267433702.5753\n",
      "Epoch 11459/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1212023050.2074 - val_loss: 1267321931.9817\n",
      "Epoch 11460/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1212102611.4129 - val_loss: 1268643667.8721\n",
      "Epoch 11461/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1211773504.3757 - val_loss: 1267809569.8995\n",
      "Epoch 11462/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1211852728.1096 - val_loss: 1268451910.1370\n",
      "Epoch 11463/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1212153060.4462 - val_loss: 1268473748.1644\n",
      "Epoch 11464/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1211967540.8532 - val_loss: 1266640758.6484\n",
      "Epoch 11465/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1211797579.8982 - val_loss: 1267864950.3562\n",
      "Epoch 11466/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1211784812.2114 - val_loss: 1266299048.6210\n",
      "Epoch 11467/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1211802918.2622 - val_loss: 1267695711.8539\n",
      "Epoch 11468/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1212257498.1135 - val_loss: 1267878820.5297\n",
      "Epoch 11469/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1212274616.6732 - val_loss: 1268393412.0913\n",
      "Epoch 11470/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1211403420.3053 - val_loss: 1267449144.4018\n",
      "Epoch 11471/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1211674997.7299 - val_loss: 1267382727.0137\n",
      "Epoch 11472/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1212454939.0528 - val_loss: 1264798453.4795\n",
      "Epoch 11473/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1211699926.9198 - val_loss: 1267488416.4384\n",
      "Epoch 11474/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1211860708.4462 - val_loss: 1266393875.8721\n",
      "Epoch 11475/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1212151186.4110 - val_loss: 1268265038.6119\n",
      "Epoch 11476/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1212755557.6986 - val_loss: 1267025039.7808\n",
      "Epoch 11477/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1212153653.3542 - val_loss: 1268770447.1963\n",
      "Epoch 11478/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1211994005.7926 - val_loss: 1266351038.5388\n",
      "Epoch 11479/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1211976345.2368 - val_loss: 1268560846.6119\n",
      "Epoch 11480/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1211824219.9922 - val_loss: 1267831836.6393\n",
      "Epoch 11481/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1211779458.3796 - val_loss: 1266240734.1005\n",
      "Epoch 11482/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1212003767.1076 - val_loss: 1268432251.6164\n",
      "Epoch 11483/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1212103074.6928 - val_loss: 1266495173.8447\n",
      "Epoch 11484/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1212529790.7476 - val_loss: 1269133507.5068\n",
      "Epoch 11485/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1212152119.8591 - val_loss: 1266484269.2968\n",
      "Epoch 11486/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1211521744.7202 - val_loss: 1266795838.2466\n",
      "Epoch 11487/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1212432013.0881 - val_loss: 1268347747.3607\n",
      "Epoch 11488/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1211631720.1409 - val_loss: 1267436918.9406\n",
      "Epoch 11489/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1211807586.9432 - val_loss: 1266416989.5160\n",
      "Epoch 11490/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1212076256.4384 - val_loss: 1268647051.6895\n",
      "Epoch 11491/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1211689616.4697 - val_loss: 1267380721.0959\n",
      "Epoch 11492/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1211517759.6243 - val_loss: 1268027416.2557\n",
      "Epoch 11493/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1211560947.9765 - val_loss: 1267261364.6027\n",
      "Epoch 11494/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1212029523.4129 - val_loss: 1268482638.6119\n",
      "Epoch 11495/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1211889676.6497 - val_loss: 1268069743.6347\n",
      "Epoch 11496/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1211571840.0000 - val_loss: 1267152924.9315\n",
      "Epoch 11497/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1211576415.1859 - val_loss: 1268058386.7032\n",
      "Epoch 11498/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1211709373.1194 - val_loss: 1266174930.7032\n",
      "Epoch 11499/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1212141998.8415 - val_loss: 1264715833.2785\n",
      "Epoch 11500/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1211584129.0020 - val_loss: 1268314936.1096\n",
      "Epoch 11501/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1211676261.6986 - val_loss: 1267872467.2877\n",
      "Epoch 11502/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1211510079.3738 - val_loss: 1266940830.3927\n",
      "Epoch 11503/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1211728759.7339 - val_loss: 1267411251.4338\n",
      "Epoch 11504/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1211587669.3542 - val_loss: 1267168660.1644\n",
      "Epoch 11505/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1212205167.9687 - val_loss: 1269149065.3516\n",
      "Epoch 11506/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1211461920.6888 - val_loss: 1266483819.2511\n",
      "Epoch 11507/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1212585869.2759 - val_loss: 1266269187.7991\n",
      "Epoch 11508/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1211741254.4501 - val_loss: 1267972235.3973\n",
      "Epoch 11509/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1211459079.0137 - val_loss: 1267848076.2740\n",
      "Epoch 11510/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1211685862.9511 - val_loss: 1267398229.6256\n",
      "Epoch 11511/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1211635110.3249 - val_loss: 1267810677.7717\n",
      "Epoch 11512/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1211355014.8885 - val_loss: 1267697636.8219\n",
      "Epoch 11513/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1211919576.5479 - val_loss: 1268275348.1644\n",
      "Epoch 11514/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1211168625.4716 - val_loss: 1267035316.0183\n",
      "Epoch 11515/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1211564726.8571 - val_loss: 1265801474.0457\n",
      "Epoch 11516/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1211931452.6184 - val_loss: 1267970092.1279\n",
      "Epoch 11517/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1211365916.5558 - val_loss: 1266982181.1142\n",
      "Epoch 11518/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1211451986.6614 - val_loss: 1267233894.2831\n",
      "Epoch 11519/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1211651123.6634 - val_loss: 1268095402.3744\n",
      "Epoch 11520/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1211357959.7652 - val_loss: 1267383264.4384\n",
      "Epoch 11521/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1212438741.9178 - val_loss: 1266689558.5023\n",
      "Epoch 11522/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1211709839.4677 - val_loss: 1268207928.6941\n",
      "Epoch 11523/15000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1211393387.2094 - val_loss: 1266938048.0000\n",
      "Epoch 11524/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1211329224.8924 - val_loss: 1266653564.2009\n",
      "Epoch 11525/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1211510834.8493 - val_loss: 1268451595.9817\n",
      "Epoch 11526/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1211572283.1155 - val_loss: 1266832882.8493\n",
      "Epoch 11527/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1212984323.4442 - val_loss: 1268932889.7169\n",
      "Epoch 11528/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1211286268.2427 - val_loss: 1266980949.6256\n",
      "Epoch 11529/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1211377141.9804 - val_loss: 1266944664.2557\n",
      "Epoch 11530/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1212202396.3053 - val_loss: 1267424043.5434\n",
      "Epoch 11531/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1211365932.3366 - val_loss: 1267730534.8676\n",
      "Epoch 11532/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1211286354.4110 - val_loss: 1267004335.3425\n",
      "Epoch 11533/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1211430977.1898 - val_loss: 1268180086.9406\n",
      "Epoch 11534/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1211297617.4090 - val_loss: 1267263766.5023\n",
      "Epoch 11535/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1211184746.4579 - val_loss: 1267007837.5160\n",
      "Epoch 11536/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1211137899.4599 - val_loss: 1266915147.6895\n",
      "Epoch 11537/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1211361370.1761 - val_loss: 1266397266.4110\n",
      "Epoch 11538/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1211430006.1057 - val_loss: 1267898114.9224\n",
      "Epoch 11539/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1211373306.9902 - val_loss: 1267952907.3973\n",
      "Epoch 11540/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1211151169.6282 - val_loss: 1268043299.6530\n",
      "Epoch 11541/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1211190544.7828 - val_loss: 1267647613.0776\n",
      "Epoch 11542/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1211324747.5225 - val_loss: 1266715892.8950\n",
      "Epoch 11543/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1210941168.7202 - val_loss: 1267392840.4749\n",
      "Epoch 11544/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1211157841.9100 - val_loss: 1267550019.5068\n",
      "Epoch 11545/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1211628173.4012 - val_loss: 1266285836.2740\n",
      "Epoch 11546/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1211011958.6067 - val_loss: 1267660084.0183\n",
      "Epoch 11547/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1211316521.3307 - val_loss: 1267682358.6484\n",
      "Epoch 11548/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1211029784.6732 - val_loss: 1267747242.6667\n",
      "Epoch 11549/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1211189311.8748 - val_loss: 1267450825.0594\n",
      "Epoch 11550/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1211038011.6164 - val_loss: 1267646289.8265\n",
      "Epoch 11551/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1211041389.7143 - val_loss: 1267811251.7260\n",
      "Epoch 11552/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1211403191.8591 - val_loss: 1267798003.4338\n",
      "Epoch 11553/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1210968425.7065 - val_loss: 1267481263.0502\n",
      "Epoch 11554/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1211048099.0685 - val_loss: 1268151809.4612\n",
      "Epoch 11555/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1211550141.8708 - val_loss: 1267837553.9726\n",
      "Epoch 11556/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1210918503.4521 - val_loss: 1267795217.8265\n",
      "Epoch 11557/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1211183015.8278 - val_loss: 1266658107.0320\n",
      "Epoch 11558/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1211914795.0841 - val_loss: 1267693122.3379\n",
      "Epoch 11559/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1210865688.2975 - val_loss: 1268014494.9772\n",
      "Epoch 11560/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1211855870.7476 - val_loss: 1267260342.6484\n",
      "Epoch 11561/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1211349800.3288 - val_loss: 1268809359.4886\n",
      "Epoch 11562/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1211217991.1389 - val_loss: 1268925884.2009\n",
      "Epoch 11563/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1211072285.0568 - val_loss: 1267755600.6575\n",
      "Epoch 11564/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1210966823.3894 - val_loss: 1267637933.8813\n",
      "Epoch 11565/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1211658322.4110 - val_loss: 1266043664.3653\n",
      "Epoch 11566/15000\n",
      "1022/1022 [==============================] - 0s 78us/step - loss: 1211925062.7632 - val_loss: 1269559049.9361\n",
      "Epoch 11567/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1210735624.1409 - val_loss: 1268168592.6575\n",
      "Epoch 11568/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1211030362.4266 - val_loss: 1268058693.2603\n",
      "Epoch 11569/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1211324261.5734 - val_loss: 1267202195.2877\n",
      "Epoch 11570/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1211082499.0685 - val_loss: 1266524816.0731\n",
      "Epoch 11571/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1211234279.7652 - val_loss: 1268694962.5571\n",
      "Epoch 11572/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1211275284.7906 - val_loss: 1268577684.7489\n",
      "Epoch 11573/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1211063579.6791 - val_loss: 1267194936.9863\n",
      "Epoch 11574/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1211065352.5166 - val_loss: 1268470319.6347\n",
      "Epoch 11575/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1211165261.0881 - val_loss: 1268726395.0320\n",
      "Epoch 11576/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1210926891.2720 - val_loss: 1267843423.2694\n",
      "Epoch 11577/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1211129197.3386 - val_loss: 1266785142.3562\n",
      "Epoch 11578/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1211007873.2524 - val_loss: 1267635453.6621\n",
      "Epoch 11579/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1211106622.3718 - val_loss: 1266907036.0548\n",
      "Epoch 11580/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1210974924.1487 - val_loss: 1267238174.9772\n",
      "Epoch 11581/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1211279186.9119 - val_loss: 1266062824.6210\n",
      "Epoch 11582/15000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1210825375.9374 - val_loss: 1267314057.6438\n",
      "Epoch 11583/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1210936471.9217 - val_loss: 1267773819.6164\n",
      "Epoch 11584/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1210887082.3327 - val_loss: 1268367829.3333\n",
      "Epoch 11585/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1210868589.9648 - val_loss: 1268458891.9817\n",
      "Epoch 11586/15000\n",
      "1022/1022 [==============================] - 0s 66us/step - loss: 1210902767.0920 - val_loss: 1267608912.0731\n",
      "Epoch 11587/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1211430452.2896 - val_loss: 1269057013.7717\n",
      "Epoch 11588/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1211012770.0665 - val_loss: 1267898044.4932\n",
      "Epoch 11589/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1210957179.9922 - val_loss: 1266656055.2329\n",
      "Epoch 11590/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1210757758.2466 - val_loss: 1267266940.2009\n",
      "Epoch 11591/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1210903153.4716 - val_loss: 1268017882.3014\n",
      "Epoch 11592/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1211089809.5342 - val_loss: 1268559087.6347\n",
      "Epoch 11593/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1210838201.8630 - val_loss: 1267786032.8037\n",
      "Epoch 11594/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1211899150.6536 - val_loss: 1266568457.0594\n",
      "Epoch 11595/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1210885447.1389 - val_loss: 1266320436.3105\n",
      "Epoch 11596/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1210937792.6888 - val_loss: 1268420293.8447\n",
      "Epoch 11597/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1210718298.6771 - val_loss: 1267935659.5434\n",
      "Epoch 11598/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1210923010.0039 - val_loss: 1267159447.0868\n",
      "Epoch 11599/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1210681185.1898 - val_loss: 1266840471.6712\n",
      "Epoch 11600/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1210840134.1370 - val_loss: 1268462235.7626\n",
      "Epoch 11601/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1211176776.7045 - val_loss: 1268437308.4932\n",
      "Epoch 11602/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1211142015.6243 - val_loss: 1267932172.8584\n",
      "Epoch 11603/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1211372991.4364 - val_loss: 1265979970.6301\n",
      "Epoch 11604/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1210864615.7025 - val_loss: 1268147825.9726\n",
      "Epoch 11605/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1210940042.8963 - val_loss: 1268332477.9543\n",
      "Epoch 11606/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1210637943.1076 - val_loss: 1267530470.5753\n",
      "Epoch 11607/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1210735949.0254 - val_loss: 1267909083.4703\n",
      "Epoch 11608/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1211007620.0078 - val_loss: 1267520669.5160\n",
      "Epoch 11609/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1210959348.5401 - val_loss: 1268922626.9224\n",
      "Epoch 11610/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1211336066.7554 - val_loss: 1267906254.0274\n",
      "Epoch 11611/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1211155749.6986 - val_loss: 1268976173.2968\n",
      "Epoch 11612/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1211430522.7397 - val_loss: 1266317154.4840\n",
      "Epoch 11613/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1210550684.3053 - val_loss: 1267449689.4247\n",
      "Epoch 11614/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1211107826.8493 - val_loss: 1268190208.8767\n",
      "Epoch 11615/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1211794563.5068 - val_loss: 1265963513.8630\n",
      "Epoch 11616/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1210732421.7613 - val_loss: 1267393540.9680\n",
      "Epoch 11617/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1210814524.8689 - val_loss: 1268598916.3836\n",
      "Epoch 11618/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1210644111.2798 - val_loss: 1267342085.8447\n",
      "Epoch 11619/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1210975241.6438 - val_loss: 1267702252.1279\n",
      "Epoch 11620/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1210709391.4051 - val_loss: 1268089415.3059\n",
      "Epoch 11621/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1210763802.6771 - val_loss: 1267870246.8676\n",
      "Epoch 11622/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1211070306.4423 - val_loss: 1267207919.3425\n",
      "Epoch 11623/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1210768806.8258 - val_loss: 1268888061.6621\n",
      "Epoch 11624/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1210880057.6125 - val_loss: 1267042545.3881\n",
      "Epoch 11625/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1210599173.5108 - val_loss: 1267945510.8676\n",
      "Epoch 11626/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1210536883.7260 - val_loss: 1268045317.5525\n",
      "Epoch 11627/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1210523026.7867 - val_loss: 1268063494.1370\n",
      "Epoch 11628/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1210675686.5753 - val_loss: 1268284723.7260\n",
      "Epoch 11629/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1210896003.2564 - val_loss: 1267079632.9498\n",
      "Epoch 11630/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1210640069.5734 - val_loss: 1266434117.5525\n",
      "Epoch 11631/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1210656837.8865 - val_loss: 1267637338.3014\n",
      "Epoch 11632/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1210446243.6321 - val_loss: 1268030224.3653\n",
      "Epoch 11633/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1210884789.8552 - val_loss: 1268327207.1598\n",
      "Epoch 11634/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1210562842.3014 - val_loss: 1268180864.2922\n",
      "Epoch 11635/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1210439542.9824 - val_loss: 1267580237.1507\n",
      "Epoch 11636/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1210542996.7906 - val_loss: 1267188271.0502\n",
      "Epoch 11637/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1210834189.4012 - val_loss: 1267663265.6073\n",
      "Epoch 11638/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1210495879.8904 - val_loss: 1267987705.2785\n",
      "Epoch 11639/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1210864776.5166 - val_loss: 1266687066.0091\n",
      "Epoch 11640/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1210460025.8630 - val_loss: 1267172572.9315\n",
      "Epoch 11641/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1210369908.2270 - val_loss: 1267606499.6530\n",
      "Epoch 11642/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1210556020.7906 - val_loss: 1267598320.5114\n",
      "Epoch 11643/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1210465719.6086 - val_loss: 1268082093.5890\n",
      "Epoch 11644/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1210987383.3581 - val_loss: 1266889637.6986\n",
      "Epoch 11645/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1210669420.0235 - val_loss: 1268351519.2694\n",
      "Epoch 11646/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1210373235.9139 - val_loss: 1267673156.6758\n",
      "Epoch 11647/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1211028649.5812 - val_loss: 1266596778.3744\n",
      "Epoch 11648/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1210461574.8885 - val_loss: 1267954315.1050\n",
      "Epoch 11649/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1210429806.9667 - val_loss: 1267796549.2603\n",
      "Epoch 11650/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1210378153.8317 - val_loss: 1268324395.5434\n",
      "Epoch 11651/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1211014336.9393 - val_loss: 1268527797.4795\n",
      "Epoch 11652/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1211793482.2074 - val_loss: 1265890431.1233\n",
      "Epoch 11653/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1210717248.2505 - val_loss: 1268309369.8630\n",
      "Epoch 11654/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1210327411.9139 - val_loss: 1267504528.6575\n",
      "Epoch 11655/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1210407120.4070 - val_loss: 1267128066.6301\n",
      "Epoch 11656/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1210822854.0117 - val_loss: 1266662195.7260\n",
      "Epoch 11657/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1210573736.4540 - val_loss: 1268983609.2785\n",
      "Epoch 11658/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1210194869.9804 - val_loss: 1268756654.7580\n",
      "Epoch 11659/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1210392675.3190 - val_loss: 1267682656.1461\n",
      "Epoch 11660/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1210860329.9569 - val_loss: 1266658987.8356\n",
      "Epoch 11661/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1210837908.5401 - val_loss: 1268498529.0228\n",
      "Epoch 11662/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1210224450.1292 - val_loss: 1268179368.6210\n",
      "Epoch 11663/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 31us/step - loss: 1210918323.8513 - val_loss: 1266413822.5388\n",
      "Epoch 11664/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1211283494.5753 - val_loss: 1269307411.2877\n",
      "Epoch 11665/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1210225654.7319 - val_loss: 1268027823.0502\n",
      "Epoch 11666/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1210657259.0215 - val_loss: 1267610248.7671\n",
      "Epoch 11667/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1211166152.6419 - val_loss: 1268992801.3151\n",
      "Epoch 11668/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1210792769.6908 - val_loss: 1267146341.4064\n",
      "Epoch 11669/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1210263260.3053 - val_loss: 1267900036.3836\n",
      "Epoch 11670/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1210166279.1389 - val_loss: 1267696227.0685\n",
      "Epoch 11671/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1210204011.0215 - val_loss: 1267437227.8356\n",
      "Epoch 11672/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1210153778.0978 - val_loss: 1267758693.9909\n",
      "Epoch 11673/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1210762966.0431 - val_loss: 1265770104.1096\n",
      "Epoch 11674/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1210776064.8767 - val_loss: 1268233074.8493\n",
      "Epoch 11675/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1210668903.4521 - val_loss: 1268435204.3836\n",
      "Epoch 11676/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1211014784.2505 - val_loss: 1265448303.9269\n",
      "Epoch 11677/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1210996780.3366 - val_loss: 1268103516.6393\n",
      "Epoch 11678/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1210204878.2779 - val_loss: 1267680251.3242\n",
      "Epoch 11679/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1210167340.5871 - val_loss: 1268118433.3151\n",
      "Epoch 11680/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1210261507.3190 - val_loss: 1267372883.2877\n",
      "Epoch 11681/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1210601686.7945 - val_loss: 1268457742.0274\n",
      "Epoch 11682/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1210673808.0313 - val_loss: 1267522018.4840\n",
      "Epoch 11683/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1210498802.1605 - val_loss: 1267958049.8995\n",
      "Epoch 11684/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1210290162.5988 - val_loss: 1267930221.5890\n",
      "Epoch 11685/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1210196861.4951 - val_loss: 1267082041.2785\n",
      "Epoch 11686/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1210252266.2074 - val_loss: 1268300421.8447\n",
      "Epoch 11687/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1210446301.3072 - val_loss: 1267131024.0731\n",
      "Epoch 11688/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1210066191.9061 - val_loss: 1267798458.1553\n",
      "Epoch 11689/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1210054295.6712 - val_loss: 1267840357.1142\n",
      "Epoch 11690/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1211636811.8982 - val_loss: 1265046080.2922\n",
      "Epoch 11691/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1210377109.5421 - val_loss: 1268608365.2968\n",
      "Epoch 11692/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1211381480.0783 - val_loss: 1266365347.3607\n",
      "Epoch 11693/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1210303386.0509 - val_loss: 1268249824.4384\n",
      "Epoch 11694/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1210777593.8630 - val_loss: 1268647351.8174\n",
      "Epoch 11695/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1210056475.3033 - val_loss: 1267311406.4658\n",
      "Epoch 11696/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1210397496.8611 - val_loss: 1266559965.5160\n",
      "Epoch 11697/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1210004082.0352 - val_loss: 1268049984.5845\n",
      "Epoch 11698/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1209973709.7143 - val_loss: 1268198280.4749\n",
      "Epoch 11699/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1210093386.0196 - val_loss: 1268317062.4292\n",
      "Epoch 11700/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1209998278.2622 - val_loss: 1267351471.9269\n",
      "Epoch 11701/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1210184922.6771 - val_loss: 1268064096.1461\n",
      "Epoch 11702/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1210349578.5205 - val_loss: 1266584144.9498\n",
      "Epoch 11703/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1209904581.5734 - val_loss: 1267353845.4795\n",
      "Epoch 11704/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1209896308.7280 - val_loss: 1268108184.8402\n",
      "Epoch 11705/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1210140739.8826 - val_loss: 1267757013.6256\n",
      "Epoch 11706/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1209961858.6301 - val_loss: 1268124988.7854\n",
      "Epoch 11707/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1210090669.5890 - val_loss: 1268460754.4110\n",
      "Epoch 11708/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1210307886.5910 - val_loss: 1265898915.3607\n",
      "Epoch 11709/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1210373937.3464 - val_loss: 1268905397.1872\n",
      "Epoch 11710/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1210331718.3875 - val_loss: 1268162847.8539\n",
      "Epoch 11711/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1209957125.8865 - val_loss: 1267768081.5342\n",
      "Epoch 11712/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1210192842.5205 - val_loss: 1267851036.3470\n",
      "Epoch 11713/15000\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 1209958647.4207 - val_loss: 1267397058.0457\n",
      "Epoch 11714/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1210247723.3346 - val_loss: 1268276358.7215\n",
      "Epoch 11715/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1209903000.2975 - val_loss: 1266841573.4064\n",
      "Epoch 11716/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1209932970.4579 - val_loss: 1266891125.4795\n",
      "Epoch 11717/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1210046783.3738 - val_loss: 1267125812.3105\n",
      "Epoch 11718/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1210478962.3483 - val_loss: 1268773989.6986\n",
      "Epoch 11719/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1209846536.8924 - val_loss: 1267358201.8630\n",
      "Epoch 11720/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1210378164.8532 - val_loss: 1266931939.6530\n",
      "Epoch 11721/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1209883866.6145 - val_loss: 1267652813.4429\n",
      "Epoch 11722/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1210273974.8571 - val_loss: 1268681742.3196\n",
      "Epoch 11723/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1211324886.9198 - val_loss: 1265560965.5525\n",
      "Epoch 11724/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1210173414.7006 - val_loss: 1269142071.8174\n",
      "Epoch 11725/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1210111068.8063 - val_loss: 1268542313.2055\n",
      "Epoch 11726/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1210013663.1233 - val_loss: 1267252141.5890\n",
      "Epoch 11727/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 28us/step - loss: 1210037176.6732 - val_loss: 1266889599.4155\n",
      "Epoch 11728/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1210003509.1037 - val_loss: 1267498267.1781\n",
      "Epoch 11729/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1210220373.8552 - val_loss: 1269227121.0959\n",
      "Epoch 11730/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1210239304.8924 - val_loss: 1269177846.3562\n",
      "Epoch 11731/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1209867443.8513 - val_loss: 1268336667.1781\n",
      "Epoch 11732/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1210147016.2661 - val_loss: 1266243129.5708\n",
      "Epoch 11733/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1209928779.1468 - val_loss: 1266064392.1826\n",
      "Epoch 11734/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1210619163.0528 - val_loss: 1267299714.0457\n",
      "Epoch 11735/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1209892557.9022 - val_loss: 1267952312.9863\n",
      "Epoch 11736/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1210326865.2838 - val_loss: 1268415975.7443\n",
      "Epoch 11737/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1210147966.0587 - val_loss: 1267786415.6347\n",
      "Epoch 11738/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1209726233.8004 - val_loss: 1268022652.2009\n",
      "Epoch 11739/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1210149200.1566 - val_loss: 1268673256.9132\n",
      "Epoch 11740/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1209659909.5108 - val_loss: 1267278042.3014\n",
      "Epoch 11741/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1209945008.7202 - val_loss: 1268609485.1507\n",
      "Epoch 11742/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1210066610.3483 - val_loss: 1266402355.4338\n",
      "Epoch 11743/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1209757752.7358 - val_loss: 1267194505.9361\n",
      "Epoch 11744/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1209708333.0881 - val_loss: 1267091237.4064\n",
      "Epoch 11745/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1210244360.5166 - val_loss: 1266906074.3014\n",
      "Epoch 11746/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1210086927.9061 - val_loss: 1268251149.4429\n",
      "Epoch 11747/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1209734505.7065 - val_loss: 1267817831.1598\n",
      "Epoch 11748/15000\n",
      "1022/1022 [==============================] - 0s 78us/step - loss: 1209543377.0959 - val_loss: 1267483587.2146\n",
      "Epoch 11749/15000\n",
      "1022/1022 [==============================] - 0s 71us/step - loss: 1209620874.2701 - val_loss: 1267740797.6621\n",
      "Epoch 11750/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1209603817.7691 - val_loss: 1267965741.2968\n",
      "Epoch 11751/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1209621734.3249 - val_loss: 1267749179.9087\n",
      "Epoch 11752/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1209902207.4990 - val_loss: 1268082380.8584\n",
      "Epoch 11753/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1209660867.2564 - val_loss: 1268169692.0548\n",
      "Epoch 11754/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1209872122.8650 - val_loss: 1267501188.6758\n",
      "Epoch 11755/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1209799596.9628 - val_loss: 1267724657.6804\n",
      "Epoch 11756/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1209975367.7652 - val_loss: 1266747809.6073\n",
      "Epoch 11757/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1209631250.1605 - val_loss: 1266719189.6256\n",
      "Epoch 11758/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1209648997.9491 - val_loss: 1266561663.1233\n",
      "Epoch 11759/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1209768066.5049 - val_loss: 1267364551.8904\n",
      "Epoch 11760/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1210064035.3190 - val_loss: 1268831885.7352\n",
      "Epoch 11761/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1210061984.6888 - val_loss: 1268532607.1233\n",
      "Epoch 11762/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1210022243.9452 - val_loss: 1267102150.7215\n",
      "Epoch 11763/15000\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 1209860892.2427 - val_loss: 1267158794.2283\n",
      "Epoch 11764/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1209890222.9667 - val_loss: 1268443849.0594\n",
      "Epoch 11765/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1209819452.1174 - val_loss: 1268807436.8584\n",
      "Epoch 11766/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1210598453.6047 - val_loss: 1268574839.2329\n",
      "Epoch 11767/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1209757820.1174 - val_loss: 1266749639.3059\n",
      "Epoch 11768/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1209768239.6556 - val_loss: 1267624669.2237\n",
      "Epoch 11769/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1209691664.6575 - val_loss: 1267420180.7489\n",
      "Epoch 11770/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1209483861.9178 - val_loss: 1266914134.5023\n",
      "Epoch 11771/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1209677559.1703 - val_loss: 1268574829.5890\n",
      "Epoch 11772/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1209888699.7417 - val_loss: 1267168850.4110\n",
      "Epoch 11773/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1209651757.4638 - val_loss: 1266966098.7032\n",
      "Epoch 11774/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1210102139.2407 - val_loss: 1269065498.8858\n",
      "Epoch 11775/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1209472538.4266 - val_loss: 1267707528.1826\n",
      "Epoch 11776/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1209906631.2642 - val_loss: 1268591301.8447\n",
      "Epoch 11777/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1209396607.1233 - val_loss: 1267508079.3425\n",
      "Epoch 11778/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1210110464.0000 - val_loss: 1265615148.4201\n",
      "Epoch 11779/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1209398133.1037 - val_loss: 1266585486.6119\n",
      "Epoch 11780/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1209329501.6204 - val_loss: 1267928149.3333\n",
      "Epoch 11781/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1209705414.5127 - val_loss: 1267712490.0822\n",
      "Epoch 11782/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1209421089.6908 - val_loss: 1268381803.5434\n",
      "Epoch 11783/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1209553353.1429 - val_loss: 1268656732.9315\n",
      "Epoch 11784/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1209325717.6673 - val_loss: 1267961211.9087\n",
      "Epoch 11785/15000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1209684806.0117 - val_loss: 1267862276.6758\n",
      "Epoch 11786/15000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1209457707.2094 - val_loss: 1267181989.6986\n",
      "Epoch 11787/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1209489956.5714 - val_loss: 1267013049.2785\n",
      "Epoch 11788/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1209484163.2564 - val_loss: 1268182397.9543\n",
      "Epoch 11789/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1209615795.7260 - val_loss: 1268161007.6347\n",
      "Epoch 11790/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1209345191.9530 - val_loss: 1268079676.2009\n",
      "Epoch 11791/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 40us/step - loss: 1209859213.7769 - val_loss: 1266951199.5616\n",
      "Epoch 11792/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1209479595.8982 - val_loss: 1267879684.9680\n",
      "Epoch 11793/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1209603466.2701 - val_loss: 1266830786.9224\n",
      "Epoch 11794/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1209488802.3170 - val_loss: 1267846512.2192\n",
      "Epoch 11795/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1209312096.4384 - val_loss: 1267745773.5890\n",
      "Epoch 11796/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1209564156.3053 - val_loss: 1266591692.8584\n",
      "Epoch 11797/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1209412184.7984 - val_loss: 1267701415.1598\n",
      "Epoch 11798/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1209833930.6458 - val_loss: 1268894210.6301\n",
      "Epoch 11799/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1210373525.0411 - val_loss: 1266269051.0320\n",
      "Epoch 11800/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1209368024.1722 - val_loss: 1268241634.4840\n",
      "Epoch 11801/15000\n",
      "1022/1022 [==============================] - 0s 65us/step - loss: 1209393990.7632 - val_loss: 1267699083.6895\n",
      "Epoch 11802/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1209512046.0900 - val_loss: 1267977871.4886\n",
      "Epoch 11803/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1209650278.9511 - val_loss: 1267060975.0502\n",
      "Epoch 11804/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1209230906.1135 - val_loss: 1267630184.3288\n",
      "Epoch 11805/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1209330993.5969 - val_loss: 1268245404.9315\n",
      "Epoch 11806/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1209291240.6419 - val_loss: 1267698119.5982\n",
      "Epoch 11807/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1210018672.4697 - val_loss: 1267196992.2922\n",
      "Epoch 11808/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1209317230.4658 - val_loss: 1267015937.7534\n",
      "Epoch 11809/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1209418680.6106 - val_loss: 1267546538.6667\n",
      "Epoch 11810/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1209314874.6145 - val_loss: 1267490912.7306\n",
      "Epoch 11811/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1209442441.2681 - val_loss: 1268737558.5023\n",
      "Epoch 11812/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1209373282.6928 - val_loss: 1268634243.7991\n",
      "Epoch 11813/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1209316632.5479 - val_loss: 1267761519.3425\n",
      "Epoch 11814/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1209404810.3953 - val_loss: 1266678440.3288\n",
      "Epoch 11815/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1209123108.2583 - val_loss: 1267112891.0320\n",
      "Epoch 11816/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1209332977.3464 - val_loss: 1267046987.9817\n",
      "Epoch 11817/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1209406586.4892 - val_loss: 1268366664.1826\n",
      "Epoch 11818/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1209258941.7456 - val_loss: 1268231599.3425\n",
      "Epoch 11819/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1209192720.7828 - val_loss: 1268076216.6941\n",
      "Epoch 11820/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1209287849.9569 - val_loss: 1268064177.6804\n",
      "Epoch 11821/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1209239017.2055 - val_loss: 1268320154.0091\n",
      "Epoch 11822/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1209306114.0039 - val_loss: 1267495611.3242\n",
      "Epoch 11823/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208986201.8004 - val_loss: 1267032287.8539\n",
      "Epoch 11824/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1209318196.3523 - val_loss: 1266812700.6393\n",
      "Epoch 11825/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1209298583.7965 - val_loss: 1267157001.3516\n",
      "Epoch 11826/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1209077132.9002 - val_loss: 1267574567.4521\n",
      "Epoch 11827/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1209049636.6967 - val_loss: 1267353921.4612\n",
      "Epoch 11828/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1209515216.2818 - val_loss: 1267685054.5388\n",
      "Epoch 11829/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1209353990.0117 - val_loss: 1267874303.7078\n",
      "Epoch 11830/15000\n",
      "1022/1022 [==============================] - 0s 65us/step - loss: 1209206223.4051 - val_loss: 1268287650.1918\n",
      "Epoch 11831/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1209199390.0587 - val_loss: 1267765630.2466\n",
      "Epoch 11832/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1209173304.6106 - val_loss: 1266823973.6986\n",
      "Epoch 11833/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1209153305.0489 - val_loss: 1267788627.5799\n",
      "Epoch 11834/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1209669231.3425 - val_loss: 1267961741.1507\n",
      "Epoch 11835/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1209385091.2564 - val_loss: 1265421186.9224\n",
      "Epoch 11836/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1208832605.3072 - val_loss: 1267041915.0320\n",
      "Epoch 11837/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1209520832.6262 - val_loss: 1268100270.4658\n",
      "Epoch 11838/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1209035221.1663 - val_loss: 1268064618.3744\n",
      "Epoch 11839/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1209205194.1448 - val_loss: 1268297186.4840\n",
      "Epoch 11840/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1209296550.5127 - val_loss: 1266879408.8037\n",
      "Epoch 11841/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1209117853.4325 - val_loss: 1267803307.5434\n",
      "Epoch 11842/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1209016617.9569 - val_loss: 1267442681.5708\n",
      "Epoch 11843/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1209210745.9883 - val_loss: 1267847255.3790\n",
      "Epoch 11844/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1208900352.8767 - val_loss: 1267038216.1826\n",
      "Epoch 11845/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1209432420.4462 - val_loss: 1266939014.1370\n",
      "Epoch 11846/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1209222490.5519 - val_loss: 1266448642.3379\n",
      "Epoch 11847/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1209078172.5558 - val_loss: 1266729080.1096\n",
      "Epoch 11848/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1209049513.5812 - val_loss: 1266295945.0594\n",
      "Epoch 11849/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1209053276.3053 - val_loss: 1266562201.7169\n",
      "Epoch 11850/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208931311.2172 - val_loss: 1268165298.8493\n",
      "Epoch 11851/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1208969188.9472 - val_loss: 1267458534.2831\n",
      "Epoch 11852/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1208846892.3366 - val_loss: 1267847807.4155\n",
      "Epoch 11853/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1208859740.0548 - val_loss: 1268200830.5388\n",
      "Epoch 11854/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1209072330.7084 - val_loss: 1267823806.8311\n",
      "Epoch 11855/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1208985532.6184 - val_loss: 1266975412.3105\n",
      "Epoch 11856/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208908771.9452 - val_loss: 1267916636.6393\n",
      "Epoch 11857/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1209211003.9295 - val_loss: 1266927854.1735\n",
      "Epoch 11858/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1208899053.7143 - val_loss: 1266973468.3470\n",
      "Epoch 11859/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1209191522.9432 - val_loss: 1266365566.2466\n",
      "Epoch 11860/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1209015016.7045 - val_loss: 1268126073.2785\n",
      "Epoch 11861/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1209593712.4070 - val_loss: 1266707235.0685\n",
      "Epoch 11862/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1209561672.8924 - val_loss: 1266565420.7123\n",
      "Epoch 11863/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1208959796.4775 - val_loss: 1268359584.7306\n",
      "Epoch 11864/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1209296337.1585 - val_loss: 1266719169.4612\n",
      "Epoch 11865/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1209932986.2387 - val_loss: 1268955846.7215\n",
      "Epoch 11866/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1209145047.7965 - val_loss: 1267161776.8037\n",
      "Epoch 11867/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1209115203.3816 - val_loss: 1266553882.5936\n",
      "Epoch 11868/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1209006245.6986 - val_loss: 1267742756.2374\n",
      "Epoch 11869/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1209012285.3699 - val_loss: 1267300766.9772\n",
      "Epoch 11870/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1209183963.6791 - val_loss: 1266397791.5616\n",
      "Epoch 11871/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1208632525.1507 - val_loss: 1267352982.5023\n",
      "Epoch 11872/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1209423959.1703 - val_loss: 1265720293.9909\n",
      "Epoch 11873/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1208949188.4462 - val_loss: 1267352752.2192\n",
      "Epoch 11874/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1209175867.8669 - val_loss: 1267934426.8858\n",
      "Epoch 11875/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1208770590.3092 - val_loss: 1267190937.1324\n",
      "Epoch 11876/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1208804240.7828 - val_loss: 1267362531.6530\n",
      "Epoch 11877/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1209399812.6341 - val_loss: 1268246739.8721\n",
      "Epoch 11878/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1209244370.6614 - val_loss: 1266637346.7763\n",
      "Epoch 11879/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1208832617.2055 - val_loss: 1267565919.8539\n",
      "Epoch 11880/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1209394969.0489 - val_loss: 1268627024.9498\n",
      "Epoch 11881/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1209045731.4442 - val_loss: 1266144408.5479\n",
      "Epoch 11882/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1208997931.9609 - val_loss: 1267884471.5251\n",
      "Epoch 11883/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208694670.7789 - val_loss: 1266548531.1416\n",
      "Epoch 11884/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1208880984.2975 - val_loss: 1268089907.7260\n",
      "Epoch 11885/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1209433160.1409 - val_loss: 1268522083.3607\n",
      "Epoch 11886/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1209098647.1703 - val_loss: 1267094914.6301\n",
      "Epoch 11887/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1209649919.3738 - val_loss: 1265319739.3242\n",
      "Epoch 11888/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1209293112.3601 - val_loss: 1267038974.2466\n",
      "Epoch 11889/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1209221609.9569 - val_loss: 1269421731.0685\n",
      "Epoch 11890/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208784421.5108 - val_loss: 1267059527.8904\n",
      "Epoch 11891/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208939919.7808 - val_loss: 1267779276.5662\n",
      "Epoch 11892/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1209433347.0059 - val_loss: 1265955050.6667\n",
      "Epoch 11893/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1209250208.5636 - val_loss: 1268375641.1324\n",
      "Epoch 11894/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1208826144.3131 - val_loss: 1266811465.6438\n",
      "Epoch 11895/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1209182322.2231 - val_loss: 1265414066.5571\n",
      "Epoch 11896/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1209596782.4658 - val_loss: 1268861065.6438\n",
      "Epoch 11897/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1208503344.8454 - val_loss: 1267695056.6575\n",
      "Epoch 11898/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1209120833.1272 - val_loss: 1266051031.3790\n",
      "Epoch 11899/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208664915.9765 - val_loss: 1267792781.7352\n",
      "Epoch 11900/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1208890944.2505 - val_loss: 1266574837.1872\n",
      "Epoch 11901/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208467439.5930 - val_loss: 1267241423.1963\n",
      "Epoch 11902/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1208600250.8023 - val_loss: 1267920838.7215\n",
      "Epoch 11903/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208911421.9961 - val_loss: 1266505278.8311\n",
      "Epoch 11904/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1208771117.2759 - val_loss: 1266873487.7808\n",
      "Epoch 11905/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1208614187.0841 - val_loss: 1266875755.5434\n",
      "Epoch 11906/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1208733903.2798 - val_loss: 1267762704.9498\n",
      "Epoch 11907/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1208581512.6419 - val_loss: 1267461748.8950\n",
      "Epoch 11908/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1209212705.0646 - val_loss: 1268577320.6210\n",
      "Epoch 11909/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1209511273.7065 - val_loss: 1266937470.2466\n",
      "Epoch 11910/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1209144572.9941 - val_loss: 1268094106.0091\n",
      "Epoch 11911/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1208502903.9843 - val_loss: 1267458937.8630\n",
      "Epoch 11912/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1208506570.5832 - val_loss: 1267106180.6758\n",
      "Epoch 11913/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1208788120.9237 - val_loss: 1267303043.7991\n",
      "Epoch 11914/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1208782932.1644 - val_loss: 1266897893.4064\n",
      "Epoch 11915/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1209026671.2172 - val_loss: 1266149576.4749\n",
      "Epoch 11916/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1208682659.3190 - val_loss: 1266332772.2374\n",
      "Epoch 11917/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1208501996.5871 - val_loss: 1267759689.3516\n",
      "Epoch 11918/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1208374969.9883 - val_loss: 1267752426.0822\n",
      "Epoch 11919/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 37us/step - loss: 1208601586.4736 - val_loss: 1267590498.4840\n",
      "Epoch 11920/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1208489707.7104 - val_loss: 1267393208.6941\n",
      "Epoch 11921/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1208760846.0900 - val_loss: 1266483021.1507\n",
      "Epoch 11922/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1209306900.5401 - val_loss: 1269310472.4749\n",
      "Epoch 11923/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1208778943.3738 - val_loss: 1268118071.5251\n",
      "Epoch 11924/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1208867839.7495 - val_loss: 1265913635.3607\n",
      "Epoch 11925/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1208481102.0274 - val_loss: 1266773504.8767\n",
      "Epoch 11926/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1209139861.0411 - val_loss: 1266289337.5708\n",
      "Epoch 11927/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1209408473.1742 - val_loss: 1265888717.1507\n",
      "Epoch 11928/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1209689859.2564 - val_loss: 1269349055.4155\n",
      "Epoch 11929/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1208593856.2505 - val_loss: 1268271540.6027\n",
      "Epoch 11930/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1208895012.0705 - val_loss: 1267001199.6347\n",
      "Epoch 11931/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1208769923.2564 - val_loss: 1267485190.4292\n",
      "Epoch 11932/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1208416337.9100 - val_loss: 1267649761.3151\n",
      "Epoch 11933/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1209068305.5342 - val_loss: 1265583120.3653\n",
      "Epoch 11934/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1208265034.8337 - val_loss: 1267199162.1553\n",
      "Epoch 11935/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1208461236.1018 - val_loss: 1267650367.1233\n",
      "Epoch 11936/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1208475995.4286 - val_loss: 1267866791.7443\n",
      "Epoch 11937/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1208358327.4834 - val_loss: 1267289097.6438\n",
      "Epoch 11938/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1208869292.8376 - val_loss: 1265865372.6393\n",
      "Epoch 11939/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1208582675.0372 - val_loss: 1267832129.4612\n",
      "Epoch 11940/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1208868283.4912 - val_loss: 1265967951.7808\n",
      "Epoch 11941/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1208278166.5440 - val_loss: 1267219466.8128\n",
      "Epoch 11942/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1208253418.7084 - val_loss: 1267769174.2100\n",
      "Epoch 11943/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1208465324.3366 - val_loss: 1266868292.6758\n",
      "Epoch 11944/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1208429691.4286 - val_loss: 1267215974.5753\n",
      "Epoch 11945/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1208286676.4149 - val_loss: 1267489262.1735\n",
      "Epoch 11946/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208245843.2877 - val_loss: 1266721488.0731\n",
      "Epoch 11947/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208590480.2818 - val_loss: 1267614695.7443\n",
      "Epoch 11948/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1208557576.2661 - val_loss: 1266573664.7306\n",
      "Epoch 11949/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208551156.4775 - val_loss: 1267813414.5753\n",
      "Epoch 11950/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1208206546.1605 - val_loss: 1267227996.9315\n",
      "Epoch 11951/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1208265351.8904 - val_loss: 1266967165.3699\n",
      "Epoch 11952/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208481801.1429 - val_loss: 1266863895.3790\n",
      "Epoch 11953/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1208380095.4990 - val_loss: 1267273973.1872\n",
      "Epoch 11954/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1209510455.1076 - val_loss: 1264965079.3790\n",
      "Epoch 11955/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1209559211.6477 - val_loss: 1269019023.1963\n",
      "Epoch 11956/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1208506713.5499 - val_loss: 1266737246.3927\n",
      "Epoch 11957/15000\n",
      "1022/1022 [==============================] - 0s 71us/step - loss: 1208537802.5205 - val_loss: 1265917008.6575\n",
      "Epoch 11958/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1208283402.7710 - val_loss: 1266951994.4475\n",
      "Epoch 11959/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1208376971.5225 - val_loss: 1267800450.3379\n",
      "Epoch 11960/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1208618171.1155 - val_loss: 1267868792.1096\n",
      "Epoch 11961/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1208718265.1115 - val_loss: 1266260742.1370\n",
      "Epoch 11962/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1208959803.8669 - val_loss: 1268863515.1781\n",
      "Epoch 11963/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208133513.7691 - val_loss: 1266710151.0137\n",
      "Epoch 11964/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208090186.6458 - val_loss: 1267149656.8402\n",
      "Epoch 11965/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208242372.4462 - val_loss: 1267475652.6758\n",
      "Epoch 11966/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1208050710.5440 - val_loss: 1267598638.1735\n",
      "Epoch 11967/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1208274702.2779 - val_loss: 1267367139.6530\n",
      "Epoch 11968/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1209416700.7436 - val_loss: 1268322248.7671\n",
      "Epoch 11969/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1208183925.9804 - val_loss: 1267163969.7534\n",
      "Epoch 11970/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1208339141.3855 - val_loss: 1266973921.6073\n",
      "Epoch 11971/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1208264434.3483 - val_loss: 1266539428.8219\n",
      "Epoch 11972/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1207932741.0098 - val_loss: 1266946409.4977\n",
      "Epoch 11973/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1208361457.2211 - val_loss: 1267939940.8219\n",
      "Epoch 11974/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1208165819.6164 - val_loss: 1267017077.4795\n",
      "Epoch 11975/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1208245182.2466 - val_loss: 1266047222.0639\n",
      "Epoch 11976/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1208231384.9237 - val_loss: 1265584032.1461\n",
      "Epoch 11977/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1208246225.0333 - val_loss: 1267304463.4886\n",
      "Epoch 11978/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1208275159.1703 - val_loss: 1268638381.8813\n",
      "Epoch 11979/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1208570129.7847 - val_loss: 1267392410.3014\n",
      "Epoch 11980/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1208567149.0254 - val_loss: 1268180504.5479\n",
      "Epoch 11981/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1209015250.5362 - val_loss: 1266331788.5662\n",
      "Epoch 11982/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1208293679.8434 - val_loss: 1267770951.3059\n",
      "Epoch 11983/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208203322.6145 - val_loss: 1266686810.0091\n",
      "Epoch 11984/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208639426.1292 - val_loss: 1267701468.6393\n",
      "Epoch 11985/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208194735.2172 - val_loss: 1266715929.7169\n",
      "Epoch 11986/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1208671619.0059 - val_loss: 1267873553.2420\n",
      "Epoch 11987/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208024917.9804 - val_loss: 1267139887.9269\n",
      "Epoch 11988/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1209497567.0607 - val_loss: 1264779980.5662\n",
      "Epoch 11989/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208400315.2407 - val_loss: 1267466368.2922\n",
      "Epoch 11990/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207959868.4932 - val_loss: 1266823213.8813\n",
      "Epoch 11991/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1208327579.3033 - val_loss: 1267168800.1461\n",
      "Epoch 11992/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1207854472.5166 - val_loss: 1267480927.8539\n",
      "Epoch 11993/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208186887.5147 - val_loss: 1267090080.4384\n",
      "Epoch 11994/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1208005844.5401 - val_loss: 1267664981.6256\n",
      "Epoch 11995/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207965800.2035 - val_loss: 1267516115.8721\n",
      "Epoch 11996/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1208123429.0724 - val_loss: 1268119557.8447\n",
      "Epoch 11997/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1207898807.3581 - val_loss: 1267307256.9863\n",
      "Epoch 11998/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1207960409.8004 - val_loss: 1266871831.3790\n",
      "Epoch 11999/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1208291561.3307 - val_loss: 1267776514.3379\n",
      "Epoch 12000/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1208197871.4677 - val_loss: 1266087002.5936\n",
      "Epoch 12001/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208218866.9119 - val_loss: 1267412486.1370\n",
      "Epoch 12002/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1208122919.8278 - val_loss: 1267298040.6941\n",
      "Epoch 12003/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208342512.4697 - val_loss: 1265991047.8904\n",
      "Epoch 12004/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208279595.4599 - val_loss: 1267439336.0365\n",
      "Epoch 12005/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1207869745.8474 - val_loss: 1267302568.9132\n",
      "Epoch 12006/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208091001.8630 - val_loss: 1266133036.1279\n",
      "Epoch 12007/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1208300978.3483 - val_loss: 1267211253.4795\n",
      "Epoch 12008/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208363370.7084 - val_loss: 1267146407.1598\n",
      "Epoch 12009/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1208154657.3151 - val_loss: 1265556306.1187\n",
      "Epoch 12010/15000\n",
      "1022/1022 [==============================] - 0s 85us/step - loss: 1208089069.9648 - val_loss: 1266230199.2329\n",
      "Epoch 12011/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207824652.6497 - val_loss: 1267624832.2922\n",
      "Epoch 12012/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207845953.1272 - val_loss: 1267952662.2100\n",
      "Epoch 12013/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207886646.3562 - val_loss: 1267248298.6667\n",
      "Epoch 12014/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1208000143.6556 - val_loss: 1265696872.3288\n",
      "Epoch 12015/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207980261.6986 - val_loss: 1267175887.7808\n",
      "Epoch 12016/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208453240.9863 - val_loss: 1265459802.8858\n",
      "Epoch 12017/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1208366355.9139 - val_loss: 1266949341.2237\n",
      "Epoch 12018/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207864224.1879 - val_loss: 1268259115.2511\n",
      "Epoch 12019/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1207958813.3072 - val_loss: 1267074827.6895\n",
      "Epoch 12020/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1208088158.6849 - val_loss: 1267797923.3607\n",
      "Epoch 12021/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1208203999.4364 - val_loss: 1266054884.8219\n",
      "Epoch 12022/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207934627.3190 - val_loss: 1266376576.2922\n",
      "Epoch 12023/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1207706711.9217 - val_loss: 1267720514.3379\n",
      "Epoch 12024/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1208028139.1468 - val_loss: 1268188579.3607\n",
      "Epoch 12025/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1208072546.8180 - val_loss: 1267413944.6941\n",
      "Epoch 12026/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208342099.6634 - val_loss: 1268642462.9772\n",
      "Epoch 12027/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1207787607.6712 - val_loss: 1266059823.3425\n",
      "Epoch 12028/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208098512.9080 - val_loss: 1265740172.8584\n",
      "Epoch 12029/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207678596.0078 - val_loss: 1267223969.3151\n",
      "Epoch 12030/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208179518.3718 - val_loss: 1268320584.4749\n",
      "Epoch 12031/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207525436.3053 - val_loss: 1266524198.8676\n",
      "Epoch 12032/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1208114193.7847 - val_loss: 1266096035.3607\n",
      "Epoch 12033/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208588883.6634 - val_loss: 1267912267.6895\n",
      "Epoch 12034/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208153844.3523 - val_loss: 1266117426.8493\n",
      "Epoch 12035/15000\n",
      "1022/1022 [==============================] - 0s 77us/step - loss: 1207941572.8219 - val_loss: 1267673874.4110\n",
      "Epoch 12036/15000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1207958284.2740 - val_loss: 1266231260.9315\n",
      "Epoch 12037/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1208241408.3131 - val_loss: 1265940370.9954\n",
      "Epoch 12038/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1207536175.2172 - val_loss: 1267347791.1963\n",
      "Epoch 12039/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1207989046.9824 - val_loss: 1266127642.0091\n",
      "Epoch 12040/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1207553260.7123 - val_loss: 1267624547.3607\n",
      "Epoch 12041/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207721689.0489 - val_loss: 1266517060.6758\n",
      "Epoch 12042/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1207534090.1448 - val_loss: 1266794939.3242\n",
      "Epoch 12043/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1208100205.4638 - val_loss: 1266698840.8402\n",
      "Epoch 12044/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1207876021.1037 - val_loss: 1268171961.5708\n",
      "Epoch 12045/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1207722248.1409 - val_loss: 1266848630.0639\n",
      "Epoch 12046/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1207812132.0705 - val_loss: 1265816370.5571\n",
      "Epoch 12047/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1207598761.0176 - val_loss: 1267747708.2009\n",
      "Epoch 12048/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1207607168.2505 - val_loss: 1267693101.8813\n",
      "Epoch 12049/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208750350.5910 - val_loss: 1267562730.6667\n",
      "Epoch 12050/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207926090.2074 - val_loss: 1267728896.0000\n",
      "Epoch 12051/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1207490830.4031 - val_loss: 1267044729.8630\n",
      "Epoch 12052/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1207883453.9335 - val_loss: 1267061497.2785\n",
      "Epoch 12053/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207492031.3738 - val_loss: 1267271261.2237\n",
      "Epoch 12054/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207566428.9941 - val_loss: 1266350449.0959\n",
      "Epoch 12055/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207915021.0881 - val_loss: 1266627427.9452\n",
      "Epoch 12056/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207582199.9843 - val_loss: 1265798496.7306\n",
      "Epoch 12057/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207682403.1937 - val_loss: 1266439239.8904\n",
      "Epoch 12058/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207557620.0391 - val_loss: 1266702333.0776\n",
      "Epoch 12059/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1207657718.9824 - val_loss: 1268483230.9772\n",
      "Epoch 12060/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1207400281.5499 - val_loss: 1267649561.1324\n",
      "Epoch 12061/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207657370.6771 - val_loss: 1268479933.0776\n",
      "Epoch 12062/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1207347549.7456 - val_loss: 1267504220.3470\n",
      "Epoch 12063/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207894188.8376 - val_loss: 1268071367.5982\n",
      "Epoch 12064/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207848296.9550 - val_loss: 1267477571.7991\n",
      "Epoch 12065/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1207332610.2544 - val_loss: 1267046807.6712\n",
      "Epoch 12066/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1207508855.4834 - val_loss: 1267580866.6301\n",
      "Epoch 12067/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1207436610.6301 - val_loss: 1266837116.2009\n",
      "Epoch 12068/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207719353.1115 - val_loss: 1265847122.1187\n",
      "Epoch 12069/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207426468.0705 - val_loss: 1266413384.4749\n",
      "Epoch 12070/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207842662.1996 - val_loss: 1265465569.3151\n",
      "Epoch 12071/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1208113814.7945 - val_loss: 1265166992.0731\n",
      "Epoch 12072/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207901770.7084 - val_loss: 1268374083.7991\n",
      "Epoch 12073/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208001315.5695 - val_loss: 1266025421.1507\n",
      "Epoch 12074/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207449912.1722 - val_loss: 1266859468.2740\n",
      "Epoch 12075/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1207496131.6321 - val_loss: 1266656712.1826\n",
      "Epoch 12076/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1207572862.4971 - val_loss: 1268074635.6895\n",
      "Epoch 12077/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207540522.2074 - val_loss: 1268524064.1461\n",
      "Epoch 12078/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208106304.0000 - val_loss: 1268694281.6438\n",
      "Epoch 12079/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207391870.4344 - val_loss: 1267172903.7443\n",
      "Epoch 12080/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207931114.8337 - val_loss: 1266349049.8630\n",
      "Epoch 12081/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207877758.8728 - val_loss: 1266931701.7717\n",
      "Epoch 12082/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1207670197.1663 - val_loss: 1266349117.9543\n",
      "Epoch 12083/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1207334427.3033 - val_loss: 1267549954.9224\n",
      "Epoch 12084/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1207361982.5597 - val_loss: 1266504060.2009\n",
      "Epoch 12085/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1207442551.0450 - val_loss: 1266907693.0046\n",
      "Epoch 12086/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1208225057.1898 - val_loss: 1267876997.8447\n",
      "Epoch 12087/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1207548298.8337 - val_loss: 1267902979.7991\n",
      "Epoch 12088/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1207164571.5538 - val_loss: 1267068868.3836\n",
      "Epoch 12089/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1207326333.1194 - val_loss: 1266779927.0868\n",
      "Epoch 12090/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1207957011.0998 - val_loss: 1267531078.4292\n",
      "Epoch 12091/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1207697969.4090 - val_loss: 1266552113.0959\n",
      "Epoch 12092/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207449036.9002 - val_loss: 1266803503.3425\n",
      "Epoch 12093/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1207256863.6869 - val_loss: 1267008796.6393\n",
      "Epoch 12094/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1207167312.0313 - val_loss: 1267788450.7763\n",
      "Epoch 12095/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1207407263.6869 - val_loss: 1266456832.2922\n",
      "Epoch 12096/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1207831897.5499 - val_loss: 1265364661.1872\n",
      "Epoch 12097/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1208448892.4932 - val_loss: 1268468103.0137\n",
      "Epoch 12098/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1208001188.9472 - val_loss: 1267412178.9954\n",
      "Epoch 12099/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207180463.7808 - val_loss: 1267862810.0091\n",
      "Epoch 12100/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1207270966.2935 - val_loss: 1266910379.5434\n",
      "Epoch 12101/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1207299568.4697 - val_loss: 1267824251.9087\n",
      "Epoch 12102/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1207784265.0176 - val_loss: 1265755723.6895\n",
      "Epoch 12103/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1207410629.6360 - val_loss: 1267705761.8995\n",
      "Epoch 12104/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1207093213.9335 - val_loss: 1267339482.3014\n",
      "Epoch 12105/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1207472790.2935 - val_loss: 1267449609.3516\n",
      "Epoch 12106/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1207375888.8454 - val_loss: 1267673987.5068\n",
      "Epoch 12107/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1207107185.7221 - val_loss: 1267240644.6758\n",
      "Epoch 12108/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1207918398.7476 - val_loss: 1267525330.7032\n",
      "Epoch 12109/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1207176745.2055 - val_loss: 1266122807.2329\n",
      "Epoch 12110/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1207565330.5362 - val_loss: 1267801284.0913\n",
      "Epoch 12111/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 28us/step - loss: 1207714996.7280 - val_loss: 1265492864.2922\n",
      "Epoch 12112/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208004401.5969 - val_loss: 1263998508.4201\n",
      "Epoch 12113/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1206968456.6419 - val_loss: 1266894718.8311\n",
      "Epoch 12114/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1207210639.0294 - val_loss: 1266975395.6530\n",
      "Epoch 12115/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1207569772.3366 - val_loss: 1267881750.5023\n",
      "Epoch 12116/15000\n",
      "1022/1022 [==============================] - 0s 73us/step - loss: 1207293733.3229 - val_loss: 1267645920.4384\n",
      "Epoch 12117/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1207107184.9706 - val_loss: 1266757843.2877\n",
      "Epoch 12118/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207226179.0059 - val_loss: 1266561981.3699\n",
      "Epoch 12119/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207657513.1429 - val_loss: 1266550907.3242\n",
      "Epoch 12120/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1207010960.1566 - val_loss: 1266673189.4064\n",
      "Epoch 12121/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207052355.8826 - val_loss: 1267590848.8767\n",
      "Epoch 12122/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1207624350.9354 - val_loss: 1267619940.8219\n",
      "Epoch 12123/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1208329137.9726 - val_loss: 1265651125.4795\n",
      "Epoch 12124/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1206995037.6204 - val_loss: 1267921642.6667\n",
      "Epoch 12125/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1207247304.2035 - val_loss: 1268015306.5205\n",
      "Epoch 12126/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1207857749.1663 - val_loss: 1266667572.3105\n",
      "Epoch 12127/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1207340600.1096 - val_loss: 1268390351.4886\n",
      "Epoch 12128/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1207188146.3483 - val_loss: 1268638183.7443\n",
      "Epoch 12129/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1206926215.5147 - val_loss: 1267804088.4018\n",
      "Epoch 12130/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207378971.5538 - val_loss: 1267760372.6027\n",
      "Epoch 12131/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207063845.0724 - val_loss: 1266945184.4384\n",
      "Epoch 12132/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207045440.8767 - val_loss: 1265904035.3607\n",
      "Epoch 12133/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207536344.6732 - val_loss: 1268068640.7306\n",
      "Epoch 12134/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1207974422.9198 - val_loss: 1264842568.7671\n",
      "Epoch 12135/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1207181362.7241 - val_loss: 1267284708.2374\n",
      "Epoch 12136/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1207630646.3562 - val_loss: 1267863883.6895\n",
      "Epoch 12137/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207033843.9139 - val_loss: 1266808735.5616\n",
      "Epoch 12138/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1207300570.6771 - val_loss: 1265781759.7078\n",
      "Epoch 12139/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207662284.6497 - val_loss: 1267799421.6621\n",
      "Epoch 12140/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1207171625.2055 - val_loss: 1265999933.9543\n",
      "Epoch 12141/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207046775.2329 - val_loss: 1267243986.1187\n",
      "Epoch 12142/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1206924267.7104 - val_loss: 1266978027.2511\n",
      "Epoch 12143/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1206909844.7906 - val_loss: 1266750902.0639\n",
      "Epoch 12144/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1206945855.4990 - val_loss: 1266843198.8311\n",
      "Epoch 12145/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1206796741.8865 - val_loss: 1266793423.7808\n",
      "Epoch 12146/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207063281.5969 - val_loss: 1266901603.3607\n",
      "Epoch 12147/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1206921173.9178 - val_loss: 1267167844.2374\n",
      "Epoch 12148/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1206916258.5675 - val_loss: 1267624111.0502\n",
      "Epoch 12149/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1206989287.4521 - val_loss: 1267256003.5068\n",
      "Epoch 12150/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207511211.2720 - val_loss: 1265561066.0822\n",
      "Epoch 12151/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207107608.4227 - val_loss: 1267355904.2922\n",
      "Epoch 12152/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1207050662.7632 - val_loss: 1267784317.0776\n",
      "Epoch 12153/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207030442.0196 - val_loss: 1266587481.7169\n",
      "Epoch 12154/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207360610.1918 - val_loss: 1268507361.3151\n",
      "Epoch 12155/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1206980444.7436 - val_loss: 1266715091.8721\n",
      "Epoch 12156/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1206714275.5695 - val_loss: 1266389888.8767\n",
      "Epoch 12157/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1206802941.9961 - val_loss: 1266184722.1187\n",
      "Epoch 12158/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1206911313.5342 - val_loss: 1266641952.7306\n",
      "Epoch 12159/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207006412.0235 - val_loss: 1268102301.8082\n",
      "Epoch 12160/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1207105918.2466 - val_loss: 1266498949.2603\n",
      "Epoch 12161/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1206892677.3855 - val_loss: 1267066041.8630\n",
      "Epoch 12162/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1207424334.4031 - val_loss: 1268441552.9498\n",
      "Epoch 12163/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1206945477.1350 - val_loss: 1267240649.0594\n",
      "Epoch 12164/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207169595.3659 - val_loss: 1265953215.4155\n",
      "Epoch 12165/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1207706731.0841 - val_loss: 1266004296.4749\n",
      "Epoch 12166/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1206635376.0939 - val_loss: 1266893719.0868\n",
      "Epoch 12167/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207092531.6008 - val_loss: 1267175973.4064\n",
      "Epoch 12168/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1206980235.5225 - val_loss: 1268243846.1370\n",
      "Epoch 12169/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1206900150.1057 - val_loss: 1267418503.3059\n",
      "Epoch 12170/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1206593490.5988 - val_loss: 1266786731.5434\n",
      "Epoch 12171/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207070686.6849 - val_loss: 1265827993.1324\n",
      "Epoch 12172/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1206681749.2916 - val_loss: 1265787444.8950\n",
      "Epoch 12173/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1206784491.0215 - val_loss: 1266860752.6575\n",
      "Epoch 12174/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1206814052.1957 - val_loss: 1266876513.3151\n",
      "Epoch 12175/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207107526.8885 - val_loss: 1266498211.0685\n",
      "Epoch 12176/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1206851286.4188 - val_loss: 1267528177.3881\n",
      "Epoch 12177/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1206961593.3620 - val_loss: 1267735796.3105\n",
      "Epoch 12178/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1206823145.9569 - val_loss: 1266730348.7123\n",
      "Epoch 12179/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1206732854.6067 - val_loss: 1267736786.4110\n",
      "Epoch 12180/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1206942426.6771 - val_loss: 1267899266.3379\n",
      "Epoch 12181/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207510732.2740 - val_loss: 1267855124.7489\n",
      "Epoch 12182/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1207306186.5832 - val_loss: 1266425990.4292\n",
      "Epoch 12183/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1206815346.6614 - val_loss: 1266947051.8356\n",
      "Epoch 12184/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1206647674.1135 - val_loss: 1266092909.5890\n",
      "Epoch 12185/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1206586572.9628 - val_loss: 1267101855.8539\n",
      "Epoch 12186/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1206678631.2016 - val_loss: 1266953911.2329\n",
      "Epoch 12187/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1206586813.4951 - val_loss: 1266325455.1963\n",
      "Epoch 12188/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1206579863.5460 - val_loss: 1267390806.5023\n",
      "Epoch 12189/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1206520328.7671 - val_loss: 1266835627.8356\n",
      "Epoch 12190/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1206995408.1566 - val_loss: 1267518158.3196\n",
      "Epoch 12191/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1207257866.0196 - val_loss: 1268372414.2466\n",
      "Epoch 12192/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1206485117.4951 - val_loss: 1267002089.2055\n",
      "Epoch 12193/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1206592389.8239 - val_loss: 1267551446.2100\n",
      "Epoch 12194/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1207236553.6438 - val_loss: 1267927855.9269\n",
      "Epoch 12195/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1207256765.4951 - val_loss: 1266837371.6164\n",
      "Epoch 12196/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1206565450.7710 - val_loss: 1266987856.3653\n",
      "Epoch 12197/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1206673424.6888 - val_loss: 1266089886.9772\n",
      "Epoch 12198/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1206658464.6888 - val_loss: 1265787922.1187\n",
      "Epoch 12199/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1206475548.8063 - val_loss: 1266703523.9452\n",
      "Epoch 12200/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1207065712.0939 - val_loss: 1268007668.8950\n",
      "Epoch 12201/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1206606167.0450 - val_loss: 1267596636.6393\n",
      "Epoch 12202/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1206734884.4462 - val_loss: 1267601936.6575\n",
      "Epoch 12203/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1206871670.9824 - val_loss: 1266806638.7580\n",
      "Epoch 12204/15000\n",
      "1022/1022 [==============================] - 0s 72us/step - loss: 1206953116.1800 - val_loss: 1265705398.6484\n",
      "Epoch 12205/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1206432852.1644 - val_loss: 1266855172.9680\n",
      "Epoch 12206/15000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1207050402.5675 - val_loss: 1267411529.6438\n",
      "Epoch 12207/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1206616131.1937 - val_loss: 1267287123.5799\n",
      "Epoch 12208/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1206465398.6693 - val_loss: 1266870825.2055\n",
      "Epoch 12209/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1206384848.1566 - val_loss: 1267021785.1324\n",
      "Epoch 12210/15000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1207193882.0509 - val_loss: 1266367496.1826\n",
      "Epoch 12211/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1206910284.0235 - val_loss: 1267454101.0411\n",
      "Epoch 12212/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1206911118.5910 - val_loss: 1267527186.4110\n",
      "Epoch 12213/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1206657917.4951 - val_loss: 1267475671.9635\n",
      "Epoch 12214/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1206621596.8063 - val_loss: 1266187078.4292\n",
      "Epoch 12215/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1207114673.0959 - val_loss: 1268181204.4566\n",
      "Epoch 12216/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1206448768.2505 - val_loss: 1265790195.7260\n",
      "Epoch 12217/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1206377837.2133 - val_loss: 1266403944.3288\n",
      "Epoch 12218/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1206515843.8826 - val_loss: 1266245500.2009\n",
      "Epoch 12219/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1206869269.0411 - val_loss: 1267172432.3653\n",
      "Epoch 12220/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1206647424.2505 - val_loss: 1267881164.8584\n",
      "Epoch 12221/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1206664948.6027 - val_loss: 1267072206.9041\n",
      "Epoch 12222/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1206865628.3053 - val_loss: 1266220416.5845\n",
      "Epoch 12223/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1206539311.7182 - val_loss: 1266728136.1826\n",
      "Epoch 12224/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1206638788.5088 - val_loss: 1265738021.1142\n",
      "Epoch 12225/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1206404382.4344 - val_loss: 1266503341.2968\n",
      "Epoch 12226/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1206654945.9413 - val_loss: 1267878662.7215\n",
      "Epoch 12227/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1206377435.1781 - val_loss: 1266116881.8265\n",
      "Epoch 12228/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1206284344.1096 - val_loss: 1266314120.7671\n",
      "Epoch 12229/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1206678000.2192 - val_loss: 1267521274.1553\n",
      "Epoch 12230/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1206761427.9139 - val_loss: 1265951483.3242\n",
      "Epoch 12231/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1206245918.8102 - val_loss: 1267196879.7808\n",
      "Epoch 12232/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1206478669.6517 - val_loss: 1266772450.1918\n",
      "Epoch 12233/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1206324660.9159 - val_loss: 1267207855.9269\n",
      "Epoch 12234/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1206427981.6517 - val_loss: 1265907182.4658\n",
      "Epoch 12235/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1206301411.9452 - val_loss: 1267167433.9361\n",
      "Epoch 12236/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1206437552.0939 - val_loss: 1268569240.5479\n",
      "Epoch 12237/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1206624772.1331 - val_loss: 1267371467.3973\n",
      "Epoch 12238/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1207757351.3268 - val_loss: 1266924397.2968\n",
      "Epoch 12239/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 28us/step - loss: 1206418041.4873 - val_loss: 1266080276.4566\n",
      "Epoch 12240/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1206245990.5753 - val_loss: 1267251923.5799\n",
      "Epoch 12241/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1206758469.1350 - val_loss: 1266447172.0913\n",
      "Epoch 12242/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1206359472.5949 - val_loss: 1267131827.7260\n",
      "Epoch 12243/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1206437170.9746 - val_loss: 1265806994.1187\n",
      "Epoch 12244/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1207194421.3542 - val_loss: 1267553708.7123\n",
      "Epoch 12245/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1206426917.0724 - val_loss: 1268467021.1507\n",
      "Epoch 12246/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1206163318.9824 - val_loss: 1266974160.6575\n",
      "Epoch 12247/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1206276089.7378 - val_loss: 1267269582.6119\n",
      "Epoch 12248/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1206269896.9550 - val_loss: 1266933889.1689\n",
      "Epoch 12249/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1206213152.6888 - val_loss: 1266077947.3242\n",
      "Epoch 12250/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1206216707.0059 - val_loss: 1266863453.5160\n",
      "Epoch 12251/15000\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 1206292224.2505 - val_loss: 1267650854.5753\n",
      "Epoch 12252/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1206253176.2348 - val_loss: 1267569382.8676\n",
      "Epoch 12253/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1206357535.6869 - val_loss: 1265666478.7580\n",
      "Epoch 12254/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1206524087.7339 - val_loss: 1267148441.1324\n",
      "Epoch 12255/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1206572141.2133 - val_loss: 1267682796.1279\n",
      "Epoch 12256/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1206441081.7378 - val_loss: 1266525462.5023\n",
      "Epoch 12257/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1206089409.8787 - val_loss: 1266318582.3562\n",
      "Epoch 12258/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1206718101.5421 - val_loss: 1266746660.2374\n",
      "Epoch 12259/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1206166867.6634 - val_loss: 1266225481.6438\n",
      "Epoch 12260/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1206411933.1194 - val_loss: 1267510953.7900\n",
      "Epoch 12261/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1206278652.4932 - val_loss: 1267138119.5982\n",
      "Epoch 12262/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1206913435.3033 - val_loss: 1267694516.3105\n",
      "Epoch 12263/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1206505050.6771 - val_loss: 1266634360.1096\n",
      "Epoch 12264/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1206128615.9530 - val_loss: 1265641524.8950\n",
      "Epoch 12265/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1206598687.3112 - val_loss: 1267205110.6484\n",
      "Epoch 12266/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1206368756.9785 - val_loss: 1265771039.8539\n",
      "Epoch 12267/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1206515181.4638 - val_loss: 1267909856.4384\n",
      "Epoch 12268/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1206333077.0411 - val_loss: 1265675330.9224\n",
      "Epoch 12269/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1206406780.4932 - val_loss: 1266593002.6667\n",
      "Epoch 12270/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1206298730.8963 - val_loss: 1266512981.3333\n",
      "Epoch 12271/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1205962493.6830 - val_loss: 1267084918.6484\n",
      "Epoch 12272/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1206492844.0861 - val_loss: 1267743387.4703\n",
      "Epoch 12273/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1206314645.7926 - val_loss: 1267706376.7671\n",
      "Epoch 12274/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1206258677.3542 - val_loss: 1265814161.2420\n",
      "Epoch 12275/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1206535354.4892 - val_loss: 1267711505.8265\n",
      "Epoch 12276/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1205982341.2603 - val_loss: 1266281786.4475\n",
      "Epoch 12277/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1206076828.8063 - val_loss: 1266484361.0594\n",
      "Epoch 12278/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1206053524.5401 - val_loss: 1266523889.0959\n",
      "Epoch 12279/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1206164035.5068 - val_loss: 1266228853.4795\n",
      "Epoch 12280/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1206576976.6575 - val_loss: 1266589505.1689\n",
      "Epoch 12281/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1206698462.9354 - val_loss: 1268061403.1781\n",
      "Epoch 12282/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1206713997.0254 - val_loss: 1266619119.3425\n",
      "Epoch 12283/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1206460149.4795 - val_loss: 1267986950.4292\n",
      "Epoch 12284/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1205839024.8454 - val_loss: 1267017027.2146\n",
      "Epoch 12285/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1206506076.3679 - val_loss: 1265020332.4201\n",
      "Epoch 12286/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1205919707.6791 - val_loss: 1266568754.5571\n",
      "Epoch 12287/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1205850716.3053 - val_loss: 1266844242.4110\n",
      "Epoch 12288/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1206082279.9530 - val_loss: 1266453631.7078\n",
      "Epoch 12289/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1206155946.8337 - val_loss: 1268215750.1370\n",
      "Epoch 12290/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1206495253.8552 - val_loss: 1266719119.7808\n",
      "Epoch 12291/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1206113187.1937 - val_loss: 1266170887.8904\n",
      "Epoch 12292/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1205956026.6145 - val_loss: 1267343030.9406\n",
      "Epoch 12293/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1206334876.8063 - val_loss: 1266588280.1096\n",
      "Epoch 12294/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1206146264.1722 - val_loss: 1267364839.7443\n",
      "Epoch 12295/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1206365212.9941 - val_loss: 1265946498.6301\n",
      "Epoch 12296/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1205800421.9491 - val_loss: 1266057317.6986\n",
      "Epoch 12297/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1206203351.0450 - val_loss: 1266286579.7260\n",
      "Epoch 12298/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1206284680.0157 - val_loss: 1268457342.8311\n",
      "Epoch 12299/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1205881573.9491 - val_loss: 1268201606.4292\n",
      "Epoch 12300/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1206288537.6751 - val_loss: 1267754780.9315\n",
      "Epoch 12301/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1205708043.2720 - val_loss: 1266949826.0457\n",
      "Epoch 12302/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1206559489.8160 - val_loss: 1267451482.0091\n",
      "Epoch 12303/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 29us/step - loss: 1205884272.9706 - val_loss: 1266668612.9680\n",
      "Epoch 12304/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1205816136.1409 - val_loss: 1266058730.6667\n",
      "Epoch 12305/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1206089086.3718 - val_loss: 1267189055.1233\n",
      "Epoch 12306/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1205740458.8337 - val_loss: 1266091225.7169\n",
      "Epoch 12307/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1205850975.1859 - val_loss: 1266540783.9269\n",
      "Epoch 12308/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1206103311.0294 - val_loss: 1267232495.9269\n",
      "Epoch 12309/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1206122122.6458 - val_loss: 1267215145.7900\n",
      "Epoch 12310/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1205860059.4286 - val_loss: 1267019008.2922\n",
      "Epoch 12311/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1205998268.6184 - val_loss: 1266507150.9041\n",
      "Epoch 12312/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1206467649.8787 - val_loss: 1264704748.1279\n",
      "Epoch 12313/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1205714070.6693 - val_loss: 1266683134.2466\n",
      "Epoch 12314/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1205927728.9080 - val_loss: 1266383082.9589\n",
      "Epoch 12315/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1206093934.4658 - val_loss: 1267146671.9269\n",
      "Epoch 12316/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1205773004.5245 - val_loss: 1266190875.7626\n",
      "Epoch 12317/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1206415631.5303 - val_loss: 1268468381.8082\n",
      "Epoch 12318/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1206131214.2779 - val_loss: 1266803026.1187\n",
      "Epoch 12319/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1206301718.6693 - val_loss: 1267543106.3379\n",
      "Epoch 12320/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1206158580.9785 - val_loss: 1265588197.1142\n",
      "Epoch 12321/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1206444625.3151 - val_loss: 1267985940.4566\n",
      "Epoch 12322/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1205924880.0313 - val_loss: 1266546066.9954\n",
      "Epoch 12323/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1205877286.5753 - val_loss: 1266495248.9498\n",
      "Epoch 12324/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1206171011.7573 - val_loss: 1268115482.5936\n",
      "Epoch 12325/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1206178689.3777 - val_loss: 1265417754.0091\n",
      "Epoch 12326/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1205520458.7710 - val_loss: 1266349923.3607\n",
      "Epoch 12327/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1205838360.2975 - val_loss: 1267685257.0594\n",
      "Epoch 12328/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1206517874.8493 - val_loss: 1267350011.6164\n",
      "Epoch 12329/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1205813644.7123 - val_loss: 1266141405.5160\n",
      "Epoch 12330/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1205922916.9472 - val_loss: 1267691068.7854\n",
      "Epoch 12331/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1205794833.5342 - val_loss: 1267724912.5114\n",
      "Epoch 12332/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1205990739.6634 - val_loss: 1265412334.4658\n",
      "Epoch 12333/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1205759253.5421 - val_loss: 1266318778.7397\n",
      "Epoch 12334/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1205575987.0998 - val_loss: 1266776517.5525\n",
      "Epoch 12335/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1206219517.7456 - val_loss: 1268736408.2557\n",
      "Epoch 12336/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1205526757.0724 - val_loss: 1267063313.5342\n",
      "Epoch 12337/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1206537083.4912 - val_loss: 1266600346.5936\n",
      "Epoch 12338/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1205550654.6849 - val_loss: 1267218212.8219\n",
      "Epoch 12339/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1206042869.1037 - val_loss: 1267985713.0959\n",
      "Epoch 12340/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1205549737.4560 - val_loss: 1266663165.3699\n",
      "Epoch 12341/15000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1205675743.5616 - val_loss: 1266166144.5845\n",
      "Epoch 12342/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1206157808.2192 - val_loss: 1268269129.6438\n",
      "Epoch 12343/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1205689643.3346 - val_loss: 1266202875.6164\n",
      "Epoch 12344/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1205607559.3894 - val_loss: 1266368862.1005\n",
      "Epoch 12345/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1206161361.6595 - val_loss: 1266644022.6484\n",
      "Epoch 12346/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1205543973.9491 - val_loss: 1266187555.0685\n",
      "Epoch 12347/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1205813709.0254 - val_loss: 1266310240.1461\n",
      "Epoch 12348/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1205583970.0665 - val_loss: 1266930945.7534\n",
      "Epoch 12349/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1205474766.7789 - val_loss: 1266639920.5114\n",
      "Epoch 12350/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1205452535.4834 - val_loss: 1266415191.3790\n",
      "Epoch 12351/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1205562694.8885 - val_loss: 1266973762.0457\n",
      "Epoch 12352/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1205461098.2074 - val_loss: 1267208466.9954\n",
      "Epoch 12353/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1205712547.8200 - val_loss: 1265676679.0137\n",
      "Epoch 12354/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1205648249.7378 - val_loss: 1265421725.8082\n",
      "Epoch 12355/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1205408420.3209 - val_loss: 1266805693.0776\n",
      "Epoch 12356/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1205726740.5401 - val_loss: 1267582958.1735\n",
      "Epoch 12357/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1205651987.4129 - val_loss: 1268264723.8721\n",
      "Epoch 12358/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1205878617.2994 - val_loss: 1267852750.0274\n",
      "Epoch 12359/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1205601145.2368 - val_loss: 1266053404.0548\n",
      "Epoch 12360/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1205582039.4207 - val_loss: 1266294988.8584\n",
      "Epoch 12361/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1205920149.0411 - val_loss: 1266805630.8311\n",
      "Epoch 12362/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1205805165.2133 - val_loss: 1265257819.4703\n",
      "Epoch 12363/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1205542125.7143 - val_loss: 1267984120.9863\n",
      "Epoch 12364/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1205686053.9491 - val_loss: 1266841166.6119\n",
      "Epoch 12365/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1205442232.2348 - val_loss: 1267217712.8037\n",
      "Epoch 12366/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1205483982.9041 - val_loss: 1267861394.1187\n",
      "Epoch 12367/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1205359253.7926 - val_loss: 1267477436.7854\n",
      "Epoch 12368/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1205629129.8317 - val_loss: 1267381202.4110\n",
      "Epoch 12369/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1205334855.2642 - val_loss: 1267231288.9863\n",
      "Epoch 12370/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1205808826.3640 - val_loss: 1267707279.7808\n",
      "Epoch 12371/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1206084009.8317 - val_loss: 1265321006.4658\n",
      "Epoch 12372/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1206220474.3640 - val_loss: 1267767207.4521\n",
      "Epoch 12373/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1205538724.0078 - val_loss: 1266613258.2283\n",
      "Epoch 12374/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1205873945.0489 - val_loss: 1268070361.7169\n",
      "Epoch 12375/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1205804464.9706 - val_loss: 1266138543.9269\n",
      "Epoch 12376/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1205724682.8963 - val_loss: 1265411287.3790\n",
      "Epoch 12377/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1205461588.4775 - val_loss: 1267580405.1872\n",
      "Epoch 12378/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1205177489.0333 - val_loss: 1267056379.0320\n",
      "Epoch 12379/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1205294607.9687 - val_loss: 1266309448.1826\n",
      "Epoch 12380/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1205237835.8982 - val_loss: 1266525785.4247\n",
      "Epoch 12381/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1205647166.3718 - val_loss: 1265459347.2877\n",
      "Epoch 12382/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1205833736.7671 - val_loss: 1266728771.7991\n",
      "Epoch 12383/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1205309983.0607 - val_loss: 1266354139.4703\n",
      "Epoch 12384/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1205731446.1057 - val_loss: 1267398462.8311\n",
      "Epoch 12385/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1205263680.7515 - val_loss: 1267475776.2922\n",
      "Epoch 12386/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1205334690.3170 - val_loss: 1266221303.5251\n",
      "Epoch 12387/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1205137295.5930 - val_loss: 1267134045.5160\n",
      "Epoch 12388/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1205363288.2975 - val_loss: 1267631383.6712\n",
      "Epoch 12389/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1205469711.7808 - val_loss: 1267448995.9452\n",
      "Epoch 12390/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1205514270.8102 - val_loss: 1266637948.7854\n",
      "Epoch 12391/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1205187094.9198 - val_loss: 1267164464.8037\n",
      "Epoch 12392/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1205233549.9022 - val_loss: 1266442897.5342\n",
      "Epoch 12393/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1205154730.4579 - val_loss: 1267431687.3059\n",
      "Epoch 12394/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1205442733.5890 - val_loss: 1265999045.5525\n",
      "Epoch 12395/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1205308247.7339 - val_loss: 1266669461.3333\n",
      "Epoch 12396/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1205669258.3953 - val_loss: 1268102828.1279\n",
      "Epoch 12397/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1205143219.2250 - val_loss: 1266509666.1918\n",
      "Epoch 12398/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1205973726.4344 - val_loss: 1266790459.0320\n",
      "Epoch 12399/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1205641797.6986 - val_loss: 1265926365.8082\n",
      "Epoch 12400/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1205311518.3718 - val_loss: 1267654846.2466\n",
      "Epoch 12401/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1205017970.2231 - val_loss: 1267312642.9224\n",
      "Epoch 12402/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1205586429.6204 - val_loss: 1266000352.7306\n",
      "Epoch 12403/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1205411589.0098 - val_loss: 1265932944.3653\n",
      "Epoch 12404/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1205652033.8787 - val_loss: 1267239099.9087\n",
      "Epoch 12405/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1205229221.6986 - val_loss: 1266985920.0000\n",
      "Epoch 12406/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1205438514.5988 - val_loss: 1267554104.4018\n",
      "Epoch 12407/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1205148187.4286 - val_loss: 1267690798.1735\n",
      "Epoch 12408/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1206320862.7476 - val_loss: 1264991682.3379\n",
      "Epoch 12409/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1204837364.1018 - val_loss: 1266365962.2283\n",
      "Epoch 12410/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1205328157.4325 - val_loss: 1268433565.8082\n",
      "Epoch 12411/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1205445865.2055 - val_loss: 1267843134.8311\n",
      "Epoch 12412/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1205545681.4090 - val_loss: 1265339973.2603\n",
      "Epoch 12413/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1205869697.5029 - val_loss: 1267370698.2283\n",
      "Epoch 12414/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1205152328.8924 - val_loss: 1266517883.9087\n",
      "Epoch 12415/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1205361698.9432 - val_loss: 1267952423.4521\n",
      "Epoch 12416/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1205136886.9824 - val_loss: 1267264671.5616\n",
      "Epoch 12417/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1205793556.5401 - val_loss: 1265054031.1963\n",
      "Epoch 12418/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1205007741.1194 - val_loss: 1266618329.1324\n",
      "Epoch 12419/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1204892299.5225 - val_loss: 1267287514.0091\n",
      "Epoch 12420/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1205003159.2955 - val_loss: 1268377734.7215\n",
      "Epoch 12421/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1205303569.2838 - val_loss: 1267787202.0457\n",
      "Epoch 12422/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1205221952.8767 - val_loss: 1268285364.3105\n",
      "Epoch 12423/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1204897200.9706 - val_loss: 1266961520.5114\n",
      "Epoch 12424/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1205222297.6125 - val_loss: 1266322009.7169\n",
      "Epoch 12425/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1205169398.7945 - val_loss: 1266808873.4977\n",
      "Epoch 12426/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1205065997.7769 - val_loss: 1266377403.0320\n",
      "Epoch 12427/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1205582302.9354 - val_loss: 1265871410.5571\n",
      "Epoch 12428/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1204907695.9687 - val_loss: 1266905489.2420\n",
      "Epoch 12429/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1204949876.8532 - val_loss: 1267333124.9680\n",
      "Epoch 12430/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1204942578.5362 - val_loss: 1267735821.7352\n",
      "Epoch 12431/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 29us/step - loss: 1205691522.2544 - val_loss: 1264990550.5023\n",
      "Epoch 12432/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1205015569.1585 - val_loss: 1267674296.6941\n",
      "Epoch 12433/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1205277454.4658 - val_loss: 1266373354.0822\n",
      "Epoch 12434/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1205023708.0548 - val_loss: 1267358748.0548\n",
      "Epoch 12435/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1205265453.0881 - val_loss: 1266345099.9817\n",
      "Epoch 12436/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1205353173.1663 - val_loss: 1268779397.2603\n",
      "Epoch 12437/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1204789475.4442 - val_loss: 1267543557.2603\n",
      "Epoch 12438/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1205640398.4031 - val_loss: 1265134022.7215\n",
      "Epoch 12439/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1204999332.8219 - val_loss: 1267707493.9909\n",
      "Epoch 12440/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1205166341.2603 - val_loss: 1267811441.3881\n",
      "Epoch 12441/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1205395219.1624 - val_loss: 1267585537.1689\n",
      "Epoch 12442/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1204795007.4990 - val_loss: 1266802568.4749\n",
      "Epoch 12443/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1205338017.1898 - val_loss: 1265420454.5753\n",
      "Epoch 12444/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1204712061.1194 - val_loss: 1265974958.1735\n",
      "Epoch 12445/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1204794823.1389 - val_loss: 1267291004.2009\n",
      "Epoch 12446/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1205046510.0900 - val_loss: 1267347429.4064\n",
      "Epoch 12447/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1205115187.6008 - val_loss: 1265586660.5297\n",
      "Epoch 12448/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1205027536.9080 - val_loss: 1268239692.8584\n",
      "Epoch 12449/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1205105724.1174 - val_loss: 1267222472.1826\n",
      "Epoch 12450/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1204974726.3875 - val_loss: 1268037208.8402\n",
      "Epoch 12451/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1205143221.9804 - val_loss: 1266202139.7626\n",
      "Epoch 12452/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1205599446.6693 - val_loss: 1267862892.7123\n",
      "Epoch 12453/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1205156832.1879 - val_loss: 1266690958.3196\n",
      "Epoch 12454/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1204791460.6967 - val_loss: 1266648187.0320\n",
      "Epoch 12455/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1205076939.5225 - val_loss: 1266652172.8584\n",
      "Epoch 12456/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1204723082.9589 - val_loss: 1267359936.5845\n",
      "Epoch 12457/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1204788065.9413 - val_loss: 1267648052.3105\n",
      "Epoch 12458/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1205102194.8493 - val_loss: 1267146575.4886\n",
      "Epoch 12459/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1205052617.5186 - val_loss: 1267682338.4840\n",
      "Epoch 12460/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1204819332.7593 - val_loss: 1266013382.4292\n",
      "Epoch 12461/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1204751197.6830 - val_loss: 1266961925.8447\n",
      "Epoch 12462/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1204838176.0626 - val_loss: 1267692800.8767\n",
      "Epoch 12463/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1205138991.2798 - val_loss: 1266888238.7580\n",
      "Epoch 12464/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1204613878.1057 - val_loss: 1266994649.7169\n",
      "Epoch 12465/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1205363668.0391 - val_loss: 1267458910.1005\n",
      "Epoch 12466/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1204706733.7143 - val_loss: 1266612777.2055\n",
      "Epoch 12467/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1204779015.6399 - val_loss: 1266228122.3014\n",
      "Epoch 12468/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1204951666.7241 - val_loss: 1266580315.4703\n",
      "Epoch 12469/15000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1204863628.5245 - val_loss: 1267137973.7717\n",
      "Epoch 12470/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1204812199.7025 - val_loss: 1265823850.0822\n",
      "Epoch 12471/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1204534439.7025 - val_loss: 1266712094.9772\n",
      "Epoch 12472/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1204722206.1840 - val_loss: 1266781458.9954\n",
      "Epoch 12473/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1205139146.3953 - val_loss: 1265653329.2420\n",
      "Epoch 12474/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1205264664.6732 - val_loss: 1268601045.9178\n",
      "Epoch 12475/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1205275225.0489 - val_loss: 1267039469.0046\n",
      "Epoch 12476/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1205365221.6986 - val_loss: 1267079404.1279\n",
      "Epoch 12477/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1204949866.4579 - val_loss: 1267868437.0411\n",
      "Epoch 12478/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1204511077.0724 - val_loss: 1266979593.6438\n",
      "Epoch 12479/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1204699562.2701 - val_loss: 1266614887.7443\n",
      "Epoch 12480/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1204629437.9961 - val_loss: 1266890178.6301\n",
      "Epoch 12481/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1204506996.8532 - val_loss: 1267044736.2922\n",
      "Epoch 12482/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1205169549.6517 - val_loss: 1265782613.0411\n",
      "Epoch 12483/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1204723206.2622 - val_loss: 1267595764.3105\n",
      "Epoch 12484/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1205092186.3014 - val_loss: 1266212715.5434\n",
      "Epoch 12485/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1205081748.2896 - val_loss: 1265573363.7260\n",
      "Epoch 12486/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1204806593.7534 - val_loss: 1267981708.5662\n",
      "Epoch 12487/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1204995180.8376 - val_loss: 1266415998.5388\n",
      "Epoch 12488/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1204649145.8630 - val_loss: 1268308722.2648\n",
      "Epoch 12489/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1204902421.0411 - val_loss: 1265999396.2374\n",
      "Epoch 12490/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1204870135.7339 - val_loss: 1268285358.7580\n",
      "Epoch 12491/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1204495746.4423 - val_loss: 1267234863.9269\n",
      "Epoch 12492/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1204769373.6204 - val_loss: 1267165285.4064\n",
      "Epoch 12493/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1205161558.4814 - val_loss: 1268313627.1781\n",
      "Epoch 12494/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1204602323.9139 - val_loss: 1266645776.9498\n",
      "Epoch 12495/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1205493294.5910 - val_loss: 1267589185.1689\n",
      "Epoch 12496/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1204452605.9961 - val_loss: 1266404657.9726\n",
      "Epoch 12497/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1204481990.7632 - val_loss: 1266141613.5890\n",
      "Epoch 12498/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1204791534.7162 - val_loss: 1267703612.7854\n",
      "Epoch 12499/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1205002743.2329 - val_loss: 1265908232.1826\n",
      "Epoch 12500/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1204615243.8982 - val_loss: 1266311978.3744\n",
      "Epoch 12501/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1204613735.7652 - val_loss: 1266525356.1279\n",
      "Epoch 12502/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1205194177.5029 - val_loss: 1267399601.6804\n",
      "Epoch 12503/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1205203024.0313 - val_loss: 1267369363.5799\n",
      "Epoch 12504/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1205160437.9804 - val_loss: 1265668333.0046\n",
      "Epoch 12505/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1204526075.6164 - val_loss: 1267159597.8813\n",
      "Epoch 12506/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1205006182.3249 - val_loss: 1268351204.8219\n",
      "Epoch 12507/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1204618554.1135 - val_loss: 1265920463.7808\n",
      "Epoch 12508/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1204927226.9902 - val_loss: 1266931871.8539\n",
      "Epoch 12509/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1204627104.0626 - val_loss: 1266890601.2055\n",
      "Epoch 12510/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1204775643.4286 - val_loss: 1265780734.5388\n",
      "Epoch 12511/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1204656855.0450 - val_loss: 1266034934.6484\n",
      "Epoch 12512/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1204446512.8454 - val_loss: 1266904242.2648\n",
      "Epoch 12513/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1204615720.4540 - val_loss: 1268038257.9726\n",
      "Epoch 12514/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1204359880.4540 - val_loss: 1266766368.4384\n",
      "Epoch 12515/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1204413997.0881 - val_loss: 1267300974.7580\n",
      "Epoch 12516/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1204883093.5421 - val_loss: 1265047923.4338\n",
      "Epoch 12517/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1204836867.0059 - val_loss: 1267632938.0822\n",
      "Epoch 12518/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1204380424.2661 - val_loss: 1266988990.8311\n",
      "Epoch 12519/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1204275560.8297 - val_loss: 1267202956.2740\n",
      "Epoch 12520/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1204850557.1194 - val_loss: 1266758902.9406\n",
      "Epoch 12521/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1204295742.8728 - val_loss: 1266326515.7260\n",
      "Epoch 12522/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1204526500.8219 - val_loss: 1266341325.4429\n",
      "Epoch 12523/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1204813983.5616 - val_loss: 1266883351.9635\n",
      "Epoch 12524/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1204229367.0450 - val_loss: 1267499224.2557\n",
      "Epoch 12525/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1204497831.9530 - val_loss: 1266658962.7032\n",
      "Epoch 12526/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1204375490.2544 - val_loss: 1267982011.0320\n",
      "Epoch 12527/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1204327459.8200 - val_loss: 1266907569.3881\n",
      "Epoch 12528/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1204692009.5812 - val_loss: 1265840195.2146\n",
      "Epoch 12529/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1204545853.1194 - val_loss: 1268210580.1644\n",
      "Epoch 12530/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1204848411.4286 - val_loss: 1268069579.9817\n",
      "Epoch 12531/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1204593680.5949 - val_loss: 1265810217.7900\n",
      "Epoch 12532/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1204409243.8043 - val_loss: 1265671786.0822\n",
      "Epoch 12533/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1204458170.6145 - val_loss: 1266505208.1096\n",
      "Epoch 12534/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1204826081.1898 - val_loss: 1267399204.2374\n",
      "Epoch 12535/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1204416629.9804 - val_loss: 1267182467.2146\n",
      "Epoch 12536/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1204184920.6732 - val_loss: 1267041003.2511\n",
      "Epoch 12537/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1205022302.9354 - val_loss: 1264603939.0685\n",
      "Epoch 12538/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1205215227.4912 - val_loss: 1268194453.9178\n",
      "Epoch 12539/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1204319705.1742 - val_loss: 1266187252.3105\n",
      "Epoch 12540/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1204592307.0372 - val_loss: 1266716140.1279\n",
      "Epoch 12541/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1204667213.5264 - val_loss: 1267912169.4977\n",
      "Epoch 12542/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1204201664.3131 - val_loss: 1267470636.1279\n",
      "Epoch 12543/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1204339844.2583 - val_loss: 1266555000.1096\n",
      "Epoch 12544/15000\n",
      "1022/1022 [==============================] - 0s 90us/step - loss: 1204445421.9648 - val_loss: 1266963074.0457\n",
      "Epoch 12545/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1204403560.2035 - val_loss: 1266570892.5662\n",
      "Epoch 12546/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1204268802.3796 - val_loss: 1267251201.4612\n",
      "Epoch 12547/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1204321294.7789 - val_loss: 1267342953.4977\n",
      "Epoch 12548/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1204150459.1155 - val_loss: 1266612914.2648\n",
      "Epoch 12549/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1204505881.5499 - val_loss: 1266510320.5114\n",
      "Epoch 12550/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1204200933.8239 - val_loss: 1266923663.4886\n",
      "Epoch 12551/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1204104108.3366 - val_loss: 1266425796.6758\n",
      "Epoch 12552/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1204107106.4423 - val_loss: 1267076407.2329\n",
      "Epoch 12553/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1204159308.9628 - val_loss: 1266309801.2055\n",
      "Epoch 12554/15000\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 1204052523.4599 - val_loss: 1266426639.7808\n",
      "Epoch 12555/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1204235500.4618 - val_loss: 1267315659.1050\n",
      "Epoch 12556/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1204189344.3131 - val_loss: 1265863398.2831\n",
      "Epoch 12557/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1204030983.2642 - val_loss: 1266249832.3288\n",
      "Epoch 12558/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1204469829.1350 - val_loss: 1267784247.2329\n",
      "Epoch 12559/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 31us/step - loss: 1204204975.5930 - val_loss: 1267632274.4110\n",
      "Epoch 12560/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1204159258.4266 - val_loss: 1267691317.7717\n",
      "Epoch 12561/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1204181623.2955 - val_loss: 1265792700.2009\n",
      "Epoch 12562/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1204060156.5558 - val_loss: 1266638257.3881\n",
      "Epoch 12563/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1204798272.2505 - val_loss: 1268341030.2831\n",
      "Epoch 12564/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1204619605.9804 - val_loss: 1266076773.1142\n",
      "Epoch 12565/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1204163143.6399 - val_loss: 1267070593.1689\n",
      "Epoch 12566/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1204200617.3307 - val_loss: 1266009374.6849\n",
      "Epoch 12567/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203975955.2877 - val_loss: 1267410825.3516\n",
      "Epoch 12568/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1204314020.0705 - val_loss: 1266189597.5160\n",
      "Epoch 12569/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1204098539.0215 - val_loss: 1267172305.2420\n",
      "Epoch 12570/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1205095048.1409 - val_loss: 1268573358.1735\n",
      "Epoch 12571/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1204469501.0881 - val_loss: 1265648573.6621\n",
      "Epoch 12572/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1204421524.2896 - val_loss: 1267536681.7900\n",
      "Epoch 12573/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1204115285.0411 - val_loss: 1267386381.4429\n",
      "Epoch 12574/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1204036093.3699 - val_loss: 1266838957.0046\n",
      "Epoch 12575/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203939485.3072 - val_loss: 1266872307.1416\n",
      "Epoch 12576/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1204081727.1233 - val_loss: 1266247871.7078\n",
      "Epoch 12577/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203953257.2055 - val_loss: 1266691138.0457\n",
      "Epoch 12578/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1204141967.2798 - val_loss: 1267364755.2877\n",
      "Epoch 12579/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203955887.5930 - val_loss: 1267748518.2831\n",
      "Epoch 12580/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1204031795.2877 - val_loss: 1265903425.7534\n",
      "Epoch 12581/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1204027329.3777 - val_loss: 1266787462.4292\n",
      "Epoch 12582/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1203978216.3288 - val_loss: 1266037943.5251\n",
      "Epoch 12583/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1203945180.0548 - val_loss: 1266682929.3881\n",
      "Epoch 12584/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1203870984.7671 - val_loss: 1266776555.5434\n",
      "Epoch 12585/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1204033975.6086 - val_loss: 1268572916.8950\n",
      "Epoch 12586/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1203746389.2290 - val_loss: 1267048332.8584\n",
      "Epoch 12587/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1204023686.5753 - val_loss: 1267818080.1461\n",
      "Epoch 12588/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1204272827.4912 - val_loss: 1268292917.4795\n",
      "Epoch 12589/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1203936056.6106 - val_loss: 1266441740.2740\n",
      "Epoch 12590/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1204096434.2231 - val_loss: 1267103121.5342\n",
      "Epoch 12591/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1204247566.4031 - val_loss: 1266842249.0594\n",
      "Epoch 12592/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203869042.2231 - val_loss: 1266866607.3425\n",
      "Epoch 12593/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1204010060.6497 - val_loss: 1267870117.9909\n",
      "Epoch 12594/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1204107343.0294 - val_loss: 1267658023.1598\n",
      "Epoch 12595/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1204123584.1879 - val_loss: 1266316011.5434\n",
      "Epoch 12596/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1203874228.1018 - val_loss: 1266537363.5799\n",
      "Epoch 12597/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1204050327.4207 - val_loss: 1266368185.2785\n",
      "Epoch 12598/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1204475011.2564 - val_loss: 1266473145.8630\n",
      "Epoch 12599/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1204295728.8454 - val_loss: 1265782641.6804\n",
      "Epoch 12600/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1203942696.8924 - val_loss: 1267296688.8037\n",
      "Epoch 12601/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1204257139.2250 - val_loss: 1265549783.6712\n",
      "Epoch 12602/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1204124767.4364 - val_loss: 1267969889.6073\n",
      "Epoch 12603/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1203822375.9530 - val_loss: 1268283157.3333\n",
      "Epoch 12604/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1203787400.7671 - val_loss: 1267782989.1507\n",
      "Epoch 12605/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203750119.4521 - val_loss: 1266435626.9589\n",
      "Epoch 12606/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1204527256.7984 - val_loss: 1268489147.0320\n",
      "Epoch 12607/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1204807853.0881 - val_loss: 1265400351.5616\n",
      "Epoch 12608/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1204296806.7006 - val_loss: 1268297106.4110\n",
      "Epoch 12609/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203780140.8376 - val_loss: 1267947389.9543\n",
      "Epoch 12610/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203720518.1370 - val_loss: 1266813261.4429\n",
      "Epoch 12611/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203828264.9550 - val_loss: 1267681632.1461\n",
      "Epoch 12612/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1204879323.3033 - val_loss: 1266036578.1918\n",
      "Epoch 12613/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1204084862.2466 - val_loss: 1267962546.8493\n",
      "Epoch 12614/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203653688.8611 - val_loss: 1266779440.5114\n",
      "Epoch 12615/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1204147301.3229 - val_loss: 1267712557.2968\n",
      "Epoch 12616/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203743596.4618 - val_loss: 1266661280.1461\n",
      "Epoch 12617/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203606050.3170 - val_loss: 1267071601.0959\n",
      "Epoch 12618/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203863583.1859 - val_loss: 1267982365.2237\n",
      "Epoch 12619/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203848588.9002 - val_loss: 1266317046.3562\n",
      "Epoch 12620/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1204356389.5734 - val_loss: 1268399096.9863\n",
      "Epoch 12621/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1204026060.1487 - val_loss: 1265775554.3379\n",
      "Epoch 12622/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1205047570.2857 - val_loss: 1265155738.0091\n",
      "Epoch 12623/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203695313.9100 - val_loss: 1266570123.9817\n",
      "Epoch 12624/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203943834.8650 - val_loss: 1268244391.1598\n",
      "Epoch 12625/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203647878.3875 - val_loss: 1267140015.6347\n",
      "Epoch 12626/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1203536359.2016 - val_loss: 1267011396.0913\n",
      "Epoch 12627/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203768679.1389 - val_loss: 1266681012.3105\n",
      "Epoch 12628/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1203957499.6791 - val_loss: 1266451438.1735\n",
      "Epoch 12629/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1203562703.6556 - val_loss: 1267022793.0594\n",
      "Epoch 12630/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203904992.5636 - val_loss: 1268197598.6849\n",
      "Epoch 12631/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203682243.6321 - val_loss: 1266975825.8265\n",
      "Epoch 12632/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203491078.5127 - val_loss: 1267598814.1005\n",
      "Epoch 12633/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1204428132.4462 - val_loss: 1267137200.2192\n",
      "Epoch 12634/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203536731.3346 - val_loss: 1267657350.7215\n",
      "Epoch 12635/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1203788574.4344 - val_loss: 1266395218.7032\n",
      "Epoch 12636/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1204056200.7045 - val_loss: 1268211142.4292\n",
      "Epoch 12637/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1203416264.3288 - val_loss: 1267278280.4749\n",
      "Epoch 12638/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203661325.7769 - val_loss: 1266559362.9224\n",
      "Epoch 12639/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1203502744.5479 - val_loss: 1267333687.8174\n",
      "Epoch 12640/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1203444467.0998 - val_loss: 1266630718.2466\n",
      "Epoch 12641/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1203435067.0528 - val_loss: 1266378238.8311\n",
      "Epoch 12642/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1203953707.2094 - val_loss: 1266484538.4475\n",
      "Epoch 12643/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203450777.7378 - val_loss: 1267573989.1142\n",
      "Epoch 12644/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1204032808.2035 - val_loss: 1267113212.7854\n",
      "Epoch 12645/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203830658.6301 - val_loss: 1267924112.3653\n",
      "Epoch 12646/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1204529320.6419 - val_loss: 1265172629.9178\n",
      "Epoch 12647/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1203852814.0274 - val_loss: 1266623355.9087\n",
      "Epoch 12648/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1204231799.4834 - val_loss: 1265401127.7443\n",
      "Epoch 12649/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1203809263.7808 - val_loss: 1267055146.0822\n",
      "Epoch 12650/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1203554457.6125 - val_loss: 1267119828.7489\n",
      "Epoch 12651/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203899293.9335 - val_loss: 1267867248.5114\n",
      "Epoch 12652/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203636878.7789 - val_loss: 1268204708.5297\n",
      "Epoch 12653/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203553310.9354 - val_loss: 1267257147.6164\n",
      "Epoch 12654/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203642187.6477 - val_loss: 1267250506.8128\n",
      "Epoch 12655/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203781619.9765 - val_loss: 1265523181.2968\n",
      "Epoch 12656/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203704743.5773 - val_loss: 1268467510.0639\n",
      "Epoch 12657/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1204342163.0372 - val_loss: 1266441219.7991\n",
      "Epoch 12658/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1203584362.4579 - val_loss: 1267070366.6849\n",
      "Epoch 12659/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203574043.8043 - val_loss: 1267576954.4475\n",
      "Epoch 12660/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203903048.6419 - val_loss: 1266691010.6301\n",
      "Epoch 12661/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1203267830.4188 - val_loss: 1267869031.7443\n",
      "Epoch 12662/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203587807.9374 - val_loss: 1267422884.8219\n",
      "Epoch 12663/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1203668390.7006 - val_loss: 1266834021.4064\n",
      "Epoch 12664/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203480304.4697 - val_loss: 1268449254.8676\n",
      "Epoch 12665/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1203342806.7945 - val_loss: 1267349686.9406\n",
      "Epoch 12666/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1203463089.5969 - val_loss: 1267903173.5525\n",
      "Epoch 12667/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1204093746.9119 - val_loss: 1265396579.9452\n",
      "Epoch 12668/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203585362.0978 - val_loss: 1266459331.5068\n",
      "Epoch 12669/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203582076.1174 - val_loss: 1268302092.8584\n",
      "Epoch 12670/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203598152.8924 - val_loss: 1266690025.2055\n",
      "Epoch 12671/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203757525.9178 - val_loss: 1268292350.2466\n",
      "Epoch 12672/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203544791.6712 - val_loss: 1268096859.4703\n",
      "Epoch 12673/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203671472.2192 - val_loss: 1266970979.3607\n",
      "Epoch 12674/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203500771.6321 - val_loss: 1266444832.7306\n",
      "Epoch 12675/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1203467457.8787 - val_loss: 1267416060.2009\n",
      "Epoch 12676/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1204117850.8023 - val_loss: 1265707655.3059\n",
      "Epoch 12677/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1203234128.9080 - val_loss: 1266221253.2603\n",
      "Epoch 12678/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1203393129.4560 - val_loss: 1268335938.3379\n",
      "Epoch 12679/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1203594195.9139 - val_loss: 1266262794.5205\n",
      "Epoch 12680/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1203215752.5166 - val_loss: 1267368264.7671\n",
      "Epoch 12681/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1203324450.3170 - val_loss: 1267207994.7397\n",
      "Epoch 12682/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1203394276.8219 - val_loss: 1266736282.8858\n",
      "Epoch 12683/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1203299017.3307 - val_loss: 1267685645.7352\n",
      "Epoch 12684/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1203237144.5479 - val_loss: 1267289178.0091\n",
      "Epoch 12685/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1203554251.6477 - val_loss: 1266562799.3425\n",
      "Epoch 12686/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203631362.0039 - val_loss: 1268723225.1324\n",
      "Epoch 12687/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 26us/step - loss: 1203153758.6849 - val_loss: 1267882242.0457\n",
      "Epoch 12688/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203100986.3640 - val_loss: 1267438463.4155\n",
      "Epoch 12689/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1203723711.1233 - val_loss: 1265970260.7489\n",
      "Epoch 12690/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203262037.4168 - val_loss: 1266521855.1233\n",
      "Epoch 12691/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1203550469.5108 - val_loss: 1265868901.1142\n",
      "Epoch 12692/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1203504945.5969 - val_loss: 1267248206.9041\n",
      "Epoch 12693/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1203408989.7456 - val_loss: 1268598813.5160\n",
      "Epoch 12694/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1203162586.8023 - val_loss: 1267540629.3333\n",
      "Epoch 12695/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203104061.1194 - val_loss: 1267150749.5160\n",
      "Epoch 12696/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1203221473.5656 - val_loss: 1267043711.1233\n",
      "Epoch 12697/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1203544951.3581 - val_loss: 1267758594.6301\n",
      "Epoch 12698/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203946910.3092 - val_loss: 1265582487.9635\n",
      "Epoch 12699/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1204198077.3699 - val_loss: 1267838002.8493\n",
      "Epoch 12700/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203125498.4892 - val_loss: 1267254985.0594\n",
      "Epoch 12701/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203762668.8376 - val_loss: 1267648895.7078\n",
      "Epoch 12702/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1203062097.4090 - val_loss: 1267674154.9589\n",
      "Epoch 12703/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1203410695.5147 - val_loss: 1267555688.6210\n",
      "Epoch 12704/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1203190695.8278 - val_loss: 1267690962.7032\n",
      "Epoch 12705/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203018470.1996 - val_loss: 1266801119.2694\n",
      "Epoch 12706/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203289052.4305 - val_loss: 1265959274.0822\n",
      "Epoch 12707/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1203490612.1644 - val_loss: 1265617358.3196\n",
      "Epoch 12708/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203128162.6301 - val_loss: 1267766098.1187\n",
      "Epoch 12709/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203723691.7104 - val_loss: 1265889493.9178\n",
      "Epoch 12710/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1203620066.8180 - val_loss: 1267422133.4795\n",
      "Epoch 12711/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203183060.9785 - val_loss: 1267296804.2374\n",
      "Epoch 12712/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203169154.7554 - val_loss: 1267644631.6712\n",
      "Epoch 12713/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203360342.1683 - val_loss: 1266076052.4566\n",
      "Epoch 12714/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1203519237.7613 - val_loss: 1267826843.4703\n",
      "Epoch 12715/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203108951.7339 - val_loss: 1267547850.2283\n",
      "Epoch 12716/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203435124.9785 - val_loss: 1266434131.2877\n",
      "Epoch 12717/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203175987.0998 - val_loss: 1265997320.1826\n",
      "Epoch 12718/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203237835.1468 - val_loss: 1265984794.0091\n",
      "Epoch 12719/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203776722.1605 - val_loss: 1269314055.8904\n",
      "Epoch 12720/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203549405.8082 - val_loss: 1266901317.8447\n",
      "Epoch 12721/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203121018.3640 - val_loss: 1267354045.0776\n",
      "Epoch 12722/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203182443.3973 - val_loss: 1267920799.2694\n",
      "Epoch 12723/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203288832.0000 - val_loss: 1267296463.4886\n",
      "Epoch 12724/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202976417.0646 - val_loss: 1266627303.7443\n",
      "Epoch 12725/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1203653592.2975 - val_loss: 1267303806.2466\n",
      "Epoch 12726/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202987754.3327 - val_loss: 1266684108.2740\n",
      "Epoch 12727/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1203471671.8591 - val_loss: 1267840136.7671\n",
      "Epoch 12728/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203192216.8924 - val_loss: 1266355685.1142\n",
      "Epoch 12729/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203268669.3699 - val_loss: 1267756802.0457\n",
      "Epoch 12730/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202870264.2348 - val_loss: 1266309920.4384\n",
      "Epoch 12731/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202978321.8474 - val_loss: 1266612964.5297\n",
      "Epoch 12732/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203190158.5284 - val_loss: 1266766606.3196\n",
      "Epoch 12733/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203518321.9726 - val_loss: 1265612789.1872\n",
      "Epoch 12734/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203592875.5851 - val_loss: 1267679462.5753\n",
      "Epoch 12735/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202932344.2348 - val_loss: 1266425988.3836\n",
      "Epoch 12736/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203238123.5851 - val_loss: 1268086499.9452\n",
      "Epoch 12737/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203192363.0215 - val_loss: 1266368504.1096\n",
      "Epoch 12738/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202971952.3444 - val_loss: 1267725033.4977\n",
      "Epoch 12739/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203354220.5245 - val_loss: 1265787061.4795\n",
      "Epoch 12740/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203120721.0959 - val_loss: 1267300591.6347\n",
      "Epoch 12741/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202804051.0372 - val_loss: 1267584984.5479\n",
      "Epoch 12742/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1203235401.1429 - val_loss: 1266586239.4155\n",
      "Epoch 12743/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1202929864.5793 - val_loss: 1266941467.4703\n",
      "Epoch 12744/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202861980.0548 - val_loss: 1267030185.4977\n",
      "Epoch 12745/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203487047.1389 - val_loss: 1269214890.0822\n",
      "Epoch 12746/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202978332.5558 - val_loss: 1266984916.7489\n",
      "Epoch 12747/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1202836231.8904 - val_loss: 1266594778.3014\n",
      "Epoch 12748/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203024590.6536 - val_loss: 1267650813.6621\n",
      "Epoch 12749/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202803978.8963 - val_loss: 1267290056.1826\n",
      "Epoch 12750/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1202831881.2055 - val_loss: 1266435381.7717\n",
      "Epoch 12751/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202652499.1624 - val_loss: 1266489527.2329\n",
      "Epoch 12752/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202901126.7632 - val_loss: 1267073870.9041\n",
      "Epoch 12753/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1202999854.3405 - val_loss: 1268033220.3836\n",
      "Epoch 12754/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1203386353.3464 - val_loss: 1267861682.8493\n",
      "Epoch 12755/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202773875.6008 - val_loss: 1266693530.3014\n",
      "Epoch 12756/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1202784922.9902 - val_loss: 1267070319.6347\n",
      "Epoch 12757/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1203348717.8395 - val_loss: 1265815122.9954\n",
      "Epoch 12758/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202978658.6301 - val_loss: 1267116825.4247\n",
      "Epoch 12759/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203345743.2798 - val_loss: 1266371673.7169\n",
      "Epoch 12760/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202553234.7867 - val_loss: 1266878439.4521\n",
      "Epoch 12761/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203000434.7241 - val_loss: 1267668787.7260\n",
      "Epoch 12762/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202708522.4579 - val_loss: 1267604908.4201\n",
      "Epoch 12763/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1202739937.3151 - val_loss: 1267796754.9954\n",
      "Epoch 12764/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203020379.3659 - val_loss: 1266388208.5114\n",
      "Epoch 12765/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202805301.6047 - val_loss: 1267285009.5342\n",
      "Epoch 12766/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1202917647.5303 - val_loss: 1266269979.7626\n",
      "Epoch 12767/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1203191359.4990 - val_loss: 1268268716.1279\n",
      "Epoch 12768/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202881491.6634 - val_loss: 1268164813.7352\n",
      "Epoch 12769/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202684937.6438 - val_loss: 1267784424.9132\n",
      "Epoch 12770/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1203210262.9198 - val_loss: 1265440154.5936\n",
      "Epoch 12771/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202725855.6869 - val_loss: 1267753188.5297\n",
      "Epoch 12772/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202606572.4618 - val_loss: 1266818148.2374\n",
      "Epoch 12773/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202501008.3444 - val_loss: 1267349188.6758\n",
      "Epoch 12774/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202629562.8650 - val_loss: 1267534451.7260\n",
      "Epoch 12775/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202663330.0665 - val_loss: 1267325888.8767\n",
      "Epoch 12776/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1203132717.9648 - val_loss: 1267902789.8447\n",
      "Epoch 12777/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202800361.7691 - val_loss: 1266341184.0000\n",
      "Epoch 12778/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1202645494.6693 - val_loss: 1266857152.8767\n",
      "Epoch 12779/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202641454.2153 - val_loss: 1266729400.9863\n",
      "Epoch 12780/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202705079.9217 - val_loss: 1266753459.7260\n",
      "Epoch 12781/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202726308.0705 - val_loss: 1267384760.4018\n",
      "Epoch 12782/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202699301.4481 - val_loss: 1267278667.3973\n",
      "Epoch 12783/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202790099.4129 - val_loss: 1266937791.4155\n",
      "Epoch 12784/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202824707.5068 - val_loss: 1266996473.2785\n",
      "Epoch 12785/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1202661434.4266 - val_loss: 1266649206.6484\n",
      "Epoch 12786/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1203141823.3738 - val_loss: 1268577333.4795\n",
      "Epoch 12787/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202671009.3151 - val_loss: 1266664351.2694\n",
      "Epoch 12788/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202496118.9824 - val_loss: 1267264764.2009\n",
      "Epoch 12789/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202662076.0548 - val_loss: 1265900260.2374\n",
      "Epoch 12790/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1202793378.9432 - val_loss: 1266891131.0320\n",
      "Epoch 12791/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202763868.1800 - val_loss: 1266354726.5753\n",
      "Epoch 12792/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202618312.0157 - val_loss: 1267453171.4338\n",
      "Epoch 12793/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202623326.9354 - val_loss: 1267183699.2877\n",
      "Epoch 12794/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202639037.8708 - val_loss: 1268211235.9452\n",
      "Epoch 12795/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202554652.3053 - val_loss: 1267642516.4566\n",
      "Epoch 12796/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1203973816.4853 - val_loss: 1265298639.7808\n",
      "Epoch 12797/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202505939.8513 - val_loss: 1267298825.3516\n",
      "Epoch 12798/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1202511720.0783 - val_loss: 1267863608.1096\n",
      "Epoch 12799/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1203792166.7006 - val_loss: 1265677314.6301\n",
      "Epoch 12800/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1202656862.9354 - val_loss: 1267753438.1005\n",
      "Epoch 12801/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202869904.0313 - val_loss: 1267509444.6758\n",
      "Epoch 12802/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202381396.3523 - val_loss: 1267004561.2420\n",
      "Epoch 12803/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202814129.2211 - val_loss: 1267717840.9498\n",
      "Epoch 12804/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202697981.2446 - val_loss: 1267567392.7306\n",
      "Epoch 12805/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1202463861.4795 - val_loss: 1267670591.7078\n",
      "Epoch 12806/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1202552260.8845 - val_loss: 1267493973.3333\n",
      "Epoch 12807/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202408999.8278 - val_loss: 1267075928.8402\n",
      "Epoch 12808/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1202446734.7789 - val_loss: 1268045354.0822\n",
      "Epoch 12809/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1202598554.5519 - val_loss: 1267257870.3196\n",
      "Epoch 12810/15000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1202558150.8258 - val_loss: 1267872107.5434\n",
      "Epoch 12811/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202573355.3346 - val_loss: 1266501153.6073\n",
      "Epoch 12812/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202311253.2290 - val_loss: 1267267979.9817\n",
      "Epoch 12813/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202987135.1233 - val_loss: 1268473259.2511\n",
      "Epoch 12814/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202920039.5773 - val_loss: 1267677152.4384\n",
      "Epoch 12815/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202680687.5930 - val_loss: 1267170376.7671\n",
      "Epoch 12816/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202360277.9178 - val_loss: 1267015312.0731\n",
      "Epoch 12817/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1204166555.8043 - val_loss: 1268615606.0639\n",
      "Epoch 12818/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202544611.3190 - val_loss: 1266187910.1370\n",
      "Epoch 12819/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1202505692.6184 - val_loss: 1266634563.7991\n",
      "Epoch 12820/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202869153.8160 - val_loss: 1264765565.6621\n",
      "Epoch 12821/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202308919.9843 - val_loss: 1267342542.0274\n",
      "Epoch 12822/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202671774.9354 - val_loss: 1268913584.2192\n",
      "Epoch 12823/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1202571367.2016 - val_loss: 1266141911.9635\n",
      "Epoch 12824/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202352133.6986 - val_loss: 1267250914.1918\n",
      "Epoch 12825/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202389079.0450 - val_loss: 1266835569.3881\n",
      "Epoch 12826/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202280124.9941 - val_loss: 1267733251.2146\n",
      "Epoch 12827/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202333314.3170 - val_loss: 1267713280.0000\n",
      "Epoch 12828/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1203488394.1448 - val_loss: 1268701037.5890\n",
      "Epoch 12829/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1202641032.5166 - val_loss: 1266922438.7215\n",
      "Epoch 12830/15000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1202323743.5616 - val_loss: 1266874086.2831\n",
      "Epoch 12831/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202403056.9706 - val_loss: 1266698091.2511\n",
      "Epoch 12832/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202392437.2290 - val_loss: 1266956570.5936\n",
      "Epoch 12833/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202332405.4795 - val_loss: 1267667863.6712\n",
      "Epoch 12834/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1203663143.2016 - val_loss: 1264680933.1142\n",
      "Epoch 12835/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1203821077.7926 - val_loss: 1268808490.3744\n",
      "Epoch 12836/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202129937.2838 - val_loss: 1267435902.5388\n",
      "Epoch 12837/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1204155384.7358 - val_loss: 1264802513.5342\n",
      "Epoch 12838/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202426970.9276 - val_loss: 1268363733.6256\n",
      "Epoch 12839/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202482183.1389 - val_loss: 1267736383.7078\n",
      "Epoch 12840/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1202426305.1898 - val_loss: 1267990423.3790\n",
      "Epoch 12841/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202260342.3562 - val_loss: 1266855742.8311\n",
      "Epoch 12842/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1202452567.1703 - val_loss: 1267568662.7945\n",
      "Epoch 12843/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202437355.2094 - val_loss: 1267441427.2877\n",
      "Epoch 12844/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202330257.4090 - val_loss: 1266210649.7169\n",
      "Epoch 12845/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202322153.3307 - val_loss: 1267706680.1096\n",
      "Epoch 12846/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202284251.0528 - val_loss: 1267512117.1872\n",
      "Epoch 12847/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202217161.3933 - val_loss: 1267640144.0731\n",
      "Epoch 12848/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202430012.8689 - val_loss: 1266197582.0274\n",
      "Epoch 12849/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202278735.7808 - val_loss: 1266411339.1050\n",
      "Epoch 12850/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202594352.9706 - val_loss: 1268440141.7352\n",
      "Epoch 12851/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202391418.1135 - val_loss: 1267636886.5023\n",
      "Epoch 12852/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202185484.3366 - val_loss: 1267658652.9315\n",
      "Epoch 12853/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1202168556.0861 - val_loss: 1267557423.9269\n",
      "Epoch 12854/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202191077.3229 - val_loss: 1267437971.2877\n",
      "Epoch 12855/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202241069.5890 - val_loss: 1266007579.7626\n",
      "Epoch 12856/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202147751.4521 - val_loss: 1266258735.0502\n",
      "Epoch 12857/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202210090.3327 - val_loss: 1265906574.9041\n",
      "Epoch 12858/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202049066.8337 - val_loss: 1266920784.6575\n",
      "Epoch 12859/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202420254.8102 - val_loss: 1267642211.3607\n",
      "Epoch 12860/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202156072.3914 - val_loss: 1266449850.7397\n",
      "Epoch 12861/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1201953069.8395 - val_loss: 1266974080.5845\n",
      "Epoch 12862/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202519672.7358 - val_loss: 1268432263.8904\n",
      "Epoch 12863/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202104330.6458 - val_loss: 1266426841.1324\n",
      "Epoch 12864/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202020189.9335 - val_loss: 1266803826.8493\n",
      "Epoch 12865/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202098388.2896 - val_loss: 1266989816.9863\n",
      "Epoch 12866/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1202013338.9276 - val_loss: 1267274654.9772\n",
      "Epoch 12867/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202416119.2329 - val_loss: 1266857765.6986\n",
      "Epoch 12868/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202231613.3699 - val_loss: 1267335068.6393\n",
      "Epoch 12869/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202032890.2387 - val_loss: 1266846615.6712\n",
      "Epoch 12870/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1203300092.2427 - val_loss: 1268955845.2603\n",
      "Epoch 12871/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1202261618.7867 - val_loss: 1267059579.6164\n",
      "Epoch 12872/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202211616.3131 - val_loss: 1268136876.1279\n",
      "Epoch 12873/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201879317.0411 - val_loss: 1267637514.5205\n",
      "Epoch 12874/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202121442.9432 - val_loss: 1266821736.0365\n",
      "Epoch 12875/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202277551.4051 - val_loss: 1265906254.3196\n",
      "Epoch 12876/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1202153843.7260 - val_loss: 1266798319.9269\n",
      "Epoch 12877/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202159278.9667 - val_loss: 1267917130.2283\n",
      "Epoch 12878/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1201936731.1781 - val_loss: 1267937665.4612\n",
      "Epoch 12879/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 40us/step - loss: 1202071775.1859 - val_loss: 1267509945.5708\n",
      "Epoch 12880/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1202494615.5460 - val_loss: 1266834349.8813\n",
      "Epoch 12881/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1201910902.1057 - val_loss: 1267230746.5936\n",
      "Epoch 12882/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1201903018.8337 - val_loss: 1267510360.2557\n",
      "Epoch 12883/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1201943557.6360 - val_loss: 1267150268.4932\n",
      "Epoch 12884/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202241019.6164 - val_loss: 1266452123.4703\n",
      "Epoch 12885/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1201900446.2466 - val_loss: 1266742532.3836\n",
      "Epoch 12886/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202400195.3816 - val_loss: 1268417183.5616\n",
      "Epoch 12887/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1201996537.7378 - val_loss: 1267154847.2694\n",
      "Epoch 12888/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1201955803.6791 - val_loss: 1267380880.9498\n",
      "Epoch 12889/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1202266903.1703 - val_loss: 1268378446.3196\n",
      "Epoch 12890/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1201879418.8650 - val_loss: 1266861367.8174\n",
      "Epoch 12891/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1202025068.0861 - val_loss: 1267216301.0046\n",
      "Epoch 12892/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202152587.0215 - val_loss: 1265854106.0091\n",
      "Epoch 12893/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202117201.2211 - val_loss: 1267447247.7808\n",
      "Epoch 12894/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201933287.5773 - val_loss: 1267833697.3151\n",
      "Epoch 12895/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202208229.8239 - val_loss: 1268146418.2648\n",
      "Epoch 12896/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1201776164.3209 - val_loss: 1267044343.5251\n",
      "Epoch 12897/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202006719.3738 - val_loss: 1265656658.4110\n",
      "Epoch 12898/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1201986222.4658 - val_loss: 1266969405.9543\n",
      "Epoch 12899/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1201862448.5323 - val_loss: 1267080871.4521\n",
      "Epoch 12900/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202554154.7710 - val_loss: 1265744730.8858\n",
      "Epoch 12901/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201889160.5166 - val_loss: 1266127310.3196\n",
      "Epoch 12902/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202342352.4070 - val_loss: 1265672516.3836\n",
      "Epoch 12903/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202066381.6517 - val_loss: 1268312716.5662\n",
      "Epoch 12904/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201968244.9159 - val_loss: 1267159128.5479\n",
      "Epoch 12905/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201824132.8845 - val_loss: 1268162194.7032\n",
      "Epoch 12906/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202003374.7162 - val_loss: 1268124619.6895\n",
      "Epoch 12907/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202178480.3444 - val_loss: 1268632712.7671\n",
      "Epoch 12908/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201629248.2505 - val_loss: 1267363779.5068\n",
      "Epoch 12909/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201803673.8004 - val_loss: 1267327927.5251\n",
      "Epoch 12910/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201644881.8474 - val_loss: 1266821309.3699\n",
      "Epoch 12911/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202359198.8102 - val_loss: 1267288441.2785\n",
      "Epoch 12912/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1202338424.7358 - val_loss: 1265776516.6758\n",
      "Epoch 12913/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202668541.6204 - val_loss: 1267549614.7580\n",
      "Epoch 12914/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201824702.4971 - val_loss: 1266337705.4977\n",
      "Epoch 12915/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201938128.4070 - val_loss: 1265691427.9452\n",
      "Epoch 12916/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1202337922.3170 - val_loss: 1267524695.9635\n",
      "Epoch 12917/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1202543401.1429 - val_loss: 1266918956.7123\n",
      "Epoch 12918/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1201835910.7632 - val_loss: 1266756043.1050\n",
      "Epoch 12919/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1201915775.1233 - val_loss: 1267303672.4018\n",
      "Epoch 12920/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201773821.2446 - val_loss: 1267804958.9772\n",
      "Epoch 12921/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202282461.0568 - val_loss: 1266550902.3562\n",
      "Epoch 12922/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1202261897.2681 - val_loss: 1268286089.6438\n",
      "Epoch 12923/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1202319047.6399 - val_loss: 1266445522.9954\n",
      "Epoch 12924/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1201829648.4070 - val_loss: 1267948695.3790\n",
      "Epoch 12925/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1202549035.9609 - val_loss: 1266701964.2740\n",
      "Epoch 12926/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1201935300.8845 - val_loss: 1266081280.2922\n",
      "Epoch 12927/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1202184018.0978 - val_loss: 1268846616.5479\n",
      "Epoch 12928/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1201677998.0900 - val_loss: 1267771873.6073\n",
      "Epoch 12929/15000\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 1201793638.1996 - val_loss: 1266314204.9315\n",
      "Epoch 12930/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1201635612.8063 - val_loss: 1268077317.5525\n",
      "Epoch 12931/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1201734152.2661 - val_loss: 1267794233.5708\n",
      "Epoch 12932/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1201901947.4912 - val_loss: 1268098559.7078\n",
      "Epoch 12933/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202419030.1683 - val_loss: 1268640369.0959\n",
      "Epoch 12934/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202021119.2485 - val_loss: 1266235708.7854\n",
      "Epoch 12935/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1201814182.4501 - val_loss: 1268052962.4840\n",
      "Epoch 12936/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202328895.1859 - val_loss: 1266771303.7443\n",
      "Epoch 12937/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202290830.0274 - val_loss: 1268129288.4749\n",
      "Epoch 12938/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201590135.8591 - val_loss: 1267082346.6667\n",
      "Epoch 12939/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1201707697.0959 - val_loss: 1267928388.0913\n",
      "Epoch 12940/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202110941.6830 - val_loss: 1265733605.4064\n",
      "Epoch 12941/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201713846.7319 - val_loss: 1267165690.1553\n",
      "Epoch 12942/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1201705493.4168 - val_loss: 1266839074.4840\n",
      "Epoch 12943/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 27us/step - loss: 1201786362.4892 - val_loss: 1267465883.1781\n",
      "Epoch 12944/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1201926126.4658 - val_loss: 1267393544.4749\n",
      "Epoch 12945/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1201737975.4834 - val_loss: 1268193082.1553\n",
      "Epoch 12946/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1201932676.2583 - val_loss: 1266567047.8904\n",
      "Epoch 12947/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1201718050.5049 - val_loss: 1267221679.6347\n",
      "Epoch 12948/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1201879239.3894 - val_loss: 1268838393.2785\n",
      "Epoch 12949/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1201849643.3346 - val_loss: 1265840787.5799\n",
      "Epoch 12950/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1201408246.6693 - val_loss: 1266845056.2922\n",
      "Epoch 12951/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1201545714.4736 - val_loss: 1267113870.6119\n",
      "Epoch 12952/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1201513011.6008 - val_loss: 1267508853.4795\n",
      "Epoch 12953/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1202072452.0705 - val_loss: 1267991932.7854\n",
      "Epoch 12954/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201470428.9315 - val_loss: 1266551594.3744\n",
      "Epoch 12955/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1202000795.6791 - val_loss: 1266566472.7671\n",
      "Epoch 12956/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201508249.1742 - val_loss: 1267210848.7306\n",
      "Epoch 12957/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1201418648.9237 - val_loss: 1266830879.5616\n",
      "Epoch 12958/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1201880008.8924 - val_loss: 1267925013.3333\n",
      "Epoch 12959/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1202013445.8865 - val_loss: 1268382050.7763\n",
      "Epoch 12960/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1201511918.8415 - val_loss: 1267708187.1781\n",
      "Epoch 12961/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201685403.3033 - val_loss: 1265903827.2877\n",
      "Epoch 12962/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201292828.3679 - val_loss: 1266584496.2192\n",
      "Epoch 12963/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1201918755.6947 - val_loss: 1265869484.4201\n",
      "Epoch 12964/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1201718106.4892 - val_loss: 1266555053.5890\n",
      "Epoch 12965/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1201487513.2994 - val_loss: 1268527644.9315\n",
      "Epoch 12966/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1202068769.1898 - val_loss: 1267409833.4977\n",
      "Epoch 12967/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1201874877.6204 - val_loss: 1268542993.2420\n",
      "Epoch 12968/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1201386661.1977 - val_loss: 1267146782.9772\n",
      "Epoch 12969/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1201515797.0411 - val_loss: 1266848931.0685\n",
      "Epoch 12970/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1201330187.2720 - val_loss: 1267734017.1689\n",
      "Epoch 12971/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201903722.2074 - val_loss: 1267656119.2329\n",
      "Epoch 12972/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201494450.9746 - val_loss: 1267532097.1689\n",
      "Epoch 12973/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201632896.0000 - val_loss: 1268056113.6804\n",
      "Epoch 12974/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1201896345.2994 - val_loss: 1267585189.1142\n",
      "Epoch 12975/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201582554.1761 - val_loss: 1265762487.8174\n",
      "Epoch 12976/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1201532079.9687 - val_loss: 1267248249.8630\n",
      "Epoch 12977/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201761580.9628 - val_loss: 1267716544.5845\n",
      "Epoch 12978/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201356205.4638 - val_loss: 1267293108.3105\n",
      "Epoch 12979/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1201728994.9432 - val_loss: 1267946242.0457\n",
      "Epoch 12980/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1201418530.0665 - val_loss: 1267322415.0502\n",
      "Epoch 12981/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1202103027.4755 - val_loss: 1264487338.9589\n",
      "Epoch 12982/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1201399454.5597 - val_loss: 1266965892.6758\n",
      "Epoch 12983/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1201813739.9609 - val_loss: 1266930417.0959\n",
      "Epoch 12984/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1201511908.9472 - val_loss: 1266887070.6849\n",
      "Epoch 12985/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1201494166.2935 - val_loss: 1266282341.6986\n",
      "Epoch 12986/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1202259791.5303 - val_loss: 1266106366.8311\n",
      "Epoch 12987/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1201240452.0705 - val_loss: 1266811865.1324\n",
      "Epoch 12988/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1201348207.4677 - val_loss: 1267975245.4429\n",
      "Epoch 12989/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1201295608.9863 - val_loss: 1267611600.3653\n",
      "Epoch 12990/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201241627.8043 - val_loss: 1267648049.9726\n",
      "Epoch 12991/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1201298832.3444 - val_loss: 1266892237.4429\n",
      "Epoch 12992/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1201421543.0763 - val_loss: 1267065467.6164\n",
      "Epoch 12993/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1201269029.3229 - val_loss: 1266667613.2237\n",
      "Epoch 12994/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1201569952.1879 - val_loss: 1267269418.3744\n",
      "Epoch 12995/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1201561189.1977 - val_loss: 1267357703.5982\n",
      "Epoch 12996/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1201926343.7652 - val_loss: 1268729263.9269\n",
      "Epoch 12997/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1201251664.9080 - val_loss: 1267310696.0365\n",
      "Epoch 12998/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1201618895.0294 - val_loss: 1268235740.0548\n",
      "Epoch 12999/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1201701202.5988 - val_loss: 1269014067.4338\n",
      "Epoch 13000/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1201011638.6693 - val_loss: 1266938677.1872\n",
      "Epoch 13001/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1201900628.4149 - val_loss: 1268592864.1461\n",
      "Epoch 13002/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1202057075.7260 - val_loss: 1264873210.7397\n",
      "Epoch 13003/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1201215246.3405 - val_loss: 1267047550.5388\n",
      "Epoch 13004/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1201428723.4755 - val_loss: 1267404815.1963\n",
      "Epoch 13005/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1201446678.4188 - val_loss: 1267519753.9361\n",
      "Epoch 13006/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1201191706.8023 - val_loss: 1267254318.4658\n",
      "Epoch 13007/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 32us/step - loss: 1201230307.2564 - val_loss: 1266272724.4566\n",
      "Epoch 13008/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1201519713.6908 - val_loss: 1267863213.0046\n",
      "Epoch 13009/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1202291446.9824 - val_loss: 1265682435.2146\n",
      "Epoch 13010/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1201753468.4305 - val_loss: 1267527671.5251\n",
      "Epoch 13011/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1201217382.1996 - val_loss: 1267506586.0091\n",
      "Epoch 13012/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1201919544.3601 - val_loss: 1266889250.1918\n",
      "Epoch 13013/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1201146476.0861 - val_loss: 1267330991.0502\n",
      "Epoch 13014/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1201320257.3777 - val_loss: 1267672973.7352\n",
      "Epoch 13015/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1201243023.1546 - val_loss: 1266931401.3516\n",
      "Epoch 13016/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1201355761.0959 - val_loss: 1268264135.8904\n",
      "Epoch 13017/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1201113842.3483 - val_loss: 1267003384.6941\n",
      "Epoch 13018/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1201389306.7397 - val_loss: 1267620264.9132\n",
      "Epoch 13019/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201087220.7280 - val_loss: 1266923146.8128\n",
      "Epoch 13020/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1201801226.3953 - val_loss: 1268544621.8813\n",
      "Epoch 13021/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1201088364.9628 - val_loss: 1266970837.9178\n",
      "Epoch 13022/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201043995.4286 - val_loss: 1267620876.5662\n",
      "Epoch 13023/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201055950.1526 - val_loss: 1266932148.6027\n",
      "Epoch 13024/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1201115514.7397 - val_loss: 1267906180.0913\n",
      "Epoch 13025/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1201249947.5538 - val_loss: 1267098514.1187\n",
      "Epoch 13026/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1201022672.4070 - val_loss: 1266539783.3059\n",
      "Epoch 13027/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1201182130.8493 - val_loss: 1267240296.9132\n",
      "Epoch 13028/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1201585502.4344 - val_loss: 1268409527.5251\n",
      "Epoch 13029/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1201320832.0000 - val_loss: 1268101655.6712\n",
      "Epoch 13030/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1201807147.7730 - val_loss: 1265922885.8447\n",
      "Epoch 13031/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201598109.5577 - val_loss: 1268378510.6119\n",
      "Epoch 13032/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1202042433.0020 - val_loss: 1266069139.5799\n",
      "Epoch 13033/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1201034688.1252 - val_loss: 1266583146.0822\n",
      "Epoch 13034/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1200954362.9902 - val_loss: 1266511099.3242\n",
      "Epoch 13035/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1201316270.5910 - val_loss: 1267076013.0046\n",
      "Epoch 13036/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1201473945.9883 - val_loss: 1268874103.8174\n",
      "Epoch 13037/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1201561088.5010 - val_loss: 1265961093.8447\n",
      "Epoch 13038/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1200842142.5597 - val_loss: 1266643365.9909\n",
      "Epoch 13039/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1200815415.8591 - val_loss: 1267163321.2785\n",
      "Epoch 13040/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1200983140.1957 - val_loss: 1266847561.0594\n",
      "Epoch 13041/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1201210773.9491 - val_loss: 1266640302.7580\n",
      "Epoch 13042/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1201227995.6791 - val_loss: 1266640390.4292\n",
      "Epoch 13043/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1201330868.1018 - val_loss: 1267203232.1461\n",
      "Epoch 13044/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1201249408.7515 - val_loss: 1267316770.1918\n",
      "Epoch 13045/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1201264101.5108 - val_loss: 1269091529.3516\n",
      "Epoch 13046/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1201375271.9530 - val_loss: 1267578102.3562\n",
      "Epoch 13047/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1201015388.9315 - val_loss: 1268027625.4977\n",
      "Epoch 13048/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200875225.1742 - val_loss: 1267388575.5616\n",
      "Epoch 13049/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1201013246.2779 - val_loss: 1266432967.3059\n",
      "Epoch 13050/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1201056555.0841 - val_loss: 1267509129.6438\n",
      "Epoch 13051/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1201397681.7221 - val_loss: 1267046662.7215\n",
      "Epoch 13052/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1202633146.2387 - val_loss: 1265684884.4566\n",
      "Epoch 13053/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1200921316.9472 - val_loss: 1267687158.6484\n",
      "Epoch 13054/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1201337350.7006 - val_loss: 1267323958.3562\n",
      "Epoch 13055/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1201038868.1644 - val_loss: 1267388045.4429\n",
      "Epoch 13056/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1201192333.2133 - val_loss: 1268267906.9224\n",
      "Epoch 13057/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1200986770.0352 - val_loss: 1267757022.1005\n",
      "Epoch 13058/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201077225.3307 - val_loss: 1266876202.0822\n",
      "Epoch 13059/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1201094551.7965 - val_loss: 1267873339.6164\n",
      "Epoch 13060/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1201068611.3816 - val_loss: 1266311463.4521\n",
      "Epoch 13061/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1200785522.7241 - val_loss: 1267430542.9041\n",
      "Epoch 13062/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1200936855.2955 - val_loss: 1267971052.7123\n",
      "Epoch 13063/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1201738562.8806 - val_loss: 1268671446.7945\n",
      "Epoch 13064/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200922842.1761 - val_loss: 1267164677.2603\n",
      "Epoch 13065/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200747939.3190 - val_loss: 1267281530.7397\n",
      "Epoch 13066/15000\n",
      "1022/1022 [==============================] - 0s 74us/step - loss: 1201038065.7221 - val_loss: 1266743355.6164\n",
      "Epoch 13067/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1200791949.7143 - val_loss: 1266452656.2192\n",
      "Epoch 13068/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1201510215.6399 - val_loss: 1267175329.3151\n",
      "Epoch 13069/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1200927720.7045 - val_loss: 1267620502.5023\n",
      "Epoch 13070/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1200955643.1155 - val_loss: 1265881613.7352\n",
      "Epoch 13071/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 33us/step - loss: 1200791492.0078 - val_loss: 1266696520.7671\n",
      "Epoch 13072/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1200805495.1703 - val_loss: 1266083796.7489\n",
      "Epoch 13073/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1201414553.0489 - val_loss: 1265600105.7900\n",
      "Epoch 13074/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1201134193.0959 - val_loss: 1268592395.6895\n",
      "Epoch 13075/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1200946851.3190 - val_loss: 1268376696.1096\n",
      "Epoch 13076/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1200579660.6497 - val_loss: 1266917270.5023\n",
      "Epoch 13077/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201010726.8258 - val_loss: 1267025462.3562\n",
      "Epoch 13078/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200779001.3620 - val_loss: 1266785645.8813\n",
      "Epoch 13079/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1201022524.4932 - val_loss: 1267976821.4795\n",
      "Epoch 13080/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200981116.7436 - val_loss: 1266203270.1370\n",
      "Epoch 13081/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1201426348.0861 - val_loss: 1268243361.6073\n",
      "Epoch 13082/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1201159794.1605 - val_loss: 1266847853.8813\n",
      "Epoch 13083/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1201342221.2133 - val_loss: 1267485901.7352\n",
      "Epoch 13084/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1200991317.9178 - val_loss: 1266861901.4429\n",
      "Epoch 13085/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1200602926.8415 - val_loss: 1266604258.7763\n",
      "Epoch 13086/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201028839.0763 - val_loss: 1266641853.3699\n",
      "Epoch 13087/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200828275.0372 - val_loss: 1268016620.1279\n",
      "Epoch 13088/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201733161.7065 - val_loss: 1266531551.5616\n",
      "Epoch 13089/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200725252.5088 - val_loss: 1267157346.7763\n",
      "Epoch 13090/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1201023258.1135 - val_loss: 1267690479.9269\n",
      "Epoch 13091/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1201085031.2016 - val_loss: 1265842670.4658\n",
      "Epoch 13092/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200705020.8689 - val_loss: 1266124286.8311\n",
      "Epoch 13093/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201173688.6106 - val_loss: 1266749950.2466\n",
      "Epoch 13094/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201034650.3014 - val_loss: 1267938507.9817\n",
      "Epoch 13095/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1201006291.5382 - val_loss: 1266544089.1324\n",
      "Epoch 13096/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1200814019.4442 - val_loss: 1267606045.5160\n",
      "Epoch 13097/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1200806047.5616 - val_loss: 1268272944.8037\n",
      "Epoch 13098/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1200598933.5421 - val_loss: 1266851232.1461\n",
      "Epoch 13099/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200632262.0744 - val_loss: 1266625633.0228\n",
      "Epoch 13100/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1200684322.0665 - val_loss: 1267126764.4201\n",
      "Epoch 13101/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1200706380.6497 - val_loss: 1267303192.2557\n",
      "Epoch 13102/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1200957947.9922 - val_loss: 1266401015.2329\n",
      "Epoch 13103/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1200740237.9022 - val_loss: 1266048734.6849\n",
      "Epoch 13104/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1201253149.8082 - val_loss: 1265598130.8493\n",
      "Epoch 13105/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1200848371.4755 - val_loss: 1267308132.2374\n",
      "Epoch 13106/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200676592.7202 - val_loss: 1266982148.6758\n",
      "Epoch 13107/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200577237.3542 - val_loss: 1266903831.0868\n",
      "Epoch 13108/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200721670.5127 - val_loss: 1267494689.3151\n",
      "Epoch 13109/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1200669725.4325 - val_loss: 1267928237.2968\n",
      "Epoch 13110/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201247257.0489 - val_loss: 1264806036.4566\n",
      "Epoch 13111/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201240859.6791 - val_loss: 1267586207.8539\n",
      "Epoch 13112/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200662700.0861 - val_loss: 1266630120.0365\n",
      "Epoch 13113/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200681121.6908 - val_loss: 1267807268.2374\n",
      "Epoch 13114/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1200733502.6223 - val_loss: 1265944390.7215\n",
      "Epoch 13115/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1200436891.0528 - val_loss: 1266348633.7169\n",
      "Epoch 13116/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1200702490.9276 - val_loss: 1265827918.0274\n",
      "Epoch 13117/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200494934.8571 - val_loss: 1266857434.5936\n",
      "Epoch 13118/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1200860879.2798 - val_loss: 1268495199.2694\n",
      "Epoch 13119/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1200618809.4873 - val_loss: 1267584241.9726\n",
      "Epoch 13120/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1200359570.7867 - val_loss: 1267474120.1826\n",
      "Epoch 13121/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1200646303.5616 - val_loss: 1266685721.7169\n",
      "Epoch 13122/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1200410196.1644 - val_loss: 1265877301.7717\n",
      "Epoch 13123/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1200479746.5049 - val_loss: 1267722689.7534\n",
      "Epoch 13124/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1200428182.4188 - val_loss: 1266370580.4566\n",
      "Epoch 13125/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1200345319.5773 - val_loss: 1266774504.0365\n",
      "Epoch 13126/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201576948.9785 - val_loss: 1269310725.8447\n",
      "Epoch 13127/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200465304.6732 - val_loss: 1266705422.0274\n",
      "Epoch 13128/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1200388857.1115 - val_loss: 1266607780.5297\n",
      "Epoch 13129/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200662564.9472 - val_loss: 1266034799.9269\n",
      "Epoch 13130/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1200631585.1898 - val_loss: 1266715345.8265\n",
      "Epoch 13131/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200738725.6986 - val_loss: 1267292686.3196\n",
      "Epoch 13132/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1200715651.0059 - val_loss: 1267455039.1233\n",
      "Epoch 13133/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200701920.9393 - val_loss: 1265165733.9909\n",
      "Epoch 13134/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1200415779.0685 - val_loss: 1266302356.4566\n",
      "Epoch 13135/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1200492169.2681 - val_loss: 1266258120.7671\n",
      "Epoch 13136/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1200461894.3249 - val_loss: 1267469470.9772\n",
      "Epoch 13137/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200366406.3875 - val_loss: 1266784635.3242\n",
      "Epoch 13138/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200376006.9511 - val_loss: 1267238849.7534\n",
      "Epoch 13139/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200416779.7730 - val_loss: 1267046445.5890\n",
      "Epoch 13140/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201119330.9432 - val_loss: 1265541521.5342\n",
      "Epoch 13141/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1200694779.3659 - val_loss: 1267558001.0959\n",
      "Epoch 13142/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1200948621.6517 - val_loss: 1267489209.8630\n",
      "Epoch 13143/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200436198.9511 - val_loss: 1266465992.1826\n",
      "Epoch 13144/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200254641.5342 - val_loss: 1266304155.4703\n",
      "Epoch 13145/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200378517.0411 - val_loss: 1266997155.3607\n",
      "Epoch 13146/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1201203919.9061 - val_loss: 1268343182.9041\n",
      "Epoch 13147/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200456691.4755 - val_loss: 1267434858.3744\n",
      "Epoch 13148/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200322837.2916 - val_loss: 1266544883.4338\n",
      "Epoch 13149/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200732827.3033 - val_loss: 1267348035.7991\n",
      "Epoch 13150/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1200525381.5734 - val_loss: 1266020102.7215\n",
      "Epoch 13151/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200795289.1742 - val_loss: 1266202628.0913\n",
      "Epoch 13152/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1200482208.0626 - val_loss: 1267120675.9452\n",
      "Epoch 13153/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1200289000.4540 - val_loss: 1266405417.4977\n",
      "Epoch 13154/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200122199.5460 - val_loss: 1266563009.7534\n",
      "Epoch 13155/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200476624.1566 - val_loss: 1267441349.8447\n",
      "Epoch 13156/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1200460989.2446 - val_loss: 1267965921.6073\n",
      "Epoch 13157/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200256258.1918 - val_loss: 1266596629.3333\n",
      "Epoch 13158/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1200319495.7652 - val_loss: 1266481478.7215\n",
      "Epoch 13159/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200181968.1566 - val_loss: 1265965160.9132\n",
      "Epoch 13160/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1200486818.9432 - val_loss: 1266339200.8767\n",
      "Epoch 13161/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200134762.2074 - val_loss: 1266708226.0457\n",
      "Epoch 13162/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1200255206.7006 - val_loss: 1267638450.5571\n",
      "Epoch 13163/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200313076.9159 - val_loss: 1266062776.4018\n",
      "Epoch 13164/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200247454.3092 - val_loss: 1267052872.7671\n",
      "Epoch 13165/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1200566991.5303 - val_loss: 1266524942.3196\n",
      "Epoch 13166/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200532530.5362 - val_loss: 1267609392.2192\n",
      "Epoch 13167/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1200594632.6419 - val_loss: 1266361419.9817\n",
      "Epoch 13168/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1200368272.2818 - val_loss: 1266933490.2648\n",
      "Epoch 13169/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200422857.0176 - val_loss: 1266737732.0913\n",
      "Epoch 13170/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1200417505.4403 - val_loss: 1266471509.9178\n",
      "Epoch 13171/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1200296064.0626 - val_loss: 1266632258.9224\n",
      "Epoch 13172/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200587179.9609 - val_loss: 1266265439.2694\n",
      "Epoch 13173/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200297531.1155 - val_loss: 1267312799.8539\n",
      "Epoch 13174/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200166567.5773 - val_loss: 1267226799.6347\n",
      "Epoch 13175/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200342694.5753 - val_loss: 1265657760.7306\n",
      "Epoch 13176/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200848190.9980 - val_loss: 1267663739.0320\n",
      "Epoch 13177/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200145227.3973 - val_loss: 1266474735.0502\n",
      "Epoch 13178/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200395393.2524 - val_loss: 1265853952.5845\n",
      "Epoch 13179/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200159244.0235 - val_loss: 1265818117.2603\n",
      "Epoch 13180/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1200141603.5695 - val_loss: 1265923597.4429\n",
      "Epoch 13181/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1200193405.6204 - val_loss: 1267074153.4977\n",
      "Epoch 13182/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200203965.8708 - val_loss: 1267419910.4292\n",
      "Epoch 13183/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1200217219.4442 - val_loss: 1266567119.1963\n",
      "Epoch 13184/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200514395.5538 - val_loss: 1267042990.4658\n",
      "Epoch 13185/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200833931.2720 - val_loss: 1268095188.1644\n",
      "Epoch 13186/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1201170959.0294 - val_loss: 1265258455.6712\n",
      "Epoch 13187/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1200738312.7671 - val_loss: 1267394740.8950\n",
      "Epoch 13188/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1200146041.9883 - val_loss: 1266481820.0548\n",
      "Epoch 13189/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200572901.3855 - val_loss: 1267102456.1096\n",
      "Epoch 13190/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1200373056.5010 - val_loss: 1266771292.0548\n",
      "Epoch 13191/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200201119.4364 - val_loss: 1266634415.6347\n",
      "Epoch 13192/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1200515992.6732 - val_loss: 1266051625.4977\n",
      "Epoch 13193/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200387988.7906 - val_loss: 1266897587.7260\n",
      "Epoch 13194/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200370489.3620 - val_loss: 1267409555.5799\n",
      "Epoch 13195/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200131291.5538 - val_loss: 1266019191.5251\n",
      "Epoch 13196/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200067733.2916 - val_loss: 1267092810.8128\n",
      "Epoch 13197/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1200139654.4501 - val_loss: 1265936817.6804\n",
      "Epoch 13198/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200215901.4638 - val_loss: 1266951959.0868\n",
      "Epoch 13199/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 32us/step - loss: 1200042026.8337 - val_loss: 1267211052.4201\n",
      "Epoch 13200/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1200498114.8806 - val_loss: 1265496344.2557\n",
      "Epoch 13201/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200108684.7750 - val_loss: 1265929080.4018\n",
      "Epoch 13202/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199989459.9139 - val_loss: 1267487668.0183\n",
      "Epoch 13203/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200596107.1468 - val_loss: 1265729402.1553\n",
      "Epoch 13204/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199814099.7886 - val_loss: 1266644786.8493\n",
      "Epoch 13205/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200230322.8493 - val_loss: 1267406351.1963\n",
      "Epoch 13206/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1200021002.5205 - val_loss: 1266549547.5434\n",
      "Epoch 13207/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1199978516.1018 - val_loss: 1265726317.0046\n",
      "Epoch 13208/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1200087806.9980 - val_loss: 1266336783.4886\n",
      "Epoch 13209/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199842400.9393 - val_loss: 1267071009.0228\n",
      "Epoch 13210/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199925440.3757 - val_loss: 1265979402.8128\n",
      "Epoch 13211/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199976502.1057 - val_loss: 1267501043.1416\n",
      "Epoch 13212/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1200035510.1057 - val_loss: 1266161265.3881\n",
      "Epoch 13213/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200320302.8415 - val_loss: 1265505800.4749\n",
      "Epoch 13214/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1200882174.7476 - val_loss: 1268076853.1872\n",
      "Epoch 13215/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200269590.6693 - val_loss: 1265795737.4247\n",
      "Epoch 13216/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200578467.4442 - val_loss: 1267623484.4932\n",
      "Epoch 13217/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1199831589.4481 - val_loss: 1266535857.0959\n",
      "Epoch 13218/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200159234.7554 - val_loss: 1265616876.1279\n",
      "Epoch 13219/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200656332.1487 - val_loss: 1267887953.5342\n",
      "Epoch 13220/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1200200971.2720 - val_loss: 1265968636.2009\n",
      "Epoch 13221/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1199839961.1742 - val_loss: 1267006995.8721\n",
      "Epoch 13222/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200960914.6614 - val_loss: 1264684990.2466\n",
      "Epoch 13223/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200649750.0431 - val_loss: 1266659869.5160\n",
      "Epoch 13224/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199804580.9472 - val_loss: 1267206557.5160\n",
      "Epoch 13225/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200274320.9080 - val_loss: 1268023049.9361\n",
      "Epoch 13226/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199706521.1742 - val_loss: 1266536425.4977\n",
      "Epoch 13227/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1200675499.8356 - val_loss: 1267872248.4018\n",
      "Epoch 13228/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200080967.1389 - val_loss: 1265049257.7900\n",
      "Epoch 13229/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199960139.1468 - val_loss: 1266617249.3151\n",
      "Epoch 13230/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1199910712.1722 - val_loss: 1266387802.5936\n",
      "Epoch 13231/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199922782.4344 - val_loss: 1265671045.2603\n",
      "Epoch 13232/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1199705971.7260 - val_loss: 1266529400.4018\n",
      "Epoch 13233/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199787855.1546 - val_loss: 1267208563.7260\n",
      "Epoch 13234/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1199922111.3738 - val_loss: 1267438428.9315\n",
      "Epoch 13235/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200908722.5988 - val_loss: 1265636451.3607\n",
      "Epoch 13236/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200082976.8141 - val_loss: 1265701155.0685\n",
      "Epoch 13237/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199579884.7123 - val_loss: 1267350368.4384\n",
      "Epoch 13238/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199854732.5245 - val_loss: 1268420452.2374\n",
      "Epoch 13239/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1200850262.8571 - val_loss: 1266037846.7945\n",
      "Epoch 13240/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1199650054.5127 - val_loss: 1266579104.4384\n",
      "Epoch 13241/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199675772.6810 - val_loss: 1267587645.9543\n",
      "Epoch 13242/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199945452.3366 - val_loss: 1266988477.0776\n",
      "Epoch 13243/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199719083.9609 - val_loss: 1266607434.2283\n",
      "Epoch 13244/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1199798117.6986 - val_loss: 1265755323.9087\n",
      "Epoch 13245/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199607401.3307 - val_loss: 1267040687.9269\n",
      "Epoch 13246/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199715957.7299 - val_loss: 1267275797.0411\n",
      "Epoch 13247/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1199802657.1898 - val_loss: 1267472951.2329\n",
      "Epoch 13248/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199698283.6477 - val_loss: 1267045567.7078\n",
      "Epoch 13249/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199946419.4755 - val_loss: 1267932016.5114\n",
      "Epoch 13250/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1199739225.4247 - val_loss: 1266254922.2283\n",
      "Epoch 13251/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1199826405.9491 - val_loss: 1265047373.1507\n",
      "Epoch 13252/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1199588287.3738 - val_loss: 1266733382.4292\n",
      "Epoch 13253/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199879211.3346 - val_loss: 1266178250.5205\n",
      "Epoch 13254/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199857968.4697 - val_loss: 1267150885.4064\n",
      "Epoch 13255/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199637975.6712 - val_loss: 1267493835.1050\n",
      "Epoch 13256/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1201567598.8415 - val_loss: 1264664074.8128\n",
      "Epoch 13257/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1199523721.4560 - val_loss: 1267038864.9498\n",
      "Epoch 13258/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199951168.3131 - val_loss: 1266028845.2968\n",
      "Epoch 13259/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1199488621.5264 - val_loss: 1266882486.0639\n",
      "Epoch 13260/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1199672256.8767 - val_loss: 1267193467.9087\n",
      "Epoch 13261/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1199607570.7867 - val_loss: 1267389411.6530\n",
      "Epoch 13262/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199887310.2779 - val_loss: 1266393720.4018\n",
      "Epoch 13263/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199622127.9687 - val_loss: 1267350221.4429\n",
      "Epoch 13264/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199881464.9863 - val_loss: 1266832653.7352\n",
      "Epoch 13265/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1199726831.2172 - val_loss: 1267351445.6256\n",
      "Epoch 13266/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1200602616.7671 - val_loss: 1265513307.1781\n",
      "Epoch 13267/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1199896054.9824 - val_loss: 1265587821.8813\n",
      "Epoch 13268/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1199862462.3718 - val_loss: 1266829699.2146\n",
      "Epoch 13269/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199974367.0607 - val_loss: 1265929718.0639\n",
      "Epoch 13270/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1199726964.1018 - val_loss: 1267981495.8174\n",
      "Epoch 13271/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199906773.2916 - val_loss: 1267636776.6210\n",
      "Epoch 13272/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199604779.5851 - val_loss: 1266248284.3470\n",
      "Epoch 13273/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199895609.9883 - val_loss: 1267272579.2146\n",
      "Epoch 13274/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199602186.0196 - val_loss: 1266375724.7123\n",
      "Epoch 13275/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199659949.3386 - val_loss: 1265748118.5023\n",
      "Epoch 13276/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199578567.5147 - val_loss: 1266227230.1005\n",
      "Epoch 13277/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199383734.3562 - val_loss: 1266122164.3105\n",
      "Epoch 13278/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199413994.1448 - val_loss: 1266518538.2283\n",
      "Epoch 13279/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1199648482.5675 - val_loss: 1267199871.4155\n",
      "Epoch 13280/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199555497.8317 - val_loss: 1265836378.5936\n",
      "Epoch 13281/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199650387.7886 - val_loss: 1267054670.3196\n",
      "Epoch 13282/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200507444.1018 - val_loss: 1266273199.6347\n",
      "Epoch 13283/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200115715.3816 - val_loss: 1268647789.5890\n",
      "Epoch 13284/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199527716.3209 - val_loss: 1267694044.9315\n",
      "Epoch 13285/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199801214.9980 - val_loss: 1267848723.5799\n",
      "Epoch 13286/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1199610049.3777 - val_loss: 1266652160.8767\n",
      "Epoch 13287/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1199435238.7006 - val_loss: 1266464554.9589\n",
      "Epoch 13288/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199692163.7573 - val_loss: 1265573854.1005\n",
      "Epoch 13289/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199944166.1370 - val_loss: 1266770917.4064\n",
      "Epoch 13290/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200413939.0998 - val_loss: 1267597705.0594\n",
      "Epoch 13291/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199810035.0998 - val_loss: 1266938841.7169\n",
      "Epoch 13292/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199529272.9237 - val_loss: 1266943520.4384\n",
      "Epoch 13293/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1199650459.4912 - val_loss: 1265402868.8950\n",
      "Epoch 13294/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199826440.1409 - val_loss: 1265949736.6210\n",
      "Epoch 13295/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1199387417.4247 - val_loss: 1267050913.6073\n",
      "Epoch 13296/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1199825824.5636 - val_loss: 1265950087.5982\n",
      "Epoch 13297/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199454704.0939 - val_loss: 1266517958.1370\n",
      "Epoch 13298/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1199541718.6693 - val_loss: 1266453720.8402\n",
      "Epoch 13299/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199508100.1331 - val_loss: 1265914565.8447\n",
      "Epoch 13300/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199249741.0254 - val_loss: 1266869395.5799\n",
      "Epoch 13301/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199833629.0568 - val_loss: 1267704052.8950\n",
      "Epoch 13302/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1200167009.6908 - val_loss: 1268124384.7306\n",
      "Epoch 13303/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1199342635.5851 - val_loss: 1266187447.8174\n",
      "Epoch 13304/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1199331252.9785 - val_loss: 1266277234.5571\n",
      "Epoch 13305/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1199784098.9432 - val_loss: 1265178786.1918\n",
      "Epoch 13306/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200233447.0450 - val_loss: 1268265885.8082\n",
      "Epoch 13307/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199341569.8787 - val_loss: 1266423357.9543\n",
      "Epoch 13308/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199485775.1546 - val_loss: 1267301545.7900\n",
      "Epoch 13309/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1199569180.9315 - val_loss: 1266665945.7169\n",
      "Epoch 13310/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1199318093.6517 - val_loss: 1266235984.3653\n",
      "Epoch 13311/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1199467451.6164 - val_loss: 1267150183.1598\n",
      "Epoch 13312/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1200935550.4971 - val_loss: 1264181095.7443\n",
      "Epoch 13313/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1199711995.9922 - val_loss: 1267535236.9680\n",
      "Epoch 13314/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1199689152.9393 - val_loss: 1266577476.3836\n",
      "Epoch 13315/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199391278.4658 - val_loss: 1267856435.7260\n",
      "Epoch 13316/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1199714066.7867 - val_loss: 1265828795.9087\n",
      "Epoch 13317/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199718648.4853 - val_loss: 1265576869.6986\n",
      "Epoch 13318/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1199646905.6751 - val_loss: 1266699964.4932\n",
      "Epoch 13319/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1199258231.1703 - val_loss: 1267220323.9452\n",
      "Epoch 13320/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1199891512.2348 - val_loss: 1265667295.5616\n",
      "Epoch 13321/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1199483480.0470 - val_loss: 1267961989.8447\n",
      "Epoch 13322/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1199842305.1272 - val_loss: 1268943350.3562\n",
      "Epoch 13323/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1199286632.5793 - val_loss: 1266473569.0228\n",
      "Epoch 13324/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1200065708.5871 - val_loss: 1266360052.6027\n",
      "Epoch 13325/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1199384539.2407 - val_loss: 1265535047.5982\n",
      "Epoch 13326/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1199634059.2720 - val_loss: 1265566616.2557\n",
      "Epoch 13327/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 32us/step - loss: 1199721095.2642 - val_loss: 1264731211.1050\n",
      "Epoch 13328/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1199190384.8454 - val_loss: 1266707056.8037\n",
      "Epoch 13329/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199458550.7319 - val_loss: 1267059542.2100\n",
      "Epoch 13330/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199304957.9961 - val_loss: 1267649321.7900\n",
      "Epoch 13331/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1199465027.3816 - val_loss: 1265921778.2648\n",
      "Epoch 13332/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199588784.5949 - val_loss: 1267314821.5525\n",
      "Epoch 13333/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1199209179.4286 - val_loss: 1266506002.7032\n",
      "Epoch 13334/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1199093791.0607 - val_loss: 1265770570.5205\n",
      "Epoch 13335/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1199512367.4677 - val_loss: 1266808381.9543\n",
      "Epoch 13336/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1199219463.5147 - val_loss: 1266026934.3562\n",
      "Epoch 13337/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1199466680.1096 - val_loss: 1267505626.0091\n",
      "Epoch 13338/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1199187986.0352 - val_loss: 1266465826.4840\n",
      "Epoch 13339/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199159560.2661 - val_loss: 1266982651.3242\n",
      "Epoch 13340/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1199693897.3933 - val_loss: 1267934643.7260\n",
      "Epoch 13341/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1200055850.7084 - val_loss: 1266140142.7580\n",
      "Epoch 13342/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199261623.1076 - val_loss: 1266590299.7626\n",
      "Epoch 13343/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1199204323.9452 - val_loss: 1266282069.3333\n",
      "Epoch 13344/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199178350.0274 - val_loss: 1266491074.0457\n",
      "Epoch 13345/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1199391785.5812 - val_loss: 1266730924.7123\n",
      "Epoch 13346/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1199634242.8806 - val_loss: 1267609495.9635\n",
      "Epoch 13347/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1199352085.0411 - val_loss: 1267913044.1644\n",
      "Epoch 13348/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1199274352.2818 - val_loss: 1267387835.3242\n",
      "Epoch 13349/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199395525.0098 - val_loss: 1266958142.5388\n",
      "Epoch 13350/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199739155.0372 - val_loss: 1264851698.8493\n",
      "Epoch 13351/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1199080179.7260 - val_loss: 1267482059.1050\n",
      "Epoch 13352/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199550866.0352 - val_loss: 1266316329.4977\n",
      "Epoch 13353/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199137070.3405 - val_loss: 1267031674.1553\n",
      "Epoch 13354/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1199063206.3249 - val_loss: 1266067609.1324\n",
      "Epoch 13355/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1200143855.0920 - val_loss: 1268331696.2192\n",
      "Epoch 13356/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1199270181.5734 - val_loss: 1265368841.6438\n",
      "Epoch 13357/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1199150922.8337 - val_loss: 1266183485.6621\n",
      "Epoch 13358/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1199708717.2133 - val_loss: 1268302085.5525\n",
      "Epoch 13359/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1199178762.0196 - val_loss: 1267268874.8128\n",
      "Epoch 13360/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1199672928.3131 - val_loss: 1266029426.5571\n",
      "Epoch 13361/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1199519500.5245 - val_loss: 1265330185.9361\n",
      "Epoch 13362/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1199030883.1937 - val_loss: 1266672498.8493\n",
      "Epoch 13363/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1199118309.2603 - val_loss: 1266824260.6758\n",
      "Epoch 13364/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1199096751.8434 - val_loss: 1265867571.1416\n",
      "Epoch 13365/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1199125289.5812 - val_loss: 1267032161.6073\n",
      "Epoch 13366/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1199477568.5010 - val_loss: 1268262961.6804\n",
      "Epoch 13367/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1199135308.5245 - val_loss: 1267383452.3470\n",
      "Epoch 13368/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1199213796.6967 - val_loss: 1265954431.1233\n",
      "Epoch 13369/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1199414505.2055 - val_loss: 1266298547.4338\n",
      "Epoch 13370/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199217806.5910 - val_loss: 1265268855.2329\n",
      "Epoch 13371/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1198929162.2701 - val_loss: 1265656949.1872\n",
      "Epoch 13372/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1199513817.1742 - val_loss: 1265440481.3151\n",
      "Epoch 13373/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1198874704.6575 - val_loss: 1266626344.9132\n",
      "Epoch 13374/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1199078085.1977 - val_loss: 1268035590.4292\n",
      "Epoch 13375/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1199390183.3268 - val_loss: 1266529784.9863\n",
      "Epoch 13376/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1199186239.6869 - val_loss: 1266364831.2694\n",
      "Epoch 13377/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1199262394.6145 - val_loss: 1265478388.8950\n",
      "Epoch 13378/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1198995885.0881 - val_loss: 1266503571.2877\n",
      "Epoch 13379/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1198903068.5558 - val_loss: 1266802380.8584\n",
      "Epoch 13380/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199342818.5675 - val_loss: 1267516372.4566\n",
      "Epoch 13381/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199985939.0372 - val_loss: 1265095921.6804\n",
      "Epoch 13382/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199093303.8591 - val_loss: 1267640727.6712\n",
      "Epoch 13383/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199357682.5988 - val_loss: 1268035940.2374\n",
      "Epoch 13384/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199345529.9256 - val_loss: 1266129234.7032\n",
      "Epoch 13385/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199033466.3014 - val_loss: 1267110282.5205\n",
      "Epoch 13386/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1199304648.6419 - val_loss: 1267375554.3379\n",
      "Epoch 13387/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199583076.0705 - val_loss: 1265168166.5753\n",
      "Epoch 13388/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198910121.5812 - val_loss: 1267417278.2466\n",
      "Epoch 13389/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1199058216.3288 - val_loss: 1266861985.0228\n",
      "Epoch 13390/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1198963316.4775 - val_loss: 1266259797.9178\n",
      "Epoch 13391/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 31us/step - loss: 1198797741.7143 - val_loss: 1266885278.6849\n",
      "Epoch 13392/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1199625229.7769 - val_loss: 1266373236.8950\n",
      "Epoch 13393/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1198887659.5851 - val_loss: 1267421064.1826\n",
      "Epoch 13394/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199313063.6399 - val_loss: 1267685942.6484\n",
      "Epoch 13395/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199593065.9569 - val_loss: 1268060922.1553\n",
      "Epoch 13396/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1198866224.7202 - val_loss: 1266241037.1507\n",
      "Epoch 13397/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1198888387.6321 - val_loss: 1267119823.4886\n",
      "Epoch 13398/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199005174.9824 - val_loss: 1266904576.5845\n",
      "Epoch 13399/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1199084631.6712 - val_loss: 1266794532.2374\n",
      "Epoch 13400/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1199327066.3640 - val_loss: 1264958626.4840\n",
      "Epoch 13401/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198943923.4129 - val_loss: 1267710517.7717\n",
      "Epoch 13402/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198717215.0607 - val_loss: 1266905752.8402\n",
      "Epoch 13403/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1198959619.3190 - val_loss: 1267159931.9087\n",
      "Epoch 13404/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199165230.7789 - val_loss: 1267758887.4521\n",
      "Epoch 13405/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199035632.5949 - val_loss: 1265972149.1872\n",
      "Epoch 13406/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198846201.4873 - val_loss: 1266003980.5662\n",
      "Epoch 13407/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199095479.6086 - val_loss: 1266585224.1826\n",
      "Epoch 13408/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198942436.9472 - val_loss: 1267938519.0868\n",
      "Epoch 13409/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199390534.3875 - val_loss: 1265844474.4475\n",
      "Epoch 13410/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199809853.4951 - val_loss: 1268196565.9178\n",
      "Epoch 13411/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199307213.6517 - val_loss: 1267691996.6393\n",
      "Epoch 13412/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1198566847.7495 - val_loss: 1267004893.8082\n",
      "Epoch 13413/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198784859.1781 - val_loss: 1266058226.2648\n",
      "Epoch 13414/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198967218.2857 - val_loss: 1266156119.6712\n",
      "Epoch 13415/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198774856.6419 - val_loss: 1266986366.8311\n",
      "Epoch 13416/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199362750.3718 - val_loss: 1264377625.4247\n",
      "Epoch 13417/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1200001597.3699 - val_loss: 1267323227.4703\n",
      "Epoch 13418/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198686433.4403 - val_loss: 1266370642.4110\n",
      "Epoch 13419/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1199509237.9804 - val_loss: 1267815597.2968\n",
      "Epoch 13420/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1198818379.5851 - val_loss: 1267450095.9269\n",
      "Epoch 13421/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198653559.2329 - val_loss: 1266283012.9680\n",
      "Epoch 13422/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198825566.3092 - val_loss: 1266567795.4338\n",
      "Epoch 13423/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198767581.6830 - val_loss: 1266415842.7763\n",
      "Epoch 13424/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1199463086.3405 - val_loss: 1264858580.4566\n",
      "Epoch 13425/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198695196.5558 - val_loss: 1266266328.2557\n",
      "Epoch 13426/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198643645.1194 - val_loss: 1266501406.1005\n",
      "Epoch 13427/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198779660.2114 - val_loss: 1267515407.1963\n",
      "Epoch 13428/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199732777.2055 - val_loss: 1265955955.7260\n",
      "Epoch 13429/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1198825503.4364 - val_loss: 1266137226.8128\n",
      "Epoch 13430/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1198641610.8963 - val_loss: 1267181524.4566\n",
      "Epoch 13431/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1199205805.3386 - val_loss: 1268659385.5708\n",
      "Epoch 13432/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1198640658.2857 - val_loss: 1266898014.9772\n",
      "Epoch 13433/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199217524.2270 - val_loss: 1268304751.9269\n",
      "Epoch 13434/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199903631.4051 - val_loss: 1265035626.9589\n",
      "Epoch 13435/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199148384.3131 - val_loss: 1267309361.3881\n",
      "Epoch 13436/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1198661519.6556 - val_loss: 1266870672.9498\n",
      "Epoch 13437/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198827325.1820 - val_loss: 1266313369.7169\n",
      "Epoch 13438/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198566010.7397 - val_loss: 1267252225.4612\n",
      "Epoch 13439/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1198873337.3620 - val_loss: 1266173478.8676\n",
      "Epoch 13440/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199091813.9491 - val_loss: 1267497773.8813\n",
      "Epoch 13441/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198560421.4481 - val_loss: 1266992013.7352\n",
      "Epoch 13442/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1198753690.1761 - val_loss: 1267264614.2831\n",
      "Epoch 13443/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198768500.7280 - val_loss: 1267219081.3516\n",
      "Epoch 13444/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198883370.5832 - val_loss: 1265611519.1233\n",
      "Epoch 13445/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1198513268.9785 - val_loss: 1266877410.1918\n",
      "Epoch 13446/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198787205.6360 - val_loss: 1266577656.6941\n",
      "Epoch 13447/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199152013.6517 - val_loss: 1265065158.7215\n",
      "Epoch 13448/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1198383076.1957 - val_loss: 1265864779.6895\n",
      "Epoch 13449/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1198951764.7906 - val_loss: 1267689064.3288\n",
      "Epoch 13450/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198559877.5108 - val_loss: 1266174596.3836\n",
      "Epoch 13451/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199374098.7867 - val_loss: 1264905882.8858\n",
      "Epoch 13452/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198460773.1977 - val_loss: 1267387565.8813\n",
      "Epoch 13453/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198536426.2074 - val_loss: 1266954584.8402\n",
      "Epoch 13454/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198601079.7339 - val_loss: 1266357142.7945\n",
      "Epoch 13455/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198619548.3053 - val_loss: 1267705125.6986\n",
      "Epoch 13456/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198599473.4716 - val_loss: 1268189790.6849\n",
      "Epoch 13457/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198665689.6751 - val_loss: 1268114946.3379\n",
      "Epoch 13458/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1198768533.7926 - val_loss: 1266654901.4795\n",
      "Epoch 13459/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1198847859.4755 - val_loss: 1267223157.7717\n",
      "Epoch 13460/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198658646.5440 - val_loss: 1267761833.7900\n",
      "Epoch 13461/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199245198.2153 - val_loss: 1265416450.3379\n",
      "Epoch 13462/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198415413.6047 - val_loss: 1266565113.8630\n",
      "Epoch 13463/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198497729.0020 - val_loss: 1265901475.3607\n",
      "Epoch 13464/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199016947.7260 - val_loss: 1268425430.5023\n",
      "Epoch 13465/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199055876.2583 - val_loss: 1265973131.3973\n",
      "Epoch 13466/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198613481.2055 - val_loss: 1266900098.3379\n",
      "Epoch 13467/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1198580194.3796 - val_loss: 1266621073.2420\n",
      "Epoch 13468/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199000566.4814 - val_loss: 1268220572.3470\n",
      "Epoch 13469/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1198626620.3679 - val_loss: 1266980527.9269\n",
      "Epoch 13470/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198695002.0509 - val_loss: 1266748800.2922\n",
      "Epoch 13471/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1198636699.8043 - val_loss: 1265899510.9406\n",
      "Epoch 13472/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1198502247.2016 - val_loss: 1267561550.6119\n",
      "Epoch 13473/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1198490933.3542 - val_loss: 1267653073.2420\n",
      "Epoch 13474/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1199368018.8493 - val_loss: 1265207938.6301\n",
      "Epoch 13475/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1198360245.6047 - val_loss: 1266839029.7717\n",
      "Epoch 13476/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1198529812.1644 - val_loss: 1267881830.8676\n",
      "Epoch 13477/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1199342611.5382 - val_loss: 1267398280.7671\n",
      "Epoch 13478/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1198401596.2427 - val_loss: 1267507244.1279\n",
      "Epoch 13479/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1198911976.2035 - val_loss: 1266673829.1142\n",
      "Epoch 13480/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198601960.0783 - val_loss: 1266810261.0411\n",
      "Epoch 13481/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1198860766.6849 - val_loss: 1267437510.4292\n",
      "Epoch 13482/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1198340998.0117 - val_loss: 1266623194.5936\n",
      "Epoch 13483/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1198420386.1292 - val_loss: 1266638353.5342\n",
      "Epoch 13484/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198377292.5245 - val_loss: 1266702645.4795\n",
      "Epoch 13485/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199396881.7847 - val_loss: 1268050279.7443\n",
      "Epoch 13486/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198412999.9530 - val_loss: 1266825404.2009\n",
      "Epoch 13487/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1198430841.9883 - val_loss: 1266275177.7900\n",
      "Epoch 13488/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198682185.6438 - val_loss: 1267422711.2329\n",
      "Epoch 13489/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1198602559.2485 - val_loss: 1266877719.3790\n",
      "Epoch 13490/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198534654.3092 - val_loss: 1266341872.8037\n",
      "Epoch 13491/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198401752.2975 - val_loss: 1267243938.7763\n",
      "Epoch 13492/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1198266096.7202 - val_loss: 1266797889.1689\n",
      "Epoch 13493/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1198640308.6027 - val_loss: 1266537023.7078\n",
      "Epoch 13494/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198198332.3679 - val_loss: 1267237345.8995\n",
      "Epoch 13495/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1198462643.7886 - val_loss: 1267182147.5068\n",
      "Epoch 13496/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1198265902.0900 - val_loss: 1267355190.3562\n",
      "Epoch 13497/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1198424352.5636 - val_loss: 1266690318.0274\n",
      "Epoch 13498/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198802553.4873 - val_loss: 1267918199.8174\n",
      "Epoch 13499/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1198285690.2387 - val_loss: 1267117281.6073\n",
      "Epoch 13500/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198321856.3131 - val_loss: 1265810812.4932\n",
      "Epoch 13501/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1198570959.4051 - val_loss: 1266781712.3653\n",
      "Epoch 13502/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198268967.0763 - val_loss: 1266825244.9315\n",
      "Epoch 13503/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1198538215.3268 - val_loss: 1266878177.0228\n",
      "Epoch 13504/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1198173951.6243 - val_loss: 1266094660.6758\n",
      "Epoch 13505/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1198323999.4990 - val_loss: 1266528622.1735\n",
      "Epoch 13506/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1198871507.4129 - val_loss: 1268477396.7489\n",
      "Epoch 13507/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1198323695.5303 - val_loss: 1266880770.3379\n",
      "Epoch 13508/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1198454412.2740 - val_loss: 1266457549.4429\n",
      "Epoch 13509/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198306733.2133 - val_loss: 1266562071.6712\n",
      "Epoch 13510/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198404274.0978 - val_loss: 1265917847.6712\n",
      "Epoch 13511/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1198313091.7573 - val_loss: 1265895688.1826\n",
      "Epoch 13512/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198441929.4560 - val_loss: 1265977327.0502\n",
      "Epoch 13513/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198379786.7710 - val_loss: 1267368274.4110\n",
      "Epoch 13514/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198383644.3053 - val_loss: 1267969691.4703\n",
      "Epoch 13515/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198239682.3796 - val_loss: 1267850851.0685\n",
      "Epoch 13516/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198575807.3738 - val_loss: 1265396282.1553\n",
      "Epoch 13517/15000\n",
      "1022/1022 [==============================] - 0s 95us/step - loss: 1198130000.1566 - val_loss: 1266921996.8584\n",
      "Epoch 13518/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1198222535.2016 - val_loss: 1267657960.9132\n",
      "Epoch 13519/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 38us/step - loss: 1198552636.2427 - val_loss: 1266788247.0868\n",
      "Epoch 13520/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1198174376.4540 - val_loss: 1266724994.0457\n",
      "Epoch 13521/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1198336000.6262 - val_loss: 1268218991.0502\n",
      "Epoch 13522/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1198203037.5577 - val_loss: 1267024612.5297\n",
      "Epoch 13523/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198244392.1409 - val_loss: 1266461760.2922\n",
      "Epoch 13524/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198142084.2583 - val_loss: 1267650294.0639\n",
      "Epoch 13525/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198213210.6771 - val_loss: 1266861122.3379\n",
      "Epoch 13526/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198136275.4129 - val_loss: 1267038786.9224\n",
      "Epoch 13527/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1198391083.2094 - val_loss: 1267914557.9543\n",
      "Epoch 13528/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198396035.2564 - val_loss: 1266878129.6804\n",
      "Epoch 13529/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198155944.8297 - val_loss: 1267611356.6393\n",
      "Epoch 13530/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198436010.2074 - val_loss: 1267103883.9817\n",
      "Epoch 13531/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198309033.8317 - val_loss: 1267895478.6484\n",
      "Epoch 13532/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1198000323.5068 - val_loss: 1266639710.1005\n",
      "Epoch 13533/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1198352818.8493 - val_loss: 1267532184.5479\n",
      "Epoch 13534/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1198452321.1898 - val_loss: 1265507176.6210\n",
      "Epoch 13535/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1198100809.8317 - val_loss: 1266903891.8721\n",
      "Epoch 13536/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1198409109.5421 - val_loss: 1267232198.4292\n",
      "Epoch 13537/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1198361441.3151 - val_loss: 1266214728.4749\n",
      "Epoch 13538/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198164293.6360 - val_loss: 1267781885.3699\n",
      "Epoch 13539/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198163635.3503 - val_loss: 1266878531.5068\n",
      "Epoch 13540/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198018103.6086 - val_loss: 1267325873.9726\n",
      "Epoch 13541/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1198123002.6145 - val_loss: 1267200758.3562\n",
      "Epoch 13542/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198332361.6438 - val_loss: 1266556628.1644\n",
      "Epoch 13543/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198177423.6556 - val_loss: 1267335854.1735\n",
      "Epoch 13544/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198786888.0157 - val_loss: 1267382027.9817\n",
      "Epoch 13545/15000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1198307843.0059 - val_loss: 1267190669.7352\n",
      "Epoch 13546/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1198307097.9256 - val_loss: 1266333471.2694\n",
      "Epoch 13547/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1198340055.0450 - val_loss: 1267459836.7854\n",
      "Epoch 13548/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1198636728.6106 - val_loss: 1268419851.6895\n",
      "Epoch 13549/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1198217795.8826 - val_loss: 1267093339.1781\n",
      "Epoch 13550/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1197829767.0137 - val_loss: 1266664713.0594\n",
      "Epoch 13551/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1197989411.9452 - val_loss: 1267469855.5616\n",
      "Epoch 13552/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1198331143.0763 - val_loss: 1267443812.2374\n",
      "Epoch 13553/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198014993.1585 - val_loss: 1267693705.3516\n",
      "Epoch 13554/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198010011.3033 - val_loss: 1266726321.9726\n",
      "Epoch 13555/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198845641.6438 - val_loss: 1267925391.7808\n",
      "Epoch 13556/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1198483746.8180 - val_loss: 1267818088.3288\n",
      "Epoch 13557/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198250112.0000 - val_loss: 1266682250.5205\n",
      "Epoch 13558/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1197932646.8258 - val_loss: 1266203335.5982\n",
      "Epoch 13559/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198457888.5636 - val_loss: 1267875473.8265\n",
      "Epoch 13560/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1198012625.4716 - val_loss: 1266509085.8082\n",
      "Epoch 13561/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1198019914.7710 - val_loss: 1267752437.1872\n",
      "Epoch 13562/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198017019.1155 - val_loss: 1267421480.9132\n",
      "Epoch 13563/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198128690.4736 - val_loss: 1266670046.1005\n",
      "Epoch 13564/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198008807.5773 - val_loss: 1266870670.0274\n",
      "Epoch 13565/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197993060.9472 - val_loss: 1266859851.1050\n",
      "Epoch 13566/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198322577.9100 - val_loss: 1265659530.2283\n",
      "Epoch 13567/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197864972.0235 - val_loss: 1266188919.2329\n",
      "Epoch 13568/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198152424.3288 - val_loss: 1268290746.1553\n",
      "Epoch 13569/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197889533.9961 - val_loss: 1267411688.9132\n",
      "Epoch 13570/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197885255.8904 - val_loss: 1267936992.4384\n",
      "Epoch 13571/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198453386.0196 - val_loss: 1267438446.1735\n",
      "Epoch 13572/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197824622.9667 - val_loss: 1267546629.8447\n",
      "Epoch 13573/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197758937.6751 - val_loss: 1267560997.6986\n",
      "Epoch 13574/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1197800605.6830 - val_loss: 1267273287.8904\n",
      "Epoch 13575/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198047965.9335 - val_loss: 1267322456.8402\n",
      "Epoch 13576/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198135473.0959 - val_loss: 1266966815.2694\n",
      "Epoch 13577/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1197817792.7515 - val_loss: 1267098430.8311\n",
      "Epoch 13578/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1199314176.6262 - val_loss: 1268810960.3653\n",
      "Epoch 13579/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197997467.5538 - val_loss: 1267323228.3470\n",
      "Epoch 13580/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198080804.9472 - val_loss: 1266594648.5479\n",
      "Epoch 13581/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1197815106.8806 - val_loss: 1268006885.4064\n",
      "Epoch 13582/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1197831542.1057 - val_loss: 1267911438.3196\n",
      "Epoch 13583/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1197835690.7084 - val_loss: 1266390522.4475\n",
      "Epoch 13584/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1197787406.5284 - val_loss: 1266465445.1142\n",
      "Epoch 13585/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1198406386.1605 - val_loss: 1265791439.7808\n",
      "Epoch 13586/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1197696361.9569 - val_loss: 1267314942.5388\n",
      "Epoch 13587/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198464862.6849 - val_loss: 1265509555.7260\n",
      "Epoch 13588/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197567312.6575 - val_loss: 1267846019.2146\n",
      "Epoch 13589/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197741879.8591 - val_loss: 1267948423.3059\n",
      "Epoch 13590/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197834114.7554 - val_loss: 1267762240.0000\n",
      "Epoch 13591/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197795853.1507 - val_loss: 1267574560.4384\n",
      "Epoch 13592/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198295127.1703 - val_loss: 1266495547.3242\n",
      "Epoch 13593/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197957083.9922 - val_loss: 1266667831.8174\n",
      "Epoch 13594/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197776632.8611 - val_loss: 1268412815.4886\n",
      "Epoch 13595/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197900549.8865 - val_loss: 1267707559.7443\n",
      "Epoch 13596/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198359541.2290 - val_loss: 1266747493.1142\n",
      "Epoch 13597/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1197768492.3366 - val_loss: 1267445622.6484\n",
      "Epoch 13598/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1198012391.9530 - val_loss: 1266805822.2466\n",
      "Epoch 13599/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1197665073.0959 - val_loss: 1267502890.3744\n",
      "Epoch 13600/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1198363900.6184 - val_loss: 1269474240.8767\n",
      "Epoch 13601/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197912922.6145 - val_loss: 1267431690.2283\n",
      "Epoch 13602/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197910908.8689 - val_loss: 1267569023.7078\n",
      "Epoch 13603/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1198676136.3288 - val_loss: 1269263971.9452\n",
      "Epoch 13604/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1197777369.5499 - val_loss: 1267086217.0594\n",
      "Epoch 13605/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1197862794.0196 - val_loss: 1266898106.1553\n",
      "Epoch 13606/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1197787309.5890 - val_loss: 1267708110.9041\n",
      "Epoch 13607/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197656676.9472 - val_loss: 1266603507.1416\n",
      "Epoch 13608/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1197772805.5108 - val_loss: 1267897656.1096\n",
      "Epoch 13609/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1197881296.9080 - val_loss: 1267273560.8402\n",
      "Epoch 13610/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1197873939.9139 - val_loss: 1267838056.0365\n",
      "Epoch 13611/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1197618343.3268 - val_loss: 1266868489.6438\n",
      "Epoch 13612/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197980852.8532 - val_loss: 1267584359.4521\n",
      "Epoch 13613/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1198358970.3014 - val_loss: 1266477591.6712\n",
      "Epoch 13614/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1197657094.5127 - val_loss: 1266994068.7489\n",
      "Epoch 13615/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1197754014.0587 - val_loss: 1266730501.5525\n",
      "Epoch 13616/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1198621620.6027 - val_loss: 1268419086.9041\n",
      "Epoch 13617/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197758043.5538 - val_loss: 1267946129.8265\n",
      "Epoch 13618/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197552306.9746 - val_loss: 1266946024.9132\n",
      "Epoch 13619/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1197674203.4286 - val_loss: 1267129579.5434\n",
      "Epoch 13620/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1198345124.5088 - val_loss: 1266159034.7397\n",
      "Epoch 13621/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1197493709.5264 - val_loss: 1267621169.0959\n",
      "Epoch 13622/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198193356.7750 - val_loss: 1266926225.8265\n",
      "Epoch 13623/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197684533.8552 - val_loss: 1268198097.2420\n",
      "Epoch 13624/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1197963730.0352 - val_loss: 1267459699.4338\n",
      "Epoch 13625/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1197615233.0020 - val_loss: 1267254841.2785\n",
      "Epoch 13626/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1197676624.6575 - val_loss: 1267816047.3425\n",
      "Epoch 13627/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198244857.7378 - val_loss: 1269168074.8128\n",
      "Epoch 13628/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198041015.6086 - val_loss: 1266058599.7443\n",
      "Epoch 13629/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197522635.8982 - val_loss: 1267575142.8676\n",
      "Epoch 13630/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197755654.5127 - val_loss: 1267841322.9589\n",
      "Epoch 13631/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197786387.9765 - val_loss: 1267233192.3288\n",
      "Epoch 13632/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198272623.4677 - val_loss: 1268234795.5434\n",
      "Epoch 13633/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197656635.9922 - val_loss: 1267214002.8493\n",
      "Epoch 13634/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198470748.3053 - val_loss: 1266983315.2877\n",
      "Epoch 13635/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198032853.6673 - val_loss: 1266585255.4521\n",
      "Epoch 13636/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197469661.8082 - val_loss: 1267482670.7580\n",
      "Epoch 13637/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197472442.3640 - val_loss: 1268232878.1735\n",
      "Epoch 13638/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198365955.5068 - val_loss: 1264907708.7854\n",
      "Epoch 13639/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197229577.2681 - val_loss: 1267307005.3699\n",
      "Epoch 13640/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197540110.9041 - val_loss: 1267968651.9817\n",
      "Epoch 13641/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197853636.1331 - val_loss: 1268809541.2603\n",
      "Epoch 13642/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197940426.6458 - val_loss: 1267581690.1553\n",
      "Epoch 13643/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197909518.6536 - val_loss: 1266365289.7900\n",
      "Epoch 13644/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197749018.0509 - val_loss: 1267985337.2785\n",
      "Epoch 13645/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1197498923.0841 - val_loss: 1267344250.1553\n",
      "Epoch 13646/15000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1197506922.0822 - val_loss: 1267494893.5890\n",
      "Epoch 13647/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 39us/step - loss: 1197530158.3405 - val_loss: 1266532514.4840\n",
      "Epoch 13648/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1198267079.2016 - val_loss: 1268979573.4795\n",
      "Epoch 13649/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1197851515.9922 - val_loss: 1266291184.5114\n",
      "Epoch 13650/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1197376291.6947 - val_loss: 1266752281.4247\n",
      "Epoch 13651/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1197505893.0724 - val_loss: 1267545638.2831\n",
      "Epoch 13652/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1197621759.3738 - val_loss: 1267795074.6301\n",
      "Epoch 13653/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197421598.8102 - val_loss: 1268295865.8630\n",
      "Epoch 13654/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1197665039.0294 - val_loss: 1267542342.7215\n",
      "Epoch 13655/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198321346.1292 - val_loss: 1268358135.8174\n",
      "Epoch 13656/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1198552995.8200 - val_loss: 1264583417.2785\n",
      "Epoch 13657/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1197176908.9002 - val_loss: 1267017679.7808\n",
      "Epoch 13658/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1197683086.7789 - val_loss: 1266241084.4932\n",
      "Epoch 13659/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1197438906.8650 - val_loss: 1267225116.6393\n",
      "Epoch 13660/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197589104.7202 - val_loss: 1268657655.2329\n",
      "Epoch 13661/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197776887.7339 - val_loss: 1268025560.8402\n",
      "Epoch 13662/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1197481365.9178 - val_loss: 1268546486.3562\n",
      "Epoch 13663/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197682822.6380 - val_loss: 1267025065.2055\n",
      "Epoch 13664/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1197566734.0274 - val_loss: 1267227000.9863\n",
      "Epoch 13665/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1198134970.3640 - val_loss: 1269401501.5160\n",
      "Epoch 13666/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197727653.5734 - val_loss: 1267110350.6119\n",
      "Epoch 13667/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198067030.2935 - val_loss: 1268520079.1963\n",
      "Epoch 13668/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197384857.6751 - val_loss: 1267345544.1826\n",
      "Epoch 13669/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197437206.0431 - val_loss: 1266244227.5068\n",
      "Epoch 13670/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197341888.1252 - val_loss: 1267971850.8128\n",
      "Epoch 13671/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197941458.5362 - val_loss: 1266740160.0000\n",
      "Epoch 13672/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197342367.8121 - val_loss: 1267436852.0183\n",
      "Epoch 13673/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197191402.8337 - val_loss: 1268076060.9315\n",
      "Epoch 13674/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198160479.4364 - val_loss: 1267734896.5114\n",
      "Epoch 13675/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197563173.1977 - val_loss: 1266528177.6804\n",
      "Epoch 13676/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197758560.1879 - val_loss: 1266444477.3699\n",
      "Epoch 13677/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1197375509.7926 - val_loss: 1268338386.4110\n",
      "Epoch 13678/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1197341963.1468 - val_loss: 1267407564.8584\n",
      "Epoch 13679/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197283108.1957 - val_loss: 1267812343.8174\n",
      "Epoch 13680/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1198170330.9276 - val_loss: 1269250813.9543\n",
      "Epoch 13681/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1198164502.0431 - val_loss: 1268166226.1187\n",
      "Epoch 13682/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197846157.4012 - val_loss: 1267842171.0320\n",
      "Epoch 13683/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1198479544.1096 - val_loss: 1266902130.2648\n",
      "Epoch 13684/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1198761366.2935 - val_loss: 1268748410.1553\n",
      "Epoch 13685/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1197939776.1252 - val_loss: 1266031607.8174\n",
      "Epoch 13686/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197666803.0998 - val_loss: 1266047574.2100\n",
      "Epoch 13687/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197404779.4599 - val_loss: 1267810543.6347\n",
      "Epoch 13688/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1197514239.8748 - val_loss: 1267160864.1461\n",
      "Epoch 13689/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1197552945.3464 - val_loss: 1267662504.0365\n",
      "Epoch 13690/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197376126.4971 - val_loss: 1267658523.7626\n",
      "Epoch 13691/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1197256146.7867 - val_loss: 1267276754.4110\n",
      "Epoch 13692/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1197320113.8474 - val_loss: 1268457351.3059\n",
      "Epoch 13693/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1197226661.3229 - val_loss: 1267323790.6119\n",
      "Epoch 13694/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197700908.5871 - val_loss: 1268647442.7032\n",
      "Epoch 13695/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1197173605.3855 - val_loss: 1268009866.5205\n",
      "Epoch 13696/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197081152.0000 - val_loss: 1267504159.2694\n",
      "Epoch 13697/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197268739.3816 - val_loss: 1267071917.2968\n",
      "Epoch 13698/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197354177.6282 - val_loss: 1266345340.2009\n",
      "Epoch 13699/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197091036.1800 - val_loss: 1266964945.2420\n",
      "Epoch 13700/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197060376.2975 - val_loss: 1267619413.0411\n",
      "Epoch 13701/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197291326.3718 - val_loss: 1267424710.4292\n",
      "Epoch 13702/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197468071.5773 - val_loss: 1268414317.2968\n",
      "Epoch 13703/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197328100.3209 - val_loss: 1268520270.6119\n",
      "Epoch 13704/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197018878.4971 - val_loss: 1267354884.9680\n",
      "Epoch 13705/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1197709849.4247 - val_loss: 1266453164.4201\n",
      "Epoch 13706/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1197333901.4012 - val_loss: 1267779818.6667\n",
      "Epoch 13707/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197158404.8845 - val_loss: 1267069090.1918\n",
      "Epoch 13708/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197336326.7632 - val_loss: 1266362811.3242\n",
      "Epoch 13709/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197319664.5323 - val_loss: 1267988194.7763\n",
      "Epoch 13710/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197280526.8415 - val_loss: 1267885398.2100\n",
      "Epoch 13711/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197869454.0274 - val_loss: 1269365255.8904\n",
      "Epoch 13712/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1199055106.2544 - val_loss: 1265116911.6347\n",
      "Epoch 13713/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197599329.8160 - val_loss: 1268522748.2009\n",
      "Epoch 13714/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1197264260.7593 - val_loss: 1266977831.7443\n",
      "Epoch 13715/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1197430623.6869 - val_loss: 1266779188.8950\n",
      "Epoch 13716/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1197052272.6575 - val_loss: 1267423630.3196\n",
      "Epoch 13717/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1197023324.9315 - val_loss: 1268073284.6758\n",
      "Epoch 13718/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197522984.8297 - val_loss: 1268378507.9817\n",
      "Epoch 13719/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1197575746.7554 - val_loss: 1266393596.4932\n",
      "Epoch 13720/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197205061.6360 - val_loss: 1266303739.3242\n",
      "Epoch 13721/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197517761.8787 - val_loss: 1268701214.9772\n",
      "Epoch 13722/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197427941.8865 - val_loss: 1266915139.2146\n",
      "Epoch 13723/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197279492.6341 - val_loss: 1266542148.3836\n",
      "Epoch 13724/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196920769.7534 - val_loss: 1268039691.3973\n",
      "Epoch 13725/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1197155812.8219 - val_loss: 1268091039.8539\n",
      "Epoch 13726/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197206751.1859 - val_loss: 1267595303.1598\n",
      "Epoch 13727/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197281896.9550 - val_loss: 1268091804.6393\n",
      "Epoch 13728/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197417915.6164 - val_loss: 1269170537.4977\n",
      "Epoch 13729/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1196993884.9315 - val_loss: 1267993867.3973\n",
      "Epoch 13730/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197721137.4090 - val_loss: 1266568061.6621\n",
      "Epoch 13731/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197391937.7534 - val_loss: 1267551555.2146\n",
      "Epoch 13732/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197137423.9061 - val_loss: 1267766469.2603\n",
      "Epoch 13733/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196924998.0117 - val_loss: 1267564731.6164\n",
      "Epoch 13734/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197343639.2955 - val_loss: 1267575500.8584\n",
      "Epoch 13735/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197337883.0528 - val_loss: 1266930420.6027\n",
      "Epoch 13736/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197100090.1135 - val_loss: 1266273616.9498\n",
      "Epoch 13737/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197023462.4501 - val_loss: 1267646089.0594\n",
      "Epoch 13738/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197001955.6947 - val_loss: 1266591235.7991\n",
      "Epoch 13739/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197462505.9569 - val_loss: 1267193427.2877\n",
      "Epoch 13740/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197256304.8454 - val_loss: 1266478142.5388\n",
      "Epoch 13741/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197182401.5029 - val_loss: 1267100742.7215\n",
      "Epoch 13742/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197061481.2055 - val_loss: 1267509741.5890\n",
      "Epoch 13743/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197572775.3268 - val_loss: 1266264148.4566\n",
      "Epoch 13744/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197060637.8082 - val_loss: 1268784448.8767\n",
      "Epoch 13745/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1197163723.3973 - val_loss: 1268665969.0959\n",
      "Epoch 13746/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197270387.4755 - val_loss: 1266322779.7626\n",
      "Epoch 13747/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1197203197.3699 - val_loss: 1268683387.9087\n",
      "Epoch 13748/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1196878934.4188 - val_loss: 1267824863.2694\n",
      "Epoch 13749/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196999939.6321 - val_loss: 1267110755.3607\n",
      "Epoch 13750/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1197304266.0196 - val_loss: 1265993311.2694\n",
      "Epoch 13751/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1196903268.9472 - val_loss: 1267809263.0502\n",
      "Epoch 13752/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197032414.0587 - val_loss: 1266869408.1461\n",
      "Epoch 13753/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196941506.0665 - val_loss: 1268390469.5525\n",
      "Epoch 13754/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196792638.3718 - val_loss: 1267398088.7671\n",
      "Epoch 13755/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197050916.8219 - val_loss: 1267071317.6256\n",
      "Epoch 13756/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197015705.9256 - val_loss: 1267804979.4338\n",
      "Epoch 13757/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196884338.2857 - val_loss: 1267719159.2329\n",
      "Epoch 13758/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1197638995.7886 - val_loss: 1268454402.3379\n",
      "Epoch 13759/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196868838.4501 - val_loss: 1268271916.1279\n",
      "Epoch 13760/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197515798.7945 - val_loss: 1266645328.0731\n",
      "Epoch 13761/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197045818.3640 - val_loss: 1266226816.0000\n",
      "Epoch 13762/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1196893945.7378 - val_loss: 1266471994.4475\n",
      "Epoch 13763/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197281317.1350 - val_loss: 1266306402.7763\n",
      "Epoch 13764/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1196951107.6321 - val_loss: 1268712543.2694\n",
      "Epoch 13765/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1197291343.4051 - val_loss: 1268927886.0274\n",
      "Epoch 13766/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196788649.3307 - val_loss: 1268022132.6027\n",
      "Epoch 13767/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196866015.1859 - val_loss: 1267548782.7580\n",
      "Epoch 13768/15000\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 1196861149.9335 - val_loss: 1267425802.8128\n",
      "Epoch 13769/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1196886332.8689 - val_loss: 1266685885.0776\n",
      "Epoch 13770/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196866143.6243 - val_loss: 1267134854.4292\n",
      "Epoch 13771/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1197300728.6106 - val_loss: 1265702641.9726\n",
      "Epoch 13772/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1197488535.6712 - val_loss: 1267538900.4566\n",
      "Epoch 13773/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1196688338.9119 - val_loss: 1266907403.9817\n",
      "Epoch 13774/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1196768423.5773 - val_loss: 1266922344.0365\n",
      "Epoch 13775/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 27us/step - loss: 1196969783.8591 - val_loss: 1267213934.7580\n",
      "Epoch 13776/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1196883573.2290 - val_loss: 1267592539.1781\n",
      "Epoch 13777/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1197054041.6751 - val_loss: 1266592526.3196\n",
      "Epoch 13778/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1196940250.7397 - val_loss: 1267550463.4155\n",
      "Epoch 13779/15000\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 1197019269.8865 - val_loss: 1266552198.7215\n",
      "Epoch 13780/15000\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 1196826921.7065 - val_loss: 1267167668.0183\n",
      "Epoch 13781/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197214516.2270 - val_loss: 1265547000.9863\n",
      "Epoch 13782/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196524491.5851 - val_loss: 1266602081.0228\n",
      "Epoch 13783/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1196817034.7710 - val_loss: 1268240486.2831\n",
      "Epoch 13784/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1196668213.6047 - val_loss: 1266944338.7032\n",
      "Epoch 13785/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1196880194.3796 - val_loss: 1268230893.5890\n",
      "Epoch 13786/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196771221.4795 - val_loss: 1267713415.3059\n",
      "Epoch 13787/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197300275.0998 - val_loss: 1265208712.7671\n",
      "Epoch 13788/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196964289.9413 - val_loss: 1265764566.7945\n",
      "Epoch 13789/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1197215338.0822 - val_loss: 1267371703.5251\n",
      "Epoch 13790/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196685751.6086 - val_loss: 1267403233.8995\n",
      "Epoch 13791/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197080211.5382 - val_loss: 1268906282.9589\n",
      "Epoch 13792/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196570681.3620 - val_loss: 1267757277.2237\n",
      "Epoch 13793/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196798601.2681 - val_loss: 1267481076.3105\n",
      "Epoch 13794/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1196890208.6888 - val_loss: 1268488195.7991\n",
      "Epoch 13795/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1196744943.4677 - val_loss: 1267086525.9543\n",
      "Epoch 13796/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196908975.3425 - val_loss: 1266957943.8174\n",
      "Epoch 13797/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1196556285.8082 - val_loss: 1266704878.1735\n",
      "Epoch 13798/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1196760553.9569 - val_loss: 1266867273.6438\n",
      "Epoch 13799/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1197036776.9550 - val_loss: 1265957254.7215\n",
      "Epoch 13800/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1196571040.0626 - val_loss: 1266652850.2648\n",
      "Epoch 13801/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196642975.0607 - val_loss: 1267426685.3699\n",
      "Epoch 13802/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196926603.1468 - val_loss: 1266750603.1050\n",
      "Epoch 13803/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196671119.5930 - val_loss: 1267670926.3196\n",
      "Epoch 13804/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1197563911.7652 - val_loss: 1267405301.1872\n",
      "Epoch 13805/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196678257.8474 - val_loss: 1267390235.4703\n",
      "Epoch 13806/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1196728360.0783 - val_loss: 1265645079.0868\n",
      "Epoch 13807/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1196464516.7593 - val_loss: 1266243875.3607\n",
      "Epoch 13808/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1196674639.1546 - val_loss: 1265922157.0046\n",
      "Epoch 13809/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196911313.2838 - val_loss: 1267883324.2009\n",
      "Epoch 13810/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1196459070.0587 - val_loss: 1266882569.0594\n",
      "Epoch 13811/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196598993.7847 - val_loss: 1266714298.4475\n",
      "Epoch 13812/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196599634.6614 - val_loss: 1267069456.6575\n",
      "Epoch 13813/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196517246.7789 - val_loss: 1267392754.5571\n",
      "Epoch 13814/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1197016003.7573 - val_loss: 1265887417.5708\n",
      "Epoch 13815/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1196411656.2661 - val_loss: 1267176889.8630\n",
      "Epoch 13816/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196728574.9667 - val_loss: 1267872831.7078\n",
      "Epoch 13817/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196796945.7847 - val_loss: 1267735678.8311\n",
      "Epoch 13818/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196713932.1487 - val_loss: 1267971730.1187\n",
      "Epoch 13819/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196412807.5147 - val_loss: 1266853323.1050\n",
      "Epoch 13820/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1196521724.9941 - val_loss: 1266718941.5160\n",
      "Epoch 13821/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196644294.2622 - val_loss: 1267122057.0594\n",
      "Epoch 13822/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196493473.5029 - val_loss: 1266409358.3196\n",
      "Epoch 13823/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197363463.5147 - val_loss: 1265188662.0639\n",
      "Epoch 13824/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1196393403.1155 - val_loss: 1266418410.0822\n",
      "Epoch 13825/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196910593.2524 - val_loss: 1267480201.6438\n",
      "Epoch 13826/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196353119.3738 - val_loss: 1266891081.0594\n",
      "Epoch 13827/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1196765539.8200 - val_loss: 1265281573.4064\n",
      "Epoch 13828/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1197042323.5382 - val_loss: 1267776054.0639\n",
      "Epoch 13829/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196701223.3268 - val_loss: 1266241131.8356\n",
      "Epoch 13830/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1196752387.5068 - val_loss: 1268022577.3881\n",
      "Epoch 13831/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196383462.0744 - val_loss: 1266009805.1507\n",
      "Epoch 13832/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196368457.1429 - val_loss: 1266618424.9863\n",
      "Epoch 13833/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197064397.1507 - val_loss: 1265512528.9498\n",
      "Epoch 13834/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196455666.4736 - val_loss: 1265222625.6073\n",
      "Epoch 13835/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196653473.0646 - val_loss: 1268118795.3973\n",
      "Epoch 13836/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1196422755.0059 - val_loss: 1266484368.9498\n",
      "Epoch 13837/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1196978273.9413 - val_loss: 1268048741.6986\n",
      "Epoch 13838/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196649752.9237 - val_loss: 1266130723.0685\n",
      "Epoch 13839/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1196690529.1898 - val_loss: 1267968252.4932\n",
      "Epoch 13840/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1196378845.8082 - val_loss: 1266991650.1918\n",
      "Epoch 13841/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1196737445.4481 - val_loss: 1265542057.7900\n",
      "Epoch 13842/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1196457969.9726 - val_loss: 1265377697.6073\n",
      "Epoch 13843/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1197104470.9198 - val_loss: 1264301316.9680\n",
      "Epoch 13844/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196195607.0450 - val_loss: 1267200885.1872\n",
      "Epoch 13845/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1196652262.1996 - val_loss: 1268438909.0776\n",
      "Epoch 13846/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1196386538.5832 - val_loss: 1267427204.3836\n",
      "Epoch 13847/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196386529.6908 - val_loss: 1266372157.3699\n",
      "Epoch 13848/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1196212972.7123 - val_loss: 1266398695.1598\n",
      "Epoch 13849/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196326474.6458 - val_loss: 1267205410.7763\n",
      "Epoch 13850/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196220554.0196 - val_loss: 1266992571.3242\n",
      "Epoch 13851/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1196606853.8239 - val_loss: 1266667263.4155\n",
      "Epoch 13852/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196434283.8356 - val_loss: 1266414986.8128\n",
      "Epoch 13853/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1196311561.1429 - val_loss: 1266526446.7580\n",
      "Epoch 13854/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196235121.9100 - val_loss: 1266018727.4521\n",
      "Epoch 13855/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196851867.0528 - val_loss: 1267361703.7443\n",
      "Epoch 13856/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1196157066.7710 - val_loss: 1266113640.3288\n",
      "Epoch 13857/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1196109702.3875 - val_loss: 1267123215.7808\n",
      "Epoch 13858/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196296777.6438 - val_loss: 1266922929.3881\n",
      "Epoch 13859/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196646351.7808 - val_loss: 1265614243.3607\n",
      "Epoch 13860/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196388419.6321 - val_loss: 1265877604.5297\n",
      "Epoch 13861/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196373209.9256 - val_loss: 1268050136.2557\n",
      "Epoch 13862/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1196114989.0881 - val_loss: 1266607626.8128\n",
      "Epoch 13863/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196191232.6262 - val_loss: 1267032556.4201\n",
      "Epoch 13864/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1197418734.7162 - val_loss: 1268057353.6438\n",
      "Epoch 13865/15000\n",
      "1022/1022 [==============================] - 0s 75us/step - loss: 1196080265.7691 - val_loss: 1267228903.4521\n",
      "Epoch 13866/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1196105278.8728 - val_loss: 1265858221.8813\n",
      "Epoch 13867/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196345163.7730 - val_loss: 1266285911.3790\n",
      "Epoch 13868/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196273038.1526 - val_loss: 1266206927.1963\n",
      "Epoch 13869/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1196434222.3405 - val_loss: 1266376448.0000\n",
      "Epoch 13870/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1197380065.9413 - val_loss: 1264159274.9589\n",
      "Epoch 13871/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1196348620.4618 - val_loss: 1266631270.5753\n",
      "Epoch 13872/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196198186.3327 - val_loss: 1265948048.6575\n",
      "Epoch 13873/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196924472.2348 - val_loss: 1265642185.3516\n",
      "Epoch 13874/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196969541.8865 - val_loss: 1267959027.7260\n",
      "Epoch 13875/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196798051.0059 - val_loss: 1264830495.2694\n",
      "Epoch 13876/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196098394.8023 - val_loss: 1266564197.6986\n",
      "Epoch 13877/15000\n",
      "1022/1022 [==============================] - 0s 70us/step - loss: 1196741362.2857 - val_loss: 1266713653.7717\n",
      "Epoch 13878/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1195960089.1742 - val_loss: 1266265626.5936\n",
      "Epoch 13879/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1196209757.5577 - val_loss: 1266313398.0639\n",
      "Epoch 13880/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1196075392.0000 - val_loss: 1266014908.2009\n",
      "Epoch 13881/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1196264464.5949 - val_loss: 1266541707.6895\n",
      "Epoch 13882/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1196452130.0039 - val_loss: 1264936233.7900\n",
      "Epoch 13883/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1196302932.4775 - val_loss: 1264736737.8995\n",
      "Epoch 13884/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1195826513.0333 - val_loss: 1266835412.7489\n",
      "Epoch 13885/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1196236705.8160 - val_loss: 1267318276.6758\n",
      "Epoch 13886/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1197000988.8063 - val_loss: 1266427671.0868\n",
      "Epoch 13887/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1196562051.0059 - val_loss: 1265178008.2557\n",
      "Epoch 13888/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1196194767.0920 - val_loss: 1266247811.7991\n",
      "Epoch 13889/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1196845259.0215 - val_loss: 1267407671.2329\n",
      "Epoch 13890/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196325751.1703 - val_loss: 1265846798.3196\n",
      "Epoch 13891/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1196081492.2896 - val_loss: 1266829879.8174\n",
      "Epoch 13892/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195996173.1507 - val_loss: 1266310835.4338\n",
      "Epoch 13893/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196235142.0117 - val_loss: 1267260691.8721\n",
      "Epoch 13894/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1195911779.1937 - val_loss: 1266573884.4932\n",
      "Epoch 13895/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1196159305.4560 - val_loss: 1266175514.3014\n",
      "Epoch 13896/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196098961.0333 - val_loss: 1267496675.6530\n",
      "Epoch 13897/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196048332.9002 - val_loss: 1265206859.9817\n",
      "Epoch 13898/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1196115995.5538 - val_loss: 1265568261.5525\n",
      "Epoch 13899/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196895414.6067 - val_loss: 1265368109.5890\n",
      "Epoch 13900/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195926215.0137 - val_loss: 1267277855.2694\n",
      "Epoch 13901/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1196732858.8650 - val_loss: 1264463090.2648\n",
      "Epoch 13902/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195759374.9041 - val_loss: 1265995174.2831\n",
      "Epoch 13903/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196692518.7006 - val_loss: 1267800206.0274\n",
      "Epoch 13904/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196222011.7417 - val_loss: 1267429603.9452\n",
      "Epoch 13905/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1195898985.9569 - val_loss: 1266550933.9178\n",
      "Epoch 13906/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1195891341.7769 - val_loss: 1265855480.1096\n",
      "Epoch 13907/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196475795.2877 - val_loss: 1267500947.2877\n",
      "Epoch 13908/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1195823514.2387 - val_loss: 1266316411.6164\n",
      "Epoch 13909/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1195967802.3640 - val_loss: 1266145908.0183\n",
      "Epoch 13910/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1195834599.5773 - val_loss: 1265823298.9224\n",
      "Epoch 13911/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196051637.5421 - val_loss: 1265114516.7489\n",
      "Epoch 13912/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196439024.6575 - val_loss: 1267636870.4292\n",
      "Epoch 13913/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1195897471.3738 - val_loss: 1266081725.3699\n",
      "Epoch 13914/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196335958.6693 - val_loss: 1266623401.2055\n",
      "Epoch 13915/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1195819666.0352 - val_loss: 1266640364.7123\n",
      "Epoch 13916/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1195794216.0783 - val_loss: 1266977243.7626\n",
      "Epoch 13917/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195986398.4344 - val_loss: 1266101653.9178\n",
      "Epoch 13918/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195838127.7182 - val_loss: 1266318747.7626\n",
      "Epoch 13919/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195934058.5832 - val_loss: 1265802271.2694\n",
      "Epoch 13920/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1195700838.1996 - val_loss: 1266618788.8219\n",
      "Epoch 13921/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196323254.8571 - val_loss: 1264661838.0274\n",
      "Epoch 13922/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1195648061.9961 - val_loss: 1266633752.2557\n",
      "Epoch 13923/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1196902600.8924 - val_loss: 1268730218.0822\n",
      "Epoch 13924/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1195551118.5284 - val_loss: 1267248928.4384\n",
      "Epoch 13925/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195669321.7065 - val_loss: 1265484980.3105\n",
      "Epoch 13926/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1196055589.8239 - val_loss: 1266799417.8630\n",
      "Epoch 13927/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1195732807.2642 - val_loss: 1265713198.7580\n",
      "Epoch 13928/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1195768323.0059 - val_loss: 1265188150.6484\n",
      "Epoch 13929/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1195925379.0059 - val_loss: 1266229296.2192\n",
      "Epoch 13930/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1195666179.0059 - val_loss: 1266290064.3653\n",
      "Epoch 13931/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1195742608.9080 - val_loss: 1266610939.6164\n",
      "Epoch 13932/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1197341956.0078 - val_loss: 1265147282.7032\n",
      "Epoch 13933/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195936600.9237 - val_loss: 1267536375.5251\n",
      "Epoch 13934/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1195642553.1115 - val_loss: 1266295228.7854\n",
      "Epoch 13935/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1195943829.2916 - val_loss: 1266730066.4110\n",
      "Epoch 13936/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195916866.8806 - val_loss: 1265848515.2146\n",
      "Epoch 13937/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1195733593.4247 - val_loss: 1266355759.9269\n",
      "Epoch 13938/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1195895112.7671 - val_loss: 1266986098.2648\n",
      "Epoch 13939/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1195586682.3640 - val_loss: 1266548354.0457\n",
      "Epoch 13940/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1195977799.3894 - val_loss: 1267319295.7078\n",
      "Epoch 13941/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1196027316.2896 - val_loss: 1264911774.6849\n",
      "Epoch 13942/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1196024427.7104 - val_loss: 1266718517.7717\n",
      "Epoch 13943/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1195779415.4834 - val_loss: 1266156616.4749\n",
      "Epoch 13944/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1196243429.8239 - val_loss: 1264604336.5114\n",
      "Epoch 13945/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1195716885.0411 - val_loss: 1267095549.6621\n",
      "Epoch 13946/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196341002.5205 - val_loss: 1264698708.1644\n",
      "Epoch 13947/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1195571686.9511 - val_loss: 1266077413.9909\n",
      "Epoch 13948/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1195691952.0939 - val_loss: 1266527017.4977\n",
      "Epoch 13949/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1195900346.1135 - val_loss: 1266806559.5616\n",
      "Epoch 13950/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196497127.4521 - val_loss: 1268645770.8128\n",
      "Epoch 13951/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195943275.7104 - val_loss: 1264766319.3425\n",
      "Epoch 13952/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195640252.3679 - val_loss: 1266459539.8721\n",
      "Epoch 13953/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195671546.2387 - val_loss: 1265408029.2237\n",
      "Epoch 13954/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1195823098.0509 - val_loss: 1265019692.4201\n",
      "Epoch 13955/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1195441769.8943 - val_loss: 1265543349.1872\n",
      "Epoch 13956/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1195774720.0000 - val_loss: 1267072482.7763\n",
      "Epoch 13957/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195736616.4540 - val_loss: 1267554770.7032\n",
      "Epoch 13958/15000\n",
      "1022/1022 [==============================] - 0s 95us/step - loss: 1195680910.2153 - val_loss: 1267030947.0685\n",
      "Epoch 13959/15000\n",
      "1022/1022 [==============================] - 0s 63us/step - loss: 1195592240.0939 - val_loss: 1265368025.7169\n",
      "Epoch 13960/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1195476103.5147 - val_loss: 1266414189.0046\n",
      "Epoch 13961/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1195612555.3973 - val_loss: 1266794619.9087\n",
      "Epoch 13962/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1195741362.4736 - val_loss: 1265905592.9863\n",
      "Epoch 13963/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195529203.4755 - val_loss: 1267011467.9817\n",
      "Epoch 13964/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1195538964.0391 - val_loss: 1265806748.9315\n",
      "Epoch 13965/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1195972730.7397 - val_loss: 1266789532.0548\n",
      "Epoch 13966/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195552213.4168 - val_loss: 1266461871.9269\n",
      "Epoch 13967/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 28us/step - loss: 1195535792.0939 - val_loss: 1266691486.3927\n",
      "Epoch 13968/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1195515996.0548 - val_loss: 1266876404.0183\n",
      "Epoch 13969/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1195562076.9315 - val_loss: 1266076509.5160\n",
      "Epoch 13970/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1195512241.4716 - val_loss: 1265351779.6530\n",
      "Epoch 13971/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1195679571.9139 - val_loss: 1264592538.8858\n",
      "Epoch 13972/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1195466123.0215 - val_loss: 1265936197.8447\n",
      "Epoch 13973/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1195530953.0176 - val_loss: 1266926302.9772\n",
      "Epoch 13974/15000\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 1195408097.4403 - val_loss: 1266882215.7443\n",
      "Epoch 13975/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1195669126.8885 - val_loss: 1266863734.3562\n",
      "Epoch 13976/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1195763459.0059 - val_loss: 1264847526.5753\n",
      "Epoch 13977/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1196029765.0098 - val_loss: 1266819724.2740\n",
      "Epoch 13978/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195404722.8493 - val_loss: 1265237962.5205\n",
      "Epoch 13979/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1195688493.2133 - val_loss: 1266633923.5068\n",
      "Epoch 13980/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1195337468.9941 - val_loss: 1266614289.2420\n",
      "Epoch 13981/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196385006.2153 - val_loss: 1264141094.2831\n",
      "Epoch 13982/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1196240680.9550 - val_loss: 1266956311.0868\n",
      "Epoch 13983/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1195630970.2387 - val_loss: 1265607619.5068\n",
      "Epoch 13984/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1195382783.9374 - val_loss: 1266325255.5982\n",
      "Epoch 13985/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195423033.4873 - val_loss: 1265992663.9635\n",
      "Epoch 13986/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195401491.6634 - val_loss: 1265811706.4475\n",
      "Epoch 13987/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195349521.5342 - val_loss: 1266434174.8311\n",
      "Epoch 13988/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1196349506.2544 - val_loss: 1267949010.1187\n",
      "Epoch 13989/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195549188.6341 - val_loss: 1266467860.1644\n",
      "Epoch 13990/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195243347.9765 - val_loss: 1266112752.8037\n",
      "Epoch 13991/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1195949879.8591 - val_loss: 1266174135.2329\n",
      "Epoch 13992/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195667755.3346 - val_loss: 1266315431.1598\n",
      "Epoch 13993/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1195737591.0450 - val_loss: 1266189657.4247\n",
      "Epoch 13994/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1195146964.3523 - val_loss: 1265305553.8265\n",
      "Epoch 13995/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1195584735.1859 - val_loss: 1266284562.4110\n",
      "Epoch 13996/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1196608174.8415 - val_loss: 1263284442.8858\n",
      "Epoch 13997/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195154772.0391 - val_loss: 1264828385.3151\n",
      "Epoch 13998/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1195380748.9002 - val_loss: 1266634867.7260\n",
      "Epoch 13999/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195183974.6380 - val_loss: 1266621487.6347\n",
      "Epoch 14000/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1195450430.4971 - val_loss: 1265677985.3151\n",
      "Epoch 14001/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195346504.3914 - val_loss: 1266115908.6758\n",
      "Epoch 14002/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1195292544.8141 - val_loss: 1266451012.9680\n",
      "Epoch 14003/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1195324830.8102 - val_loss: 1266905696.7306\n",
      "Epoch 14004/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1195529610.0196 - val_loss: 1267687048.4749\n",
      "Epoch 14005/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1195129143.1076 - val_loss: 1266592770.9224\n",
      "Epoch 14006/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1195268437.6673 - val_loss: 1266233069.0046\n",
      "Epoch 14007/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1195738621.1194 - val_loss: 1265754247.3059\n",
      "Epoch 14008/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1195347475.1624 - val_loss: 1265889461.7717\n",
      "Epoch 14009/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1195453524.6654 - val_loss: 1264891606.2100\n",
      "Epoch 14010/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1195428188.8063 - val_loss: 1264908142.7580\n",
      "Epoch 14011/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1195130372.5088 - val_loss: 1266519198.9772\n",
      "Epoch 14012/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1195375077.1977 - val_loss: 1267903652.5297\n",
      "Epoch 14013/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1195513893.0098 - val_loss: 1266921181.2237\n",
      "Epoch 14014/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1195513014.2309 - val_loss: 1265503699.5799\n",
      "Epoch 14015/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1195136977.0333 - val_loss: 1266371134.5388\n",
      "Epoch 14016/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1195882734.4658 - val_loss: 1264943320.2557\n",
      "Epoch 14017/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1195170877.8708 - val_loss: 1266929924.3836\n",
      "Epoch 14018/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1195703140.1957 - val_loss: 1265568516.9680\n",
      "Epoch 14019/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195711139.3190 - val_loss: 1267322154.0822\n",
      "Epoch 14020/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195121411.2564 - val_loss: 1266533254.4292\n",
      "Epoch 14021/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1195309743.0920 - val_loss: 1266727919.6347\n",
      "Epoch 14022/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1195182491.9295 - val_loss: 1266564024.6941\n",
      "Epoch 14023/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1195314095.0920 - val_loss: 1266666164.8950\n",
      "Epoch 14024/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1195570586.9276 - val_loss: 1266290129.8265\n",
      "Epoch 14025/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1195724129.5656 - val_loss: 1265184682.3744\n",
      "Epoch 14026/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1195337007.9061 - val_loss: 1267158013.3699\n",
      "Epoch 14027/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1195524265.9569 - val_loss: 1265267858.1187\n",
      "Epoch 14028/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1195228024.7358 - val_loss: 1265141225.4977\n",
      "Epoch 14029/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1195646046.1840 - val_loss: 1265115287.6712\n",
      "Epoch 14030/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1195184999.5773 - val_loss: 1267122415.0502\n",
      "Epoch 14031/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1195281467.4912 - val_loss: 1267960588.5662\n",
      "Epoch 14032/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1196239596.8376 - val_loss: 1265135822.9041\n",
      "Epoch 14033/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1195456015.9061 - val_loss: 1267637729.8995\n",
      "Epoch 14034/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1195110213.0098 - val_loss: 1266665148.4932\n",
      "Epoch 14035/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1195253280.4384 - val_loss: 1267230175.2694\n",
      "Epoch 14036/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194912463.7182 - val_loss: 1265820909.0046\n",
      "Epoch 14037/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1195592010.8963 - val_loss: 1267584583.0137\n",
      "Epoch 14038/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1195386899.8513 - val_loss: 1265715186.5571\n",
      "Epoch 14039/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1195264785.5969 - val_loss: 1265790310.5753\n",
      "Epoch 14040/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1195517774.4031 - val_loss: 1265459339.1050\n",
      "Epoch 14041/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195031369.6438 - val_loss: 1266242514.1187\n",
      "Epoch 14042/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1195706061.5264 - val_loss: 1267479247.4886\n",
      "Epoch 14043/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194896575.8748 - val_loss: 1266356344.1096\n",
      "Epoch 14044/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1195139396.6341 - val_loss: 1266211942.5753\n",
      "Epoch 14045/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1195268187.8043 - val_loss: 1265535176.1826\n",
      "Epoch 14046/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1195041078.6067 - val_loss: 1265644991.7078\n",
      "Epoch 14047/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1195114893.5890 - val_loss: 1266234001.8265\n",
      "Epoch 14048/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1195493585.4090 - val_loss: 1266170990.7580\n",
      "Epoch 14049/15000\n",
      "1022/1022 [==============================] - 0s 79us/step - loss: 1195060498.7241 - val_loss: 1266858925.5890\n",
      "Epoch 14050/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1195354277.2603 - val_loss: 1266240957.3699\n",
      "Epoch 14051/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1195279022.8415 - val_loss: 1265844932.0913\n",
      "Epoch 14052/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1194880052.2270 - val_loss: 1266968661.0411\n",
      "Epoch 14053/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1195206030.9041 - val_loss: 1266799834.8858\n",
      "Epoch 14054/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1195208503.3581 - val_loss: 1265903809.4612\n",
      "Epoch 14055/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1195310873.5499 - val_loss: 1265694943.8539\n",
      "Epoch 14056/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1195301111.2329 - val_loss: 1265439581.5160\n",
      "Epoch 14057/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1195782773.6047 - val_loss: 1267949198.0274\n",
      "Epoch 14058/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195025594.1135 - val_loss: 1267134074.4475\n",
      "Epoch 14059/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195257536.5010 - val_loss: 1265822542.6119\n",
      "Epoch 14060/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1196152281.9256 - val_loss: 1267959165.3699\n",
      "Epoch 14061/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1194920987.5538 - val_loss: 1265687547.3242\n",
      "Epoch 14062/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1194835958.1057 - val_loss: 1265654030.0274\n",
      "Epoch 14063/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1195056011.4599 - val_loss: 1266185917.3699\n",
      "Epoch 14064/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1195060030.8728 - val_loss: 1266126820.8219\n",
      "Epoch 14065/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1195155423.8121 - val_loss: 1266220725.1872\n",
      "Epoch 14066/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195043663.0294 - val_loss: 1265723135.7078\n",
      "Epoch 14067/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1195330143.6869 - val_loss: 1265678973.9543\n",
      "Epoch 14068/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1195254837.6047 - val_loss: 1267810869.7717\n",
      "Epoch 14069/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194812319.3112 - val_loss: 1267555149.4429\n",
      "Epoch 14070/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1195043137.7534 - val_loss: 1265556488.7671\n",
      "Epoch 14071/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1194919850.3327 - val_loss: 1266962945.4612\n",
      "Epoch 14072/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1195405595.0528 - val_loss: 1266592538.3014\n",
      "Epoch 14073/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1194949261.8395 - val_loss: 1267348165.8447\n",
      "Epoch 14074/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1195507060.1018 - val_loss: 1266467077.2603\n",
      "Epoch 14075/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1195150715.6791 - val_loss: 1266083851.6895\n",
      "Epoch 14076/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1194738020.8219 - val_loss: 1266067497.2055\n",
      "Epoch 14077/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1194959994.7397 - val_loss: 1267074542.1735\n",
      "Epoch 14078/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1194848660.2896 - val_loss: 1266055199.8539\n",
      "Epoch 14079/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1196107168.4384 - val_loss: 1267112101.1142\n",
      "Epoch 14080/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195162226.0978 - val_loss: 1266995373.5890\n",
      "Epoch 14081/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1194792303.8434 - val_loss: 1266173563.3242\n",
      "Epoch 14082/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195089152.7515 - val_loss: 1266898559.7078\n",
      "Epoch 14083/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195009806.2153 - val_loss: 1265057112.5479\n",
      "Epoch 14084/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195517682.8493 - val_loss: 1267194547.4338\n",
      "Epoch 14085/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1194900656.3444 - val_loss: 1266530523.4703\n",
      "Epoch 14086/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194796966.5753 - val_loss: 1266246793.0594\n",
      "Epoch 14087/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194873001.9569 - val_loss: 1265456067.5068\n",
      "Epoch 14088/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194947331.5068 - val_loss: 1266898001.8265\n",
      "Epoch 14089/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194793961.9569 - val_loss: 1267277386.5205\n",
      "Epoch 14090/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195472942.8415 - val_loss: 1265876476.7854\n",
      "Epoch 14091/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1194782663.8904 - val_loss: 1265190063.3425\n",
      "Epoch 14092/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1194660276.1018 - val_loss: 1265960475.7626\n",
      "Epoch 14093/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1194943898.5519 - val_loss: 1265316175.4886\n",
      "Epoch 14094/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1194667637.4168 - val_loss: 1265787401.9361\n",
      "Epoch 14095/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 28us/step - loss: 1194969093.5108 - val_loss: 1267281444.5297\n",
      "Epoch 14096/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1195298942.2466 - val_loss: 1265477798.8676\n",
      "Epoch 14097/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1194695553.5029 - val_loss: 1266576876.1279\n",
      "Epoch 14098/15000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1195023754.8963 - val_loss: 1266264429.5890\n",
      "Epoch 14099/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1194820141.4012 - val_loss: 1267910588.4932\n",
      "Epoch 14100/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1195170164.4775 - val_loss: 1266941731.9452\n",
      "Epoch 14101/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1194704206.7162 - val_loss: 1266442918.2831\n",
      "Epoch 14102/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1195201335.7339 - val_loss: 1266820883.5799\n",
      "Epoch 14103/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1194710506.8337 - val_loss: 1267343213.0046\n",
      "Epoch 14104/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1194709281.6282 - val_loss: 1266008074.5205\n",
      "Epoch 14105/15000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1194889499.3033 - val_loss: 1266509444.3836\n",
      "Epoch 14106/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1194684604.3679 - val_loss: 1266183412.0183\n",
      "Epoch 14107/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1194807041.7534 - val_loss: 1266388864.2922\n",
      "Epoch 14108/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1195001223.3894 - val_loss: 1265438755.6530\n",
      "Epoch 14109/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1194686935.1703 - val_loss: 1266174547.5799\n",
      "Epoch 14110/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1194966328.2348 - val_loss: 1267877940.6027\n",
      "Epoch 14111/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1194734510.2779 - val_loss: 1266420466.5571\n",
      "Epoch 14112/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1194768604.3053 - val_loss: 1265807602.2648\n",
      "Epoch 14113/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1194722398.9354 - val_loss: 1266440545.6073\n",
      "Epoch 14114/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195425592.8611 - val_loss: 1266861374.5388\n",
      "Epoch 14115/15000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1194641660.9941 - val_loss: 1267864091.7626\n",
      "Epoch 14116/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195239032.4227 - val_loss: 1266533183.1233\n",
      "Epoch 14117/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1194525999.0920 - val_loss: 1266361525.1872\n",
      "Epoch 14118/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1194500434.9119 - val_loss: 1266913541.8447\n",
      "Epoch 14119/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194742428.3053 - val_loss: 1266757392.9498\n",
      "Epoch 14120/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1194582283.7104 - val_loss: 1266895328.7306\n",
      "Epoch 14121/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194818219.3346 - val_loss: 1267327596.4201\n",
      "Epoch 14122/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1194581472.5323 - val_loss: 1265703582.6849\n",
      "Epoch 14123/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1194518359.4207 - val_loss: 1266868631.6712\n",
      "Epoch 14124/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194633576.5793 - val_loss: 1265804374.5023\n",
      "Epoch 14125/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1194769209.2368 - val_loss: 1266176604.3470\n",
      "Epoch 14126/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1195162662.3249 - val_loss: 1266111670.9406\n",
      "Epoch 14127/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1194725954.3796 - val_loss: 1266671540.8950\n",
      "Epoch 14128/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1194786328.7984 - val_loss: 1267464229.4064\n",
      "Epoch 14129/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1194645190.1370 - val_loss: 1267450863.9269\n",
      "Epoch 14130/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1194463616.0000 - val_loss: 1265704755.4338\n",
      "Epoch 14131/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1194558536.6419 - val_loss: 1266525152.7306\n",
      "Epoch 14132/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1194567777.0646 - val_loss: 1266858435.2146\n",
      "Epoch 14133/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1194716936.5166 - val_loss: 1265614115.0685\n",
      "Epoch 14134/15000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1194443344.6575 - val_loss: 1266544422.2831\n",
      "Epoch 14135/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194543231.1233 - val_loss: 1266225382.8676\n",
      "Epoch 14136/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195605690.3640 - val_loss: 1267926930.7032\n",
      "Epoch 14137/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1194903552.7515 - val_loss: 1266490317.1507\n",
      "Epoch 14138/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1195174217.6438 - val_loss: 1267752797.5160\n",
      "Epoch 14139/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1194444149.4168 - val_loss: 1265489198.7580\n",
      "Epoch 14140/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1194681958.1996 - val_loss: 1265879125.6256\n",
      "Epoch 14141/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1195398054.0744 - val_loss: 1267340952.8402\n",
      "Epoch 14142/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194495073.8160 - val_loss: 1266748938.8128\n",
      "Epoch 14143/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1194389339.4286 - val_loss: 1266181625.8630\n",
      "Epoch 14144/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1194451084.3992 - val_loss: 1265826314.2283\n",
      "Epoch 14145/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1194739568.4697 - val_loss: 1267050897.8265\n",
      "Epoch 14146/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1194570538.2074 - val_loss: 1266282331.4703\n",
      "Epoch 14147/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194663519.0607 - val_loss: 1265485193.9361\n",
      "Epoch 14148/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194490769.6595 - val_loss: 1266609019.6164\n",
      "Epoch 14149/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1194482863.3425 - val_loss: 1265999028.8950\n",
      "Epoch 14150/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1194441443.6947 - val_loss: 1266204879.7808\n",
      "Epoch 14151/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1194527514.1135 - val_loss: 1266241916.7854\n",
      "Epoch 14152/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1194505178.3014 - val_loss: 1265538142.6849\n",
      "Epoch 14153/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194303759.4051 - val_loss: 1266558067.4338\n",
      "Epoch 14154/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1194592698.8650 - val_loss: 1267137457.0959\n",
      "Epoch 14155/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1194889169.4090 - val_loss: 1268290409.4977\n",
      "Epoch 14156/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194535032.2348 - val_loss: 1266820557.4429\n",
      "Epoch 14157/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194948100.2583 - val_loss: 1266511100.7854\n",
      "Epoch 14158/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194626646.9198 - val_loss: 1265392026.5936\n",
      "Epoch 14159/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 27us/step - loss: 1194311040.6262 - val_loss: 1266299916.5662\n",
      "Epoch 14160/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1194309289.4560 - val_loss: 1266587461.8447\n",
      "Epoch 14161/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1194556308.0391 - val_loss: 1267812094.2466\n",
      "Epoch 14162/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1194546162.3483 - val_loss: 1266887810.0457\n",
      "Epoch 14163/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1195004429.4638 - val_loss: 1267973433.5708\n",
      "Epoch 14164/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1194634663.8278 - val_loss: 1267271323.1781\n",
      "Epoch 14165/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1194310401.3777 - val_loss: 1266752167.1598\n",
      "Epoch 14166/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1195391821.9022 - val_loss: 1265953120.1461\n",
      "Epoch 14167/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1194503423.8748 - val_loss: 1267525586.7032\n",
      "Epoch 14168/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1194689767.5773 - val_loss: 1267361581.2968\n",
      "Epoch 14169/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1194584132.3836 - val_loss: 1267041342.2466\n",
      "Epoch 14170/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1194238753.2524 - val_loss: 1266890924.1279\n",
      "Epoch 14171/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1194259101.3072 - val_loss: 1266146379.6895\n",
      "Epoch 14172/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1194230638.3405 - val_loss: 1266250049.7534\n",
      "Epoch 14173/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1194589782.7945 - val_loss: 1265961059.0685\n",
      "Epoch 14174/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1194765995.5851 - val_loss: 1267624900.9680\n",
      "Epoch 14175/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1194896135.5147 - val_loss: 1265354774.5023\n",
      "Epoch 14176/15000\n",
      "1022/1022 [==============================] - 0s 66us/step - loss: 1194768109.4638 - val_loss: 1264313678.9041\n",
      "Epoch 14177/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1194393159.3894 - val_loss: 1266674589.2237\n",
      "Epoch 14178/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1194540009.7691 - val_loss: 1267999319.6712\n",
      "Epoch 14179/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1194291731.5382 - val_loss: 1267551792.2192\n",
      "Epoch 14180/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1194242688.9393 - val_loss: 1266782641.9726\n",
      "Epoch 14181/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1194190663.0137 - val_loss: 1266749597.2237\n",
      "Epoch 14182/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194486915.6321 - val_loss: 1265554088.9132\n",
      "Epoch 14183/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194380805.0098 - val_loss: 1266793830.5753\n",
      "Epoch 14184/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1194318421.6673 - val_loss: 1267693208.8402\n",
      "Epoch 14185/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194327709.4951 - val_loss: 1267673008.5114\n",
      "Epoch 14186/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194034528.3131 - val_loss: 1266488313.2785\n",
      "Epoch 14187/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1194452323.3190 - val_loss: 1266713874.7032\n",
      "Epoch 14188/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194232401.9100 - val_loss: 1267090276.2374\n",
      "Epoch 14189/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194713377.0646 - val_loss: 1268329386.9589\n",
      "Epoch 14190/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194821361.7221 - val_loss: 1264736049.0959\n",
      "Epoch 14191/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1194343907.4442 - val_loss: 1267076897.0228\n",
      "Epoch 14192/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194992616.8297 - val_loss: 1267580353.7534\n",
      "Epoch 14193/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1194259473.0333 - val_loss: 1266825554.1187\n",
      "Epoch 14194/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1194158988.2740 - val_loss: 1266233609.6438\n",
      "Epoch 14195/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194784062.9354 - val_loss: 1265208886.0639\n",
      "Epoch 14196/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1194342862.6536 - val_loss: 1265362385.2420\n",
      "Epoch 14197/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1194395759.2172 - val_loss: 1266652523.5434\n",
      "Epoch 14198/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194086069.3542 - val_loss: 1266345432.2557\n",
      "Epoch 14199/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1194464182.1683 - val_loss: 1265962981.9909\n",
      "Epoch 14200/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1194064723.6634 - val_loss: 1267485967.7808\n",
      "Epoch 14201/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194186635.7104 - val_loss: 1267046581.4795\n",
      "Epoch 14202/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1195221258.6458 - val_loss: 1265674965.3333\n",
      "Epoch 14203/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194131660.7123 - val_loss: 1266661746.2648\n",
      "Epoch 14204/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194038611.1624 - val_loss: 1267585144.1096\n",
      "Epoch 14205/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194554062.9041 - val_loss: 1268237477.6986\n",
      "Epoch 14206/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194137982.1213 - val_loss: 1266376794.3014\n",
      "Epoch 14207/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1195043602.0352 - val_loss: 1268820964.5297\n",
      "Epoch 14208/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194083134.8728 - val_loss: 1267285696.8767\n",
      "Epoch 14209/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1194334278.6380 - val_loss: 1265760876.7123\n",
      "Epoch 14210/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1194092532.4775 - val_loss: 1265672829.6621\n",
      "Epoch 14211/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1194041789.8708 - val_loss: 1265554638.6119\n",
      "Epoch 14212/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1194726753.5029 - val_loss: 1265135259.7626\n",
      "Epoch 14213/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194727985.8474 - val_loss: 1268417160.1826\n",
      "Epoch 14214/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194333619.0998 - val_loss: 1266648864.7306\n",
      "Epoch 14215/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1194285206.2935 - val_loss: 1267445173.4795\n",
      "Epoch 14216/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1194300708.5714 - val_loss: 1265714974.9772\n",
      "Epoch 14217/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1194601748.5401 - val_loss: 1265025480.7671\n",
      "Epoch 14218/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194659800.2975 - val_loss: 1267805190.1370\n",
      "Epoch 14219/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1194485024.3757 - val_loss: 1266003466.5205\n",
      "Epoch 14220/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1194061536.9393 - val_loss: 1267675212.5662\n",
      "Epoch 14221/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194268074.4579 - val_loss: 1266350247.1598\n",
      "Epoch 14222/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194104974.6536 - val_loss: 1267439149.2968\n",
      "Epoch 14223/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 40us/step - loss: 1194014596.5088 - val_loss: 1267419749.4064\n",
      "Epoch 14224/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1194034091.4599 - val_loss: 1266254807.3790\n",
      "Epoch 14225/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194441528.8611 - val_loss: 1266996324.2374\n",
      "Epoch 14226/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1194522268.9941 - val_loss: 1267548170.8128\n",
      "Epoch 14227/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194196632.0470 - val_loss: 1265928241.0959\n",
      "Epoch 14228/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1194257131.8356 - val_loss: 1267515210.8128\n",
      "Epoch 14229/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1194152025.6751 - val_loss: 1267471802.1553\n",
      "Epoch 14230/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195200712.0157 - val_loss: 1265732983.5251\n",
      "Epoch 14231/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194047920.3444 - val_loss: 1266400291.9452\n",
      "Epoch 14232/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1194051006.4971 - val_loss: 1267744956.4932\n",
      "Epoch 14233/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1194130793.3307 - val_loss: 1267356126.1005\n",
      "Epoch 14234/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194407665.7221 - val_loss: 1268430974.8311\n",
      "Epoch 14235/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193818885.8239 - val_loss: 1267598218.5205\n",
      "Epoch 14236/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1194137254.4501 - val_loss: 1267392971.6895\n",
      "Epoch 14237/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1193958075.8669 - val_loss: 1266334845.0776\n",
      "Epoch 14238/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1193946239.8121 - val_loss: 1265949347.6530\n",
      "Epoch 14239/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194182861.4638 - val_loss: 1266552699.3242\n",
      "Epoch 14240/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194199583.9374 - val_loss: 1265431644.6393\n",
      "Epoch 14241/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1194546383.4051 - val_loss: 1268611351.3790\n",
      "Epoch 14242/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1194112456.8924 - val_loss: 1267274911.8539\n",
      "Epoch 14243/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1193859136.3757 - val_loss: 1267337733.2603\n",
      "Epoch 14244/15000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1194269919.8121 - val_loss: 1265224621.0046\n",
      "Epoch 14245/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194151333.8239 - val_loss: 1265864770.6301\n",
      "Epoch 14246/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1194063638.9824 - val_loss: 1267682968.8402\n",
      "Epoch 14247/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194147495.7025 - val_loss: 1266266049.7534\n",
      "Epoch 14248/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193891427.0685 - val_loss: 1266330959.4886\n",
      "Epoch 14249/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193889709.3386 - val_loss: 1266099503.3425\n",
      "Epoch 14250/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1193987113.2055 - val_loss: 1266199153.6804\n",
      "Epoch 14251/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194171267.5695 - val_loss: 1268300288.0000\n",
      "Epoch 14252/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193787673.8004 - val_loss: 1267747896.6941\n",
      "Epoch 14253/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193861596.4305 - val_loss: 1267280766.5388\n",
      "Epoch 14254/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193810947.2564 - val_loss: 1267445283.9452\n",
      "Epoch 14255/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1193724101.2603 - val_loss: 1266692139.2511\n",
      "Epoch 14256/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1193980804.0078 - val_loss: 1267319719.1598\n",
      "Epoch 14257/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193862111.1859 - val_loss: 1267128689.0959\n",
      "Epoch 14258/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193966548.9159 - val_loss: 1267429733.4064\n",
      "Epoch 14259/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193818688.1879 - val_loss: 1266206330.7397\n",
      "Epoch 14260/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1193802709.4168 - val_loss: 1266929998.9041\n",
      "Epoch 14261/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193687650.1918 - val_loss: 1265867623.1598\n",
      "Epoch 14262/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1194174555.3033 - val_loss: 1265102223.7808\n",
      "Epoch 14263/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1194388608.0000 - val_loss: 1268149349.9909\n",
      "Epoch 14264/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1194290259.4129 - val_loss: 1267577791.4155\n",
      "Epoch 14265/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1194165124.0078 - val_loss: 1265580800.2922\n",
      "Epoch 14266/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1195440660.7906 - val_loss: 1268487131.4703\n",
      "Epoch 14267/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1194601829.8239 - val_loss: 1265604263.4521\n",
      "Epoch 14268/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194141664.9393 - val_loss: 1264668107.1050\n",
      "Epoch 14269/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1193584824.9237 - val_loss: 1267119273.7900\n",
      "Epoch 14270/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1193996125.3072 - val_loss: 1266653378.0457\n",
      "Epoch 14271/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1193864278.1683 - val_loss: 1266686574.1735\n",
      "Epoch 14272/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1195257680.1566 - val_loss: 1269384671.8539\n",
      "Epoch 14273/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1194188843.6477 - val_loss: 1265865297.2420\n",
      "Epoch 14274/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194123406.8415 - val_loss: 1267577243.7626\n",
      "Epoch 14275/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193946477.2133 - val_loss: 1267518944.7306\n",
      "Epoch 14276/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193666941.2446 - val_loss: 1266563906.3379\n",
      "Epoch 14277/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194101090.8180 - val_loss: 1267496324.6758\n",
      "Epoch 14278/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193632515.2564 - val_loss: 1265937764.2374\n",
      "Epoch 14279/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1194146130.6614 - val_loss: 1264464188.7854\n",
      "Epoch 14280/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193556969.0802 - val_loss: 1266513881.7169\n",
      "Epoch 14281/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1194040640.2505 - val_loss: 1268397819.3242\n",
      "Epoch 14282/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1194549863.2016 - val_loss: 1265227681.3151\n",
      "Epoch 14283/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193993913.9883 - val_loss: 1267925502.2466\n",
      "Epoch 14284/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1194030132.3523 - val_loss: 1266959112.4749\n",
      "Epoch 14285/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1193969169.2838 - val_loss: 1267991219.4338\n",
      "Epoch 14286/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1193688342.2309 - val_loss: 1266579174.2831\n",
      "Epoch 14287/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 27us/step - loss: 1194069097.4560 - val_loss: 1265687520.1461\n",
      "Epoch 14288/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1194048106.3327 - val_loss: 1267237693.0776\n",
      "Epoch 14289/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1193590261.4795 - val_loss: 1267758985.9361\n",
      "Epoch 14290/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1193706231.8591 - val_loss: 1267356192.1461\n",
      "Epoch 14291/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193927581.3699 - val_loss: 1266206694.8676\n",
      "Epoch 14292/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1193524317.1820 - val_loss: 1266611645.6621\n",
      "Epoch 14293/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193839012.9472 - val_loss: 1266848299.2511\n",
      "Epoch 14294/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193982422.5440 - val_loss: 1266344281.1324\n",
      "Epoch 14295/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193606655.0607 - val_loss: 1266571846.1370\n",
      "Epoch 14296/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193764259.7573 - val_loss: 1266434499.5068\n",
      "Epoch 14297/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1193654335.3738 - val_loss: 1267076966.8676\n",
      "Epoch 14298/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1193762912.4384 - val_loss: 1266060662.9406\n",
      "Epoch 14299/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1194331981.3386 - val_loss: 1267222435.3607\n",
      "Epoch 14300/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1193740546.0039 - val_loss: 1267531200.0000\n",
      "Epoch 14301/15000\n",
      "1022/1022 [==============================] - 0s 84us/step - loss: 1194217975.6712 - val_loss: 1265944897.4612\n",
      "Epoch 14302/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1194475739.4286 - val_loss: 1267531112.3288\n",
      "Epoch 14303/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1193700881.5342 - val_loss: 1267183824.9498\n",
      "Epoch 14304/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1193551319.1703 - val_loss: 1267081699.0685\n",
      "Epoch 14305/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1193760152.7984 - val_loss: 1265629399.0868\n",
      "Epoch 14306/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1193492666.8023 - val_loss: 1266523859.2877\n",
      "Epoch 14307/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1193908370.7867 - val_loss: 1265410101.7717\n",
      "Epoch 14308/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193818146.4423 - val_loss: 1268067323.6164\n",
      "Epoch 14309/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193436938.2701 - val_loss: 1267036135.7443\n",
      "Epoch 14310/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193746146.4423 - val_loss: 1267141609.2055\n",
      "Epoch 14311/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193587661.9022 - val_loss: 1265566583.2329\n",
      "Epoch 14312/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193567434.0196 - val_loss: 1265988793.5708\n",
      "Epoch 14313/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193954106.1135 - val_loss: 1266557733.1142\n",
      "Epoch 14314/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1194188357.8865 - val_loss: 1267377334.6484\n",
      "Epoch 14315/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1193686383.4051 - val_loss: 1266864459.3973\n",
      "Epoch 14316/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1193627780.2583 - val_loss: 1266854192.2192\n",
      "Epoch 14317/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1193458604.7123 - val_loss: 1266669543.1598\n",
      "Epoch 14318/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1193323177.0802 - val_loss: 1267353329.6804\n",
      "Epoch 14319/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193472415.5616 - val_loss: 1267149009.2420\n",
      "Epoch 14320/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1194226797.7143 - val_loss: 1264706062.9041\n",
      "Epoch 14321/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193716053.4168 - val_loss: 1268170786.1918\n",
      "Epoch 14322/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193558514.0978 - val_loss: 1267548586.6667\n",
      "Epoch 14323/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193323757.2133 - val_loss: 1267602466.4840\n",
      "Epoch 14324/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193501909.3542 - val_loss: 1266075482.5936\n",
      "Epoch 14325/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193477183.8748 - val_loss: 1266647382.7945\n",
      "Epoch 14326/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1193826331.8043 - val_loss: 1267623390.9772\n",
      "Epoch 14327/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1193344666.7397 - val_loss: 1267263952.9498\n",
      "Epoch 14328/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1193500831.8121 - val_loss: 1266186273.6073\n",
      "Epoch 14329/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193779884.3366 - val_loss: 1265038607.1963\n",
      "Epoch 14330/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194730633.5186 - val_loss: 1268161917.0776\n",
      "Epoch 14331/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193407924.6027 - val_loss: 1266492262.5753\n",
      "Epoch 14332/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1193636167.6399 - val_loss: 1266052630.2100\n",
      "Epoch 14333/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1193816669.6830 - val_loss: 1267142844.4932\n",
      "Epoch 14334/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1193998728.8924 - val_loss: 1267395238.2831\n",
      "Epoch 14335/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1193864339.2877 - val_loss: 1265217530.7397\n",
      "Epoch 14336/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1193234235.1781 - val_loss: 1266224251.6164\n",
      "Epoch 14337/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1193623970.6928 - val_loss: 1267323384.1096\n",
      "Epoch 14338/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1193689612.6497 - val_loss: 1267443285.6256\n",
      "Epoch 14339/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1194112231.9530 - val_loss: 1268148451.9452\n",
      "Epoch 14340/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1193905898.2701 - val_loss: 1265663070.3927\n",
      "Epoch 14341/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1193500964.0705 - val_loss: 1267485374.5388\n",
      "Epoch 14342/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193922985.3933 - val_loss: 1265257035.9817\n",
      "Epoch 14343/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1193369460.2270 - val_loss: 1266590693.4064\n",
      "Epoch 14344/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193216913.6595 - val_loss: 1266957822.5388\n",
      "Epoch 14345/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193627715.3816 - val_loss: 1266976678.2831\n",
      "Epoch 14346/15000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1193572648.5793 - val_loss: 1266448379.6164\n",
      "Epoch 14347/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193379169.5656 - val_loss: 1266147453.0776\n",
      "Epoch 14348/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193402138.4266 - val_loss: 1266774926.3196\n",
      "Epoch 14349/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1194175837.9335 - val_loss: 1268334372.5297\n",
      "Epoch 14350/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1194076869.8865 - val_loss: 1268409279.7078\n",
      "Epoch 14351/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1194025054.4344 - val_loss: 1265303941.8447\n",
      "Epoch 14352/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193385773.9648 - val_loss: 1266609434.0091\n",
      "Epoch 14353/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1193465011.0998 - val_loss: 1266324733.6621\n",
      "Epoch 14354/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193303015.7025 - val_loss: 1266962791.7443\n",
      "Epoch 14355/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1193260117.4168 - val_loss: 1266698548.3105\n",
      "Epoch 14356/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1193573709.4012 - val_loss: 1267486910.2466\n",
      "Epoch 14357/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193473742.7789 - val_loss: 1267126986.5205\n",
      "Epoch 14358/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1194258283.9609 - val_loss: 1265529139.4338\n",
      "Epoch 14359/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193139067.2407 - val_loss: 1267185917.3699\n",
      "Epoch 14360/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1193776005.7613 - val_loss: 1265578587.4703\n",
      "Epoch 14361/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193237359.7182 - val_loss: 1267058555.9087\n",
      "Epoch 14362/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193380391.9530 - val_loss: 1268312860.6393\n",
      "Epoch 14363/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193377098.3327 - val_loss: 1267462957.2968\n",
      "Epoch 14364/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193984203.7104 - val_loss: 1265480388.9680\n",
      "Epoch 14365/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193218856.4540 - val_loss: 1267236532.8950\n",
      "Epoch 14366/15000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1193106491.1155 - val_loss: 1266989303.5251\n",
      "Epoch 14367/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1193499158.2935 - val_loss: 1268114643.8721\n",
      "Epoch 14368/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193275939.1311 - val_loss: 1267860930.9224\n",
      "Epoch 14369/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193106835.7886 - val_loss: 1266837342.3927\n",
      "Epoch 14370/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1193227537.0333 - val_loss: 1266698451.2877\n",
      "Epoch 14371/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193357095.9530 - val_loss: 1266533310.2466\n",
      "Epoch 14372/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193066035.7260 - val_loss: 1266344089.4247\n",
      "Epoch 14373/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193331668.1644 - val_loss: 1267230613.3333\n",
      "Epoch 14374/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193893016.7984 - val_loss: 1265930313.0594\n",
      "Epoch 14375/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193186914.1918 - val_loss: 1267814819.3607\n",
      "Epoch 14376/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193134977.5029 - val_loss: 1267158767.6347\n",
      "Epoch 14377/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1193287054.7162 - val_loss: 1267557189.5525\n",
      "Epoch 14378/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193114356.2270 - val_loss: 1267091575.2329\n",
      "Epoch 14379/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1193276952.7984 - val_loss: 1267161660.4932\n",
      "Epoch 14380/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193703149.5890 - val_loss: 1265873933.1507\n",
      "Epoch 14381/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1193200387.0059 - val_loss: 1267373954.9224\n",
      "Epoch 14382/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193378742.2935 - val_loss: 1267076487.3059\n",
      "Epoch 14383/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1193067010.5049 - val_loss: 1266976455.5982\n",
      "Epoch 14384/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1193332704.1879 - val_loss: 1266538076.0548\n",
      "Epoch 14385/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193350610.1605 - val_loss: 1267860000.7306\n",
      "Epoch 14386/15000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1193216320.3757 - val_loss: 1265928414.6849\n",
      "Epoch 14387/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192993793.6282 - val_loss: 1267196267.5434\n",
      "Epoch 14388/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1193429845.0411 - val_loss: 1265925026.1918\n",
      "Epoch 14389/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1193323333.1977 - val_loss: 1267824374.9406\n",
      "Epoch 14390/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1193322955.0841 - val_loss: 1268064795.4703\n",
      "Epoch 14391/15000\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 1193381498.8650 - val_loss: 1266655357.0776\n",
      "Epoch 14392/15000\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 1193325968.0313 - val_loss: 1267673248.1461\n",
      "Epoch 14393/15000\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 1193444618.3953 - val_loss: 1265836876.8584\n",
      "Epoch 14394/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1193158110.6849 - val_loss: 1266854287.7808\n",
      "Epoch 14395/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1193346087.5773 - val_loss: 1266156786.2648\n",
      "Epoch 14396/15000\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 1193389112.1096 - val_loss: 1266338470.5753\n",
      "Epoch 14397/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1193129655.1076 - val_loss: 1266985767.4521\n",
      "Epoch 14398/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1193391071.1859 - val_loss: 1267044577.3151\n",
      "Epoch 14399/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1193228604.1174 - val_loss: 1267687600.5114\n",
      "Epoch 14400/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1193470714.1761 - val_loss: 1267337607.3059\n",
      "Epoch 14401/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1193326841.4873 - val_loss: 1267152479.2694\n",
      "Epoch 14402/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1193296934.3249 - val_loss: 1267499485.2237\n",
      "Epoch 14403/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1193770831.6556 - val_loss: 1264991375.7808\n",
      "Epoch 14404/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192903965.9335 - val_loss: 1266966056.9132\n",
      "Epoch 14405/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193251766.2309 - val_loss: 1267099579.6164\n",
      "Epoch 14406/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193341622.2309 - val_loss: 1267599253.3333\n",
      "Epoch 14407/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1193298341.3229 - val_loss: 1267723181.2968\n",
      "Epoch 14408/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193126602.3953 - val_loss: 1265970273.0228\n",
      "Epoch 14409/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193210085.6986 - val_loss: 1267032526.0274\n",
      "Epoch 14410/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1193941119.2485 - val_loss: 1265484529.6804\n",
      "Epoch 14411/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193363427.4442 - val_loss: 1268317877.7717\n",
      "Epoch 14412/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192986358.9824 - val_loss: 1268117347.6530\n",
      "Epoch 14413/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192973514.3953 - val_loss: 1266349501.0776\n",
      "Epoch 14414/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1192910585.5499 - val_loss: 1266808551.1598\n",
      "Epoch 14415/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193790673.1585 - val_loss: 1268234661.9909\n",
      "Epoch 14416/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193845479.4521 - val_loss: 1265958416.6575\n",
      "Epoch 14417/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1193320119.2955 - val_loss: 1267349624.1096\n",
      "Epoch 14418/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193659369.9569 - val_loss: 1265639477.7717\n",
      "Epoch 14419/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1194026188.1487 - val_loss: 1267513594.7397\n",
      "Epoch 14420/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192755729.2838 - val_loss: 1266715741.8082\n",
      "Epoch 14421/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1193270561.1272 - val_loss: 1267011904.5845\n",
      "Epoch 14422/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193864055.7339 - val_loss: 1265135691.3973\n",
      "Epoch 14423/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193335198.6223 - val_loss: 1268108302.6119\n",
      "Epoch 14424/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1193014479.1546 - val_loss: 1266487699.2877\n",
      "Epoch 14425/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1193220660.6654 - val_loss: 1267502670.3196\n",
      "Epoch 14426/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1193102291.6634 - val_loss: 1266741495.2329\n",
      "Epoch 14427/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1193597574.7006 - val_loss: 1268262208.0000\n",
      "Epoch 14428/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1192967654.6380 - val_loss: 1266198864.6575\n",
      "Epoch 14429/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192861153.8160 - val_loss: 1266372909.5890\n",
      "Epoch 14430/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1193154435.5068 - val_loss: 1267971788.5662\n",
      "Epoch 14431/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1192947757.7769 - val_loss: 1267330216.9132\n",
      "Epoch 14432/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1193202750.9354 - val_loss: 1265911182.6119\n",
      "Epoch 14433/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193051165.4951 - val_loss: 1267143430.7215\n",
      "Epoch 14434/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192722742.1057 - val_loss: 1266917727.8539\n",
      "Epoch 14435/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1193120469.1663 - val_loss: 1265934010.1553\n",
      "Epoch 14436/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1192920026.8023 - val_loss: 1266698110.2466\n",
      "Epoch 14437/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1194056526.4031 - val_loss: 1268112927.8539\n",
      "Epoch 14438/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1193584665.8004 - val_loss: 1267102122.6667\n",
      "Epoch 14439/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1193121838.7789 - val_loss: 1265391649.8995\n",
      "Epoch 14440/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193104730.1761 - val_loss: 1267656535.9635\n",
      "Epoch 14441/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1193134495.3112 - val_loss: 1265859666.7032\n",
      "Epoch 14442/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193325743.9687 - val_loss: 1265088018.1187\n",
      "Epoch 14443/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1192872972.4618 - val_loss: 1265688267.6895\n",
      "Epoch 14444/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1193751750.0744 - val_loss: 1268045228.7123\n",
      "Epoch 14445/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1193246095.9061 - val_loss: 1266539525.8447\n",
      "Epoch 14446/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1192940663.4834 - val_loss: 1267063866.4475\n",
      "Epoch 14447/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192763667.5382 - val_loss: 1266997146.0091\n",
      "Epoch 14448/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193204005.6360 - val_loss: 1266441350.7215\n",
      "Epoch 14449/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193334385.3464 - val_loss: 1268105920.5845\n",
      "Epoch 14450/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193096070.7632 - val_loss: 1267685469.2237\n",
      "Epoch 14451/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1193020106.2074 - val_loss: 1267863632.9498\n",
      "Epoch 14452/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192823472.0939 - val_loss: 1267221007.7808\n",
      "Epoch 14453/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193227996.9315 - val_loss: 1267839803.0320\n",
      "Epoch 14454/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193269037.4638 - val_loss: 1265853110.3562\n",
      "Epoch 14455/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192868701.3072 - val_loss: 1267418759.5982\n",
      "Epoch 14456/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193647244.5871 - val_loss: 1265908032.0000\n",
      "Epoch 14457/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192885679.4677 - val_loss: 1266531887.6347\n",
      "Epoch 14458/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193101430.8571 - val_loss: 1266998270.8311\n",
      "Epoch 14459/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192856724.9785 - val_loss: 1267434563.5068\n",
      "Epoch 14460/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192834936.1096 - val_loss: 1268042952.1826\n",
      "Epoch 14461/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192854528.9393 - val_loss: 1266714795.8356\n",
      "Epoch 14462/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192693499.5538 - val_loss: 1266444425.0594\n",
      "Epoch 14463/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1192841173.1663 - val_loss: 1265967481.8630\n",
      "Epoch 14464/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192668441.5499 - val_loss: 1266330114.9224\n",
      "Epoch 14465/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192879166.6223 - val_loss: 1266899972.3836\n",
      "Epoch 14466/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1193446051.6947 - val_loss: 1265264235.8356\n",
      "Epoch 14467/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1192488869.0724 - val_loss: 1266912182.9406\n",
      "Epoch 14468/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1192659710.4344 - val_loss: 1267207566.3196\n",
      "Epoch 14469/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1193230727.9530 - val_loss: 1267942730.5205\n",
      "Epoch 14470/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1192811936.6888 - val_loss: 1267270863.7808\n",
      "Epoch 14471/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193705350.7632 - val_loss: 1265167659.8356\n",
      "Epoch 14472/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193090661.3229 - val_loss: 1265997787.4703\n",
      "Epoch 14473/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192816273.0333 - val_loss: 1267102848.2922\n",
      "Epoch 14474/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1192721010.8493 - val_loss: 1266237136.0731\n",
      "Epoch 14475/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192677650.1605 - val_loss: 1267055703.3790\n",
      "Epoch 14476/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192747344.5323 - val_loss: 1267418179.2146\n",
      "Epoch 14477/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192875285.7926 - val_loss: 1266624715.9817\n",
      "Epoch 14478/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192604617.3933 - val_loss: 1267329995.1050\n",
      "Epoch 14479/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192579535.0294 - val_loss: 1267089645.5890\n",
      "Epoch 14480/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192616940.2114 - val_loss: 1266708138.0822\n",
      "Epoch 14481/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1192680332.2740 - val_loss: 1267714808.1096\n",
      "Epoch 14482/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192714263.3581 - val_loss: 1267096093.2237\n",
      "Epoch 14483/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1193727419.3033 - val_loss: 1264978960.6575\n",
      "Epoch 14484/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192533050.6145 - val_loss: 1266665705.7900\n",
      "Epoch 14485/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192887763.9139 - val_loss: 1268091136.0000\n",
      "Epoch 14486/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192837119.3112 - val_loss: 1268258775.3790\n",
      "Epoch 14487/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1192797454.2779 - val_loss: 1266529571.6530\n",
      "Epoch 14488/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192593520.7202 - val_loss: 1266419458.9224\n",
      "Epoch 14489/15000\n",
      "1022/1022 [==============================] - 0s 76us/step - loss: 1192762289.8474 - val_loss: 1266752145.2420\n",
      "Epoch 14490/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1192990238.1840 - val_loss: 1266860409.8630\n",
      "Epoch 14491/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1192891757.8395 - val_loss: 1267558293.6256\n",
      "Epoch 14492/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1192770205.0568 - val_loss: 1268127462.5753\n",
      "Epoch 14493/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1192458865.0959 - val_loss: 1267614300.0548\n",
      "Epoch 14494/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1193057519.9687 - val_loss: 1267004828.3470\n",
      "Epoch 14495/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192554603.9609 - val_loss: 1266634767.4886\n",
      "Epoch 14496/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1192734212.7593 - val_loss: 1267223538.8493\n",
      "Epoch 14497/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192510991.2798 - val_loss: 1265874134.5023\n",
      "Epoch 14498/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1192425324.7123 - val_loss: 1266314259.2877\n",
      "Epoch 14499/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1192545753.8004 - val_loss: 1266360077.4429\n",
      "Epoch 14500/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1193346286.7162 - val_loss: 1268382436.2374\n",
      "Epoch 14501/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1192448080.1566 - val_loss: 1266723455.1233\n",
      "Epoch 14502/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192425349.8865 - val_loss: 1266125686.0639\n",
      "Epoch 14503/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192896140.5245 - val_loss: 1264707922.1187\n",
      "Epoch 14504/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1192640079.2798 - val_loss: 1267127688.1826\n",
      "Epoch 14505/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1192867563.2094 - val_loss: 1265361002.6667\n",
      "Epoch 14506/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1192655271.5773 - val_loss: 1267610876.4932\n",
      "Epoch 14507/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192469112.9863 - val_loss: 1267532079.3425\n",
      "Epoch 14508/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1192705407.7495 - val_loss: 1265439946.5205\n",
      "Epoch 14509/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1192620621.1507 - val_loss: 1264944855.9635\n",
      "Epoch 14510/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1192596477.1194 - val_loss: 1265969264.5114\n",
      "Epoch 14511/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1192581490.7241 - val_loss: 1267598109.2237\n",
      "Epoch 14512/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1193224303.5930 - val_loss: 1265989027.3607\n",
      "Epoch 14513/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1192535285.2290 - val_loss: 1266820270.7580\n",
      "Epoch 14514/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1192731759.2172 - val_loss: 1266417626.8858\n",
      "Epoch 14515/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1192396206.2153 - val_loss: 1268101769.9361\n",
      "Epoch 14516/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1192442725.1977 - val_loss: 1267959578.0091\n",
      "Epoch 14517/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1192700091.2407 - val_loss: 1267135558.1370\n",
      "Epoch 14518/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192911191.0450 - val_loss: 1267860484.0913\n",
      "Epoch 14519/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192917556.8532 - val_loss: 1265098584.5479\n",
      "Epoch 14520/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1192785980.8689 - val_loss: 1267945368.5479\n",
      "Epoch 14521/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192591759.0294 - val_loss: 1266356158.5388\n",
      "Epoch 14522/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1192533201.6595 - val_loss: 1266573660.6393\n",
      "Epoch 14523/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1192296360.0157 - val_loss: 1266951530.3744\n",
      "Epoch 14524/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1192865057.5656 - val_loss: 1264876918.9406\n",
      "Epoch 14525/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1193101713.6595 - val_loss: 1267928815.6347\n",
      "Epoch 14526/15000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1192261771.7730 - val_loss: 1267096808.0365\n",
      "Epoch 14527/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1192284333.0881 - val_loss: 1267041605.8447\n",
      "Epoch 14528/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1192367329.8160 - val_loss: 1266849005.8813\n",
      "Epoch 14529/15000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1192980826.9276 - val_loss: 1266261686.0639\n",
      "Epoch 14530/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1192250385.2838 - val_loss: 1266055532.4201\n",
      "Epoch 14531/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192474033.0959 - val_loss: 1265711245.4429\n",
      "Epoch 14532/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1192376399.1546 - val_loss: 1267611230.3927\n",
      "Epoch 14533/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192355018.3953 - val_loss: 1266426811.9087\n",
      "Epoch 14534/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192262718.2466 - val_loss: 1266677242.4475\n",
      "Epoch 14535/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192359173.4481 - val_loss: 1266674744.1096\n",
      "Epoch 14536/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192387896.7358 - val_loss: 1267355010.3379\n",
      "Epoch 14537/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192395668.4149 - val_loss: 1267154142.9772\n",
      "Epoch 14538/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1192436554.1448 - val_loss: 1267827829.4795\n",
      "Epoch 14539/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1192588707.3190 - val_loss: 1267432392.7671\n",
      "Epoch 14540/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1192276520.7671 - val_loss: 1266954477.2968\n",
      "Epoch 14541/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1192221962.6458 - val_loss: 1266957525.0411\n",
      "Epoch 14542/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1192596840.8297 - val_loss: 1267142650.7397\n",
      "Epoch 14543/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 31us/step - loss: 1192308864.5010 - val_loss: 1266473173.6256\n",
      "Epoch 14544/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192315828.6027 - val_loss: 1265395726.9041\n",
      "Epoch 14545/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192539546.3014 - val_loss: 1266741361.0959\n",
      "Epoch 14546/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192713092.2583 - val_loss: 1265086619.1781\n",
      "Epoch 14547/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192215993.6125 - val_loss: 1265935183.1963\n",
      "Epoch 14548/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192454562.1918 - val_loss: 1268258203.1781\n",
      "Epoch 14549/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1192473695.3738 - val_loss: 1267296432.2192\n",
      "Epoch 14550/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192311868.6810 - val_loss: 1266504193.7534\n",
      "Epoch 14551/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192271774.6849 - val_loss: 1266631573.6256\n",
      "Epoch 14552/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192186657.6282 - val_loss: 1267205448.4749\n",
      "Epoch 14553/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1192068406.4814 - val_loss: 1267212500.7489\n",
      "Epoch 14554/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1192432513.2524 - val_loss: 1267672275.8721\n",
      "Epoch 14555/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192640083.9139 - val_loss: 1266364182.7945\n",
      "Epoch 14556/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1192650253.2759 - val_loss: 1265391532.4201\n",
      "Epoch 14557/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1192247098.6145 - val_loss: 1267926759.7443\n",
      "Epoch 14558/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1192802068.2896 - val_loss: 1267595746.4840\n",
      "Epoch 14559/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1192620643.6947 - val_loss: 1265744640.8767\n",
      "Epoch 14560/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1192109073.6595 - val_loss: 1266465362.1187\n",
      "Epoch 14561/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1192350394.6145 - val_loss: 1265932361.6438\n",
      "Epoch 14562/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1192490249.2681 - val_loss: 1267145882.5936\n",
      "Epoch 14563/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1192787560.0783 - val_loss: 1267634676.0183\n",
      "Epoch 14564/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1192241851.8669 - val_loss: 1266561640.3288\n",
      "Epoch 14565/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1192541625.1742 - val_loss: 1266271943.3059\n",
      "Epoch 14566/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1192363687.5773 - val_loss: 1267498985.4977\n",
      "Epoch 14567/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1192615526.9511 - val_loss: 1268659044.2374\n",
      "Epoch 14568/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1192203138.5049 - val_loss: 1267608980.7489\n",
      "Epoch 14569/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1192601520.9706 - val_loss: 1266913918.2466\n",
      "Epoch 14570/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1192413240.1096 - val_loss: 1266907723.3973\n",
      "Epoch 14571/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1192367535.0920 - val_loss: 1267079194.8858\n",
      "Epoch 14572/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192679313.5342 - val_loss: 1267549205.9178\n",
      "Epoch 14573/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192485899.6791 - val_loss: 1266589577.6438\n",
      "Epoch 14574/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1192124781.2133 - val_loss: 1267208985.1324\n",
      "Epoch 14575/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1192404309.1663 - val_loss: 1267247591.7443\n",
      "Epoch 14576/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1192220838.3249 - val_loss: 1266658669.8813\n",
      "Epoch 14577/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192295527.8904 - val_loss: 1265594864.2192\n",
      "Epoch 14578/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192481621.6673 - val_loss: 1266675941.4064\n",
      "Epoch 14579/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192455215.0920 - val_loss: 1267233822.6849\n",
      "Epoch 14580/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192162042.9276 - val_loss: 1266843232.4384\n",
      "Epoch 14581/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192270610.7867 - val_loss: 1266493840.6575\n",
      "Epoch 14582/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1192047037.3699 - val_loss: 1266356558.6119\n",
      "Epoch 14583/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192043454.6223 - val_loss: 1266476923.6164\n",
      "Epoch 14584/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192222654.2466 - val_loss: 1267033376.4384\n",
      "Epoch 14585/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191982682.1761 - val_loss: 1266617815.3790\n",
      "Epoch 14586/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192554676.9785 - val_loss: 1265971635.7260\n",
      "Epoch 14587/15000\n",
      "1022/1022 [==============================] - 0s 84us/step - loss: 1192304712.2661 - val_loss: 1266992100.8219\n",
      "Epoch 14588/15000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1192436426.7084 - val_loss: 1266121664.2922\n",
      "Epoch 14589/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1192141471.3112 - val_loss: 1267651120.5114\n",
      "Epoch 14590/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1192260941.9022 - val_loss: 1268346252.2740\n",
      "Epoch 14591/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1192571773.6830 - val_loss: 1265784655.7808\n",
      "Epoch 14592/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1192389554.2231 - val_loss: 1267733313.4612\n",
      "Epoch 14593/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1192244143.5930 - val_loss: 1267572482.3379\n",
      "Epoch 14594/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192796830.9354 - val_loss: 1266622116.5297\n",
      "Epoch 14595/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192258461.8082 - val_loss: 1267101502.2466\n",
      "Epoch 14596/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1192054067.7260 - val_loss: 1267197432.1096\n",
      "Epoch 14597/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192074229.1037 - val_loss: 1266468041.6438\n",
      "Epoch 14598/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192255919.0920 - val_loss: 1267424392.1826\n",
      "Epoch 14599/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192307286.2935 - val_loss: 1267167356.4932\n",
      "Epoch 14600/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192164369.6595 - val_loss: 1266123621.9909\n",
      "Epoch 14601/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1192082514.9119 - val_loss: 1267035433.7900\n",
      "Epoch 14602/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192292975.4677 - val_loss: 1267243116.7123\n",
      "Epoch 14603/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191972048.3444 - val_loss: 1266391685.5525\n",
      "Epoch 14604/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1191977840.4697 - val_loss: 1266263536.8037\n",
      "Epoch 14605/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1192193670.5127 - val_loss: 1266117537.0228\n",
      "Epoch 14606/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1192015660.5871 - val_loss: 1265901664.7306\n",
      "Epoch 14607/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1192462721.7534 - val_loss: 1264880146.4110\n",
      "Epoch 14608/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191953690.5519 - val_loss: 1265954964.4566\n",
      "Epoch 14609/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1191740793.7378 - val_loss: 1266891919.7808\n",
      "Epoch 14610/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1192349163.4599 - val_loss: 1268865017.8630\n",
      "Epoch 14611/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1191852728.3601 - val_loss: 1267626613.7717\n",
      "Epoch 14612/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1192303796.9785 - val_loss: 1268187198.8311\n",
      "Epoch 14613/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1191883168.8141 - val_loss: 1266627281.5342\n",
      "Epoch 14614/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192033726.7476 - val_loss: 1266121381.9909\n",
      "Epoch 14615/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191928742.9511 - val_loss: 1267486468.9680\n",
      "Epoch 14616/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1191927441.4090 - val_loss: 1266398083.2146\n",
      "Epoch 14617/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1192431484.7436 - val_loss: 1267024874.0822\n",
      "Epoch 14618/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191800682.8337 - val_loss: 1267541283.0685\n",
      "Epoch 14619/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1192097462.8571 - val_loss: 1268311377.2420\n",
      "Epoch 14620/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192003199.1233 - val_loss: 1267505566.1005\n",
      "Epoch 14621/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192187938.8180 - val_loss: 1266300798.5388\n",
      "Epoch 14622/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1191880104.2035 - val_loss: 1266531096.2557\n",
      "Epoch 14623/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192077670.5753 - val_loss: 1267114368.8767\n",
      "Epoch 14624/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192148474.6145 - val_loss: 1266698637.4429\n",
      "Epoch 14625/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1192263811.6321 - val_loss: 1266578723.3607\n",
      "Epoch 14626/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1191884245.6673 - val_loss: 1267524248.2557\n",
      "Epoch 14627/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192221975.2329 - val_loss: 1267818389.6256\n",
      "Epoch 14628/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1192153012.3523 - val_loss: 1266482984.6210\n",
      "Epoch 14629/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1192201484.0235 - val_loss: 1267788102.1370\n",
      "Epoch 14630/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1191849681.6595 - val_loss: 1266996683.3973\n",
      "Epoch 14631/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1191851956.1018 - val_loss: 1267582701.5890\n",
      "Epoch 14632/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1192139976.7671 - val_loss: 1267564476.7854\n",
      "Epoch 14633/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1191927044.6341 - val_loss: 1266510197.1872\n",
      "Epoch 14634/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192171573.4795 - val_loss: 1267068644.2374\n",
      "Epoch 14635/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1191919409.0333 - val_loss: 1266350128.8037\n",
      "Epoch 14636/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1191895547.7417 - val_loss: 1266815583.8539\n",
      "Epoch 14637/15000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1191674866.4736 - val_loss: 1266628716.7123\n",
      "Epoch 14638/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1192260312.4227 - val_loss: 1265359283.1416\n",
      "Epoch 14639/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192595762.0978 - val_loss: 1267808737.8995\n",
      "Epoch 14640/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1191751269.2603 - val_loss: 1266910801.2420\n",
      "Epoch 14641/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191803931.6791 - val_loss: 1266563328.0000\n",
      "Epoch 14642/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1192402864.9080 - val_loss: 1266456336.9498\n",
      "Epoch 14643/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1191954251.5225 - val_loss: 1266025779.1416\n",
      "Epoch 14644/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1192034850.0665 - val_loss: 1267397363.7260\n",
      "Epoch 14645/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191782752.0626 - val_loss: 1267201111.6712\n",
      "Epoch 14646/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1192383999.2485 - val_loss: 1266029376.2922\n",
      "Epoch 14647/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191732219.8669 - val_loss: 1267423755.1050\n",
      "Epoch 14648/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192070503.9530 - val_loss: 1268034839.9635\n",
      "Epoch 14649/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191840949.7299 - val_loss: 1266795227.1781\n",
      "Epoch 14650/15000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1191783912.3288 - val_loss: 1267214145.4612\n",
      "Epoch 14651/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1191715311.2172 - val_loss: 1266639154.2648\n",
      "Epoch 14652/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1191708633.5499 - val_loss: 1267037327.4886\n",
      "Epoch 14653/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1192520035.6947 - val_loss: 1264929581.5890\n",
      "Epoch 14654/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1193061498.8650 - val_loss: 1268045892.3836\n",
      "Epoch 14655/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192089766.8258 - val_loss: 1266618387.2877\n",
      "Epoch 14656/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191778378.8963 - val_loss: 1267383215.6347\n",
      "Epoch 14657/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191698531.9452 - val_loss: 1266197811.4338\n",
      "Epoch 14658/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191737823.9374 - val_loss: 1267188801.1689\n",
      "Epoch 14659/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1191773386.8963 - val_loss: 1267521810.9954\n",
      "Epoch 14660/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1191974204.7436 - val_loss: 1266741382.7215\n",
      "Epoch 14661/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1192058261.5421 - val_loss: 1265656184.6941\n",
      "Epoch 14662/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191797179.2407 - val_loss: 1267053576.4749\n",
      "Epoch 14663/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191697883.6791 - val_loss: 1267664210.7032\n",
      "Epoch 14664/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1191966690.7554 - val_loss: 1266630140.7854\n",
      "Epoch 14665/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191969428.0391 - val_loss: 1267472357.4064\n",
      "Epoch 14666/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192253198.2779 - val_loss: 1266000315.6164\n",
      "Epoch 14667/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191744386.5675 - val_loss: 1266227625.7900\n",
      "Epoch 14668/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1191627033.4247 - val_loss: 1266557799.4521\n",
      "Epoch 14669/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191641610.9589 - val_loss: 1266893960.7671\n",
      "Epoch 14670/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191664017.4716 - val_loss: 1267280540.3470\n",
      "Epoch 14671/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 34us/step - loss: 1191647911.8278 - val_loss: 1267828489.0594\n",
      "Epoch 14672/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191864803.9452 - val_loss: 1266319874.3379\n",
      "Epoch 14673/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1191787753.7065 - val_loss: 1267505281.7534\n",
      "Epoch 14674/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1191549565.2446 - val_loss: 1267653244.7854\n",
      "Epoch 14675/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191507284.9159 - val_loss: 1266848902.7215\n",
      "Epoch 14676/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192301215.7495 - val_loss: 1266159464.9132\n",
      "Epoch 14677/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191793640.0157 - val_loss: 1266595012.3836\n",
      "Epoch 14678/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1191795887.8434 - val_loss: 1267163284.7489\n",
      "Epoch 14679/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1191941596.4305 - val_loss: 1266816386.0457\n",
      "Epoch 14680/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1191665869.9022 - val_loss: 1268137157.5525\n",
      "Epoch 14681/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191747770.2387 - val_loss: 1266546331.7626\n",
      "Epoch 14682/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1192215539.2250 - val_loss: 1269142437.4064\n",
      "Epoch 14683/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1191763661.6517 - val_loss: 1267863210.3744\n",
      "Epoch 14684/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1191955625.5812 - val_loss: 1268092760.5479\n",
      "Epoch 14685/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1191782412.6497 - val_loss: 1267199649.3151\n",
      "Epoch 14686/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1191837225.8317 - val_loss: 1265728350.3927\n",
      "Epoch 14687/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1191554720.3131 - val_loss: 1265508355.2146\n",
      "Epoch 14688/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191531547.6791 - val_loss: 1267046403.5068\n",
      "Epoch 14689/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191470387.0998 - val_loss: 1266915032.5479\n",
      "Epoch 14690/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191487445.6673 - val_loss: 1267530591.8539\n",
      "Epoch 14691/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1192763350.9198 - val_loss: 1264197822.5388\n",
      "Epoch 14692/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191321839.7182 - val_loss: 1267093254.4292\n",
      "Epoch 14693/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1191862349.6517 - val_loss: 1265858421.1872\n",
      "Epoch 14694/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191821179.6164 - val_loss: 1267918094.9041\n",
      "Epoch 14695/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1191520606.0587 - val_loss: 1267411507.4338\n",
      "Epoch 14696/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191587507.3503 - val_loss: 1267829817.5708\n",
      "Epoch 14697/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192271501.5264 - val_loss: 1267525544.6210\n",
      "Epoch 14698/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192178336.4384 - val_loss: 1268630870.2100\n",
      "Epoch 14699/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1191556937.7691 - val_loss: 1267328057.2785\n",
      "Epoch 14700/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192063223.4834 - val_loss: 1265844169.3516\n",
      "Epoch 14701/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1192054538.3953 - val_loss: 1268054058.6667\n",
      "Epoch 14702/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192028740.8845 - val_loss: 1265572247.6712\n",
      "Epoch 14703/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191624011.1468 - val_loss: 1267017036.8584\n",
      "Epoch 14704/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1191733599.6869 - val_loss: 1265857045.9178\n",
      "Epoch 14705/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191633082.8650 - val_loss: 1265799552.8767\n",
      "Epoch 14706/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191686282.0196 - val_loss: 1267563874.1918\n",
      "Epoch 14707/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191491148.2740 - val_loss: 1267375037.0776\n",
      "Epoch 14708/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191548583.3268 - val_loss: 1266751255.9635\n",
      "Epoch 14709/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1191646008.9863 - val_loss: 1267168839.3059\n",
      "Epoch 14710/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1191851353.1742 - val_loss: 1266139097.4247\n",
      "Epoch 14711/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1191743652.6341 - val_loss: 1264797043.4338\n",
      "Epoch 14712/15000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1191754122.0196 - val_loss: 1267405973.9178\n",
      "Epoch 14713/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192125200.5323 - val_loss: 1265047119.4886\n",
      "Epoch 14714/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1192104416.9393 - val_loss: 1268353619.2877\n",
      "Epoch 14715/15000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1191269319.7652 - val_loss: 1266639284.0183\n",
      "Epoch 14716/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1191563818.8337 - val_loss: 1267037180.2009\n",
      "Epoch 14717/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1191546263.2955 - val_loss: 1267333479.4521\n",
      "Epoch 14718/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1191809880.7984 - val_loss: 1266822610.4110\n",
      "Epoch 14719/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191341659.4286 - val_loss: 1266324801.4612\n",
      "Epoch 14720/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1191634178.2544 - val_loss: 1266484693.6256\n",
      "Epoch 14721/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1191476124.5558 - val_loss: 1267159550.5388\n",
      "Epoch 14722/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191321207.7965 - val_loss: 1267188828.9315\n",
      "Epoch 14723/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1192091436.8376 - val_loss: 1265573335.9635\n",
      "Epoch 14724/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1191524959.0607 - val_loss: 1266190144.8767\n",
      "Epoch 14725/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191345439.1859 - val_loss: 1268066394.3014\n",
      "Epoch 14726/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1192127146.5832 - val_loss: 1268086403.5068\n",
      "Epoch 14727/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1191489435.3659 - val_loss: 1267959746.0457\n",
      "Epoch 14728/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1191420153.6125 - val_loss: 1267057384.3288\n",
      "Epoch 14729/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191941185.1272 - val_loss: 1268584865.0228\n",
      "Epoch 14730/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1192237736.3288 - val_loss: 1267321984.2922\n",
      "Epoch 14731/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191608285.9335 - val_loss: 1265160090.5936\n",
      "Epoch 14732/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191162802.8493 - val_loss: 1265855546.7397\n",
      "Epoch 14733/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191375335.0137 - val_loss: 1267088803.3607\n",
      "Epoch 14734/15000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1192162526.6849 - val_loss: 1265906628.6758\n",
      "Epoch 14735/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191628041.5186 - val_loss: 1265205320.7671\n",
      "Epoch 14736/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1191118144.2505 - val_loss: 1267481157.2603\n",
      "Epoch 14737/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1191237937.3464 - val_loss: 1267620778.3744\n",
      "Epoch 14738/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1192270709.2290 - val_loss: 1269558046.3927\n",
      "Epoch 14739/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1191459150.7789 - val_loss: 1267590647.8174\n",
      "Epoch 14740/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1191820697.4247 - val_loss: 1267061488.2192\n",
      "Epoch 14741/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1191786009.1742 - val_loss: 1267586530.1918\n",
      "Epoch 14742/15000\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 1191179243.3346 - val_loss: 1266102852.6758\n",
      "Epoch 14743/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1191156550.0744 - val_loss: 1266322253.4429\n",
      "Epoch 14744/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1191485549.9648 - val_loss: 1266583226.7397\n",
      "Epoch 14745/15000\n",
      "1022/1022 [==============================] - 0s 76us/step - loss: 1191509246.5597 - val_loss: 1267293683.1416\n",
      "Epoch 14746/15000\n",
      "1022/1022 [==============================] - 0s 24us/step - loss: 1191712018.8493 - val_loss: 1266336022.7945\n",
      "Epoch 14747/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1191558541.2759 - val_loss: 1267739318.6484\n",
      "Epoch 14748/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1191158494.4344 - val_loss: 1267121668.3836\n",
      "Epoch 14749/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1191720659.6634 - val_loss: 1266313918.8311\n",
      "Epoch 14750/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1191313756.6810 - val_loss: 1266223850.3744\n",
      "Epoch 14751/15000\n",
      "1022/1022 [==============================] - 0s 25us/step - loss: 1191346178.2544 - val_loss: 1267208239.0502\n",
      "Epoch 14752/15000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1191495523.6947 - val_loss: 1265768545.3151\n",
      "Epoch 14753/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1191837851.0528 - val_loss: 1268324892.9315\n",
      "Epoch 14754/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1191513621.1037 - val_loss: 1265565712.9498\n",
      "Epoch 14755/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190996633.2368 - val_loss: 1266362523.7626\n",
      "Epoch 14756/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191294342.5127 - val_loss: 1267131748.2374\n",
      "Epoch 14757/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191177092.6341 - val_loss: 1267182331.6164\n",
      "Epoch 14758/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1191049653.9804 - val_loss: 1267010396.0548\n",
      "Epoch 14759/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1191502567.9530 - val_loss: 1267321838.1735\n",
      "Epoch 14760/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1191359650.8180 - val_loss: 1267271833.7169\n",
      "Epoch 14761/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1191211036.3053 - val_loss: 1266343252.4566\n",
      "Epoch 14762/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1191190712.3601 - val_loss: 1266492964.5297\n",
      "Epoch 14763/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1191173359.8434 - val_loss: 1266901612.7123\n",
      "Epoch 14764/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1191395080.0157 - val_loss: 1267264758.6484\n",
      "Epoch 14765/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1191535737.9883 - val_loss: 1265605569.7534\n",
      "Epoch 14766/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1191549044.2270 - val_loss: 1267124256.7306\n",
      "Epoch 14767/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191400256.5010 - val_loss: 1267232867.6530\n",
      "Epoch 14768/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1191339592.6419 - val_loss: 1266644422.4292\n",
      "Epoch 14769/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1191104325.1350 - val_loss: 1266644680.4749\n",
      "Epoch 14770/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1191536095.4990 - val_loss: 1266636824.2557\n",
      "Epoch 14771/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191307805.0568 - val_loss: 1266504316.7854\n",
      "Epoch 14772/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1191231031.6086 - val_loss: 1266257697.6073\n",
      "Epoch 14773/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191286307.3190 - val_loss: 1266901431.5251\n",
      "Epoch 14774/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191326908.6184 - val_loss: 1267812116.4566\n",
      "Epoch 14775/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191866194.9119 - val_loss: 1268317680.2192\n",
      "Epoch 14776/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1190940879.0294 - val_loss: 1266830734.0274\n",
      "Epoch 14777/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191639019.2094 - val_loss: 1267837036.7123\n",
      "Epoch 14778/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1192163055.2172 - val_loss: 1264802445.1507\n",
      "Epoch 14779/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191976526.2779 - val_loss: 1267383163.6164\n",
      "Epoch 14780/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191256452.2583 - val_loss: 1265973286.8676\n",
      "Epoch 14781/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191294079.1233 - val_loss: 1267609282.3379\n",
      "Epoch 14782/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1190973603.5068 - val_loss: 1266638642.8493\n",
      "Epoch 14783/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191176284.0548 - val_loss: 1265957687.8174\n",
      "Epoch 14784/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1190950679.4207 - val_loss: 1266830954.0822\n",
      "Epoch 14785/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191193648.5949 - val_loss: 1266132705.8995\n",
      "Epoch 14786/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191135460.6967 - val_loss: 1266535521.8995\n",
      "Epoch 14787/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191107552.8141 - val_loss: 1266208379.0320\n",
      "Epoch 14788/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191405092.9472 - val_loss: 1267781738.0822\n",
      "Epoch 14789/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191142414.9041 - val_loss: 1267043890.8493\n",
      "Epoch 14790/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1191366758.3249 - val_loss: 1267323877.4064\n",
      "Epoch 14791/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191222200.3601 - val_loss: 1266894223.7808\n",
      "Epoch 14792/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191179372.9628 - val_loss: 1266765373.9543\n",
      "Epoch 14793/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1190928315.6164 - val_loss: 1266411896.6941\n",
      "Epoch 14794/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1191744830.9354 - val_loss: 1267718331.0320\n",
      "Epoch 14795/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1191060681.3933 - val_loss: 1266144342.5023\n",
      "Epoch 14796/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1191547803.8669 - val_loss: 1267796212.3105\n",
      "Epoch 14797/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1191016983.4207 - val_loss: 1267193393.3881\n",
      "Epoch 14798/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1191367285.1037 - val_loss: 1267166217.6438\n",
      "Epoch 14799/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 32us/step - loss: 1191934894.8415 - val_loss: 1264483712.5845\n",
      "Epoch 14800/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1191512415.9374 - val_loss: 1265727507.8721\n",
      "Epoch 14801/15000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1191096673.0646 - val_loss: 1266923631.0502\n",
      "Epoch 14802/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1191004935.5147 - val_loss: 1267599757.4429\n",
      "Epoch 14803/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190929548.1487 - val_loss: 1267539526.1370\n",
      "Epoch 14804/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1190887261.1820 - val_loss: 1267277446.7215\n",
      "Epoch 14805/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191251407.4051 - val_loss: 1266093753.5708\n",
      "Epoch 14806/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1191447674.7397 - val_loss: 1268160874.0822\n",
      "Epoch 14807/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190907329.6282 - val_loss: 1267184379.0320\n",
      "Epoch 14808/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190992523.0215 - val_loss: 1267144548.8219\n",
      "Epoch 14809/15000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1191125062.3875 - val_loss: 1265982831.6347\n",
      "Epoch 14810/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191268638.9354 - val_loss: 1266962507.6895\n",
      "Epoch 14811/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191003614.1840 - val_loss: 1267764685.4429\n",
      "Epoch 14812/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190884493.1507 - val_loss: 1267204508.6393\n",
      "Epoch 14813/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1190869245.6204 - val_loss: 1266295835.1781\n",
      "Epoch 14814/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191292739.2564 - val_loss: 1267102881.0228\n",
      "Epoch 14815/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1191428834.8180 - val_loss: 1267628266.6667\n",
      "Epoch 14816/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191011847.5147 - val_loss: 1266126914.6301\n",
      "Epoch 14817/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1191070862.8415 - val_loss: 1266909781.0411\n",
      "Epoch 14818/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1192059224.1722 - val_loss: 1265078387.1416\n",
      "Epoch 14819/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1191190163.4755 - val_loss: 1265836409.2785\n",
      "Epoch 14820/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191083577.8630 - val_loss: 1266032678.5753\n",
      "Epoch 14821/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1190703686.5127 - val_loss: 1267469285.9909\n",
      "Epoch 14822/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1190935261.3072 - val_loss: 1267376147.8721\n",
      "Epoch 14823/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1191503915.6477 - val_loss: 1268754101.1872\n",
      "Epoch 14824/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1190942330.4266 - val_loss: 1267171100.3470\n",
      "Epoch 14825/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191109504.8141 - val_loss: 1266521139.1416\n",
      "Epoch 14826/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191079370.2701 - val_loss: 1266704803.6530\n",
      "Epoch 14827/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191440716.7750 - val_loss: 1268305519.3425\n",
      "Epoch 14828/15000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1190836842.2074 - val_loss: 1265886762.6667\n",
      "Epoch 14829/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1191168806.0744 - val_loss: 1267012029.6621\n",
      "Epoch 14830/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191024346.5519 - val_loss: 1266307169.0228\n",
      "Epoch 14831/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191332707.1937 - val_loss: 1266252432.6575\n",
      "Epoch 14832/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1191865596.1174 - val_loss: 1265101814.0639\n",
      "Epoch 14833/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1191177484.6497 - val_loss: 1267976576.5845\n",
      "Epoch 14834/15000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1191039549.8708 - val_loss: 1267469404.6393\n",
      "Epoch 14835/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191550721.5029 - val_loss: 1268156309.6256\n",
      "Epoch 14836/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190770620.8689 - val_loss: 1267456355.3607\n",
      "Epoch 14837/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190906094.7162 - val_loss: 1266105988.0913\n",
      "Epoch 14838/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1192497530.6771 - val_loss: 1264075864.5479\n",
      "Epoch 14839/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1190543027.0372 - val_loss: 1266734391.5251\n",
      "Epoch 14840/15000\n",
      "1022/1022 [==============================] - 0s 32us/step - loss: 1190823186.1605 - val_loss: 1267684977.9726\n",
      "Epoch 14841/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190736661.7926 - val_loss: 1267821080.5479\n",
      "Epoch 14842/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190841084.9941 - val_loss: 1267859579.6164\n",
      "Epoch 14843/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1191802548.7280 - val_loss: 1265914329.7169\n",
      "Epoch 14844/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1191131060.7906 - val_loss: 1266935558.7215\n",
      "Epoch 14845/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1191302279.1389 - val_loss: 1268259752.6210\n",
      "Epoch 14846/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191517350.8258 - val_loss: 1265891806.3927\n",
      "Epoch 14847/15000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1191201509.4481 - val_loss: 1267654581.4795\n",
      "Epoch 14848/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191278043.4286 - val_loss: 1267806334.5388\n",
      "Epoch 14849/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190675488.8141 - val_loss: 1267180482.3379\n",
      "Epoch 14850/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191030428.8063 - val_loss: 1265217272.6941\n",
      "Epoch 14851/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1191616910.5284 - val_loss: 1267824440.1096\n",
      "Epoch 14852/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190824413.6830 - val_loss: 1266216300.7123\n",
      "Epoch 14853/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190873542.9511 - val_loss: 1266483044.8219\n",
      "Epoch 14854/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1191228116.3523 - val_loss: 1267095699.8721\n",
      "Epoch 14855/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1191000746.4266 - val_loss: 1266859886.1735\n",
      "Epoch 14856/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190731264.0000 - val_loss: 1266474380.8584\n",
      "Epoch 14857/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1190719180.4618 - val_loss: 1266239920.2192\n",
      "Epoch 14858/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191089779.0372 - val_loss: 1266573787.4703\n",
      "Epoch 14859/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190965246.7476 - val_loss: 1266214405.8447\n",
      "Epoch 14860/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1190748090.8650 - val_loss: 1267535416.6941\n",
      "Epoch 14861/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190940988.1174 - val_loss: 1266641418.2283\n",
      "Epoch 14862/15000\n",
      "1022/1022 [==============================] - 0s 82us/step - loss: 1190956879.4051 - val_loss: 1267841984.0000\n",
      "Epoch 14863/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 53us/step - loss: 1190771312.3444 - val_loss: 1266373589.0411\n",
      "Epoch 14864/15000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1190748714.3953 - val_loss: 1266646367.8539\n",
      "Epoch 14865/15000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1190991814.8885 - val_loss: 1265262091.1050\n",
      "Epoch 14866/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190780515.6947 - val_loss: 1268079764.1644\n",
      "Epoch 14867/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190996265.8317 - val_loss: 1268326188.1279\n",
      "Epoch 14868/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190876870.1996 - val_loss: 1265662626.4840\n",
      "Epoch 14869/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190778953.1429 - val_loss: 1267427857.5342\n",
      "Epoch 14870/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190847820.2740 - val_loss: 1265862117.6986\n",
      "Epoch 14871/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191140344.7358 - val_loss: 1265872850.4110\n",
      "Epoch 14872/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191161035.5225 - val_loss: 1267931148.8584\n",
      "Epoch 14873/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1190584743.4521 - val_loss: 1267493444.3836\n",
      "Epoch 14874/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190602481.9726 - val_loss: 1267279168.5845\n",
      "Epoch 14875/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191093263.7808 - val_loss: 1267690195.2877\n",
      "Epoch 14876/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190668161.7534 - val_loss: 1266901528.5479\n",
      "Epoch 14877/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1190682372.1331 - val_loss: 1265658074.8858\n",
      "Epoch 14878/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190827888.7202 - val_loss: 1266609742.6119\n",
      "Epoch 14879/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191036485.7613 - val_loss: 1265180119.3790\n",
      "Epoch 14880/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191308955.5538 - val_loss: 1267715112.0365\n",
      "Epoch 14881/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1191423278.5910 - val_loss: 1265176552.6210\n",
      "Epoch 14882/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1190590886.8258 - val_loss: 1267087866.4475\n",
      "Epoch 14883/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1190617830.8258 - val_loss: 1266568811.2511\n",
      "Epoch 14884/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190541679.5303 - val_loss: 1266944975.7808\n",
      "Epoch 14885/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190809366.7945 - val_loss: 1267826019.0685\n",
      "Epoch 14886/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190820248.7984 - val_loss: 1265738309.2603\n",
      "Epoch 14887/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190558497.0646 - val_loss: 1266673759.5616\n",
      "Epoch 14888/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190741366.2309 - val_loss: 1267712560.8037\n",
      "Epoch 14889/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190409611.0215 - val_loss: 1266836451.0685\n",
      "Epoch 14890/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1191035204.3836 - val_loss: 1266431257.7169\n",
      "Epoch 14891/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191341911.4207 - val_loss: 1267805773.1507\n",
      "Epoch 14892/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1190493656.4227 - val_loss: 1266276437.3333\n",
      "Epoch 14893/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191288132.0078 - val_loss: 1265027437.0046\n",
      "Epoch 14894/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1190670748.9315 - val_loss: 1267606348.8584\n",
      "Epoch 14895/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1190581814.4814 - val_loss: 1267645055.7078\n",
      "Epoch 14896/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1191056304.4697 - val_loss: 1266930003.2877\n",
      "Epoch 14897/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190510003.9765 - val_loss: 1265704575.1233\n",
      "Epoch 14898/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190524284.4932 - val_loss: 1266524925.3699\n",
      "Epoch 14899/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1190531514.3014 - val_loss: 1266979405.7352\n",
      "Epoch 14900/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190764726.6067 - val_loss: 1266481303.9635\n",
      "Epoch 14901/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190580969.2055 - val_loss: 1266471355.0320\n",
      "Epoch 14902/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190513322.2701 - val_loss: 1267160771.5068\n",
      "Epoch 14903/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190449202.7241 - val_loss: 1266987458.3379\n",
      "Epoch 14904/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190585822.4344 - val_loss: 1267366330.7397\n",
      "Epoch 14905/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190956063.5616 - val_loss: 1267083865.1324\n",
      "Epoch 14906/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1190867929.0489 - val_loss: 1267454734.0274\n",
      "Epoch 14907/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190344031.2485 - val_loss: 1266346079.2694\n",
      "Epoch 14908/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190897322.8337 - val_loss: 1266070867.8721\n",
      "Epoch 14909/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190731445.8552 - val_loss: 1266048037.1142\n",
      "Epoch 14910/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190392645.2603 - val_loss: 1266885978.3014\n",
      "Epoch 14911/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1190379942.0744 - val_loss: 1266836289.4612\n",
      "Epoch 14912/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190749196.6497 - val_loss: 1266075467.1050\n",
      "Epoch 14913/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1190523548.9315 - val_loss: 1267217307.1781\n",
      "Epoch 14914/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190418976.5636 - val_loss: 1266591397.1142\n",
      "Epoch 14915/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1191088576.6888 - val_loss: 1265886189.8813\n",
      "Epoch 14916/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190475417.4247 - val_loss: 1267544759.5251\n",
      "Epoch 14917/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190465496.9863 - val_loss: 1267102087.3059\n",
      "Epoch 14918/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1191803919.6556 - val_loss: 1265445103.0502\n",
      "Epoch 14919/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1191001302.9198 - val_loss: 1268961458.8493\n",
      "Epoch 14920/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190291368.6419 - val_loss: 1267272704.8767\n",
      "Epoch 14921/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190936121.0489 - val_loss: 1265392152.5479\n",
      "Epoch 14922/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1190582288.0313 - val_loss: 1267704620.4201\n",
      "Epoch 14923/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190581874.1605 - val_loss: 1265880400.3653\n",
      "Epoch 14924/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1190340090.9276 - val_loss: 1265831262.1005\n",
      "Epoch 14925/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190816250.9902 - val_loss: 1267609461.7717\n",
      "Epoch 14926/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1190752154.3014 - val_loss: 1267979110.8676\n",
      "Epoch 14927/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190537233.4090 - val_loss: 1266628598.9406\n",
      "Epoch 14928/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1190598398.4971 - val_loss: 1266593045.6256\n",
      "Epoch 14929/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190415720.4540 - val_loss: 1266958150.7215\n",
      "Epoch 14930/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190482788.4462 - val_loss: 1267110877.5160\n",
      "Epoch 14931/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1190680389.3855 - val_loss: 1266227489.6073\n",
      "Epoch 14932/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190461138.2231 - val_loss: 1267623919.3425\n",
      "Epoch 14933/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1190819326.2466 - val_loss: 1267769559.9635\n",
      "Epoch 14934/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190305078.8571 - val_loss: 1266280766.5388\n",
      "Epoch 14935/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1190443164.3053 - val_loss: 1266252287.1233\n",
      "Epoch 14936/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191045194.6458 - val_loss: 1268180527.6347\n",
      "Epoch 14937/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190505691.1781 - val_loss: 1266943594.0822\n",
      "Epoch 14938/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1190592798.4344 - val_loss: 1266258707.2877\n",
      "Epoch 14939/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1190397760.7515 - val_loss: 1265912043.2511\n",
      "Epoch 14940/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1191621582.9041 - val_loss: 1267032694.6484\n",
      "Epoch 14941/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190681166.0274 - val_loss: 1265998067.7260\n",
      "Epoch 14942/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190448486.4501 - val_loss: 1267182249.7900\n",
      "Epoch 14943/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190702915.4442 - val_loss: 1266940679.0137\n",
      "Epoch 14944/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1190576385.7534 - val_loss: 1267947322.1553\n",
      "Epoch 14945/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190254427.6791 - val_loss: 1266241083.3242\n",
      "Epoch 14946/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190131543.7339 - val_loss: 1266535981.0046\n",
      "Epoch 14947/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190381539.3190 - val_loss: 1266624103.1598\n",
      "Epoch 14948/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1190533280.8141 - val_loss: 1266140001.8995\n",
      "Epoch 14949/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190506494.9980 - val_loss: 1265913014.0639\n",
      "Epoch 14950/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191035128.9863 - val_loss: 1268645176.4018\n",
      "Epoch 14951/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190328628.1644 - val_loss: 1267708869.5525\n",
      "Epoch 14952/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190399001.1742 - val_loss: 1266738391.3790\n",
      "Epoch 14953/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190378837.0411 - val_loss: 1267163347.5799\n",
      "Epoch 14954/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190418642.2857 - val_loss: 1265962750.8311\n",
      "Epoch 14955/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1190452889.4247 - val_loss: 1265580821.9178\n",
      "Epoch 14956/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1191009470.1213 - val_loss: 1266273510.8676\n",
      "Epoch 14957/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1190153670.2622 - val_loss: 1266301270.7945\n",
      "Epoch 14958/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1191267071.6243 - val_loss: 1267747896.9863\n",
      "Epoch 14959/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190198710.2309 - val_loss: 1266414023.0137\n",
      "Epoch 14960/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190263480.6106 - val_loss: 1266308333.0046\n",
      "Epoch 14961/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190656920.6732 - val_loss: 1266770672.5114\n",
      "Epoch 14962/15000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1190316903.0763 - val_loss: 1267019850.2283\n",
      "Epoch 14963/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1190202995.4755 - val_loss: 1266130622.2466\n",
      "Epoch 14964/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190305224.3914 - val_loss: 1267287726.1735\n",
      "Epoch 14965/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1190895088.2192 - val_loss: 1265273446.8676\n",
      "Epoch 14966/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190495661.3386 - val_loss: 1267874693.5525\n",
      "Epoch 14967/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190394712.4227 - val_loss: 1266470887.1598\n",
      "Epoch 14968/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190323499.2094 - val_loss: 1267168042.3744\n",
      "Epoch 14969/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190800480.1879 - val_loss: 1265519907.3607\n",
      "Epoch 14970/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190424044.5871 - val_loss: 1266059737.4247\n",
      "Epoch 14971/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190249049.4247 - val_loss: 1266055894.7945\n",
      "Epoch 14972/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1191475042.9432 - val_loss: 1268866427.9087\n",
      "Epoch 14973/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190213129.0176 - val_loss: 1266649862.7215\n",
      "Epoch 14974/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1190376380.6810 - val_loss: 1267741041.0959\n",
      "Epoch 14975/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190703536.1566 - val_loss: 1265472229.9909\n",
      "Epoch 14976/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190137942.6693 - val_loss: 1266474923.8356\n",
      "Epoch 14977/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190646890.4579 - val_loss: 1268120844.8584\n",
      "Epoch 14978/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190737926.0117 - val_loss: 1266451927.0868\n",
      "Epoch 14979/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1190187170.0665 - val_loss: 1266809350.1370\n",
      "Epoch 14980/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1190448622.5910 - val_loss: 1266998425.1324\n",
      "Epoch 14981/15000\n",
      "1022/1022 [==============================] - 0s 26us/step - loss: 1190228710.4501 - val_loss: 1266952303.0502\n",
      "Epoch 14982/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1190264756.7906 - val_loss: 1267742973.3699\n",
      "Epoch 14983/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190216470.7945 - val_loss: 1267751252.1644\n",
      "Epoch 14984/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190332941.0254 - val_loss: 1268173481.7900\n",
      "Epoch 14985/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1190064748.2114 - val_loss: 1266085603.6530\n",
      "Epoch 14986/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1191001507.7573 - val_loss: 1267777614.3196\n",
      "Epoch 14987/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1190127698.9119 - val_loss: 1266409146.1553\n",
      "Epoch 14988/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1190138069.4168 - val_loss: 1265717131.1050\n",
      "Epoch 14989/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190634274.5675 - val_loss: 1264916682.2283\n",
      "Epoch 14990/15000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1190430624.0626 - val_loss: 1266912341.3333\n",
      "Epoch 14991/15000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 36us/step - loss: 1189960410.0509 - val_loss: 1267277009.2420\n",
      "Epoch 14992/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190123979.8982 - val_loss: 1266123241.7900\n",
      "Epoch 14993/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190061980.9315 - val_loss: 1266754412.4201\n",
      "Epoch 14994/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190115450.7397 - val_loss: 1266450908.3470\n",
      "Epoch 14995/15000\n",
      "1022/1022 [==============================] - 0s 33us/step - loss: 1190488238.3405 - val_loss: 1265335381.3333\n",
      "Epoch 14996/15000\n",
      "1022/1022 [==============================] - 0s 27us/step - loss: 1190483350.2935 - val_loss: 1268514700.2740\n",
      "Epoch 14997/15000\n",
      "1022/1022 [==============================] - 0s 29us/step - loss: 1190047126.5440 - val_loss: 1267750240.1461\n",
      "Epoch 14998/15000\n",
      "1022/1022 [==============================] - 0s 28us/step - loss: 1190033532.7436 - val_loss: 1266704769.4612\n",
      "Epoch 14999/15000\n",
      "1022/1022 [==============================] - 0s 30us/step - loss: 1190274607.3425 - val_loss: 1266990689.0228\n",
      "Epoch 15000/15000\n",
      "1022/1022 [==============================] - 0s 31us/step - loss: 1190114638.9041 - val_loss: 1267727293.6621\n",
      "2019-07-31 15:16:58.674514\n"
     ]
    }
   ],
   "source": [
    "model = Sequential([\n",
    "    Dense(10, activation='relu', input_shape=(10,)),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(1, kernel_initializer='normal'),\n",
    "])\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "hist = model.fit(X_train, Y_train,\n",
    "          batch_size=32, epochs=15000,\n",
    "          validation_data=(X_test, Y_test))\n",
    "\n",
    "print(datetime.datetime.now())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "438/438 [==============================] - 0s 39us/step\n",
      "R2 Score:      0.806\n",
      "RMSLE:         0.174\n"
     ]
    }
   ],
   "source": [
    "model.evaluate(X_test, Y_test)\n",
    "\n",
    "Y_predicted = model.predict(X_test)\n",
    "\n",
    "df_Y_predicted = pd.Series(Y_predicted.tolist())\n",
    "\n",
    "df_Y_predicted = pd.DataFrame(Y_predicted)\n",
    "df_Y_predicted.columns = [\"previsto\"]\n",
    "df_Y_predicted[df_Y_predicted[\"previsto\"] <= 0] = np.mean(Y_train_full)\n",
    "\n",
    "print(\"R2 Score: {:10.3f}\".format(r2_score(Y_test.values, df_Y_predicted.round(0).values)))\n",
    "print(\"RMSLE:    {:10.3f}\".format(rmsle(Y_test.values, df_Y_predicted.values)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Houve uma melhora significativa nos índices. O modelo linear com melhor resultado foi a regressão linear ordinária das menores raizes (*LinearRegression*). A rede neural apresentou resultado ainda melhor com 15.00 *epochs*, portanto passará a ser nosso *benchmark*."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Pares de atributo com grau de correlação entre si maior do que 50%.  \n",
    "\n",
    "Para tais pares, indicaremos qual deles tem mais correlação com o valor de venda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"-----------------------------------------------------------------\")\n",
    "for id in corrmat.index:\n",
    "    achouDiagonal = False\n",
    "    imprimiu_algo = False\n",
    "    for col in corrmat.columns:\n",
    "        if id == col:\n",
    "            achouDiagonal = True\n",
    "        if (id != \"SalePrice\") & (col != \"SalePrice\") & (id != col) & (achouDiagonal) & (corrmat.loc[id][col] > 0.5):\n",
    "            imprimiu_algo = True\n",
    "            print(\"Id: {}, Col: {}\".format(id, col))\n",
    "            if corrmat.loc[id][\"SalePrice\"] > corrmat.loc[col][\"SalePrice\"]:\n",
    "                print(\"O atributo com maior correlação com o preço é: {}: {:7.3f}. A correlação de {} é {:7.3f}\".format(id, corrmat.loc[id][\"SalePrice\"], col, corrmat.loc[col][\"SalePrice\"]))\n",
    "                \n",
    "            else:\n",
    "                print(\"O atributo com maior correlação com o preço é: {}: {:7.3f}. A correlação de {} é {:7.3f}\".format(col, corrmat.loc[col][\"SalePrice\"], id, corrmat.loc[id][\"SalePrice\"]))\n",
    "            print(\"\")\n",
    "    if imprimiu_algo:\n",
    "        print(\"-----------------------------------------------------------------\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Considerando os resultados acima, vamos remover os atributos BedroomAbvGr, BsmtFullBath e HalfBath, pois são bem representados por outros atributos, devida à alta correlação, e possuem correlações abaixo de 30% com o preço de venda."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train.drop(\"BedroomAbvGr\", axis=1)\n",
    "X_train = X_train.drop(\"BsmtFullBath\", axis=1)\n",
    "X_train = X_train.drop(\"HalfBath\", axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vamos agora analisar quais atributos apresentam grau de correlação maior do que 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for id in corrmat.index:\n",
    "    if (id != 'SalePrice') &(corrmat.loc[id]['SalePrice'] > 0.3):\n",
    "        print(id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train = train[[\"LotArea\",\"OverallCond\", \"TotalBsmtSF\", \"FullBath\", \"HalfBath\",\"BedroomAbvGr\", \"TotRmsAbvGrd\", \"Fireplaces\", \"GarageArea\", \"SalePrice\"]]\n",
    "train_array = train.values\n",
    "# train_array\n",
    "\n",
    "# list(train)\n",
    "# train_array.shape\n",
    "\n",
    "X = train_array[:,0:80]\n",
    "\n",
    "Y = train_array[:,80]\n",
    "\n",
    "# from sklearn import preprocessing\n",
    "# min_max_scaler = preprocessing.MinMaxScaler()\n",
    "# X_scale = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y, test_size=0.3)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)\n",
    "# X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(X_train, Y_train)\n",
    "\n",
    "Y_resultado_2 = reg.predict(X_test)\n",
    "\n",
    "rmsle(Y_test, Y_resultado_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reg = LinearRegression().fit(X_train, Y_train)\n",
    "\n",
    "Y_resultado_2 = reg.predict(X_test)\n",
    "\n",
    "rmsle(Y_test, Y_resultado_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train.csv\")\n",
    "list(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X_atributos_correlacao_preco_maior_50)\n",
    "\n",
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y_train_full, test_size=0.3)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)\n",
    "\n",
    "reg = DecisionTreeClassifier().fit(X_train, Y_train.values)\n",
    "\n",
    "Y_predicted = reg.predict(X_val)\n",
    "\n",
    "df_Y_predicted = pd.Series(Y_predicted)\n",
    "\n",
    "df_Y_predicted = pd.DataFrame(Y_predicted)\n",
    "df_Y_predicted.columns = [\"previsto\"]\n",
    "df_Y_predicted[df_Y_predicted[\"previsto\"] <= 0] = np.mean(Y_train_full)\n",
    "\n",
    "print(\"R2 Score: {:10.3f}\".format(r2_score(Y_val.values, df_Y_predicted.round(0).values)))\n",
    "print(\"RMSLE:    {:10.3f}\".format(rmsle(Y_val.values, df_Y_predicted.values)[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usar Root-Mean-Squared-Error (RMSE)  \n",
    "sklearn.metrics.mean_squared_error(y_true, y_pred, sample_weight=None, multioutput=’uniform_average’)[source]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'kernel':('linear', 'rbf'), 'C':[1, 10]}\n",
    "svc = svm.SVC(gamma=\"scale\")\n",
    "clf = GridSearchCV(svc, parameters, cv=5)\n",
    "clf.fit(iris.data, iris.target)\n",
    "\n",
    "reg = LinearRegression().fit(X_train, Y_train)\n",
    "\n",
    "Y_resultado_2 = reg.predict(X_test)\n",
    "\n",
    "rmsle(Y_test, Y_resultado_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Descrição dos dados](data_description.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[[\"LotArea\",\"OverallCond\", \"TotalBsmtSF\", \"FullBath\", \"HalfBath\",\"BedroomAbvGr\", \"TotRmsAbvGrd\", \"Fireplaces\", \"GarageArea\", \"SalePrice\"]]\n",
    "train_array = train.values\n",
    "# train_array\n",
    "\n",
    "# list(train)\n",
    "\n",
    "X = train_array[:,0:9]\n",
    "Y = train_array[:,9]\n",
    "\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [1760425580.7123287, 0.0]\n",
    "model.evaluate(X_test, Y_test)\n",
    "Y_resultado = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_resultado = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_Y = pd.DataFrame(Y_resultado)\n",
    "df_Y.columns = [\"projetado\"]\n",
    "\n",
    "df_Y_test = pd.DataFrame(Y_test)\n",
    "df_Y_test.columns = [\"original\"]\n",
    "\n",
    "df_join = df_Y.join(df_Y_test, lsuffix='_caller', rsuffix='_other')\n",
    "df_join[\"diferenca\"] = df_join[\"projetado\"] - df_join[\"original\"]\n",
    "df_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(Y).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_Y_cheat = df_Y_test[\"original\"] - 7000\n",
    "# df_Y_cheat.columns = [\"cheat\"]\n",
    "# df_Y_cheat\n",
    "# rmsle(Y_test, Y_cheat)\n",
    "\n",
    "# df_join_2 = df_Y_test.join(df_Y_cheat, lsuffix='_caller', rsuffix='_other')\n",
    "# df_join_2[\"diferenca\"] = df_join_2[\"original_caller\"] - df_join_2[\"original_other\"]\n",
    "# df_Y_test[\"original\"].values\n",
    "# df_Y_cheat.values\n",
    "# rmsle(df_Y_test[\"original\"].values, df_Y_cheat.values)\n",
    "\n",
    "rmsle(Y_test, Y_resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(noise=4, random_state=0)\n",
    "reg2 = LassoCV(cv=5, random_state=0).fit(X_train, Y_train)\n",
    "\n",
    "Y_resultado_4 = reg2.predict(X_test)\n",
    "\n",
    "rmsle(Y_test, Y_resultado_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(noise=4, random_state=0)\n",
    "reg2 = LassoLars(alpha=0.01).fit(X_train, Y_train)\n",
    "\n",
    "Y_resultado_4 = reg2.predict(X_test)\n",
    "\n",
    "rmsle(Y_test, Y_resultado_4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = make_regression(n_features=2, random_state=0)\n",
    "reg3 = ElasticNet(random_state=0)\n",
    "reg3.fit(X_train, Y_train)  \n",
    "Y_resultado_5 = reg3.predict(X_test)\n",
    "rmsle(Y_test, Y_resultado_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_resultado_6 = [np.mean(Y_test) for i in range(len(X_test))]\n",
    "rmsle(Y_test, Y_resultado_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_resultado_7 = np.full((len(X_test)), np.median(Y_test))\n",
    "rmsle(Y_test, Y_resultado_7)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descrição dos dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "````\n",
    "MSSubClass: Identifies the type of dwelling involved in the sale.    \n",
    "\n",
    "        20    1-STORY 1946 & NEWER ALL STYLES\n",
    "        30    1-STORY 1945 & OLDER\n",
    "        40    1-STORY W/FINISHED ATTIC ALL AGES\n",
    "        45    1-1/2 STORY - UNFINISHED ALL AGES\n",
    "        50    1-1/2 STORY FINISHED ALL AGES\n",
    "        60    2-STORY 1946 & NEWER\n",
    "        70    2-STORY 1945 & OLDER\n",
    "        75    2-1/2 STORY ALL AGES\n",
    "        80    SPLIT OR MULTI-LEVEL\n",
    "        85    SPLIT FOYER\n",
    "        90    DUPLEX - ALL STYLES AND AGES\n",
    "       120    1-STORY PUD (Planned Unit Development) - 1946 & NEWER\n",
    "       150    1-1/2 STORY PUD - ALL AGES\n",
    "       160    2-STORY PUD - 1946 & NEWER\n",
    "       180    PUD - MULTILEVEL - INCL SPLIT LEV/FOYER\n",
    "       190    2 FAMILY CONVERSION - ALL STYLES AND AGES\n",
    "\n",
    "MSZoning: Identifies the general zoning classification of the sale.\n",
    "        \n",
    "       A    Agriculture\n",
    "       C    Commercial\n",
    "       FV   Floating Village Residential\n",
    "       I    Industrial\n",
    "       RH   Residential High Density\n",
    "       RL   Residential Low Density\n",
    "       RP   Residential Low Density Park \n",
    "       RM   Residential Medium Density\n",
    "    \n",
    "LotFrontage: Linear feet of street connected to property\n",
    "\n",
    "LotArea: Lot size in square feet\n",
    "\n",
    "Street: Type of road access to property\n",
    "\n",
    "       Grvl    Gravel    \n",
    "       Pave    Paved\n",
    "           \n",
    "Alley: Type of alley access to property\n",
    "    \n",
    "       Grvl    Gravel\n",
    "       Pave    Paved\n",
    "       NA      No alley access\n",
    "        \n",
    "LotShape: General shape of property\n",
    "\n",
    "       Reg    Regular    \n",
    "       IR1    Slightly irregular\n",
    "       IR2    Moderately Irregular\n",
    "       IR3    Irregular\n",
    "       \n",
    "LandContour: Flatness of the property\n",
    "\n",
    "       Lvl    Near Flat/Level    \n",
    "       Bnk    Banked - Quick and significant rise from street grade to building\n",
    "       HLS    Hillside - Significant slope from side to side\n",
    "       Low    Depression\n",
    "        \n",
    "Utilities: Type of utilities available\n",
    "        \n",
    "       AllPub   All public Utilities (E,G,W,& S)    \n",
    "       NoSewr   Electricity, Gas, and Water (Septic Tank)\n",
    "       NoSeWa   Electricity and Gas Only\n",
    "       ELO      Electricity only    \n",
    "    \n",
    "LotConfig: Lot configuration\n",
    "\n",
    "       Inside   Inside lot\n",
    "       Corner   Corner lot\n",
    "       CulDSac  Cul-de-sac\n",
    "       FR2      Frontage on 2 sides of property\n",
    "       FR3      Frontage on 3 sides of property\n",
    "    \n",
    "LandSlope: Slope of property\n",
    "        \n",
    "       Gtl    Gentle slope\n",
    "       Mod    Moderate Slope    \n",
    "       Sev    Severe Slope\n",
    "    \n",
    "Neighborhood: Physical locations within Ames city limits\n",
    "\n",
    "       Blmngtn    Bloomington Heights\n",
    "       Blueste    Bluestem\n",
    "       BrDale     Briardale\n",
    "       BrkSide    Brookside\n",
    "       ClearCr    Clear Creek\n",
    "       CollgCr    College Creek\n",
    "       Crawfor    Crawford\n",
    "       Edwards    Edwards\n",
    "       Gilbert    Gilbert\n",
    "       IDOTRR     Iowa DOT and Rail Road\n",
    "       MeadowV    Meadow Village\n",
    "       Mitchel    Mitchell\n",
    "       Names      North Ames\n",
    "       NoRidge    Northridge\n",
    "       NPkVill    Northpark Villa\n",
    "       NridgHt    Northridge Heights\n",
    "       NWAmes     Northwest Ames\n",
    "       OldTown    Old Town\n",
    "       SWISU      South & West of Iowa State University\n",
    "       Sawyer     Sawyer\n",
    "       SawyerW    Sawyer West\n",
    "       Somerst    Somerset\n",
    "       StoneBr    Stone Brook\n",
    "       Timber     Timberland\n",
    "       Veenker    Veenker\n",
    "            \n",
    "Condition1: Proximity to various conditions\n",
    "    \n",
    "       Artery   Adjacent to arterial street\n",
    "       Feedr    Adjacent to feeder street    \n",
    "       Norm     Normal    \n",
    "       RRNn     Within 200' of North-South Railroad\n",
    "       RRAn     Adjacent to North-South Railroad\n",
    "       PosN     Near positive off-site feature--park, greenbelt, etc.\n",
    "       PosA     Adjacent to postive off-site feature\n",
    "       RRNe     Within 200' of East-West Railroad\n",
    "       RRAe     Adjacent to East-West Railroad\n",
    "    \n",
    "Condition2: Proximity to various conditions (if more than one is present)\n",
    "        \n",
    "       Artery   Adjacent to arterial street\n",
    "       Feedr    Adjacent to feeder street    \n",
    "       Norm     Normal    \n",
    "       RRNn     Within 200' of North-South Railroad\n",
    "       RRAn     Adjacent to North-South Railroad\n",
    "       PosN     Near positive off-site feature--park, greenbelt, etc.\n",
    "       PosA     Adjacent to postive off-site feature\n",
    "       RRNe     Within 200' of East-West Railroad\n",
    "       RRAe     Adjacent to East-West Railroad\n",
    "    \n",
    "BldgType: Type of dwelling\n",
    "        \n",
    "       1Fam     Single-family Detached    \n",
    "       2FmCon   Two-family Conversion; originally built as one-family dwelling\n",
    "       Duplx    Duplex\n",
    "       TwnhsE   Townhouse End Unit\n",
    "       TwnhsI   Townhouse Inside Unit\n",
    "    \n",
    "HouseStyle: Style of dwelling\n",
    "    \n",
    "       1Story    One story\n",
    "       1.5Fin    One and one-half story: 2nd level finished\n",
    "       1.5Unf    One and one-half story: 2nd level unfinished\n",
    "       2Story    Two story\n",
    "       2.5Fin    Two and one-half story: 2nd level finished\n",
    "       2.5Unf    Two and one-half story: 2nd level unfinished\n",
    "       SFoyer    Split Foyer\n",
    "       SLvl      Split Level\n",
    "    \n",
    "OverallQual: Rates the overall material and finish of the house\n",
    "\n",
    "       10   Very Excellent\n",
    "       9    Excellent\n",
    "       8    Very Good\n",
    "       7    Good\n",
    "       6    Above Average\n",
    "       5    Average\n",
    "       4    Below Average\n",
    "       3    Fair\n",
    "       2    Poor\n",
    "       1    Very Poor\n",
    "    \n",
    "OverallCond: Rates the overall condition of the house\n",
    "\n",
    "       10   Very Excellent\n",
    "       9    Excellent\n",
    "       8    Very Good\n",
    "       7    Good\n",
    "       6    Above Average    \n",
    "       5    Average\n",
    "       4    Below Average    \n",
    "       3    Fair\n",
    "       2    Poor\n",
    "       1    Very Poor\n",
    "        \n",
    "YearBuilt: Original construction date\n",
    "\n",
    "YearRemodAdd: Remodel date (same as construction date if no remodeling or additions)\n",
    "\n",
    "RoofStyle: Type of roof\n",
    "\n",
    "       Flat       Flat\n",
    "       Gable      Gable\n",
    "       Gambrel    Gabrel (Barn)\n",
    "       Hip        Hip\n",
    "       Mansard    Mansard\n",
    "       Shed       Shed\n",
    "        \n",
    "RoofMatl: Roof material\n",
    "\n",
    "       ClyTile    Clay or Tile\n",
    "       CompShg    Standard (Composite) Shingle\n",
    "       Membran    Membrane\n",
    "       Metal      Metal\n",
    "       Roll       Roll\n",
    "       Tar&Grv    Gravel & Tar\n",
    "       WdShake    Wood Shakes\n",
    "       WdShngl    Wood Shingles\n",
    "        \n",
    "Exterior1st: Exterior covering on house\n",
    "\n",
    "       AsbShng    Asbestos Shingles\n",
    "       AsphShn    Asphalt Shingles\n",
    "       BrkComm    Brick Common\n",
    "       BrkFace    Brick Face\n",
    "       CBlock     Cinder Block\n",
    "       CemntBd    Cement Board\n",
    "       HdBoard    Hard Board\n",
    "       ImStucc    Imitation Stucco\n",
    "       MetalSd    Metal Siding\n",
    "       Other      Other\n",
    "       Plywood    Plywood\n",
    "       PreCast    PreCast    \n",
    "       Stone      Stone\n",
    "       Stucco     Stucco\n",
    "       VinylSd    Vinyl Siding\n",
    "       Wd Sdng    Wood Siding\n",
    "       WdShing    Wood Shingles\n",
    "    \n",
    "Exterior2nd: Exterior covering on house (if more than one material)\n",
    "\n",
    "       AsbShng    Asbestos Shingles\n",
    "       AsphShn    Asphalt Shingles\n",
    "       BrkComm    Brick Common\n",
    "       BrkFace    Brick Face\n",
    "       CBlock     Cinder Block\n",
    "       CemntBd    Cement Board\n",
    "       HdBoard    Hard Board\n",
    "       ImStucc    Imitation Stucco\n",
    "       MetalSd    Metal Siding\n",
    "       Other      Other\n",
    "       Plywood    Plywood\n",
    "       PreCast    PreCast\n",
    "       Stone      Stone\n",
    "       Stucco     Stucco\n",
    "       VinylSd    Vinyl Siding\n",
    "       Wd Sdng    Wood Siding\n",
    "       WdShing    Wood Shingles\n",
    "    \n",
    "MasVnrType: Masonry veneer type\n",
    "\n",
    "       BrkCmn    Brick Common\n",
    "       BrkFace   Brick Face\n",
    "       CBlock    Cinder Block\n",
    "       None      None\n",
    "       Stone     Stone\n",
    "    \n",
    "MasVnrArea: Masonry veneer area in square feet\n",
    "\n",
    "ExterQual: Evaluates the quality of the material on the exterior \n",
    "        \n",
    "       Ex    Excellent\n",
    "       Gd    Good\n",
    "       TA    Average/Typical\n",
    "       Fa    Fair\n",
    "       Po    Poor\n",
    "        \n",
    "ExterCond: Evaluates the present condition of the material on the exterior\n",
    "        \n",
    "       Ex    Excellent\n",
    "       Gd    Good\n",
    "       TA    Average/Typical\n",
    "       Fa    Fair\n",
    "       Po    Poor\n",
    "        \n",
    "Foundation: Type of foundation\n",
    "        \n",
    "       BrkTil   Brick & Tile\n",
    "       CBlock   Cinder Block\n",
    "       PConc    Poured Contrete    \n",
    "       Slab     Slab\n",
    "       Stone    Stone\n",
    "       Wood     Wood\n",
    "        \n",
    "BsmtQual: Evaluates the height of the basement\n",
    "\n",
    "       Ex    Excellent (100+ inches)    \n",
    "       Gd    Good (90-99 inches)\n",
    "       TA    Typical (80-89 inches)\n",
    "       Fa    Fair (70-79 inches)\n",
    "       Po    Poor (<70 inches\n",
    "       NA    No Basement\n",
    "        \n",
    "BsmtCond: Evaluates the general condition of the basement\n",
    "\n",
    "       Ex    Excellent\n",
    "       Gd    Good\n",
    "       TA    Typical - slight dampness allowed\n",
    "       Fa    Fair - dampness or some cracking or settling\n",
    "       Po    Poor - Severe cracking, settling, or wetness\n",
    "       NA    No Basement\n",
    "    \n",
    "BsmtExposure: Refers to walkout or garden level walls\n",
    "\n",
    "       Gd    Good Exposure\n",
    "       Av    Average Exposure (split levels or foyers typically score average or above)    \n",
    "       Mn    Mimimum Exposure\n",
    "       No    No Exposure\n",
    "       NA    No Basement\n",
    "    \n",
    "BsmtFinType1: Rating of basement finished area\n",
    "\n",
    "       GLQ    Good Living Quarters\n",
    "       ALQ    Average Living Quarters\n",
    "       BLQ    Below Average Living Quarters    \n",
    "       Rec    Average Rec Room\n",
    "       LwQ    Low Quality\n",
    "       Unf    Unfinshed\n",
    "       NA     No Basement\n",
    "        \n",
    "BsmtFinSF1: Type 1 finished square feet\n",
    "\n",
    "BsmtFinType2: Rating of basement finished area (if multiple types)\n",
    "\n",
    "       GLQ    Good Living Quarters\n",
    "       ALQ    Average Living Quarters\n",
    "       BLQ    Below Average Living Quarters    \n",
    "       Rec    Average Rec Room\n",
    "       LwQ    Low Quality\n",
    "       Unf    Unfinshed\n",
    "       NA     No Basement\n",
    "\n",
    "BsmtFinSF2: Type 2 finished square feet\n",
    "\n",
    "BsmtUnfSF: Unfinished square feet of basement area\n",
    "\n",
    "TotalBsmtSF: Total square feet of basement area\n",
    "\n",
    "Heating: Type of heating\n",
    "        \n",
    "       Floor    Floor Furnace\n",
    "       GasA     Gas forced warm air furnace\n",
    "       GasW     Gas hot water or steam heat\n",
    "       Grav     Gravity furnace    \n",
    "       OthW     Hot water or steam heat other than gas\n",
    "       Wall     Wall furnace\n",
    "        \n",
    "HeatingQC: Heating quality and condition\n",
    "\n",
    "       Ex    Excellent\n",
    "       Gd    Good\n",
    "       TA    Average/Typical\n",
    "       Fa    Fair\n",
    "       Po    Poor\n",
    "        \n",
    "CentralAir: Central air conditioning\n",
    "\n",
    "       N    No\n",
    "       Y    Yes\n",
    "        \n",
    "Electrical: Electrical system\n",
    "\n",
    "       SBrkr    Standard Circuit Breakers & Romex\n",
    "       FuseA    Fuse Box over 60 AMP and all Romex wiring (Average)    \n",
    "       FuseF    60 AMP Fuse Box and mostly Romex wiring (Fair)\n",
    "       FuseP    60 AMP Fuse Box and mostly knob & tube wiring (poor)\n",
    "       Mix      Mixed\n",
    "        \n",
    "1stFlrSF: First Floor square feet\n",
    " \n",
    "2ndFlrSF: Second floor square feet\n",
    "\n",
    "LowQualFinSF: Low quality finished square feet (all floors)\n",
    "\n",
    "GrLivArea: Above grade (ground) living area square feet\n",
    "\n",
    "BsmtFullBath: Basement full bathrooms\n",
    "\n",
    "BsmtHalfBath: Basement half bathrooms\n",
    "\n",
    "FullBath: Full bathrooms above grade\n",
    "\n",
    "HalfBath: Half baths above grade\n",
    "\n",
    "Bedroom: Bedrooms above grade (does NOT include basement bedrooms)\n",
    "\n",
    "Kitchen: Kitchens above grade\n",
    "\n",
    "KitchenQual: Kitchen quality\n",
    "\n",
    "       Ex    Excellent\n",
    "       Gd    Good\n",
    "       TA    Typical/Average\n",
    "       Fa    Fair\n",
    "       Po    Poor\n",
    "           \n",
    "TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)\n",
    "\n",
    "Functional: Home functionality (Assume typical unless deductions are warranted)\n",
    "\n",
    "       Typ    Typical Functionality\n",
    "       Min1   Minor Deductions 1\n",
    "       Min2   Minor Deductions 2\n",
    "       Mod    Moderate Deductions\n",
    "       Maj1   Major Deductions 1\n",
    "       Maj2   Major Deductions 2\n",
    "       Sev    Severely Damaged\n",
    "       Sal    Salvage only\n",
    "        \n",
    "Fireplaces: Number of fireplaces\n",
    "\n",
    "FireplaceQu: Fireplace quality\n",
    "\n",
    "       Ex    Excellent - Exceptional Masonry Fireplace\n",
    "       Gd    Good - Masonry Fireplace in main level\n",
    "       TA    Average - Prefabricated Fireplace in main living area or Masonry Fireplace in basement\n",
    "       Fa    Fair - Prefabricated Fireplace in basement\n",
    "       Po    Poor - Ben Franklin Stove\n",
    "       NA    No Fireplace\n",
    "        \n",
    "GarageType: Garage location\n",
    "        \n",
    "       2Types    More than one type of garage\n",
    "       Attchd    Attached to home\n",
    "       Basment   Basement Garage\n",
    "       BuiltIn   Built-In (Garage part of house - typically has room above garage)\n",
    "       CarPort   Car Port\n",
    "       Detchd    Detached from home\n",
    "       NA        No Garage\n",
    "        \n",
    "GarageYrBlt: Year garage was built\n",
    "        \n",
    "GarageFinish: Interior finish of the garage\n",
    "\n",
    "       Fin    Finished\n",
    "       RFn    Rough Finished    \n",
    "       Unf    Unfinished\n",
    "       NA     No Garage\n",
    "        \n",
    "GarageCars: Size of garage in car capacity\n",
    "\n",
    "GarageArea: Size of garage in square feet\n",
    "\n",
    "GarageQual: Garage quality\n",
    "\n",
    "       Ex    Excellent\n",
    "       Gd    Good\n",
    "       TA    Typical/Average\n",
    "       Fa    Fair\n",
    "       Po    Poor\n",
    "       NA    No Garage\n",
    "        \n",
    "GarageCond: Garage condition\n",
    "\n",
    "       Ex    Excellent\n",
    "       Gd    Good\n",
    "       TA    Typical/Average\n",
    "       Fa    Fair\n",
    "       Po    Poor\n",
    "       NA    No Garage\n",
    "        \n",
    "PavedDrive: Paved driveway\n",
    "\n",
    "       Y    Paved \n",
    "       P    Partial Pavement\n",
    "       N    Dirt/Gravel\n",
    "        \n",
    "WoodDeckSF: Wood deck area in square feet\n",
    "\n",
    "OpenPorchSF: Open porch area in square feet\n",
    "\n",
    "EnclosedPorch: Enclosed porch area in square feet\n",
    "\n",
    "3SsnPorch: Three season porch area in square feet\n",
    "\n",
    "ScreenPorch: Screen porch area in square feet\n",
    "\n",
    "PoolArea: Pool area in square feet\n",
    "\n",
    "PoolQC: Pool quality\n",
    "        \n",
    "       Ex    Excellent\n",
    "       Gd    Good\n",
    "       TA    Average/Typical\n",
    "       Fa    Fair\n",
    "       NA    No Pool\n",
    "        \n",
    "Fence: Fence quality\n",
    "        \n",
    "       GdPrv       Good Privacy\n",
    "       MnPrv       Minimum Privacy\n",
    "       GdWo        Good Wood\n",
    "       MnWw        Minimum Wood/Wire\n",
    "       NA          No Fence\n",
    "    \n",
    "MiscFeature: Miscellaneous feature not covered in other categories\n",
    "        \n",
    "       Elev    Elevator\n",
    "       Gar2    2nd Garage (if not described in garage section)\n",
    "       Othr    Other\n",
    "       Shed    Shed (over 100 SF)\n",
    "       TenC    Tennis Court\n",
    "       NA      None\n",
    "        \n",
    "MiscVal: $Value of miscellaneous feature\n",
    "\n",
    "MoSold: Month Sold (MM)\n",
    "\n",
    "YrSold: Year Sold (YYYY)\n",
    "\n",
    "SaleType: Type of sale\n",
    "    \n",
    "       WD         Warranty Deed - Conventional\n",
    "       CWD        Warranty Deed - Cash\n",
    "       VWD        Warranty Deed - VA Loan\n",
    "       New        Home just constructed and sold\n",
    "       COD        Court Officer Deed/Estate\n",
    "       Con        Contract 15% Down payment regular terms\n",
    "       ConLw      Contract Low Down payment and low interest\n",
    "       ConLI      Contract Low Interest\n",
    "       ConLD      Contract Low Down\n",
    "       Oth        Other\n",
    "        \n",
    "SaleCondition: Condition of sale\n",
    "\n",
    "       Normal     Normal Sale\n",
    "       Abnorml    Abnormal Sale -  trade, foreclosure, short sale\n",
    "       AdjLand    Adjoining Land Purchase\n",
    "       Alloca     Allocation - two linked properties with separate deeds, typically condo with a garage unit    \n",
    "       Family     Sale between family members\n",
    "       Partial    Home was not completed when last assessed (associated with New Homes)\n",
    "````"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Referências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[A] Almeida, Pedro Henrique Ramos. Fatores determinantes para a formação de preço no mercado imobiliário de Brasília. Brasília. 2001. Universidade de Brasília. Disponível em [http://bdm.unb.br/bitstream/10483/2122/1/2011_PedroHenriqueRamosdeAlmeida.pdf](http://bdm.unb.br/bitstream/10483/2122/1/2011_PedroHenriqueRamosdeAlmeida.pdf)\n",
    "\n",
    "[B] Belfiore, Patrícia Prado. Fávero, Luiz Paulo Lopes. Lima, Gerlando A. S. Franco. Modelos de precificação hedônica de imóveis residenciais na região metropolitana de São Paulo: uma abordagem sob as perspectivas da demanda e da oferta. São Paulo Jan./Mar. 2008. Estud. Econ. vol.38. Disponível em [http://www.scielo.br/scielo.php?script=sci_arttext&pid=S0101-41612008000100004](http://www.scielo.br/scielo.php?script=sci_arttext&pid=S0101-41612008000100004)\n",
    "\n",
    "[C] Kaggle. House Prices: Advanced Regression Techniques. Disponível em [https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview](https://www.kaggle.com/c/house-prices-advanced-regression-techniques/overview)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3] *",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
