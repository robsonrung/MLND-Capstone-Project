{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usar Root-Mean-Squared-Error (RMSE)  \n",
    "sklearn.metrics.mean_squared_error(y_true, y_pred, sample_weight=None, multioutput=’uniform_average’)[source]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Id',\n",
       " 'MSSubClass',\n",
       " 'MSZoning',\n",
       " 'LotFrontage',\n",
       " 'LotArea',\n",
       " 'Street',\n",
       " 'Alley',\n",
       " 'LotShape',\n",
       " 'LandContour',\n",
       " 'Utilities',\n",
       " 'LotConfig',\n",
       " 'LandSlope',\n",
       " 'Neighborhood',\n",
       " 'Condition1',\n",
       " 'Condition2',\n",
       " 'BldgType',\n",
       " 'HouseStyle',\n",
       " 'OverallQual',\n",
       " 'OverallCond',\n",
       " 'YearBuilt',\n",
       " 'YearRemodAdd',\n",
       " 'RoofStyle',\n",
       " 'RoofMatl',\n",
       " 'Exterior1st',\n",
       " 'Exterior2nd',\n",
       " 'MasVnrType',\n",
       " 'MasVnrArea',\n",
       " 'ExterQual',\n",
       " 'ExterCond',\n",
       " 'Foundation',\n",
       " 'BsmtQual',\n",
       " 'BsmtCond',\n",
       " 'BsmtExposure',\n",
       " 'BsmtFinType1',\n",
       " 'BsmtFinSF1',\n",
       " 'BsmtFinType2',\n",
       " 'BsmtFinSF2',\n",
       " 'BsmtUnfSF',\n",
       " 'TotalBsmtSF',\n",
       " 'Heating',\n",
       " 'HeatingQC',\n",
       " 'CentralAir',\n",
       " 'Electrical',\n",
       " '1stFlrSF',\n",
       " '2ndFlrSF',\n",
       " 'LowQualFinSF',\n",
       " 'GrLivArea',\n",
       " 'BsmtFullBath',\n",
       " 'BsmtHalfBath',\n",
       " 'FullBath',\n",
       " 'HalfBath',\n",
       " 'BedroomAbvGr',\n",
       " 'KitchenAbvGr',\n",
       " 'KitchenQual',\n",
       " 'TotRmsAbvGrd',\n",
       " 'Functional',\n",
       " 'Fireplaces',\n",
       " 'FireplaceQu',\n",
       " 'GarageType',\n",
       " 'GarageYrBlt',\n",
       " 'GarageFinish',\n",
       " 'GarageCars',\n",
       " 'GarageArea',\n",
       " 'GarageQual',\n",
       " 'GarageCond',\n",
       " 'PavedDrive',\n",
       " 'WoodDeckSF',\n",
       " 'OpenPorchSF',\n",
       " 'EnclosedPorch',\n",
       " '3SsnPorch',\n",
       " 'ScreenPorch',\n",
       " 'PoolArea',\n",
       " 'PoolQC',\n",
       " 'Fence',\n",
       " 'MiscFeature',\n",
       " 'MiscVal',\n",
       " 'MoSold',\n",
       " 'YrSold',\n",
       " 'SaleType',\n",
       " 'SaleCondition',\n",
       " 'SalePrice']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "list(train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Descrição dos dados](data_description.txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train[[\"LotArea\",\"OverallCond\", \"TotalBsmtSF\", \"FullBath\", \"HalfBath\",\"BedroomAbvGr\", \"TotRmsAbvGrd\", \"Fireplaces\", \"GarageArea\", \"SalePrice\"]]\n",
    "train_array = train.values\n",
    "# train_array\n",
    "\n",
    "# list(train)\n",
    "\n",
    "X = train_array[:,0:9]\n",
    "Y = train_array[:,9]\n",
    "\n",
    "from sklearn import preprocessing\n",
    "min_max_scaler = preprocessing.MinMaxScaler()\n",
    "X_scale = min_max_scaler.fit_transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.04066466, 0.5       , 0.2599018 , 0.66666667, 0.        ,\n",
       "       0.375     , 0.41666667, 0.33333333, 0.58180536])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_val_and_test, Y_train, Y_val_and_test = train_test_split(X_scale, Y, test_size=0.3)\n",
    "X_val, X_test, Y_val, Y_test = train_test_split(X_val_and_test, Y_val_and_test, test_size=0.5)\n",
    "X_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([227000, 280000, 140000, ..., 145000,  91000, 138000])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime.datetime(2019, 7, 29, 12, 2, 7, 957585)"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import datetime\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2019-07-29 13:55:11.392225\n",
      "Train on 1022 samples, validate on 219 samples\n",
      "Epoch 1/10000\n",
      "1022/1022 [==============================] - 1s 875us/step - loss: 39391691745.9413 - val_loss: 38517894232.8402\n",
      "Epoch 2/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 39391592728.5479 - val_loss: 38517727867.9087\n",
      "Epoch 3/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 39391312356.9472 - val_loss: 38517277625.8630\n",
      "Epoch 4/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 39390599023.7182 - val_loss: 38516202790.5753\n",
      "Epoch 5/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 39388990325.7299 - val_loss: 38513850601.7900\n",
      "Epoch 6/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 39385643629.2133 - val_loss: 38509239871.1233\n",
      "Epoch 7/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 39379435652.2583 - val_loss: 38501100127.8539\n",
      "Epoch 8/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 39368949423.3425 - val_loss: 38487749674.0822\n",
      "Epoch 9/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 39352116522.5832 - val_loss: 38466679644.3470\n",
      "Epoch 10/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 39326269103.3425 - val_loss: 38435368174.4658\n",
      "Epoch 11/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 39288738713.8004 - val_loss: 38390765259.3973\n",
      "Epoch 12/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 39236329584.2192 - val_loss: 38329833313.0228\n",
      "Epoch 13/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 39166513741.1507 - val_loss: 38248773473.0228\n",
      "Epoch 14/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 39074611560.7045 - val_loss: 38145699297.6073\n",
      "Epoch 15/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 38958550166.2935 - val_loss: 38015448162.1918\n",
      "Epoch 16/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 38813048134.6380 - val_loss: 37855063502.9041\n",
      "Epoch 17/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 38635780011.8356 - val_loss: 37659272028.3470\n",
      "Epoch 18/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 38422027646.7476 - val_loss: 37425582809.4247\n",
      "Epoch 19/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 38168337814.7945 - val_loss: 37150676365.4429\n",
      "Epoch 20/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 37871183054.4031 - val_loss: 36830304153.1324\n",
      "Epoch 21/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 37527605320.1409 - val_loss: 36459825928.1826\n",
      "Epoch 22/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 37130879989.9804 - val_loss: 36040033041.5342\n",
      "Epoch 23/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 36682481992.6419 - val_loss: 35562975213.2968\n",
      "Epoch 24/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 36175149444.7593 - val_loss: 35029062136.9863\n",
      "Epoch 25/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 35612335286.3562 - val_loss: 34427904093.5160\n",
      "Epoch 26/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 34984580274.3483 - val_loss: 33771184015.7808\n",
      "Epoch 27/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 34295123471.0294 - val_loss: 33050818419.7260\n",
      "Epoch 28/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 33538339473.2838 - val_loss: 32274999043.5069\n",
      "Epoch 29/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 32723003852.9002 - val_loss: 31426208791.3790\n",
      "Epoch 30/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 31846626245.8865 - val_loss: 30509512058.7397\n",
      "Epoch 31/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 30898352444.6184 - val_loss: 29551117466.3014\n",
      "Epoch 32/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 29898311443.5382 - val_loss: 28527589497.5708\n",
      "Epoch 33/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 28838927702.6693 - val_loss: 27449417662.5388\n",
      "Epoch 34/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 27729280775.5147 - val_loss: 26319226057.0594\n",
      "Epoch 35/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 26571101532.6810 - val_loss: 25142617167.4886\n",
      "Epoch 36/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 25364439809.5029 - val_loss: 23946515142.7215\n",
      "Epoch 37/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 24135133560.7358 - val_loss: 22700427497.7900\n",
      "Epoch 38/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 22866637184.7515 - val_loss: 21447112647.8904\n",
      "Epoch 39/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 21585859453.7456 - val_loss: 20171769332.3105\n",
      "Epoch 40/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 20292483589.0098 - val_loss: 18894300267.5434\n",
      "Epoch 41/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 18996557705.7691 - val_loss: 17629916529.3881\n",
      "Epoch 42/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 17718162838.7945 - val_loss: 16369884286.2466\n",
      "Epoch 43/10000\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 16442703226.7397 - val_loss: 15163545810.4110\n",
      "Epoch 44/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 15210165105.7221 - val_loss: 13975334542.6119\n",
      "Epoch 45/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 14017114063.9061 - val_loss: 12816392421.1142\n",
      "Epoch 46/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 12861495746.8806 - val_loss: 11732064125.0776\n",
      "Epoch 47/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 11772010862.7162 - val_loss: 10703038492.0548\n",
      "Epoch 48/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 10738590894.3405 - val_loss: 9758102701.0046\n",
      "Epoch 49/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 9787503754.2701 - val_loss: 8866809322.9589\n",
      "Epoch 50/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 8892419737.2994 - val_loss: 8090186247.0137\n",
      "Epoch 51/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 8099879571.2877 - val_loss: 7356342515.1416\n",
      "Epoch 52/10000\n",
      "1022/1022 [==============================] - 0s 76us/step - loss: 7367932860.8689 - val_loss: 6727865128.9132\n",
      "Epoch 53/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 6733000420.4462 - val_loss: 6153683067.9087\n",
      "Epoch 54/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 6167803803.3033 - val_loss: 5670356077.8813\n",
      "Epoch 55/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 5678346817.1272 - val_loss: 5274329232.9498\n",
      "Epoch 56/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 5274420371.7886 - val_loss: 4920471061.0411\n",
      "Epoch 57/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 4910370953.2681 - val_loss: 4667550479.1963\n",
      "Epoch 58/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 4630645015.5460 - val_loss: 4437611048.9132\n",
      "Epoch 59/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 4392550548.2896 - val_loss: 4259804460.4201\n",
      "Epoch 60/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 4203276319.0607 - val_loss: 4123311870.8311\n",
      "Epoch 61/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 4049397733.9491 - val_loss: 4025705489.5342\n",
      "Epoch 62/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 3932207377.5342 - val_loss: 3951782541.4429\n",
      "Epoch 63/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 3841215245.5264 - val_loss: 3897010135.0868\n",
      "Epoch 64/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 3772449790.4971 - val_loss: 3858821146.8858\n",
      "Epoch 65/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 78us/step - loss: 3716807615.8748 - val_loss: 3836208159.5616\n",
      "Epoch 66/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 3679786580.9159 - val_loss: 3819132506.0091\n",
      "Epoch 67/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 3649177693.6830 - val_loss: 3810707636.0183\n",
      "Epoch 68/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 3626069567.6243 - val_loss: 3805714091.8356\n",
      "Epoch 69/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 3610025357.0254 - val_loss: 3803397775.7808\n",
      "Epoch 70/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 3597172754.5362 - val_loss: 3802787423.8539\n",
      "Epoch 71/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 3587099149.0254 - val_loss: 3803024168.9132\n",
      "Epoch 72/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 3579043014.3875 - val_loss: 3802787778.0457\n",
      "Epoch 73/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 3572613555.3503 - val_loss: 3804217106.7032\n",
      "Epoch 74/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 3566880821.6047 - val_loss: 3804704627.7260\n",
      "Epoch 75/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 3561919029.6047 - val_loss: 3805339999.8539\n",
      "Epoch 76/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 3557755896.4853 - val_loss: 3804653997.0046\n",
      "Epoch 77/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 3553461668.3209 - val_loss: 3802837230.4658\n",
      "Epoch 78/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 3549656180.2270 - val_loss: 3800834251.3973\n",
      "Epoch 79/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 3544991237.0098 - val_loss: 3801496931.3607\n",
      "Epoch 80/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 3540556991.3738 - val_loss: 3801336632.1096\n",
      "Epoch 81/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 3536824343.0450 - val_loss: 3796359248.6575\n",
      "Epoch 82/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 3533107246.0900 - val_loss: 3796908609.4612\n",
      "Epoch 83/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 3529290696.3914 - val_loss: 3796700406.6484\n",
      "Epoch 84/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 3524537896.0783 - val_loss: 3790477538.7763\n",
      "Epoch 85/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 3520213537.0646 - val_loss: 3788135184.3653\n",
      "Epoch 86/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 3516066613.8552 - val_loss: 3787660957.8082\n",
      "Epoch 87/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 3511578979.4442 - val_loss: 3783848760.1096\n",
      "Epoch 88/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 3507488133.7613 - val_loss: 3779820291.5068\n",
      "Epoch 89/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 3503913486.5284 - val_loss: 3776391803.9087\n",
      "Epoch 90/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 3498788165.8865 - val_loss: 3776840284.3470\n",
      "Epoch 91/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 3494688591.9061 - val_loss: 3773310716.4932\n",
      "Epoch 92/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 3490109571.7573 - val_loss: 3769971412.7489\n",
      "Epoch 93/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 3485903368.0157 - val_loss: 3767490639.4886\n",
      "Epoch 94/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 3482267344.4070 - val_loss: 3761221520.9498\n",
      "Epoch 95/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 3478408341.7926 - val_loss: 3759962503.5982\n",
      "Epoch 96/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 3471991618.6301 - val_loss: 3756564242.7032\n",
      "Epoch 97/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 3467380686.9041 - val_loss: 3752694706.8493\n",
      "Epoch 98/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 3463532245.9178 - val_loss: 3749587734.2100\n",
      "Epoch 99/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 3459005371.8669 - val_loss: 3749327274.6667\n",
      "Epoch 100/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 3453190806.7945 - val_loss: 3743596539.3242\n",
      "Epoch 101/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 3448636666.4892 - val_loss: 3740537415.3059\n",
      "Epoch 102/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 3444017542.7632 - val_loss: 3736169446.2831\n",
      "Epoch 103/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 3439856198.1370 - val_loss: 3734551445.6256\n",
      "Epoch 104/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 3434724162.6301 - val_loss: 3727890527.8539\n",
      "Epoch 105/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 3429175913.7065 - val_loss: 3726784229.1142\n",
      "Epoch 106/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 3424350226.5362 - val_loss: 3723735666.5571\n",
      "Epoch 107/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 3419826124.3992 - val_loss: 3720895891.2877\n",
      "Epoch 108/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 3415966225.0333 - val_loss: 3717832991.5616\n",
      "Epoch 109/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 3409478484.6654 - val_loss: 3714173281.0228\n",
      "Epoch 110/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 3405057638.1996 - val_loss: 3711867160.5479\n",
      "Epoch 111/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 3399319148.9628 - val_loss: 3706803378.8493\n",
      "Epoch 112/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 3395158855.6399 - val_loss: 3705627494.8676\n",
      "Epoch 113/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 3389024056.1096 - val_loss: 3698118288.9498\n",
      "Epoch 114/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 3384373183.3738 - val_loss: 3695698996.6027\n",
      "Epoch 115/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 3380312275.1624 - val_loss: 3691859209.3516\n",
      "Epoch 116/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 3374080661.2916 - val_loss: 3684338579.2877\n",
      "Epoch 117/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 3367777443.3190 - val_loss: 3683963082.2283\n",
      "Epoch 118/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 3363182619.0528 - val_loss: 3681044952.2557\n",
      "Epoch 119/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 3357449833.2055 - val_loss: 3678380840.9132\n",
      "Epoch 120/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 3352442269.5577 - val_loss: 3676401181.2237\n",
      "Epoch 121/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 3347642369.0020 - val_loss: 3666810080.4384\n",
      "Epoch 122/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 3341953927.2642 - val_loss: 3665086105.1324\n",
      "Epoch 123/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 3338061793.4403 - val_loss: 3664036795.0320\n",
      "Epoch 124/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 3332100127.0607 - val_loss: 3660406006.6484\n",
      "Epoch 125/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 3325150851.7573 - val_loss: 3653027395.7991\n",
      "Epoch 126/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 3320839697.5342 - val_loss: 3649143518.1005\n",
      "Epoch 127/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 3314411318.6067 - val_loss: 3645907621.9909\n",
      "Epoch 128/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 3309221423.8434 - val_loss: 3645900021.4795\n",
      "Epoch 129/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 3303588456.2035 - val_loss: 3642687122.1187\n",
      "Epoch 130/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 54us/step - loss: 3297699102.5597 - val_loss: 3636487342.1735\n",
      "Epoch 131/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 3292362987.7104 - val_loss: 3633133743.9269\n",
      "Epoch 132/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 3287351547.4912 - val_loss: 3627441884.3470\n",
      "Epoch 133/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 3281707895.2329 - val_loss: 3628746624.0000\n",
      "Epoch 134/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 3274785920.7515 - val_loss: 3621579194.4475\n",
      "Epoch 135/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 3270072354.3170 - val_loss: 3615587993.7169\n",
      "Epoch 136/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 3264313347.7573 - val_loss: 3615203101.8082\n",
      "Epoch 137/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 3259471530.8337 - val_loss: 3613524446.6849\n",
      "Epoch 138/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 3252840162.4423 - val_loss: 3604582620.3470\n",
      "Epoch 139/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 3248157944.7358 - val_loss: 3603355673.1324\n",
      "Epoch 140/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 3242176219.9296 - val_loss: 3599222864.6575\n",
      "Epoch 141/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 3236867514.3640 - val_loss: 3596098679.2329\n",
      "Epoch 142/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 3229935947.6477 - val_loss: 3585485577.9361\n",
      "Epoch 143/10000\n",
      "1022/1022 [==============================] - 0s 68us/step - loss: 3226254262.6067 - val_loss: 3589450153.4977\n",
      "Epoch 144/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 3217763945.9569 - val_loss: 3581400023.6712\n",
      "Epoch 145/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 3212652082.5988 - val_loss: 3575043258.4475\n",
      "Epoch 146/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 3206617883.0528 - val_loss: 3572546024.0365\n",
      "Epoch 147/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 3200830513.5969 - val_loss: 3570605405.5160\n",
      "Epoch 148/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 3195392270.5284 - val_loss: 3566467937.6073\n",
      "Epoch 149/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 3189670458.1135 - val_loss: 3567714903.0868\n",
      "Epoch 150/10000\n",
      "1022/1022 [==============================] - 0s 95us/step - loss: 3184654519.6086 - val_loss: 3564282249.3516\n",
      "Epoch 151/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 3177334971.1155 - val_loss: 3555298049.1689\n",
      "Epoch 152/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 3172778939.8669 - val_loss: 3550045427.1416\n",
      "Epoch 153/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 3166711847.8278 - val_loss: 3550936757.1872\n",
      "Epoch 154/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 3160341511.5147 - val_loss: 3545722064.0731\n",
      "Epoch 155/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 3154458849.4403 - val_loss: 3540919551.4155\n",
      "Epoch 156/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 3148334994.7867 - val_loss: 3536464735.8539\n",
      "Epoch 157/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 3142510614.5440 - val_loss: 3532862805.3333\n",
      "Epoch 158/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 3136816296.3288 - val_loss: 3524515364.8219\n",
      "Epoch 159/10000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 3130822673.5342 - val_loss: 3522417488.6575\n",
      "Epoch 160/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 3125663265.8160 - val_loss: 3523922896.0731\n",
      "Epoch 161/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 3119229587.0372 - val_loss: 3522827329.4612\n",
      "Epoch 162/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 3113613887.3738 - val_loss: 3512679641.4247\n",
      "Epoch 163/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 3108572115.4129 - val_loss: 3506221489.6804\n",
      "Epoch 164/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 3102613312.3757 - val_loss: 3512571189.7717\n",
      "Epoch 165/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 3096675953.4716 - val_loss: 3503085517.1507\n",
      "Epoch 166/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 3089596131.4442 - val_loss: 3496882947.5068\n",
      "Epoch 167/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 3084096467.4129 - val_loss: 3495447847.7443\n",
      "Epoch 168/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 3078823056.7828 - val_loss: 3488249203.1416\n",
      "Epoch 169/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 3073734842.1135 - val_loss: 3493905406.8311\n",
      "Epoch 170/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 3066224452.8845 - val_loss: 3485220337.3881\n",
      "Epoch 171/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 3061424794.8023 - val_loss: 3484037976.8402\n",
      "Epoch 172/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 3054677347.4442 - val_loss: 3472935924.3105\n",
      "Epoch 173/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 3049715790.1526 - val_loss: 3469573494.0639\n",
      "Epoch 174/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 3043926038.5440 - val_loss: 3471072662.7945\n",
      "Epoch 175/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 3038737378.9432 - val_loss: 3467600602.5936\n",
      "Epoch 176/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 3031992272.4070 - val_loss: 3465314349.0046\n",
      "Epoch 177/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 3026132818.4110 - val_loss: 3457592682.3744\n",
      "Epoch 178/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 3019829291.0841 - val_loss: 3454508423.0137\n",
      "Epoch 179/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 3015000213.5421 - val_loss: 3455581558.6484\n",
      "Epoch 180/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 3007948757.1663 - val_loss: 3448294976.8767\n",
      "Epoch 181/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 3003194971.6791 - val_loss: 3441412557.1507\n",
      "Epoch 182/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2997025853.3699 - val_loss: 3436854471.8904\n",
      "Epoch 183/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2991358310.7006 - val_loss: 3435908017.6804\n",
      "Epoch 184/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 2986065783.7339 - val_loss: 3429618146.1918\n",
      "Epoch 185/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2980883595.7730 - val_loss: 3425765306.4475\n",
      "Epoch 186/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2975415221.3542 - val_loss: 3431319674.7397\n",
      "Epoch 187/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2968525046.4814 - val_loss: 3424397358.1735\n",
      "Epoch 188/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2963104297.5812 - val_loss: 3418434707.2877\n",
      "Epoch 189/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2957355789.5264 - val_loss: 3416271312.0731\n",
      "Epoch 190/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2951020849.3464 - val_loss: 3415461308.2009\n",
      "Epoch 191/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2945735014.1996 - val_loss: 3410790291.8721\n",
      "Epoch 192/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2939622305.3151 - val_loss: 3402145928.1826\n",
      "Epoch 193/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2934826391.7965 - val_loss: 3402220078.1735\n",
      "Epoch 194/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2928097222.3875 - val_loss: 3397242863.0502\n",
      "Epoch 195/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 37us/step - loss: 2922885643.3973 - val_loss: 3392880450.6301\n",
      "Epoch 196/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 2917843388.8689 - val_loss: 3386951170.9224\n",
      "Epoch 197/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2911404099.6321 - val_loss: 3390103331.6530\n",
      "Epoch 198/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2905836446.3092 - val_loss: 3384446852.6758\n",
      "Epoch 199/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2900619258.2387 - val_loss: 3385762675.1416\n",
      "Epoch 200/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2896005395.5382 - val_loss: 3379034684.2009\n",
      "Epoch 201/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2889333178.3640 - val_loss: 3371478990.3196\n",
      "Epoch 202/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2884987166.5597 - val_loss: 3372559815.8904\n",
      "Epoch 203/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2879013956.1331 - val_loss: 3365078706.2648\n",
      "Epoch 204/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2873414654.9980 - val_loss: 3366354850.4840\n",
      "Epoch 205/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2867936854.1683 - val_loss: 3363825037.4429\n",
      "Epoch 206/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2862633629.8082 - val_loss: 3354262754.7763\n",
      "Epoch 207/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2856813920.6888 - val_loss: 3353783034.1553\n",
      "Epoch 208/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2850919194.5519 - val_loss: 3354343361.4612\n",
      "Epoch 209/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2845564389.9491 - val_loss: 3347142092.5662\n",
      "Epoch 210/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2840480992.4384 - val_loss: 3349502630.5753\n",
      "Epoch 211/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2836526438.1996 - val_loss: 3343606515.1416\n",
      "Epoch 212/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2829544744.8297 - val_loss: 3335449375.5616\n",
      "Epoch 213/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2823898802.5988 - val_loss: 3335405507.2146\n",
      "Epoch 214/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2820021440.1252 - val_loss: 3334597223.4521\n",
      "Epoch 215/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2813358389.6047 - val_loss: 3331951110.4292\n",
      "Epoch 216/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 2808214977.6282 - val_loss: 3325649081.8630\n",
      "Epoch 217/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 2803167301.3855 - val_loss: 3324291548.3470\n",
      "Epoch 218/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 2799762837.4168 - val_loss: 3325949813.4795\n",
      "Epoch 219/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 2792976440.1096 - val_loss: 3314794493.6621\n",
      "Epoch 220/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 2787350168.7984 - val_loss: 3312406142.8311\n",
      "Epoch 221/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 2784102850.8806 - val_loss: 3308780203.2511\n",
      "Epoch 222/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2776894317.4638 - val_loss: 3310050081.3151\n",
      "Epoch 223/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2771683885.8395 - val_loss: 3311452012.7123\n",
      "Epoch 224/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 2768131902.6223 - val_loss: 3310860395.5434\n",
      "Epoch 225/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2762190143.1233 - val_loss: 3301176307.7260\n",
      "Epoch 226/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2757681449.0802 - val_loss: 3292398087.5982\n",
      "Epoch 227/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2752303686.1370 - val_loss: 3295061348.5297\n",
      "Epoch 228/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2748344061.9961 - val_loss: 3290919018.9589\n",
      "Epoch 229/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2741564153.9883 - val_loss: 3294752396.8584\n",
      "Epoch 230/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 2735685432.6106 - val_loss: 3286118037.0411\n",
      "Epoch 231/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 2732021268.5401 - val_loss: 3287177108.4566\n",
      "Epoch 232/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2725879338.0822 - val_loss: 3277549137.8265\n",
      "Epoch 233/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2721671607.3581 - val_loss: 3277975771.7626\n",
      "Epoch 234/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2717535594.9589 - val_loss: 3271762462.9772\n",
      "Epoch 235/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2713657852.4932 - val_loss: 3276228017.0959\n",
      "Epoch 236/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2707084422.2622 - val_loss: 3265206136.9863\n",
      "Epoch 237/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2701636963.1937 - val_loss: 3267845812.0183\n",
      "Epoch 238/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2696689338.3640 - val_loss: 3262135097.8630\n",
      "Epoch 239/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2692093403.4286 - val_loss: 3263476156.7854\n",
      "Epoch 240/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2688875197.8708 - val_loss: 3254669261.7352\n",
      "Epoch 241/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2683386944.1252 - val_loss: 3264695818.5205\n",
      "Epoch 242/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2678789907.7887 - val_loss: 3261774230.7945\n",
      "Epoch 243/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2672683987.4129 - val_loss: 3249796925.3699\n",
      "Epoch 244/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2669071312.4070 - val_loss: 3250375922.5571\n",
      "Epoch 245/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2664364998.8885 - val_loss: 3243956777.4977\n",
      "Epoch 246/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 2658307516.3679 - val_loss: 3244518875.7626\n",
      "Epoch 247/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2653862197.3542 - val_loss: 3241075952.2192\n",
      "Epoch 248/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 2649944151.1703 - val_loss: 3239925514.5205\n",
      "Epoch 249/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2646617306.9276 - val_loss: 3240205753.8630\n",
      "Epoch 250/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2640680337.2838 - val_loss: 3236835513.2785\n",
      "Epoch 251/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2635224090.9276 - val_loss: 3227297341.3699\n",
      "Epoch 252/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2630095516.5558 - val_loss: 3228434522.5936\n",
      "Epoch 253/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2627382609.6595 - val_loss: 3229431917.2968\n",
      "Epoch 254/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2622392958.9980 - val_loss: 3221960939.5434\n",
      "Epoch 255/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2616173673.7065 - val_loss: 3222380426.5205\n",
      "Epoch 256/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2613168994.1918 - val_loss: 3223703928.4018\n",
      "Epoch 257/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2607253368.2348 - val_loss: 3221337053.5160\n",
      "Epoch 258/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2604818204.0548 - val_loss: 3215220028.2009\n",
      "Epoch 259/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2599225453.4638 - val_loss: 3215579401.9361\n",
      "Epoch 260/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 38us/step - loss: 2594318718.2466 - val_loss: 3214876215.5251\n",
      "Epoch 261/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2592095055.2798 - val_loss: 3219621503.4155\n",
      "Epoch 262/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2584758288.0313 - val_loss: 3210022438.5753\n",
      "Epoch 263/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2580814611.5382 - val_loss: 3203328035.0685\n",
      "Epoch 264/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2576846538.3953 - val_loss: 3199070409.0594\n",
      "Epoch 265/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2572484437.1663 - val_loss: 3205043977.3516\n",
      "Epoch 266/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2568063235.5068 - val_loss: 3194723665.2420\n",
      "Epoch 267/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2564569453.4638 - val_loss: 3200096270.6119\n",
      "Epoch 268/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2559435407.5303 - val_loss: 3192034527.8539\n",
      "Epoch 269/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2555280851.4129 - val_loss: 3194815766.2100\n",
      "Epoch 270/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2552781948.2427 - val_loss: 3185060328.6210\n",
      "Epoch 271/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2545942377.7065 - val_loss: 3192484888.5479\n",
      "Epoch 272/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 2542392282.4266 - val_loss: 3188437157.9909\n",
      "Epoch 273/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2538476566.0431 - val_loss: 3187467993.4247\n",
      "Epoch 274/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2534033528.2348 - val_loss: 3186612537.2785\n",
      "Epoch 275/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2530319341.2133 - val_loss: 3180242474.0822\n",
      "Epoch 276/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2525209130.3327 - val_loss: 3179329277.0776\n",
      "Epoch 277/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2521603114.5832 - val_loss: 3173886460.4932\n",
      "Epoch 278/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2518796966.3249 - val_loss: 3181372608.2922\n",
      "Epoch 279/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2512966101.9178 - val_loss: 3172419988.4566\n",
      "Epoch 280/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2509640936.4540 - val_loss: 3172319515.4703\n",
      "Epoch 281/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2506092814.0274 - val_loss: 3170533211.7626\n",
      "Epoch 282/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2501333281.8160 - val_loss: 3167596432.9498\n",
      "Epoch 283/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2497969784.7358 - val_loss: 3166495580.9315\n",
      "Epoch 284/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2494756716.7123 - val_loss: 3172143549.9543\n",
      "Epoch 285/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2489188656.0939 - val_loss: 3164594673.3881\n",
      "Epoch 286/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2485974748.4305 - val_loss: 3155336335.7808\n",
      "Epoch 287/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2482487027.7260 - val_loss: 3162475623.4521\n",
      "Epoch 288/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2477697491.4129 - val_loss: 3156123481.4247\n",
      "Epoch 289/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2475580311.9217 - val_loss: 3154170515.8721\n",
      "Epoch 290/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2471076571.9296 - val_loss: 3158035785.0594\n",
      "Epoch 291/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2466379551.0607 - val_loss: 3153744015.7808\n",
      "Epoch 292/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2463490822.0117 - val_loss: 3150398108.0548\n",
      "Epoch 293/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2459108328.7045 - val_loss: 3151990071.5251\n",
      "Epoch 294/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2455421398.1683 - val_loss: 3148740152.1096\n",
      "Epoch 295/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2451454106.3014 - val_loss: 3146490236.4932\n",
      "Epoch 296/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2450700032.7515 - val_loss: 3136600274.9954\n",
      "Epoch 297/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2446574453.7299 - val_loss: 3148573580.2740\n",
      "Epoch 298/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 2441878020.5088 - val_loss: 3140183538.5571\n",
      "Epoch 299/10000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2438238105.8004 - val_loss: 3138540251.1781\n",
      "Epoch 300/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 2433432045.9648 - val_loss: 3138236789.4795\n",
      "Epoch 301/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 2431322543.0920 - val_loss: 3138335587.3607\n",
      "Epoch 302/10000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 2427388820.0391 - val_loss: 3141033218.3379\n",
      "Epoch 303/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2423179823.8434 - val_loss: 3136107221.9178\n",
      "Epoch 304/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2420210347.8356 - val_loss: 3131404417.1689\n",
      "Epoch 305/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 2416710510.2153 - val_loss: 3136623445.3333\n",
      "Epoch 306/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2412315466.6458 - val_loss: 3126897137.9726\n",
      "Epoch 307/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2409773125.6360 - val_loss: 3127527414.0639\n",
      "Epoch 308/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2406154509.0254 - val_loss: 3129390283.3973\n",
      "Epoch 309/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2402986933.8552 - val_loss: 3130042285.5890\n",
      "Epoch 310/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2399560111.5930 - val_loss: 3135939997.2237\n",
      "Epoch 311/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2396459271.5147 - val_loss: 3126734331.9087\n",
      "Epoch 312/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2392190341.7613 - val_loss: 3119701317.5525\n",
      "Epoch 313/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2389283905.7534 - val_loss: 3126903179.1050\n",
      "Epoch 314/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2385658062.1526 - val_loss: 3120180050.9954\n",
      "Epoch 315/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2384871287.9843 - val_loss: 3121717385.3516\n",
      "Epoch 316/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2379200238.4658 - val_loss: 3116742052.2374\n",
      "Epoch 317/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2376831445.9178 - val_loss: 3119599648.7306\n",
      "Epoch 318/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2374379968.3757 - val_loss: 3112821823.1233\n",
      "Epoch 319/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2369920135.2642 - val_loss: 3115542841.2785\n",
      "Epoch 320/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2367139098.0509 - val_loss: 3115130704.0731\n",
      "Epoch 321/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2364629329.6595 - val_loss: 3106810159.9269\n",
      "Epoch 322/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2360080476.1800 - val_loss: 3117703220.0183\n",
      "Epoch 323/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2356845387.8982 - val_loss: 3115613307.9087\n",
      "Epoch 324/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 2354682359.7339 - val_loss: 3112220193.3151\n",
      "Epoch 325/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 38us/step - loss: 2351644923.4912 - val_loss: 3113008592.0731\n",
      "Epoch 326/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2347654628.1957 - val_loss: 3107509521.5342\n",
      "Epoch 327/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2345087757.2759 - val_loss: 3105759087.6347\n",
      "Epoch 328/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2342116850.4736 - val_loss: 3107885386.2283\n",
      "Epoch 329/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2341019247.9687 - val_loss: 3099068087.5251\n",
      "Epoch 330/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2337933428.9785 - val_loss: 3115035657.3516\n",
      "Epoch 331/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2333919469.9648 - val_loss: 3098873242.8858\n",
      "Epoch 332/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2331546482.7241 - val_loss: 3097646554.0091\n",
      "Epoch 333/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2329491187.7260 - val_loss: 3109533689.5708\n",
      "Epoch 334/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2326314070.6693 - val_loss: 3099069772.5662\n",
      "Epoch 335/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2322270223.0294 - val_loss: 3100010928.5114\n",
      "Epoch 336/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2319509348.6967 - val_loss: 3100557392.6575\n",
      "Epoch 337/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2317489648.7202 - val_loss: 3105547823.3425\n",
      "Epoch 338/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2318703530.3327 - val_loss: 3096414817.0228\n",
      "Epoch 339/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2310211245.3386 - val_loss: 3097706802.2648\n",
      "Epoch 340/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2308402876.8689 - val_loss: 3091705445.1142\n",
      "Epoch 341/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2306578650.9276 - val_loss: 3102808907.3973\n",
      "Epoch 342/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2303383400.7045 - val_loss: 3092004490.5205\n",
      "Epoch 343/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2299649497.6751 - val_loss: 3093816733.8082\n",
      "Epoch 344/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2297355716.3836 - val_loss: 3096210039.8174\n",
      "Epoch 345/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2294970738.4736 - val_loss: 3093757002.2283\n",
      "Epoch 346/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2291860438.4188 - val_loss: 3089685835.9817\n",
      "Epoch 347/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2291240078.0274 - val_loss: 3094781750.9406\n",
      "Epoch 348/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 2287721316.6967 - val_loss: 3081799916.1279\n",
      "Epoch 349/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 2283580007.4521 - val_loss: 3088860835.0685\n",
      "Epoch 350/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2282147660.6497 - val_loss: 3088858084.5297\n",
      "Epoch 351/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2281621639.2642 - val_loss: 3087722168.1096\n",
      "Epoch 352/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2278246960.2192 - val_loss: 3096342178.4840\n",
      "Epoch 353/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2274175597.7143 - val_loss: 3083120783.1963\n",
      "Epoch 354/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2272889692.6810 - val_loss: 3079427585.1689\n",
      "Epoch 355/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2269727524.5714 - val_loss: 3089335521.6073\n",
      "Epoch 356/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2266908422.2622 - val_loss: 3082051921.8265\n",
      "Epoch 357/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2264783030.8571 - val_loss: 3089867916.2740\n",
      "Epoch 358/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2263205761.0020 - val_loss: 3077755728.6575\n",
      "Epoch 359/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2260974901.8552 - val_loss: 3091115041.3151\n",
      "Epoch 360/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2258123380.7280 - val_loss: 3079499158.7945\n",
      "Epoch 361/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2255046530.2544 - val_loss: 3083161284.3836\n",
      "Epoch 362/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2252552391.3894 - val_loss: 3081391340.7123\n",
      "Epoch 363/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2250471777.8160 - val_loss: 3076267625.7900\n",
      "Epoch 364/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2247658413.8395 - val_loss: 3079531999.2694\n",
      "Epoch 365/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2245248254.6223 - val_loss: 3085333749.4795\n",
      "Epoch 366/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2243246271.6243 - val_loss: 3083690754.3379\n",
      "Epoch 367/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2241137867.8982 - val_loss: 3082142038.5023\n",
      "Epoch 368/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2238827456.1252 - val_loss: 3074261015.9635\n",
      "Epoch 369/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2237362507.8982 - val_loss: 3081277868.4201\n",
      "Epoch 370/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2234262197.1037 - val_loss: 3075556653.5890\n",
      "Epoch 371/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2232796845.8395 - val_loss: 3072171747.9452\n",
      "Epoch 372/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2229931671.4207 - val_loss: 3079063753.6438\n",
      "Epoch 373/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2230060903.9530 - val_loss: 3080879417.8630\n",
      "Epoch 374/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2225402860.4618 - val_loss: 3074393720.9863\n",
      "Epoch 375/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 2224186301.3699 - val_loss: 3078141889.4612\n",
      "Epoch 376/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2223378241.1272 - val_loss: 3069953446.5753\n",
      "Epoch 377/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2218952555.7104 - val_loss: 3074564890.8858\n",
      "Epoch 378/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2217513017.1115 - val_loss: 3079590279.0137\n",
      "Epoch 379/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 2215306788.5714 - val_loss: 3080400162.4840\n",
      "Epoch 380/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 2212956731.1155 - val_loss: 3067735013.1142\n",
      "Epoch 381/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2211907587.0059 - val_loss: 3077071442.9954\n",
      "Epoch 382/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2209569551.5303 - val_loss: 3072386502.1370\n",
      "Epoch 383/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2209384370.5988 - val_loss: 3077616192.8767\n",
      "Epoch 384/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2206636630.1683 - val_loss: 3068983021.2968\n",
      "Epoch 385/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2203482235.2407 - val_loss: 3067901749.1872\n",
      "Epoch 386/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2201440304.5949 - val_loss: 3074125620.6027\n",
      "Epoch 387/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2199143401.7065 - val_loss: 3075635566.4658\n",
      "Epoch 388/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 2198937715.2250 - val_loss: 3079519092.3105\n",
      "Epoch 389/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2195675826.0978 - val_loss: 3065637267.8721\n",
      "Epoch 390/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 39us/step - loss: 2193509633.0020 - val_loss: 3069301179.0320\n",
      "Epoch 391/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2191249525.2290 - val_loss: 3074754870.9406\n",
      "Epoch 392/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2189435295.8121 - val_loss: 3073798146.9224\n",
      "Epoch 393/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2187639503.6556 - val_loss: 3070592722.4110\n",
      "Epoch 394/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2186735715.1937 - val_loss: 3071460866.3379\n",
      "Epoch 395/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2184392252.1174 - val_loss: 3064112473.4247\n",
      "Epoch 396/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2185219916.6497 - val_loss: 3076497148.4932\n",
      "Epoch 397/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2182246914.5049 - val_loss: 3060551159.8174\n",
      "Epoch 398/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2178773645.7769 - val_loss: 3071354119.0137\n",
      "Epoch 399/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2176364366.1526 - val_loss: 3069141511.0137\n",
      "Epoch 400/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 2175620529.8474 - val_loss: 3063371181.0046\n",
      "Epoch 401/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2172884921.8630 - val_loss: 3074355980.8584\n",
      "Epoch 402/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2171286012.9941 - val_loss: 3073550331.3242\n",
      "Epoch 403/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 2170464748.4618 - val_loss: 3072678932.4566\n",
      "Epoch 404/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2169135978.2074 - val_loss: 3060776786.4110\n",
      "Epoch 405/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2167098051.5068 - val_loss: 3071614994.1187\n",
      "Epoch 406/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2165303998.3718 - val_loss: 3061981679.0502\n",
      "Epoch 407/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2164003644.1174 - val_loss: 3073881461.4795\n",
      "Epoch 408/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2162830319.8434 - val_loss: 3066294043.4703\n",
      "Epoch 409/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2159838578.7241 - val_loss: 3067487990.6484\n",
      "Epoch 410/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2158025138.9746 - val_loss: 3069377415.0137\n",
      "Epoch 411/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2156229510.7632 - val_loss: 3061546055.8904\n",
      "Epoch 412/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2155406713.9883 - val_loss: 3065489301.6256\n",
      "Epoch 413/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2152825396.6027 - val_loss: 3064017115.1781\n",
      "Epoch 414/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2151491404.3992 - val_loss: 3068868669.3699\n",
      "Epoch 415/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2151827044.1957 - val_loss: 3059266808.4018\n",
      "Epoch 416/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2148447639.7965 - val_loss: 3067091225.7169\n",
      "Epoch 417/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2146753262.4658 - val_loss: 3067369231.1963\n",
      "Epoch 418/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2145831966.3092 - val_loss: 3062064992.4384\n",
      "Epoch 419/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2145236142.8415 - val_loss: 3073069330.1187\n",
      "Epoch 420/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2141872317.6204 - val_loss: 3065920519.5982\n",
      "Epoch 421/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2140251856.4070 - val_loss: 3064459920.3653\n",
      "Epoch 422/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2139305344.7515 - val_loss: 3065265463.5251\n",
      "Epoch 423/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2137521184.9393 - val_loss: 3064187849.6438\n",
      "Epoch 424/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2137240215.0450 - val_loss: 3063560317.6621\n",
      "Epoch 425/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2135072381.4951 - val_loss: 3072580846.4658\n",
      "Epoch 426/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 2133470709.9804 - val_loss: 3067217149.0776\n",
      "Epoch 427/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2132430546.1605 - val_loss: 3063727889.5342\n",
      "Epoch 428/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2130381056.7515 - val_loss: 3059631046.7215\n",
      "Epoch 429/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2131948860.1174 - val_loss: 3053721379.6530\n",
      "Epoch 430/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2126455787.4599 - val_loss: 3070603088.6575\n",
      "Epoch 431/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2125970169.4873 - val_loss: 3068445492.6027\n",
      "Epoch 432/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2124514846.5597 - val_loss: 3066559720.0365\n",
      "Epoch 433/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2125148549.0098 - val_loss: 3061677380.3836\n",
      "Epoch 434/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2122659605.0411 - val_loss: 3072584670.1005\n",
      "Epoch 435/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2120280479.8121 - val_loss: 3064729432.8402\n",
      "Epoch 436/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2121102637.8395 - val_loss: 3064162325.0411\n",
      "Epoch 437/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2118309859.1937 - val_loss: 3065277590.2100\n",
      "Epoch 438/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2118552544.1879 - val_loss: 3072542294.5023\n",
      "Epoch 439/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2115706384.0313 - val_loss: 3056884858.1553\n",
      "Epoch 440/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2114392665.5499 - val_loss: 3063016035.3607\n",
      "Epoch 441/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2113303314.7867 - val_loss: 3057394499.7991\n",
      "Epoch 442/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2112653100.0861 - val_loss: 3068457139.4338\n",
      "Epoch 443/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2109860190.1840 - val_loss: 3062931668.7489\n",
      "Epoch 444/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2109583869.4951 - val_loss: 3063917461.6256\n",
      "Epoch 445/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2107416097.8160 - val_loss: 3064501825.4612\n",
      "Epoch 446/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2106405424.5949 - val_loss: 3062319040.8767\n",
      "Epoch 447/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2105249257.9569 - val_loss: 3067438895.9269\n",
      "Epoch 448/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 2105440540.8063 - val_loss: 3068893748.6027\n",
      "Epoch 449/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2102197767.0137 - val_loss: 3058915271.8904\n",
      "Epoch 450/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2101589519.0294 - val_loss: 3061551821.7352\n",
      "Epoch 451/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 2099746815.7495 - val_loss: 3061776445.3699\n",
      "Epoch 452/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2098752960.3757 - val_loss: 3063360696.1096\n",
      "Epoch 453/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2100458955.8982 - val_loss: 3064566562.4840\n",
      "Epoch 454/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2098630833.8474 - val_loss: 3054062413.7352\n",
      "Epoch 455/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 38us/step - loss: 2095722023.3268 - val_loss: 3063726731.1050\n",
      "Epoch 456/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2094676513.0646 - val_loss: 3064684565.6256\n",
      "Epoch 457/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2092827370.4579 - val_loss: 3061271128.8402\n",
      "Epoch 458/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2092694285.7769 - val_loss: 3059197338.8858\n",
      "Epoch 459/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2092771573.9804 - val_loss: 3074141897.6438\n",
      "Epoch 460/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2091413849.6751 - val_loss: 3054435239.7443\n",
      "Epoch 461/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2089079603.6008 - val_loss: 3060463406.7580\n",
      "Epoch 462/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2087586155.2094 - val_loss: 3058867264.2922\n",
      "Epoch 463/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2088463241.0176 - val_loss: 3073572095.4155\n",
      "Epoch 464/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2084889818.1761 - val_loss: 3060058916.8219\n",
      "Epoch 465/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2084806461.8708 - val_loss: 3065832095.5616\n",
      "Epoch 466/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2082235642.9902 - val_loss: 3056798205.6621\n",
      "Epoch 467/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2081899672.0470 - val_loss: 3063804050.1187\n",
      "Epoch 468/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2080008504.6106 - val_loss: 3058985012.6027\n",
      "Epoch 469/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2079920846.9041 - val_loss: 3061837106.8493\n",
      "Epoch 470/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2079656241.3464 - val_loss: 3055800862.3927\n",
      "Epoch 471/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2077540596.2270 - val_loss: 3071672865.8995\n",
      "Epoch 472/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2075948967.3268 - val_loss: 3069217275.9087\n",
      "Epoch 473/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2074995716.5088 - val_loss: 3055618655.8539\n",
      "Epoch 474/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2074295961.2994 - val_loss: 3067802480.8037\n",
      "Epoch 475/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2072294891.2094 - val_loss: 3065829024.7306\n",
      "Epoch 476/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2073784370.8493 - val_loss: 3061999355.9087\n",
      "Epoch 477/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 2070852248.2975 - val_loss: 3064665089.1689\n",
      "Epoch 478/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2070211821.9648 - val_loss: 3057824011.6895\n",
      "Epoch 479/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2068278071.1076 - val_loss: 3063629633.4612\n",
      "Epoch 480/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2067439207.4521 - val_loss: 3057717089.6073\n",
      "Epoch 481/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2066820683.3973 - val_loss: 3056644506.8858\n",
      "Epoch 482/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2066447021.8395 - val_loss: 3061221549.0046\n",
      "Epoch 483/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2064603830.3562 - val_loss: 3066728615.1598\n",
      "Epoch 484/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2063133296.9706 - val_loss: 3062843099.7626\n",
      "Epoch 485/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2062622618.0509 - val_loss: 3066446589.9543\n",
      "Epoch 486/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2060976558.3405 - val_loss: 3063367617.7534\n",
      "Epoch 487/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2060227377.3464 - val_loss: 3061314407.7443\n",
      "Epoch 488/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2060867110.0744 - val_loss: 3068197938.2648\n",
      "Epoch 489/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2058171327.8748 - val_loss: 3061762783.5616\n",
      "Epoch 490/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2057921410.2544 - val_loss: 3062574048.7306\n",
      "Epoch 491/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2056271716.1957 - val_loss: 3057276916.3105\n",
      "Epoch 492/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2055939401.1429 - val_loss: 3067445686.9406\n",
      "Epoch 493/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2054057165.1507 - val_loss: 3060217778.5571\n",
      "Epoch 494/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2053187975.7652 - val_loss: 3064076896.7306\n",
      "Epoch 495/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2052836952.1722 - val_loss: 3056838942.3927\n",
      "Epoch 496/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2051277103.0920 - val_loss: 3065336464.0731\n",
      "Epoch 497/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2051848728.7984 - val_loss: 3067260190.3927\n",
      "Epoch 498/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2049508950.1683 - val_loss: 3059045547.2511\n",
      "Epoch 499/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2048417034.0196 - val_loss: 3060403136.2922\n",
      "Epoch 500/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2047892148.8532 - val_loss: 3064073938.1187\n",
      "Epoch 501/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2046854126.2153 - val_loss: 3060120665.7169\n",
      "Epoch 502/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2046189499.8669 - val_loss: 3061447495.5982\n",
      "Epoch 503/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2046610358.7319 - val_loss: 3064931501.5890\n",
      "Epoch 504/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 2043788543.7495 - val_loss: 3061186754.0457\n",
      "Epoch 505/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 2043943305.5186 - val_loss: 3056730979.9452\n",
      "Epoch 506/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2042395781.5108 - val_loss: 3057855698.9954\n",
      "Epoch 507/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2041885996.9628 - val_loss: 3060449136.8037\n",
      "Epoch 508/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2040726192.9706 - val_loss: 3066579483.7626\n",
      "Epoch 509/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2039489603.8826 - val_loss: 3062203056.5114\n",
      "Epoch 510/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2038932175.1546 - val_loss: 3066815237.5525\n",
      "Epoch 511/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2037849451.9609 - val_loss: 3063911827.2877\n",
      "Epoch 512/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2036954020.8219 - val_loss: 3059808455.0137\n",
      "Epoch 513/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2036191665.7221 - val_loss: 3062662870.5023\n",
      "Epoch 514/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2036043912.2661 - val_loss: 3063997408.1461\n",
      "Epoch 515/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2036077023.9374 - val_loss: 3055454481.2420\n",
      "Epoch 516/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2034905163.3973 - val_loss: 3070597880.1096\n",
      "Epoch 517/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2034572092.1174 - val_loss: 3056852891.4703\n",
      "Epoch 518/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2031642396.0548 - val_loss: 3066051193.5708\n",
      "Epoch 519/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2031529095.2642 - val_loss: 3067837562.4475\n",
      "Epoch 520/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 36us/step - loss: 2030592850.1605 - val_loss: 3067002449.8265\n",
      "Epoch 521/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2031085850.0509 - val_loss: 3057703511.0868\n",
      "Epoch 522/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2029821622.8571 - val_loss: 3056221195.1050\n",
      "Epoch 523/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2029352016.5323 - val_loss: 3068295760.6575\n",
      "Epoch 524/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2028013259.6477 - val_loss: 3061404227.5068\n",
      "Epoch 525/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2026287505.0333 - val_loss: 3065554009.1324\n",
      "Epoch 526/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2026658975.8121 - val_loss: 3060219831.2329\n",
      "Epoch 527/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2026629257.7691 - val_loss: 3070869561.2785\n",
      "Epoch 528/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2023830496.6888 - val_loss: 3056686357.6256\n",
      "Epoch 529/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 2023151055.9061 - val_loss: 3057147083.1050\n",
      "Epoch 530/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2022452477.9961 - val_loss: 3066736853.3333\n",
      "Epoch 531/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2022720469.4168 - val_loss: 3061316901.9909\n",
      "Epoch 532/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2020473531.8669 - val_loss: 3060289636.2374\n",
      "Epoch 533/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2020191040.1252 - val_loss: 3066888277.6256\n",
      "Epoch 534/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2019083038.3092 - val_loss: 3065016630.9406\n",
      "Epoch 535/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2018078550.6693 - val_loss: 3065062075.0320\n",
      "Epoch 536/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2018452939.1468 - val_loss: 3061148892.6393\n",
      "Epoch 537/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2017511905.9413 - val_loss: 3060348937.3516\n",
      "Epoch 538/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2017305412.3836 - val_loss: 3069180336.5114\n",
      "Epoch 539/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2016398810.6771 - val_loss: 3059436101.5525\n",
      "Epoch 540/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2014937320.7045 - val_loss: 3060822785.4612\n",
      "Epoch 541/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2014454429.8082 - val_loss: 3069124982.0639\n",
      "Epoch 542/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2013481709.2133 - val_loss: 3062535164.4932\n",
      "Epoch 543/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2012462746.8023 - val_loss: 3064552861.8082\n",
      "Epoch 544/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2012610855.5773 - val_loss: 3062063948.2740\n",
      "Epoch 545/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2011374765.4638 - val_loss: 3061258053.5525\n",
      "Epoch 546/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2010297567.4364 - val_loss: 3062449926.7215\n",
      "Epoch 547/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2009146514.7867 - val_loss: 3067658868.6027\n",
      "Epoch 548/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2009161424.1566 - val_loss: 3061880514.3379\n",
      "Epoch 549/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2008902525.2446 - val_loss: 3063501202.9954\n",
      "Epoch 550/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2007232892.7436 - val_loss: 3060855999.1233\n",
      "Epoch 551/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2006513420.9002 - val_loss: 3061655106.9224\n",
      "Epoch 552/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2005439406.8415 - val_loss: 3065264753.3881\n",
      "Epoch 553/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2005116053.6673 - val_loss: 3066581699.2146\n",
      "Epoch 554/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2004869332.9159 - val_loss: 3067426974.3927\n",
      "Epoch 555/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 2004142061.9648 - val_loss: 3066374614.2100\n",
      "Epoch 556/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2003313227.6477 - val_loss: 3063859042.1918\n",
      "Epoch 557/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2003076079.9687 - val_loss: 3063903256.5479\n",
      "Epoch 558/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2001942712.3601 - val_loss: 3056650171.6164\n",
      "Epoch 559/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 2000767544.6106 - val_loss: 3062347419.1781\n",
      "Epoch 560/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 2001371602.4110 - val_loss: 3063923582.5388\n",
      "Epoch 561/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 2000627114.3327 - val_loss: 3058572182.5023\n",
      "Epoch 562/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1998804694.4188 - val_loss: 3070251341.7352\n",
      "Epoch 563/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1998984550.1996 - val_loss: 3061654741.9178\n",
      "Epoch 564/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1998490153.5812 - val_loss: 3071974852.9680\n",
      "Epoch 565/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1998915409.1585 - val_loss: 3061713416.1826\n",
      "Epoch 566/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1997117216.5636 - val_loss: 3065114386.7032\n",
      "Epoch 567/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1996704605.9335 - val_loss: 3075022115.9452\n",
      "Epoch 568/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1996384883.4755 - val_loss: 3064651365.9909\n",
      "Epoch 569/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1994792662.9198 - val_loss: 3069714914.4840\n",
      "Epoch 570/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1994384758.9824 - val_loss: 3059191994.4475\n",
      "Epoch 571/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1997638464.1252 - val_loss: 3075899335.0137\n",
      "Epoch 572/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1992810249.7691 - val_loss: 3063061963.6895\n",
      "Epoch 573/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1992324798.8728 - val_loss: 3057573057.4612\n",
      "Epoch 574/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1991868475.8669 - val_loss: 3055281012.8950\n",
      "Epoch 575/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1991339429.0724 - val_loss: 3069634375.5982\n",
      "Epoch 576/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1990784896.2505 - val_loss: 3062579234.4840\n",
      "Epoch 577/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1990446973.9961 - val_loss: 3064474421.7717\n",
      "Epoch 578/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1988653158.9511 - val_loss: 3059171060.6027\n",
      "Epoch 579/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1988408530.4110 - val_loss: 3068834243.2146\n",
      "Epoch 580/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1988260114.0352 - val_loss: 3062326033.2420\n",
      "Epoch 581/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1987095149.7143 - val_loss: 3062684827.1781\n",
      "Epoch 582/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1986735255.0450 - val_loss: 3067437102.7580\n",
      "Epoch 583/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1987232154.0509 - val_loss: 3066919352.6941\n",
      "Epoch 584/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1984356593.2211 - val_loss: 3060737002.0822\n",
      "Epoch 585/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 49us/step - loss: 1985181417.9569 - val_loss: 3062671500.2740\n",
      "Epoch 586/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1984270886.0744 - val_loss: 3060727903.5616\n",
      "Epoch 587/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1983589031.5773 - val_loss: 3063058089.7900\n",
      "Epoch 588/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1982432823.8591 - val_loss: 3061197916.0548\n",
      "Epoch 589/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1982304071.6399 - val_loss: 3065123130.4475\n",
      "Epoch 590/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1982440159.1859 - val_loss: 3062619982.3196\n",
      "Epoch 591/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1980729509.8239 - val_loss: 3065559639.0868\n",
      "Epoch 592/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1980316560.5323 - val_loss: 3063357630.2466\n",
      "Epoch 593/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1982163061.7299 - val_loss: 3070711628.8584\n",
      "Epoch 594/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1978614679.9217 - val_loss: 3064028044.8584\n",
      "Epoch 595/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1980199261.6830 - val_loss: 3055997385.6438\n",
      "Epoch 596/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1977463162.9902 - val_loss: 3065525265.2420\n",
      "Epoch 597/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1977760104.7045 - val_loss: 3062592171.2511\n",
      "Epoch 598/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1977175073.5656 - val_loss: 3062889507.6530\n",
      "Epoch 599/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1978399748.5088 - val_loss: 3063548555.6895\n",
      "Epoch 600/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1975126856.1409 - val_loss: 3070754092.7123\n",
      "Epoch 601/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1974978102.6067 - val_loss: 3069093547.5434\n",
      "Epoch 602/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1976127377.7847 - val_loss: 3062013634.6301\n",
      "Epoch 603/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1973903914.0822 - val_loss: 3072639291.6164\n",
      "Epoch 604/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1972857176.1722 - val_loss: 3067798570.0822\n",
      "Epoch 605/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1973704133.6360 - val_loss: 3064491261.3699\n",
      "Epoch 606/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1971982511.3425 - val_loss: 3070336109.8813\n",
      "Epoch 607/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1971495977.8317 - val_loss: 3074210162.5571\n",
      "Epoch 608/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1972084968.4540 - val_loss: 3058579219.5799\n",
      "Epoch 609/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1969449917.3699 - val_loss: 3066135579.1781\n",
      "Epoch 610/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1969386528.5636 - val_loss: 3072173020.3470\n",
      "Epoch 611/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1969337624.0470 - val_loss: 3068142036.4566\n",
      "Epoch 612/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1968655405.8395 - val_loss: 3066240227.0685\n",
      "Epoch 613/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1968277995.5851 - val_loss: 3073219082.5205\n",
      "Epoch 614/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1968477588.2896 - val_loss: 3061935848.3288\n",
      "Epoch 615/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1967017796.8845 - val_loss: 3063371015.8904\n",
      "Epoch 616/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1966820285.8708 - val_loss: 3061764594.2648\n",
      "Epoch 617/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1966366646.8571 - val_loss: 3064456553.4977\n",
      "Epoch 618/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1964593766.1996 - val_loss: 3072330863.0502\n",
      "Epoch 619/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1965082213.1977 - val_loss: 3070654204.2009\n",
      "Epoch 620/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1965761568.5636 - val_loss: 3066607262.9772\n",
      "Epoch 621/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1963378003.1624 - val_loss: 3075017277.9543\n",
      "Epoch 622/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1964757299.6008 - val_loss: 3060975188.4566\n",
      "Epoch 623/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1961812215.4834 - val_loss: 3070078371.6530\n",
      "Epoch 624/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1962350849.7534 - val_loss: 3067028469.1872\n",
      "Epoch 625/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1960797192.2661 - val_loss: 3072539203.2146\n",
      "Epoch 626/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1961571163.6791 - val_loss: 3068990628.5297\n",
      "Epoch 627/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1963089275.2407 - val_loss: 3067365507.5068\n",
      "Epoch 628/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1960513129.2055 - val_loss: 3062163498.9589\n",
      "Epoch 629/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1959878801.0333 - val_loss: 3072331842.0457\n",
      "Epoch 630/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1958685447.5147 - val_loss: 3069269803.2511\n",
      "Epoch 631/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1960778672.3444 - val_loss: 3070198340.6758\n",
      "Epoch 632/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1958592780.2740 - val_loss: 3057416540.6393\n",
      "Epoch 633/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1958456589.5264 - val_loss: 3070781720.5479\n",
      "Epoch 634/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1958027749.9491 - val_loss: 3069835785.9361\n",
      "Epoch 635/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1956392819.0998 - val_loss: 3066678450.8493\n",
      "Epoch 636/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1955720387.3816 - val_loss: 3061958930.7032\n",
      "Epoch 637/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1956984228.4462 - val_loss: 3074556950.5023\n",
      "Epoch 638/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1954638927.2798 - val_loss: 3069141591.0868\n",
      "Epoch 639/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1953891216.2818 - val_loss: 3062456694.9406\n",
      "Epoch 640/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1954149391.0294 - val_loss: 3069485557.4795\n",
      "Epoch 641/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1952737365.9178 - val_loss: 3069349614.1735\n",
      "Epoch 642/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1952228105.2681 - val_loss: 3063963733.3333\n",
      "Epoch 643/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1954289246.1840 - val_loss: 3068937914.4475\n",
      "Epoch 644/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1951680841.1429 - val_loss: 3071628821.9178\n",
      "Epoch 645/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1951533944.9863 - val_loss: 3064336549.1142\n",
      "Epoch 646/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1950420500.5401 - val_loss: 3071556960.7306\n",
      "Epoch 647/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1951191271.2016 - val_loss: 3074410455.0868\n",
      "Epoch 648/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1949466793.0802 - val_loss: 3067717857.3151\n",
      "Epoch 649/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1951342246.8258 - val_loss: 3071064206.3196\n",
      "Epoch 650/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 37us/step - loss: 1950151073.8160 - val_loss: 3067416592.0731\n",
      "Epoch 651/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1948198325.3542 - val_loss: 3068690578.7032\n",
      "Epoch 652/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1947495996.1174 - val_loss: 3068599406.1735\n",
      "Epoch 653/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1947250663.7025 - val_loss: 3072932899.3607\n",
      "Epoch 654/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1947016387.8826 - val_loss: 3066646025.3516\n",
      "Epoch 655/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1945504377.2368 - val_loss: 3073712369.0959\n",
      "Epoch 656/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1945155373.3386 - val_loss: 3067753720.6941\n",
      "Epoch 657/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1946589622.8571 - val_loss: 3077459911.5982\n",
      "Epoch 658/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1945884613.8865 - val_loss: 3064951813.2603\n",
      "Epoch 659/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1943155517.1194 - val_loss: 3072057580.4201\n",
      "Epoch 660/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1943003062.3562 - val_loss: 3073564617.6438\n",
      "Epoch 661/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1943032668.1800 - val_loss: 3071023236.3836\n",
      "Epoch 662/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1944361769.0802 - val_loss: 3067580546.6301\n",
      "Epoch 663/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1941757446.2622 - val_loss: 3071202891.3973\n",
      "Epoch 664/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1942474186.8963 - val_loss: 3074395336.1826\n",
      "Epoch 665/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1941112636.9941 - val_loss: 3072757182.2466\n",
      "Epoch 666/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1941157322.1448 - val_loss: 3075841649.0959\n",
      "Epoch 667/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1940768112.3444 - val_loss: 3073277832.1826\n",
      "Epoch 668/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1939415407.4677 - val_loss: 3070861876.0183\n",
      "Epoch 669/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1938923819.0841 - val_loss: 3070617495.9635\n",
      "Epoch 670/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1938471583.5616 - val_loss: 3070563444.8950\n",
      "Epoch 671/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1938010134.0431 - val_loss: 3069691501.8813\n",
      "Epoch 672/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1939757750.8571 - val_loss: 3071473778.2648\n",
      "Epoch 673/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1937105677.0254 - val_loss: 3070905725.6621\n",
      "Epoch 674/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1937021301.6047 - val_loss: 3076706593.0228\n",
      "Epoch 675/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1937246263.6086 - val_loss: 3070259989.3333\n",
      "Epoch 676/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1935690453.1663 - val_loss: 3071883664.6575\n",
      "Epoch 677/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1935682930.5988 - val_loss: 3074573688.4018\n",
      "Epoch 678/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1937059519.8748 - val_loss: 3066024012.8584\n",
      "Epoch 679/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1938942816.9393 - val_loss: 3085907603.8721\n",
      "Epoch 680/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1934094462.4971 - val_loss: 3071101236.8950\n",
      "Epoch 681/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1933847567.7808 - val_loss: 3075333171.4338\n",
      "Epoch 682/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1932995891.0998 - val_loss: 3075742462.5388\n",
      "Epoch 683/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1932758808.5479 - val_loss: 3071058063.4886\n",
      "Epoch 684/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1931797849.6751 - val_loss: 3072333105.0959\n",
      "Epoch 685/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1934123008.7515 - val_loss: 3078898993.9726\n",
      "Epoch 686/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1931098290.8493 - val_loss: 3074151857.0959\n",
      "Epoch 687/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1932715732.7906 - val_loss: 3063268806.7215\n",
      "Epoch 688/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1929898422.3562 - val_loss: 3076294457.5708\n",
      "Epoch 689/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1930048776.5166 - val_loss: 3076685787.7626\n",
      "Epoch 690/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1931501757.3699 - val_loss: 3068745010.2648\n",
      "Epoch 691/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1930361838.7162 - val_loss: 3078199801.8630\n",
      "Epoch 692/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1930816128.2505 - val_loss: 3066928298.9589\n",
      "Epoch 693/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1928998842.8650 - val_loss: 3083923472.3653\n",
      "Epoch 694/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1928096074.6458 - val_loss: 3073367706.0091\n",
      "Epoch 695/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1927396069.4481 - val_loss: 3076846324.8950\n",
      "Epoch 696/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1927182019.1311 - val_loss: 3069081872.6575\n",
      "Epoch 697/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1925814771.4755 - val_loss: 3075980476.4932\n",
      "Epoch 698/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1928117090.9432 - val_loss: 3084789925.6986\n",
      "Epoch 699/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1925445883.4912 - val_loss: 3069538366.8311\n",
      "Epoch 700/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1925599422.3718 - val_loss: 3069682411.2511\n",
      "Epoch 701/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1924372472.2348 - val_loss: 3079302682.8858\n",
      "Epoch 702/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1925030994.6614 - val_loss: 3068666941.3699\n",
      "Epoch 703/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1924300617.3933 - val_loss: 3069067112.0365\n",
      "Epoch 704/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1923421718.5440 - val_loss: 3083411893.7717\n",
      "Epoch 705/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1922690535.9530 - val_loss: 3080613319.8904\n",
      "Epoch 706/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1922496166.3249 - val_loss: 3072898501.5525\n",
      "Epoch 707/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1921987628.5871 - val_loss: 3072794620.7854\n",
      "Epoch 708/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1923223003.3033 - val_loss: 3081320445.9543\n",
      "Epoch 709/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1920656196.1331 - val_loss: 3074990038.7945\n",
      "Epoch 710/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1921269927.8278 - val_loss: 3074573145.1324\n",
      "Epoch 711/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1921545577.7065 - val_loss: 3081578310.4292\n",
      "Epoch 712/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1919543423.2485 - val_loss: 3077569332.0183\n",
      "Epoch 713/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1919917119.8748 - val_loss: 3078654506.3744\n",
      "Epoch 714/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1919057583.8434 - val_loss: 3074140586.6667\n",
      "Epoch 715/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 38us/step - loss: 1919868579.3190 - val_loss: 3072245027.0685\n",
      "Epoch 716/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1918073134.3405 - val_loss: 3077024229.9909\n",
      "Epoch 717/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1918327774.6849 - val_loss: 3073431166.2466\n",
      "Epoch 718/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1918968545.9413 - val_loss: 3086344048.8037\n",
      "Epoch 719/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1919066019.8200 - val_loss: 3070626211.9452\n",
      "Epoch 720/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1916208390.2622 - val_loss: 3078807587.6530\n",
      "Epoch 721/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1916633261.0881 - val_loss: 3087393134.7580\n",
      "Epoch 722/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1915961310.9354 - val_loss: 3075206603.9817\n",
      "Epoch 723/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1915074471.0763 - val_loss: 3078434641.8265\n",
      "Epoch 724/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1914967658.7084 - val_loss: 3083931772.7854\n",
      "Epoch 725/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1915061729.4403 - val_loss: 3078114240.2922\n",
      "Epoch 726/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1915021955.6321 - val_loss: 3071239265.8995\n",
      "Epoch 727/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1914654973.3699 - val_loss: 3082763767.5251\n",
      "Epoch 728/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1915335137.3151 - val_loss: 3080120069.5525\n",
      "Epoch 729/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1913200939.5851 - val_loss: 3079155294.3927\n",
      "Epoch 730/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1912347348.4149 - val_loss: 3077389944.4018\n",
      "Epoch 731/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1913371611.4286 - val_loss: 3075543389.2237\n",
      "Epoch 732/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1911828547.5068 - val_loss: 3081249881.4247\n",
      "Epoch 733/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1911901442.0039 - val_loss: 3076967823.7808\n",
      "Epoch 734/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1913429869.4638 - val_loss: 3091832997.6986\n",
      "Epoch 735/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1910269398.4188 - val_loss: 3078501081.1324\n",
      "Epoch 736/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1910893830.1370 - val_loss: 3073082401.0228\n",
      "Epoch 737/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1909384289.9413 - val_loss: 3081377831.7443\n",
      "Epoch 738/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1910532664.3601 - val_loss: 3086783962.8858\n",
      "Epoch 739/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1909191722.5832 - val_loss: 3076539440.5114\n",
      "Epoch 740/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1909965667.1937 - val_loss: 3088431416.1096\n",
      "Epoch 741/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1908610590.0587 - val_loss: 3077310879.2694\n",
      "Epoch 742/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1909425171.5382 - val_loss: 3080942466.0457\n",
      "Epoch 743/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1907432789.4168 - val_loss: 3082071558.1370\n",
      "Epoch 744/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1907623679.1233 - val_loss: 3087425861.5525\n",
      "Epoch 745/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1906422060.5871 - val_loss: 3081303474.8493\n",
      "Epoch 746/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1906493636.5088 - val_loss: 3082398581.7717\n",
      "Epoch 747/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1907415387.5538 - val_loss: 3075455134.9772\n",
      "Epoch 748/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1905444914.5988 - val_loss: 3082546806.3562\n",
      "Epoch 749/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1905251374.8415 - val_loss: 3082972409.8630\n",
      "Epoch 750/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1905824654.4031 - val_loss: 3089231271.1598\n",
      "Epoch 751/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1903789947.2407 - val_loss: 3078369878.7945\n",
      "Epoch 752/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1905441379.9452 - val_loss: 3074466823.3059\n",
      "Epoch 753/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1903258853.4481 - val_loss: 3083774334.8311\n",
      "Epoch 754/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1903887573.4168 - val_loss: 3080466898.9954\n",
      "Epoch 755/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1903844670.8728 - val_loss: 3088154821.5525\n",
      "Epoch 756/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1902890957.9022 - val_loss: 3086889678.0274\n",
      "Epoch 757/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1902551371.6477 - val_loss: 3078345209.2785\n",
      "Epoch 758/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1901589800.8297 - val_loss: 3082865491.2877\n",
      "Epoch 759/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1901523207.0137 - val_loss: 3085730109.6621\n",
      "Epoch 760/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1901840222.5597 - val_loss: 3088636527.0502\n",
      "Epoch 761/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1900165096.4540 - val_loss: 3080877590.2100\n",
      "Epoch 762/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1900563286.6693 - val_loss: 3084148997.8447\n",
      "Epoch 763/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1901167701.9178 - val_loss: 3081977428.4566\n",
      "Epoch 764/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1900456140.3992 - val_loss: 3081703507.8721\n",
      "Epoch 765/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1899492730.7397 - val_loss: 3086009477.2603\n",
      "Epoch 766/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1899945487.5303 - val_loss: 3091003514.4475\n",
      "Epoch 767/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1898789548.7123 - val_loss: 3081959293.9543\n",
      "Epoch 768/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1898678720.8767 - val_loss: 3083215138.4840\n",
      "Epoch 769/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1899789036.9628 - val_loss: 3081705396.3105\n",
      "Epoch 770/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1897182040.6732 - val_loss: 3084926388.8950\n",
      "Epoch 771/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1896692315.4286 - val_loss: 3085238419.8721\n",
      "Epoch 772/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1897083395.2564 - val_loss: 3086108164.3836\n",
      "Epoch 773/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1896444423.5147 - val_loss: 3088503800.9863\n",
      "Epoch 774/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1895405070.0274 - val_loss: 3084487265.3151\n",
      "Epoch 775/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1896988408.4853 - val_loss: 3089826605.5890\n",
      "Epoch 776/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1896443238.4501 - val_loss: 3082721011.1416\n",
      "Epoch 777/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1894944085.1663 - val_loss: 3082522865.9726\n",
      "Epoch 778/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1897829839.9061 - val_loss: 3088073450.9589\n",
      "Epoch 779/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1896342526.2466 - val_loss: 3079429897.0594\n",
      "Epoch 780/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 38us/step - loss: 1894988303.2798 - val_loss: 3085149816.9863\n",
      "Epoch 781/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1895072888.4853 - val_loss: 3091971819.2511\n",
      "Epoch 782/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1896754461.3072 - val_loss: 3080372732.2009\n",
      "Epoch 783/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1892851139.3816 - val_loss: 3089145152.5845\n",
      "Epoch 784/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1893678119.0763 - val_loss: 3083347047.7443\n",
      "Epoch 785/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1893097622.7945 - val_loss: 3093197236.0183\n",
      "Epoch 786/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1892257477.6360 - val_loss: 3090397312.2922\n",
      "Epoch 787/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1891109109.9804 - val_loss: 3080704733.2237\n",
      "Epoch 788/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1891524834.4423 - val_loss: 3087524024.1096\n",
      "Epoch 789/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1890966441.3307 - val_loss: 3088671228.2009\n",
      "Epoch 790/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1890198994.4110 - val_loss: 3082889597.0776\n",
      "Epoch 791/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1890741590.6693 - val_loss: 3086464642.3379\n",
      "Epoch 792/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1889720268.9002 - val_loss: 3090260697.1324\n",
      "Epoch 793/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1889680592.1566 - val_loss: 3089086215.3059\n",
      "Epoch 794/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1888680032.4384 - val_loss: 3092333340.3470\n",
      "Epoch 795/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1888731277.5264 - val_loss: 3090828023.8174\n",
      "Epoch 796/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1888585984.7515 - val_loss: 3086908029.3699\n",
      "Epoch 797/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1888367012.6967 - val_loss: 3088280133.2603\n",
      "Epoch 798/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1890531504.3444 - val_loss: 3095800528.9498\n",
      "Epoch 799/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1887727778.0665 - val_loss: 3086043626.0822\n",
      "Epoch 800/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1887637438.3718 - val_loss: 3083733435.0320\n",
      "Epoch 801/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1886713752.0470 - val_loss: 3089338656.4384\n",
      "Epoch 802/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1886715574.3562 - val_loss: 3089743378.4110\n",
      "Epoch 803/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1886500516.6967 - val_loss: 3096477451.3973\n",
      "Epoch 804/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1886938297.8630 - val_loss: 3092839981.0046\n",
      "Epoch 805/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1885597671.4521 - val_loss: 3094243553.6073\n",
      "Epoch 806/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1886522324.9159 - val_loss: 3100702072.1096\n",
      "Epoch 807/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1884412501.6673 - val_loss: 3088106708.4566\n",
      "Epoch 808/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1886034754.1292 - val_loss: 3091286579.4338\n",
      "Epoch 809/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1883747750.5753 - val_loss: 3090960106.0822\n",
      "Epoch 810/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1884128178.7241 - val_loss: 3090089566.6849\n",
      "Epoch 811/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1883968318.8728 - val_loss: 3097083176.0365\n",
      "Epoch 812/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1883529359.0294 - val_loss: 3092271233.1689\n",
      "Epoch 813/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1882754537.4560 - val_loss: 3089597080.5479\n",
      "Epoch 814/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1883217941.7926 - val_loss: 3095487351.2329\n",
      "Epoch 815/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1882311234.6301 - val_loss: 3094721213.9543\n",
      "Epoch 816/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1881650238.8728 - val_loss: 3088638320.2192\n",
      "Epoch 817/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1882452501.1663 - val_loss: 3085892468.8950\n",
      "Epoch 818/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1882123688.5793 - val_loss: 3097304056.9863\n",
      "Epoch 819/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1882027654.0117 - val_loss: 3087981472.1461\n",
      "Epoch 820/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1881372563.5382 - val_loss: 3099995605.3333\n",
      "Epoch 821/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1881054841.7378 - val_loss: 3087728586.8128\n",
      "Epoch 822/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1879998731.6477 - val_loss: 3094212610.0457\n",
      "Epoch 823/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1880020496.0313 - val_loss: 3094446889.7900\n",
      "Epoch 824/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1880606894.3405 - val_loss: 3089452650.3744\n",
      "Epoch 825/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1881630834.4736 - val_loss: 3105078201.8630\n",
      "Epoch 826/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1878978987.8356 - val_loss: 3088702383.6347\n",
      "Epoch 827/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1880300047.0294 - val_loss: 3085039646.3927\n",
      "Epoch 828/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1878708191.9374 - val_loss: 3101330116.6758\n",
      "Epoch 829/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1878351228.2427 - val_loss: 3095966544.3653\n",
      "Epoch 830/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1877783911.2016 - val_loss: 3097857319.4521\n",
      "Epoch 831/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1877267081.5186 - val_loss: 3093871715.0685\n",
      "Epoch 832/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1878208458.6458 - val_loss: 3105879539.4338\n",
      "Epoch 833/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1878084026.7397 - val_loss: 3099758893.5890\n",
      "Epoch 834/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1878374191.3425 - val_loss: 3096586934.6484\n",
      "Epoch 835/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1875777667.6321 - val_loss: 3102356427.1050\n",
      "Epoch 836/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1876056615.3268 - val_loss: 3104197138.4110\n",
      "Epoch 837/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1875286596.8845 - val_loss: 3097448486.2831\n",
      "Epoch 838/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1874739163.8043 - val_loss: 3096356211.4338\n",
      "Epoch 839/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1874924086.1057 - val_loss: 3095209237.3333\n",
      "Epoch 840/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1874516419.3816 - val_loss: 3096268788.8950\n",
      "Epoch 841/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1874681634.5675 - val_loss: 3098023729.3881\n",
      "Epoch 842/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1874616803.4442 - val_loss: 3102461304.9863\n",
      "Epoch 843/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1874509065.0176 - val_loss: 3099608263.5982\n",
      "Epoch 844/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1873038576.5949 - val_loss: 3097690823.8904\n",
      "Epoch 845/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 38us/step - loss: 1876054130.2231 - val_loss: 3094882578.4110\n",
      "Epoch 846/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1872399372.0235 - val_loss: 3104866088.0365\n",
      "Epoch 847/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1872756659.0998 - val_loss: 3098908783.6347\n",
      "Epoch 848/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1872165255.0137 - val_loss: 3096085629.9543\n",
      "Epoch 849/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1873560863.8121 - val_loss: 3094554755.2146\n",
      "Epoch 850/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1871075368.5793 - val_loss: 3107153613.7352\n",
      "Epoch 851/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1871359440.6575 - val_loss: 3108383498.2283\n",
      "Epoch 852/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1870245385.1429 - val_loss: 3098329800.7671\n",
      "Epoch 853/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1870197015.0450 - val_loss: 3097898276.5297\n",
      "Epoch 854/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1869971474.0352 - val_loss: 3099670741.6256\n",
      "Epoch 855/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1869938395.9295 - val_loss: 3095752837.8447\n",
      "Epoch 856/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1870917648.5323 - val_loss: 3105232125.6621\n",
      "Epoch 857/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1871634004.4149 - val_loss: 3105795232.7306\n",
      "Epoch 858/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1869725850.5519 - val_loss: 3099212848.8037\n",
      "Epoch 859/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1869614814.9354 - val_loss: 3097371912.7671\n",
      "Epoch 860/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1868386141.5577 - val_loss: 3098621639.8904\n",
      "Epoch 861/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1868587835.6164 - val_loss: 3103324138.9589\n",
      "Epoch 862/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1870100197.9491 - val_loss: 3097949792.7306\n",
      "Epoch 863/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1868731139.2564 - val_loss: 3095563961.5708\n",
      "Epoch 864/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1867637913.8004 - val_loss: 3096904870.5753\n",
      "Epoch 865/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1868165318.6380 - val_loss: 3108313403.0320\n",
      "Epoch 866/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1866698903.0450 - val_loss: 3100221658.3014\n",
      "Epoch 867/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1867215997.9961 - val_loss: 3109297060.2374\n",
      "Epoch 868/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1866820787.6008 - val_loss: 3104448809.7900\n",
      "Epoch 869/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1866530088.3288 - val_loss: 3100947103.8539\n",
      "Epoch 870/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1867092724.4775 - val_loss: 3101273325.5890\n",
      "Epoch 871/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1865929875.2877 - val_loss: 3094141801.2055\n",
      "Epoch 872/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1866083775.8748 - val_loss: 3112668343.5251\n",
      "Epoch 873/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1864803174.5753 - val_loss: 3101563166.6849\n",
      "Epoch 874/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1865089054.4344 - val_loss: 3104967580.3470\n",
      "Epoch 875/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1865985981.1194 - val_loss: 3104231736.1096\n",
      "Epoch 876/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1863908439.4207 - val_loss: 3106544597.3333\n",
      "Epoch 877/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1863647875.7573 - val_loss: 3108841602.6301\n",
      "Epoch 878/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1863516236.9002 - val_loss: 3107273581.2968\n",
      "Epoch 879/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1863771783.7652 - val_loss: 3106934418.1187\n",
      "Epoch 880/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1863914299.6164 - val_loss: 3095885447.3059\n",
      "Epoch 881/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1863146731.2094 - val_loss: 3105264376.6941\n",
      "Epoch 882/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1863256329.0176 - val_loss: 3107909059.7991\n",
      "Epoch 883/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1863164584.0783 - val_loss: 3111963893.4795\n",
      "Epoch 884/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1861609911.3581 - val_loss: 3109635674.5936\n",
      "Epoch 885/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1861020378.9276 - val_loss: 3103366319.3425\n",
      "Epoch 886/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1862470338.3796 - val_loss: 3099948267.8356\n",
      "Epoch 887/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1861086369.8160 - val_loss: 3116818555.9087\n",
      "Epoch 888/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1862016813.0881 - val_loss: 3104963972.0913\n",
      "Epoch 889/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1861658818.1292 - val_loss: 3110145130.3744\n",
      "Epoch 890/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1861061035.0841 - val_loss: 3107999841.0228\n",
      "Epoch 891/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1861215918.5910 - val_loss: 3093069758.8311\n",
      "Epoch 892/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1860135121.4090 - val_loss: 3107124294.4292\n",
      "Epoch 893/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1859529563.4286 - val_loss: 3108711355.6164\n",
      "Epoch 894/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1859341678.9667 - val_loss: 3110035979.3973\n",
      "Epoch 895/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1860422812.8063 - val_loss: 3111191553.4612\n",
      "Epoch 896/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1859671312.0313 - val_loss: 3101469559.2329\n",
      "Epoch 897/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1858888239.0920 - val_loss: 3110821854.1005\n",
      "Epoch 898/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1858623425.3777 - val_loss: 3110677123.2146\n",
      "Epoch 899/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1859151789.3386 - val_loss: 3120285609.2055\n",
      "Epoch 900/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1858817183.3112 - val_loss: 3102269769.0594\n",
      "Epoch 901/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1857207881.6438 - val_loss: 3106540999.3059\n",
      "Epoch 902/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1858724452.4462 - val_loss: 3120680970.5205\n",
      "Epoch 903/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1856841091.7573 - val_loss: 3108006467.5068\n",
      "Epoch 904/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1856834619.1155 - val_loss: 3106781376.8767\n",
      "Epoch 905/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1856971410.7867 - val_loss: 3115190353.8265\n",
      "Epoch 906/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1857035204.8845 - val_loss: 3104706243.2146\n",
      "Epoch 907/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1858181660.5558 - val_loss: 3116448604.0548\n",
      "Epoch 908/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1856988712.0783 - val_loss: 3107307843.5068\n",
      "Epoch 909/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1857474604.8376 - val_loss: 3115807300.9680\n",
      "Epoch 910/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 37us/step - loss: 1855699667.9139 - val_loss: 3113520424.9132\n",
      "Epoch 911/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1857268802.3796 - val_loss: 3121978122.8128\n",
      "Epoch 912/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1855511270.9511 - val_loss: 3115355950.7580\n",
      "Epoch 913/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1854340822.1683 - val_loss: 3115125052.4932\n",
      "Epoch 914/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1854189991.0763 - val_loss: 3110914638.3196\n",
      "Epoch 915/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1858037759.7495 - val_loss: 3097422808.5479\n",
      "Epoch 916/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1854216433.7221 - val_loss: 3107934787.7991\n",
      "Epoch 917/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1852665947.1781 - val_loss: 3117643027.5799\n",
      "Epoch 918/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1853588134.8258 - val_loss: 3114607553.7534\n",
      "Epoch 919/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1852903778.5675 - val_loss: 3117873452.4201\n",
      "Epoch 920/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1853515563.3346 - val_loss: 3117975371.6895\n",
      "Epoch 921/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1852591227.9922 - val_loss: 3119591684.3836\n",
      "Epoch 922/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1853159272.7045 - val_loss: 3113682538.6667\n",
      "Epoch 923/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1853897362.5362 - val_loss: 3118877777.5342\n",
      "Epoch 924/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1852681241.9256 - val_loss: 3109362205.2237\n",
      "Epoch 925/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1852058156.0861 - val_loss: 3114925245.0776\n",
      "Epoch 926/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1851702320.5949 - val_loss: 3117691241.7900\n",
      "Epoch 927/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1851395986.7867 - val_loss: 3119981051.3242\n",
      "Epoch 928/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1851386057.6438 - val_loss: 3119702738.9954\n",
      "Epoch 929/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1852059646.2466 - val_loss: 3116431584.7306\n",
      "Epoch 930/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1850370212.6967 - val_loss: 3114930522.3014\n",
      "Epoch 931/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1850031581.4325 - val_loss: 3114080488.9132\n",
      "Epoch 932/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1850549438.1213 - val_loss: 3121594002.7032\n",
      "Epoch 933/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1850162976.8141 - val_loss: 3112850528.4384\n",
      "Epoch 934/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1850614103.4207 - val_loss: 3108610030.1735\n",
      "Epoch 935/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1850273323.8356 - val_loss: 3121773900.5662\n",
      "Epoch 936/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1849953203.6008 - val_loss: 3121463592.3288\n",
      "Epoch 937/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1848949529.0489 - val_loss: 3114364004.5297\n",
      "Epoch 938/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1848395052.0861 - val_loss: 3115561326.4658\n",
      "Epoch 939/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1848477655.9217 - val_loss: 3118081770.3744\n",
      "Epoch 940/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1847998658.6301 - val_loss: 3123071292.7854\n",
      "Epoch 941/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1847569760.8141 - val_loss: 3117068634.0091\n",
      "Epoch 942/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1847893620.4775 - val_loss: 3119526351.7808\n",
      "Epoch 943/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1847422359.0450 - val_loss: 3122979247.0502\n",
      "Epoch 944/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1846844290.7554 - val_loss: 3117774386.2648\n",
      "Epoch 945/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1847438170.5519 - val_loss: 3124389510.7215\n",
      "Epoch 946/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1846148157.6204 - val_loss: 3117531896.1096\n",
      "Epoch 947/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1846503342.3405 - val_loss: 3120306141.8082\n",
      "Epoch 948/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1846463817.8943 - val_loss: 3122300915.1416\n",
      "Epoch 949/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1845896205.5264 - val_loss: 3117539270.1370\n",
      "Epoch 950/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1845869693.2446 - val_loss: 3113843235.9452\n",
      "Epoch 951/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1846106609.9726 - val_loss: 3123937264.5114\n",
      "Epoch 952/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1845584431.5930 - val_loss: 3120695603.4338\n",
      "Epoch 953/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1844854811.0528 - val_loss: 3119003346.1187\n",
      "Epoch 954/10000\n",
      "1022/1022 [==============================] - 0s 99us/step - loss: 1844958467.0059 - val_loss: 3120622897.3881\n",
      "Epoch 955/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1844634567.6399 - val_loss: 3125623744.5845\n",
      "Epoch 956/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1845139465.0176 - val_loss: 3117330439.3059\n",
      "Epoch 957/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1846438067.8513 - val_loss: 3129773982.9772\n",
      "Epoch 958/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1843683104.3131 - val_loss: 3124484718.7580\n",
      "Epoch 959/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1846877300.3523 - val_loss: 3111855851.2511\n",
      "Epoch 960/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1845733451.3973 - val_loss: 3123103062.7945\n",
      "Epoch 961/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1843782238.6849 - val_loss: 3119823060.1644\n",
      "Epoch 962/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1843123551.9374 - val_loss: 3121810550.3562\n",
      "Epoch 963/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1842634339.4442 - val_loss: 3129343187.8721\n",
      "Epoch 964/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1842917307.3659 - val_loss: 3128833067.5434\n",
      "Epoch 965/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1843755319.6086 - val_loss: 3121549248.8767\n",
      "Epoch 966/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1843122933.9804 - val_loss: 3123163902.8311\n",
      "Epoch 967/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1842206547.1624 - val_loss: 3127664807.4521\n",
      "Epoch 968/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1842173711.5303 - val_loss: 3127561191.4521\n",
      "Epoch 969/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1841394639.1546 - val_loss: 3128628365.1507\n",
      "Epoch 970/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1841789661.1820 - val_loss: 3126674679.8174\n",
      "Epoch 971/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1841866872.9863 - val_loss: 3120606003.1416\n",
      "Epoch 972/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1840786425.7378 - val_loss: 3123409558.2100\n",
      "Epoch 973/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1840687130.0509 - val_loss: 3124216685.8813\n",
      "Epoch 974/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1840689355.8982 - val_loss: 3126162083.3607\n",
      "Epoch 975/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 37us/step - loss: 1840100877.2759 - val_loss: 3129431593.4977\n",
      "Epoch 976/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1840081466.6145 - val_loss: 3127020000.7306\n",
      "Epoch 977/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1841314820.2583 - val_loss: 3135020818.7032\n",
      "Epoch 978/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1842898258.4110 - val_loss: 3129885558.9406\n",
      "Epoch 979/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1839359271.8278 - val_loss: 3121010176.0000\n",
      "Epoch 980/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1840664653.1507 - val_loss: 3130309298.8493\n",
      "Epoch 981/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1839909699.1311 - val_loss: 3119230431.2694\n",
      "Epoch 982/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1841144318.4971 - val_loss: 3134462221.4429\n",
      "Epoch 983/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1839555194.2387 - val_loss: 3121595892.3105\n",
      "Epoch 984/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1838497037.0254 - val_loss: 3127276915.1416\n",
      "Epoch 985/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1840235028.7906 - val_loss: 3120352090.8858\n",
      "Epoch 986/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1838073266.0978 - val_loss: 3137560800.4384\n",
      "Epoch 987/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1838602575.1546 - val_loss: 3128079951.4886\n",
      "Epoch 988/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1838349683.7260 - val_loss: 3136017327.3425\n",
      "Epoch 989/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1837572247.9217 - val_loss: 3130391247.4886\n",
      "Epoch 990/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1838420015.0920 - val_loss: 3122992245.4795\n",
      "Epoch 991/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1837106623.3738 - val_loss: 3129338946.3379\n",
      "Epoch 992/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1837021819.3659 - val_loss: 3134364974.4658\n",
      "Epoch 993/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1836726975.3738 - val_loss: 3130275706.4475\n",
      "Epoch 994/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1836316575.5616 - val_loss: 3129725900.8584\n",
      "Epoch 995/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1837383604.1018 - val_loss: 3134801147.3242\n",
      "Epoch 996/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1839509465.9256 - val_loss: 3144934685.5160\n",
      "Epoch 997/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1838316164.2583 - val_loss: 3121286474.8128\n",
      "Epoch 998/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1840082714.3014 - val_loss: 3138319942.1370\n",
      "Epoch 999/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1835089927.0137 - val_loss: 3125833015.8174\n",
      "Epoch 1000/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1835318768.7202 - val_loss: 3128462038.2100\n",
      "Epoch 1001/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1834962853.8239 - val_loss: 3128097148.7854\n",
      "Epoch 1002/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1834932160.1252 - val_loss: 3131730590.6849\n",
      "Epoch 1003/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1835011182.2153 - val_loss: 3130040107.8356\n",
      "Epoch 1004/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1836463332.1957 - val_loss: 3135529327.6347\n",
      "Epoch 1005/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1837330953.5186 - val_loss: 3122263365.2603\n",
      "Epoch 1006/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1834851685.6986 - val_loss: 3145373816.9863\n",
      "Epoch 1007/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1835656144.4070 - val_loss: 3127403240.3288\n",
      "Epoch 1008/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1835536623.8434 - val_loss: 3140399054.0274\n",
      "Epoch 1009/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1833244987.3659 - val_loss: 3133139383.2329\n",
      "Epoch 1010/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1833222050.9432 - val_loss: 3133283560.9132\n",
      "Epoch 1011/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1833210613.7299 - val_loss: 3130340823.6712\n",
      "Epoch 1012/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1833187444.2270 - val_loss: 3138371561.7900\n",
      "Epoch 1013/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1834798239.3112 - val_loss: 3122955251.1416\n",
      "Epoch 1014/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1832111869.2446 - val_loss: 3139448568.4018\n",
      "Epoch 1015/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1832414349.2759 - val_loss: 3132816153.1324\n",
      "Epoch 1016/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1835000640.1252 - val_loss: 3133079828.7489\n",
      "Epoch 1017/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1831748185.1742 - val_loss: 3138048987.7626\n",
      "Epoch 1018/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1832646270.2466 - val_loss: 3142612676.6758\n",
      "Epoch 1019/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1832410484.2270 - val_loss: 3134187152.9498\n",
      "Epoch 1020/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1831961087.6243 - val_loss: 3146301993.2055\n",
      "Epoch 1021/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1830848354.9432 - val_loss: 3139067583.4155\n",
      "Epoch 1022/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1831079888.6575 - val_loss: 3130308364.2740\n",
      "Epoch 1023/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1830776478.6849 - val_loss: 3133831418.7397\n",
      "Epoch 1024/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1831704443.3659 - val_loss: 3133700592.8037\n",
      "Epoch 1025/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1833540584.4540 - val_loss: 3146273853.0776\n",
      "Epoch 1026/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1835434781.8082 - val_loss: 3123826341.9909\n",
      "Epoch 1027/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1832248140.3992 - val_loss: 3145250826.5205\n",
      "Epoch 1028/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1831621127.5147 - val_loss: 3144421842.1187\n",
      "Epoch 1029/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1830855083.5851 - val_loss: 3133367180.5662\n",
      "Epoch 1030/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1831360760.9863 - val_loss: 3139742853.8447\n",
      "Epoch 1031/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1829710109.9335 - val_loss: 3143536257.4612\n",
      "Epoch 1032/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1829477832.8924 - val_loss: 3134657649.9726\n",
      "Epoch 1033/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1829493372.2427 - val_loss: 3134305134.4658\n",
      "Epoch 1034/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1829169552.0313 - val_loss: 3144128903.5982\n",
      "Epoch 1035/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1829137719.6086 - val_loss: 3134371197.9543\n",
      "Epoch 1036/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1828972174.2779 - val_loss: 3145376848.3653\n",
      "Epoch 1037/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1830896324.6341 - val_loss: 3149104405.9178\n",
      "Epoch 1038/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1828744778.1448 - val_loss: 3138658104.1096\n",
      "Epoch 1039/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1829837339.5538 - val_loss: 3139375485.9543\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1040/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1828541839.7808 - val_loss: 3143209818.8858\n",
      "Epoch 1041/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1828345591.9843 - val_loss: 3148396917.1872\n",
      "Epoch 1042/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1827988967.2016 - val_loss: 3139193493.6256\n",
      "Epoch 1043/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1827240281.1742 - val_loss: 3137214672.0731\n",
      "Epoch 1044/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1828289621.4168 - val_loss: 3139508206.1735\n",
      "Epoch 1045/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1828024204.5245 - val_loss: 3136227410.9954\n",
      "Epoch 1046/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1828478143.3738 - val_loss: 3134519430.4292\n",
      "Epoch 1047/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1826461403.4286 - val_loss: 3148095285.7717\n",
      "Epoch 1048/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1827263568.6575 - val_loss: 3147582881.3151\n",
      "Epoch 1049/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1826694095.1546 - val_loss: 3145686872.5479\n",
      "Epoch 1050/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1826711353.1115 - val_loss: 3137676074.9589\n",
      "Epoch 1051/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1825702954.8337 - val_loss: 3145473662.8311\n",
      "Epoch 1052/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1825857881.6751 - val_loss: 3142318294.2100\n",
      "Epoch 1053/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1826534300.8063 - val_loss: 3137587209.3516\n",
      "Epoch 1054/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1826565390.0274 - val_loss: 3154096652.2740\n",
      "Epoch 1055/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1826636914.2231 - val_loss: 3143834714.0091\n",
      "Epoch 1056/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1825252539.3659 - val_loss: 3142803521.4612\n",
      "Epoch 1057/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1825250831.5303 - val_loss: 3150479492.6758\n",
      "Epoch 1058/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1825706292.3523 - val_loss: 3147234496.8767\n",
      "Epoch 1059/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1825992037.1977 - val_loss: 3147768115.7260\n",
      "Epoch 1060/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1826306499.1311 - val_loss: 3146937336.4018\n",
      "Epoch 1061/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1826104684.4618 - val_loss: 3151191027.1416\n",
      "Epoch 1062/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1824249581.7143 - val_loss: 3144171410.4110\n",
      "Epoch 1063/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1826593432.7984 - val_loss: 3139548592.5114\n",
      "Epoch 1064/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1825863390.6849 - val_loss: 3156157010.7032\n",
      "Epoch 1065/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1828189862.0744 - val_loss: 3139466531.6530\n",
      "Epoch 1066/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1825167765.9178 - val_loss: 3156057744.3653\n",
      "Epoch 1067/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1826178675.2250 - val_loss: 3140327426.9224\n",
      "Epoch 1068/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1823723513.7378 - val_loss: 3155193170.1187\n",
      "Epoch 1069/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1824921372.5558 - val_loss: 3141008060.2009\n",
      "Epoch 1070/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1824484999.2642 - val_loss: 3157511702.2100\n",
      "Epoch 1071/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1822893133.9022 - val_loss: 3149628112.3653\n",
      "Epoch 1072/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1822833203.6008 - val_loss: 3140502037.3333\n",
      "Epoch 1073/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1823781636.7593 - val_loss: 3147591538.2648\n",
      "Epoch 1074/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1822943473.2211 - val_loss: 3143771261.6621\n",
      "Epoch 1075/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1822973766.6380 - val_loss: 3147749750.3562\n",
      "Epoch 1076/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1825295936.1252 - val_loss: 3160736885.7717\n",
      "Epoch 1077/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1824514220.8376 - val_loss: 3138583454.9772\n",
      "Epoch 1078/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1821863061.2916 - val_loss: 3144993644.4201\n",
      "Epoch 1079/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1822105615.9061 - val_loss: 3150937348.6758\n",
      "Epoch 1080/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1821506542.0900 - val_loss: 3149019149.1507\n",
      "Epoch 1081/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1821490142.6849 - val_loss: 3157589680.5114\n",
      "Epoch 1082/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1822101264.7828 - val_loss: 3148868483.7991\n",
      "Epoch 1083/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1820909636.8845 - val_loss: 3156050540.7123\n",
      "Epoch 1084/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1821457407.7495 - val_loss: 3156999733.4795\n",
      "Epoch 1085/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1820930263.5460 - val_loss: 3152646575.9269\n",
      "Epoch 1086/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1821551606.2309 - val_loss: 3144020736.0000\n",
      "Epoch 1087/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1821877905.7847 - val_loss: 3156208033.8995\n",
      "Epoch 1088/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1820661484.9628 - val_loss: 3150109725.2237\n",
      "Epoch 1089/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1820933175.1076 - val_loss: 3150906883.2146\n",
      "Epoch 1090/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1820457491.0372 - val_loss: 3144589217.6073\n",
      "Epoch 1091/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1823025746.9119 - val_loss: 3156853780.1644\n",
      "Epoch 1092/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1819875898.1135 - val_loss: 3149960508.4932\n",
      "Epoch 1093/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1819388599.1076 - val_loss: 3149094770.2648\n",
      "Epoch 1094/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1819495073.8160 - val_loss: 3150830953.2055\n",
      "Epoch 1095/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1819853063.2642 - val_loss: 3150624274.7032\n",
      "Epoch 1096/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1819204093.7456 - val_loss: 3155008087.9635\n",
      "Epoch 1097/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1819321155.1311 - val_loss: 3151505032.1826\n",
      "Epoch 1098/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1820666699.6477 - val_loss: 3146769802.8128\n",
      "Epoch 1099/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1818210435.7573 - val_loss: 3153077380.9680\n",
      "Epoch 1100/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1818550531.0059 - val_loss: 3157111466.6667\n",
      "Epoch 1101/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1818661491.7260 - val_loss: 3154930887.3059\n",
      "Epoch 1102/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1818357495.7339 - val_loss: 3151526710.3562\n",
      "Epoch 1103/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1818080153.5499 - val_loss: 3160698927.3425\n",
      "Epoch 1104/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 35us/step - loss: 1818521593.7378 - val_loss: 3165241496.2557\n",
      "Epoch 1105/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1818584427.7104 - val_loss: 3158299806.1005\n",
      "Epoch 1106/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1817631121.7847 - val_loss: 3158682244.9680\n",
      "Epoch 1107/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1817132015.4677 - val_loss: 3154912110.4658\n",
      "Epoch 1108/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1817443685.1977 - val_loss: 3149586852.8219\n",
      "Epoch 1109/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1817305447.7025 - val_loss: 3148608597.0411\n",
      "Epoch 1110/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1817602915.5695 - val_loss: 3155476931.5068\n",
      "Epoch 1111/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1817285600.4384 - val_loss: 3157826087.7443\n",
      "Epoch 1112/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1817088366.7162 - val_loss: 3152190551.6712\n",
      "Epoch 1113/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1817371861.6673 - val_loss: 3156177070.7580\n",
      "Epoch 1114/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1816744763.7417 - val_loss: 3153788720.5114\n",
      "Epoch 1115/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1816092154.7397 - val_loss: 3155424019.2877\n",
      "Epoch 1116/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1817812142.5910 - val_loss: 3157144116.6027\n",
      "Epoch 1117/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1816153417.3933 - val_loss: 3157367538.8493\n",
      "Epoch 1118/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1817202204.0548 - val_loss: 3147989731.6530\n",
      "Epoch 1119/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1817194969.1742 - val_loss: 3158812553.3516\n",
      "Epoch 1120/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1816360048.7202 - val_loss: 3162410055.0137\n",
      "Epoch 1121/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1816178455.0450 - val_loss: 3157788553.3516\n",
      "Epoch 1122/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1815721103.7808 - val_loss: 3154449727.7078\n",
      "Epoch 1123/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1815517967.7808 - val_loss: 3162149034.6667\n",
      "Epoch 1124/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1815404090.1135 - val_loss: 3164857620.1644\n",
      "Epoch 1125/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1814999410.9746 - val_loss: 3160384432.5114\n",
      "Epoch 1126/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1814721106.1605 - val_loss: 3156136397.7352\n",
      "Epoch 1127/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1814791635.7886 - val_loss: 3161513575.7443\n",
      "Epoch 1128/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1814803187.6008 - val_loss: 3160124202.3744\n",
      "Epoch 1129/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1816558257.3464 - val_loss: 3168541248.0000\n",
      "Epoch 1130/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1815108050.4110 - val_loss: 3158108317.8082\n",
      "Epoch 1131/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1815835503.5930 - val_loss: 3158042320.9498\n",
      "Epoch 1132/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1814120062.9980 - val_loss: 3160192068.3836\n",
      "Epoch 1133/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1814757509.2603 - val_loss: 3160331550.1005\n",
      "Epoch 1134/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1813901340.8063 - val_loss: 3161017214.2466\n",
      "Epoch 1135/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1813344639.4990 - val_loss: 3162871910.5753\n",
      "Epoch 1136/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1815611782.0117 - val_loss: 3160552976.6575\n",
      "Epoch 1137/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1813178254.7789 - val_loss: 3166747920.6575\n",
      "Epoch 1138/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1813509509.5108 - val_loss: 3163859582.8311\n",
      "Epoch 1139/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1814949766.0117 - val_loss: 3165801711.6347\n",
      "Epoch 1140/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1813593529.8630 - val_loss: 3160102142.5388\n",
      "Epoch 1141/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1813442369.2524 - val_loss: 3163295098.4475\n",
      "Epoch 1142/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1813094101.9178 - val_loss: 3161146828.8584\n",
      "Epoch 1143/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1813297191.5773 - val_loss: 3162144412.0548\n",
      "Epoch 1144/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1815709471.8121 - val_loss: 3163792036.5297\n",
      "Epoch 1145/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1813517390.5284 - val_loss: 3175180745.9361\n",
      "Epoch 1146/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1812210717.3072 - val_loss: 3169838103.9635\n",
      "Epoch 1147/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1812400660.0391 - val_loss: 3170552956.4932\n",
      "Epoch 1148/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1814642170.7397 - val_loss: 3162974802.7032\n",
      "Epoch 1149/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1813020850.5988 - val_loss: 3162765182.2466\n",
      "Epoch 1150/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1813021773.4012 - val_loss: 3160181760.8767\n",
      "Epoch 1151/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1812170454.9198 - val_loss: 3158481465.8630\n",
      "Epoch 1152/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1813091215.5303 - val_loss: 3171853140.7489\n",
      "Epoch 1153/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1811158006.2309 - val_loss: 3164891104.7306\n",
      "Epoch 1154/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1812426257.0333 - val_loss: 3156508058.3014\n",
      "Epoch 1155/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1810759649.1898 - val_loss: 3168146023.1598\n",
      "Epoch 1156/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1811717533.0568 - val_loss: 3167036913.6804\n",
      "Epoch 1157/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1811467199.6243 - val_loss: 3165459360.7306\n",
      "Epoch 1158/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1810857262.5910 - val_loss: 3167014325.4795\n",
      "Epoch 1159/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1811003515.9922 - val_loss: 3162509717.3333\n",
      "Epoch 1160/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1811957185.8787 - val_loss: 3171163181.2968\n",
      "Epoch 1161/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1810590717.2446 - val_loss: 3166410460.9315\n",
      "Epoch 1162/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1811127723.0841 - val_loss: 3161652212.0183\n",
      "Epoch 1163/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1810027891.2250 - val_loss: 3166273209.2785\n",
      "Epoch 1164/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1812282386.5362 - val_loss: 3172636716.4201\n",
      "Epoch 1165/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1811153792.0000 - val_loss: 3162742963.7260\n",
      "Epoch 1166/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1809630416.9080 - val_loss: 3171557980.9315\n",
      "Epoch 1167/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1811600813.8395 - val_loss: 3169981984.4384\n",
      "Epoch 1168/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 37us/step - loss: 1809825436.3053 - val_loss: 3165865406.8311\n",
      "Epoch 1169/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1810149972.9159 - val_loss: 3173386635.6895\n",
      "Epoch 1170/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1809836829.6830 - val_loss: 3165001204.3105\n",
      "Epoch 1171/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1809455173.6360 - val_loss: 3166270982.1370\n",
      "Epoch 1172/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1809213547.9609 - val_loss: 3178427273.9361\n",
      "Epoch 1173/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1810037515.2720 - val_loss: 3180308670.2466\n",
      "Epoch 1174/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1811607313.0333 - val_loss: 3157220935.5982\n",
      "Epoch 1175/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1808873249.3151 - val_loss: 3172730086.5753\n",
      "Epoch 1176/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1809660354.8806 - val_loss: 3162874714.8858\n",
      "Epoch 1177/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1808509896.3914 - val_loss: 3175133694.5388\n",
      "Epoch 1178/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1809561301.6673 - val_loss: 3175196177.8265\n",
      "Epoch 1179/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1808846551.9217 - val_loss: 3162894463.1233\n",
      "Epoch 1180/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1808113901.4638 - val_loss: 3171277417.4977\n",
      "Epoch 1181/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1810713578.7084 - val_loss: 3161575853.2968\n",
      "Epoch 1182/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1810551332.5714 - val_loss: 3186926313.2055\n",
      "Epoch 1183/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1808026905.0489 - val_loss: 3171559195.7626\n",
      "Epoch 1184/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1808145067.4599 - val_loss: 3173896674.7763\n",
      "Epoch 1185/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1807892133.5734 - val_loss: 3169149136.3653\n",
      "Epoch 1186/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1808065317.8239 - val_loss: 3167237845.0411\n",
      "Epoch 1187/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1808210358.3562 - val_loss: 3170402814.8311\n",
      "Epoch 1188/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1807532654.2153 - val_loss: 3168449286.7215\n",
      "Epoch 1189/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1806569997.2759 - val_loss: 3173916221.6621\n",
      "Epoch 1190/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1809061539.0685 - val_loss: 3185428825.4247\n",
      "Epoch 1191/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1806314589.4325 - val_loss: 3171020269.8813\n",
      "Epoch 1192/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1806831426.3796 - val_loss: 3175797418.0822\n",
      "Epoch 1193/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1806723656.3914 - val_loss: 3168825641.4977\n",
      "Epoch 1194/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1807475792.6575 - val_loss: 3178976267.9817\n",
      "Epoch 1195/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1807985346.3796 - val_loss: 3164205735.1598\n",
      "Epoch 1196/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1809008998.1996 - val_loss: 3181664376.6941\n",
      "Epoch 1197/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1806555371.9609 - val_loss: 3168154393.4247\n",
      "Epoch 1198/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1807284592.2192 - val_loss: 3175988864.0000\n",
      "Epoch 1199/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1807015138.4423 - val_loss: 3179547985.5342\n",
      "Epoch 1200/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1807561118.1840 - val_loss: 3176507960.1096\n",
      "Epoch 1201/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1806018994.3483 - val_loss: 3174303620.0913\n",
      "Epoch 1202/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1806849383.7025 - val_loss: 3181257817.7169\n",
      "Epoch 1203/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1805676529.9726 - val_loss: 3172125884.4932\n",
      "Epoch 1204/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1805057292.2740 - val_loss: 3177975722.3744\n",
      "Epoch 1205/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1806590611.2877 - val_loss: 3175648014.9041\n",
      "Epoch 1206/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1805303878.8885 - val_loss: 3179188449.0228\n",
      "Epoch 1207/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1805794560.1252 - val_loss: 3185033601.1689\n",
      "Epoch 1208/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1806939239.0763 - val_loss: 3172096295.7443\n",
      "Epoch 1209/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1804288992.1879 - val_loss: 3180020054.5023\n",
      "Epoch 1210/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1805623907.1937 - val_loss: 3181151089.6804\n",
      "Epoch 1211/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1805719491.8826 - val_loss: 3173481166.9041\n",
      "Epoch 1212/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1804342601.1429 - val_loss: 3182819039.8539\n",
      "Epoch 1213/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1804866461.5577 - val_loss: 3179814231.6712\n",
      "Epoch 1214/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1808087715.5695 - val_loss: 3194811664.3653\n",
      "Epoch 1215/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1805615594.9589 - val_loss: 3167842197.9178\n",
      "Epoch 1216/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1804999955.6634 - val_loss: 3181116112.0731\n",
      "Epoch 1217/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1804696569.9883 - val_loss: 3177902102.2100\n",
      "Epoch 1218/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1803733141.9178 - val_loss: 3179067476.1644\n",
      "Epoch 1219/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1803612381.4325 - val_loss: 3176869572.3836\n",
      "Epoch 1220/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1805151516.5558 - val_loss: 3180704020.7489\n",
      "Epoch 1221/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1803914696.6419 - val_loss: 3179015977.4977\n",
      "Epoch 1222/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1804443245.9648 - val_loss: 3177286500.8219\n",
      "Epoch 1223/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1803655547.7417 - val_loss: 3179710464.0000\n",
      "Epoch 1224/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1805218091.0841 - val_loss: 3169832095.8539\n",
      "Epoch 1225/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1802922192.9080 - val_loss: 3179719911.4521\n",
      "Epoch 1226/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1803615778.5675 - val_loss: 3181698185.3516\n",
      "Epoch 1227/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1804216720.9080 - val_loss: 3191521993.3516\n",
      "Epoch 1228/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1803318024.5166 - val_loss: 3173565865.2055\n",
      "Epoch 1229/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1802611467.1468 - val_loss: 3182113870.0274\n",
      "Epoch 1230/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1804117060.6341 - val_loss: 3184367469.0046\n",
      "Epoch 1231/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1803723830.8571 - val_loss: 3190048308.8950\n",
      "Epoch 1232/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 36us/step - loss: 1802473611.0215 - val_loss: 3182550331.0320\n",
      "Epoch 1233/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1802021769.2681 - val_loss: 3180450536.6210\n",
      "Epoch 1234/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1803160990.8102 - val_loss: 3171595115.5434\n",
      "Epoch 1235/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1803251442.5988 - val_loss: 3190505933.4429\n",
      "Epoch 1236/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1802906024.9550 - val_loss: 3180848409.7169\n",
      "Epoch 1237/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1801629336.2975 - val_loss: 3187465194.6667\n",
      "Epoch 1238/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1802126544.1566 - val_loss: 3190218553.5708\n",
      "Epoch 1239/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1801621382.0117 - val_loss: 3183870569.2055\n",
      "Epoch 1240/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1801824389.7613 - val_loss: 3181449094.7215\n",
      "Epoch 1241/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1801761868.0235 - val_loss: 3182479940.0913\n",
      "Epoch 1242/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1801911897.1742 - val_loss: 3179403918.6119\n",
      "Epoch 1243/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1801898766.0274 - val_loss: 3186566654.8311\n",
      "Epoch 1244/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1801400377.1115 - val_loss: 3181501674.9589\n",
      "Epoch 1245/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1802228933.7613 - val_loss: 3190292526.4658\n",
      "Epoch 1246/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1802407362.8806 - val_loss: 3191671224.1096\n",
      "Epoch 1247/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1801072261.5108 - val_loss: 3187466619.9087\n",
      "Epoch 1248/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1802244017.5969 - val_loss: 3180077031.4521\n",
      "Epoch 1249/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1801672408.9237 - val_loss: 3185980750.9041\n",
      "Epoch 1250/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1800646863.1546 - val_loss: 3190410494.5388\n",
      "Epoch 1251/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1801562311.6399 - val_loss: 3188043938.7763\n",
      "Epoch 1252/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1802670533.3855 - val_loss: 3179904488.6210\n",
      "Epoch 1253/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1800342619.9295 - val_loss: 3187308637.8082\n",
      "Epoch 1254/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1800296930.4423 - val_loss: 3193991419.9087\n",
      "Epoch 1255/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1801872211.4129 - val_loss: 3202983486.2466\n",
      "Epoch 1256/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1800385443.3190 - val_loss: 3194664809.2055\n",
      "Epoch 1257/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1801001762.5675 - val_loss: 3183893583.7808\n",
      "Epoch 1258/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1800402567.5147 - val_loss: 3184532086.3562\n",
      "Epoch 1259/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1800027842.2544 - val_loss: 3186816624.8037\n",
      "Epoch 1260/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1803281452.0861 - val_loss: 3201715065.8630\n",
      "Epoch 1261/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1803108708.9472 - val_loss: 3180375518.6849\n",
      "Epoch 1262/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1799265046.0431 - val_loss: 3192223727.3425\n",
      "Epoch 1263/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1801207124.6654 - val_loss: 3205669455.7808\n",
      "Epoch 1264/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1799947843.1311 - val_loss: 3188926937.4247\n",
      "Epoch 1265/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1800089396.3523 - val_loss: 3193562816.8767\n",
      "Epoch 1266/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1799488953.8630 - val_loss: 3189115228.3470\n",
      "Epoch 1267/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1803247521.8160 - val_loss: 3178753350.4292\n",
      "Epoch 1268/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1799173385.5186 - val_loss: 3191123366.5753\n",
      "Epoch 1269/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1798984166.4501 - val_loss: 3190812965.1142\n",
      "Epoch 1270/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1799147130.7397 - val_loss: 3198576839.8904\n",
      "Epoch 1271/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1798959695.1546 - val_loss: 3199137242.8858\n",
      "Epoch 1272/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1801161052.1800 - val_loss: 3188640784.3653\n",
      "Epoch 1273/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1801031218.9746 - val_loss: 3204854953.2055\n",
      "Epoch 1274/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1798096988.4305 - val_loss: 3192504505.2785\n",
      "Epoch 1275/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1799724238.4031 - val_loss: 3191810590.1005\n",
      "Epoch 1276/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1798173379.0059 - val_loss: 3196209550.6119\n",
      "Epoch 1277/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1798921443.9452 - val_loss: 3196454632.0365\n",
      "Epoch 1278/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1800798421.7926 - val_loss: 3183121859.2146\n",
      "Epoch 1279/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1797422515.8513 - val_loss: 3194934628.5297\n",
      "Epoch 1280/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1798053315.5068 - val_loss: 3202477166.1735\n",
      "Epoch 1281/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1798171407.2798 - val_loss: 3193022630.8676\n",
      "Epoch 1282/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1800430374.3249 - val_loss: 3203171650.3379\n",
      "Epoch 1283/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1797584115.7260 - val_loss: 3194325066.2283\n",
      "Epoch 1284/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1798542986.0196 - val_loss: 3184734786.9224\n",
      "Epoch 1285/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1797622852.1331 - val_loss: 3189081279.7078\n",
      "Epoch 1286/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1797589961.3933 - val_loss: 3199319737.5708\n",
      "Epoch 1287/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1798423245.4012 - val_loss: 3194554960.6575\n",
      "Epoch 1288/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1797468983.3581 - val_loss: 3201061790.3927\n",
      "Epoch 1289/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1797048996.8219 - val_loss: 3195083120.5114\n",
      "Epoch 1290/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1798225864.1409 - val_loss: 3191327260.3470\n",
      "Epoch 1291/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1798490804.3523 - val_loss: 3208784669.8082\n",
      "Epoch 1292/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1796514723.8200 - val_loss: 3197863049.6438\n",
      "Epoch 1293/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1797776927.0607 - val_loss: 3192540961.6073\n",
      "Epoch 1294/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1796986802.5988 - val_loss: 3193666733.0046\n",
      "Epoch 1295/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1797874498.1292 - val_loss: 3197349942.9406\n",
      "Epoch 1296/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 38us/step - loss: 1796034735.8434 - val_loss: 3199319781.6986\n",
      "Epoch 1297/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1796778490.9902 - val_loss: 3196141562.1553\n",
      "Epoch 1298/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1796167435.6477 - val_loss: 3197617652.6027\n",
      "Epoch 1299/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1796056050.4736 - val_loss: 3199419426.1918\n",
      "Epoch 1300/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1797062546.5362 - val_loss: 3200036430.0274\n",
      "Epoch 1301/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1796107355.4286 - val_loss: 3198049708.1279\n",
      "Epoch 1302/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1797691552.8141 - val_loss: 3193873519.3425\n",
      "Epoch 1303/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1796174326.9824 - val_loss: 3205500329.2055\n",
      "Epoch 1304/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1795877380.6341 - val_loss: 3203260263.7443\n",
      "Epoch 1305/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1795971387.1155 - val_loss: 3193633853.0776\n",
      "Epoch 1306/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1795503216.2192 - val_loss: 3198281794.0457\n",
      "Epoch 1307/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1795619316.4775 - val_loss: 3196243614.6849\n",
      "Epoch 1308/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1795426847.8121 - val_loss: 3200822354.7032\n",
      "Epoch 1309/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1795232871.4521 - val_loss: 3196960796.0548\n",
      "Epoch 1310/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1795340355.3816 - val_loss: 3197004037.8447\n",
      "Epoch 1311/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1795406284.6497 - val_loss: 3204786205.8082\n",
      "Epoch 1312/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1796131507.3503 - val_loss: 3194420449.3151\n",
      "Epoch 1313/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1794786379.1468 - val_loss: 3200321244.0548\n",
      "Epoch 1314/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1795673572.5714 - val_loss: 3203780835.9452\n",
      "Epoch 1315/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1794697965.4638 - val_loss: 3202290329.4247\n",
      "Epoch 1316/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1794901206.4188 - val_loss: 3199645220.5297\n",
      "Epoch 1317/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1795499492.4462 - val_loss: 3201914979.0685\n",
      "Epoch 1318/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1794657678.7789 - val_loss: 3206636844.7123\n",
      "Epoch 1319/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1794214256.2192 - val_loss: 3204807163.3242\n",
      "Epoch 1320/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1794799648.4384 - val_loss: 3195357783.9635\n",
      "Epoch 1321/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1793886209.0020 - val_loss: 3203575222.3562\n",
      "Epoch 1322/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1794455705.8004 - val_loss: 3208345479.5982\n",
      "Epoch 1323/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1795011474.5362 - val_loss: 3207372892.3470\n",
      "Epoch 1324/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1794590609.2838 - val_loss: 3193776512.8767\n",
      "Epoch 1325/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1795087344.9706 - val_loss: 3207587640.4018\n",
      "Epoch 1326/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1793819160.5479 - val_loss: 3201156728.6941\n",
      "Epoch 1327/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1795201122.4423 - val_loss: 3202506816.0000\n",
      "Epoch 1328/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1793653583.4051 - val_loss: 3197883086.0274\n",
      "Epoch 1329/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1794611215.2798 - val_loss: 3193782428.9315\n",
      "Epoch 1330/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1792994198.2935 - val_loss: 3211348503.9635\n",
      "Epoch 1331/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1794087872.8767 - val_loss: 3203978664.3288\n",
      "Epoch 1332/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1793491144.3914 - val_loss: 3206206275.2146\n",
      "Epoch 1333/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1793232158.0587 - val_loss: 3212435352.2557\n",
      "Epoch 1334/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1793243429.0724 - val_loss: 3202978595.9452\n",
      "Epoch 1335/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1792874999.9843 - val_loss: 3201478393.5708\n",
      "Epoch 1336/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1793196153.2368 - val_loss: 3209013394.7032\n",
      "Epoch 1337/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1793002168.3601 - val_loss: 3209884726.0639\n",
      "Epoch 1338/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1792710810.5519 - val_loss: 3204208624.5114\n",
      "Epoch 1339/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1793132551.0137 - val_loss: 3208546404.8219\n",
      "Epoch 1340/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1792955580.3679 - val_loss: 3202703621.2603\n",
      "Epoch 1341/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1792964873.5186 - val_loss: 3201575153.6804\n",
      "Epoch 1342/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1792485512.5166 - val_loss: 3212861307.3242\n",
      "Epoch 1343/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1792006905.7378 - val_loss: 3208568636.7854\n",
      "Epoch 1344/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1793738626.5049 - val_loss: 3212228962.7763\n",
      "Epoch 1345/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1791966162.4110 - val_loss: 3206125614.4658\n",
      "Epoch 1346/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1792609826.3170 - val_loss: 3208987165.2237\n",
      "Epoch 1347/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1792869752.7358 - val_loss: 3196922408.9132\n",
      "Epoch 1348/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1793584630.4814 - val_loss: 3215344408.8402\n",
      "Epoch 1349/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1791910659.2564 - val_loss: 3209987837.6621\n",
      "Epoch 1350/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1791717760.1252 - val_loss: 3209027370.3744\n",
      "Epoch 1351/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1791688569.7378 - val_loss: 3201109220.8219\n",
      "Epoch 1352/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1791768551.7025 - val_loss: 3209256753.3881\n",
      "Epoch 1353/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1792351791.8434 - val_loss: 3210669311.7078\n",
      "Epoch 1354/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1792499784.3914 - val_loss: 3203538446.0274\n",
      "Epoch 1355/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1791251782.3875 - val_loss: 3213726798.9041\n",
      "Epoch 1356/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1794213005.6517 - val_loss: 3222081145.8630\n",
      "Epoch 1357/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1790863300.2583 - val_loss: 3208445527.3790\n",
      "Epoch 1358/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1792406909.9961 - val_loss: 3203432805.1142\n",
      "Epoch 1359/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1791117554.7241 - val_loss: 3204568163.3607\n",
      "Epoch 1360/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 37us/step - loss: 1792621344.9393 - val_loss: 3217287538.5571\n",
      "Epoch 1361/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1790562992.8454 - val_loss: 3213433328.8037\n",
      "Epoch 1362/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1790848666.3014 - val_loss: 3207534676.7489\n",
      "Epoch 1363/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1791028452.4462 - val_loss: 3206264924.0548\n",
      "Epoch 1364/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1791312294.5753 - val_loss: 3212264544.4384\n",
      "Epoch 1365/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1791403055.8434 - val_loss: 3215667425.6073\n",
      "Epoch 1366/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1793096216.0470 - val_loss: 3210638824.6210\n",
      "Epoch 1367/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1790827198.3718 - val_loss: 3208084077.0046\n",
      "Epoch 1368/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1790623108.5088 - val_loss: 3214937351.0137\n",
      "Epoch 1369/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1790769552.2818 - val_loss: 3207590231.0868\n",
      "Epoch 1370/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1790643851.5225 - val_loss: 3207302647.2329\n",
      "Epoch 1371/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1790016792.7984 - val_loss: 3212974493.8082\n",
      "Epoch 1372/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1790944239.5930 - val_loss: 3218874973.2237\n",
      "Epoch 1373/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1789950781.8708 - val_loss: 3214100425.0594\n",
      "Epoch 1374/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1790398104.2975 - val_loss: 3214461357.2968\n",
      "Epoch 1375/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1791303739.4912 - val_loss: 3206501646.3196\n",
      "Epoch 1376/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1790200566.7319 - val_loss: 3218963949.5890\n",
      "Epoch 1377/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1789925371.4912 - val_loss: 3210565875.7260\n",
      "Epoch 1378/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1789254985.3933 - val_loss: 3215548035.5068\n",
      "Epoch 1379/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1789885589.2916 - val_loss: 3210269309.9543\n",
      "Epoch 1380/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1789969107.6634 - val_loss: 3218911541.4795\n",
      "Epoch 1381/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1789667987.0372 - val_loss: 3210565086.6849\n",
      "Epoch 1382/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1790116891.3033 - val_loss: 3213538665.7900\n",
      "Epoch 1383/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1789370882.5049 - val_loss: 3208757558.9406\n",
      "Epoch 1384/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1789240810.2074 - val_loss: 3213484871.5982\n",
      "Epoch 1385/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1788994240.3757 - val_loss: 3222144405.9178\n",
      "Epoch 1386/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1789180779.8356 - val_loss: 3220017162.2283\n",
      "Epoch 1387/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1788752094.6849 - val_loss: 3207311184.0731\n",
      "Epoch 1388/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1788320217.1742 - val_loss: 3217644119.9635\n",
      "Epoch 1389/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1788579664.4070 - val_loss: 3213984527.1963\n",
      "Epoch 1390/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1789016303.4677 - val_loss: 3219219036.9315\n",
      "Epoch 1391/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1788923550.5597 - val_loss: 3209821635.7991\n",
      "Epoch 1392/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1788716730.3640 - val_loss: 3217180418.9224\n",
      "Epoch 1393/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1789207105.6282 - val_loss: 3222770363.0320\n",
      "Epoch 1394/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1788698856.9550 - val_loss: 3222257641.4977\n",
      "Epoch 1395/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1788163984.2818 - val_loss: 3211342413.7352\n",
      "Epoch 1396/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1788825499.0528 - val_loss: 3224429113.5708\n",
      "Epoch 1397/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1789720849.0333 - val_loss: 3223182293.9178\n",
      "Epoch 1398/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1787318476.9002 - val_loss: 3209963717.5525\n",
      "Epoch 1399/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1789071242.2701 - val_loss: 3218489137.6804\n",
      "Epoch 1400/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1788586966.4188 - val_loss: 3220950252.7123\n",
      "Epoch 1401/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1787634029.0881 - val_loss: 3215997356.7123\n",
      "Epoch 1402/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1788014583.2329 - val_loss: 3215888831.4155\n",
      "Epoch 1403/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1788054698.8337 - val_loss: 3219339379.4338\n",
      "Epoch 1404/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1787114163.3503 - val_loss: 3219660416.8767\n",
      "Epoch 1405/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1787466996.9785 - val_loss: 3217227525.2603\n",
      "Epoch 1406/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1788513308.5558 - val_loss: 3215071220.6027\n",
      "Epoch 1407/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1786834715.8043 - val_loss: 3221444981.4795\n",
      "Epoch 1408/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1789544808.7045 - val_loss: 3225923212.8584\n",
      "Epoch 1409/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1787134785.6282 - val_loss: 3223326139.6164\n",
      "Epoch 1410/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1788131207.7652 - val_loss: 3218349092.5297\n",
      "Epoch 1411/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1786754667.7104 - val_loss: 3222579500.4201\n",
      "Epoch 1412/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1787381523.2877 - val_loss: 3221945298.4110\n",
      "Epoch 1413/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1786847640.2975 - val_loss: 3220657841.6804\n",
      "Epoch 1414/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1786135526.9511 - val_loss: 3223809666.6301\n",
      "Epoch 1415/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1786593411.5068 - val_loss: 3218832624.8037\n",
      "Epoch 1416/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1788799994.7397 - val_loss: 3232827959.5251\n",
      "Epoch 1417/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1788311000.6732 - val_loss: 3210536128.8767\n",
      "Epoch 1418/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1787071971.9452 - val_loss: 3214534149.5525\n",
      "Epoch 1419/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1785324068.5714 - val_loss: 3225145045.6256\n",
      "Epoch 1420/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1785467324.3679 - val_loss: 3228249556.7489\n",
      "Epoch 1421/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1786371560.5793 - val_loss: 3232756230.1370\n",
      "Epoch 1422/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1786530520.4227 - val_loss: 3232759502.0274\n",
      "Epoch 1423/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1785595843.6321 - val_loss: 3218043481.4247\n",
      "Epoch 1424/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 37us/step - loss: 1786106188.1487 - val_loss: 3217263200.4384\n",
      "Epoch 1425/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1785003467.8982 - val_loss: 3224390027.3973\n",
      "Epoch 1426/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1785634644.9159 - val_loss: 3224161315.6530\n",
      "Epoch 1427/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1785968768.1252 - val_loss: 3223051498.6667\n",
      "Epoch 1428/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1785934506.5832 - val_loss: 3233158562.1918\n",
      "Epoch 1429/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1785238466.8806 - val_loss: 3223298692.9680\n",
      "Epoch 1430/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1785933653.1663 - val_loss: 3217209546.8128\n",
      "Epoch 1431/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1785671579.8043 - val_loss: 3230719148.7123\n",
      "Epoch 1432/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1784774009.6125 - val_loss: 3224012536.9863\n",
      "Epoch 1433/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1784987247.4677 - val_loss: 3231543376.9498\n",
      "Epoch 1434/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1785142436.3209 - val_loss: 3222123017.0594\n",
      "Epoch 1435/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1784773269.7926 - val_loss: 3223259734.2100\n",
      "Epoch 1436/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1785187957.4795 - val_loss: 3235299788.8584\n",
      "Epoch 1437/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1784211313.9726 - val_loss: 3228992668.0548\n",
      "Epoch 1438/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1785523356.5558 - val_loss: 3216510608.3653\n",
      "Epoch 1439/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1789034507.7730 - val_loss: 3236261395.5799\n",
      "Epoch 1440/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1785287995.9922 - val_loss: 3220570039.2329\n",
      "Epoch 1441/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1785125987.6947 - val_loss: 3222816141.4429\n",
      "Epoch 1442/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1783740907.5225 - val_loss: 3226427267.2146\n",
      "Epoch 1443/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1784187684.0705 - val_loss: 3236848198.7215\n",
      "Epoch 1444/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1785015135.4364 - val_loss: 3235509311.1233\n",
      "Epoch 1445/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1785790778.4892 - val_loss: 3227110095.1963\n",
      "Epoch 1446/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1786554282.8337 - val_loss: 3226624259.5068\n",
      "Epoch 1447/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1785924763.0528 - val_loss: 3217591385.1324\n",
      "Epoch 1448/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1783349509.5108 - val_loss: 3223211752.6210\n",
      "Epoch 1449/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1783492656.5949 - val_loss: 3242675969.7534\n",
      "Epoch 1450/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1784959256.5479 - val_loss: 3228648854.2100\n",
      "Epoch 1451/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1783201171.2877 - val_loss: 3237404080.8037\n",
      "Epoch 1452/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1786510022.3875 - val_loss: 3217785692.3470\n",
      "Epoch 1453/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1784422358.9198 - val_loss: 3231761600.0000\n",
      "Epoch 1454/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1783384844.2740 - val_loss: 3230243387.0320\n",
      "Epoch 1455/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1782873641.8317 - val_loss: 3232404767.8539\n",
      "Epoch 1456/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1783425449.8317 - val_loss: 3233077955.2146\n",
      "Epoch 1457/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1784005270.5440 - val_loss: 3231155858.4110\n",
      "Epoch 1458/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1782609495.4207 - val_loss: 3230157454.0274\n",
      "Epoch 1459/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1784302936.1722 - val_loss: 3237344660.4566\n",
      "Epoch 1460/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1783202007.2955 - val_loss: 3222874550.3562\n",
      "Epoch 1461/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1782465047.6712 - val_loss: 3225670558.3927\n",
      "Epoch 1462/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1784179564.4618 - val_loss: 3224187877.4064\n",
      "Epoch 1463/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1782399586.4423 - val_loss: 3239966091.3973\n",
      "Epoch 1464/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1782519797.2290 - val_loss: 3229624938.0822\n",
      "Epoch 1465/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1782959552.3757 - val_loss: 3222506938.1553\n",
      "Epoch 1466/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1784541277.4325 - val_loss: 3236753830.5753\n",
      "Epoch 1467/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1783484653.7143 - val_loss: 3223836298.8128\n",
      "Epoch 1468/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1782174995.5382 - val_loss: 3234077315.5068\n",
      "Epoch 1469/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1781985415.0137 - val_loss: 3234468517.1142\n",
      "Epoch 1470/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1784422107.8669 - val_loss: 3248720284.3470\n",
      "Epoch 1471/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1783825372.9315 - val_loss: 3232615650.7763\n",
      "Epoch 1472/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1781699962.2387 - val_loss: 3236418839.3790\n",
      "Epoch 1473/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1781979350.9198 - val_loss: 3229495269.6986\n",
      "Epoch 1474/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1782141727.6869 - val_loss: 3235598123.5434\n",
      "Epoch 1475/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1781621278.5597 - val_loss: 3238493112.6941\n",
      "Epoch 1476/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1781544222.8102 - val_loss: 3224995275.3973\n",
      "Epoch 1477/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1781233696.5636 - val_loss: 3239461065.9361\n",
      "Epoch 1478/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1782851810.4423 - val_loss: 3236176197.2603\n",
      "Epoch 1479/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1782861518.1526 - val_loss: 3248067138.6301\n",
      "Epoch 1480/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1779749658.8023 - val_loss: 3235449186.1918\n",
      "Epoch 1481/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1780858660.3209 - val_loss: 3232527748.3836\n",
      "Epoch 1482/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1781937391.2172 - val_loss: 3228543274.0822\n",
      "Epoch 1483/10000\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 1782097681.0333 - val_loss: 3224238041.7169\n",
      "Epoch 1484/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1779690252.5245 - val_loss: 3242355482.8858\n",
      "Epoch 1485/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1780182571.8356 - val_loss: 3236063962.5936\n",
      "Epoch 1486/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1780707242.3327 - val_loss: 3230802861.2968\n",
      "Epoch 1487/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1781166668.6497 - val_loss: 3233795069.6621\n",
      "Epoch 1488/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 38us/step - loss: 1781056925.3072 - val_loss: 3238956837.9909\n",
      "Epoch 1489/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1780593569.5656 - val_loss: 3239323426.1918\n",
      "Epoch 1490/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1779504221.9335 - val_loss: 3236810379.1050\n",
      "Epoch 1491/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1782467039.4364 - val_loss: 3234641252.8219\n",
      "Epoch 1492/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1779538628.6341 - val_loss: 3242045057.4612\n",
      "Epoch 1493/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1779744934.8258 - val_loss: 3240203618.1918\n",
      "Epoch 1494/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1779807604.7280 - val_loss: 3233192538.0091\n",
      "Epoch 1495/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1779671921.2211 - val_loss: 3240036050.4110\n",
      "Epoch 1496/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1779676533.2290 - val_loss: 3236700634.5936\n",
      "Epoch 1497/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1779864343.0450 - val_loss: 3236551531.2511\n",
      "Epoch 1498/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1779934744.4227 - val_loss: 3235129605.2603\n",
      "Epoch 1499/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1779810559.2485 - val_loss: 3236474487.2329\n",
      "Epoch 1500/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1780059550.8102 - val_loss: 3234365845.0411\n",
      "Epoch 1501/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1779291154.0352 - val_loss: 3237220928.5845\n",
      "Epoch 1502/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1781304981.1663 - val_loss: 3255538200.2557\n",
      "Epoch 1503/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1779841459.8513 - val_loss: 3233302347.6895\n",
      "Epoch 1504/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1778699863.9217 - val_loss: 3241364936.7671\n",
      "Epoch 1505/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1779707338.8963 - val_loss: 3231808582.4292\n",
      "Epoch 1506/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1780309000.5166 - val_loss: 3250970830.9041\n",
      "Epoch 1507/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1780873072.5949 - val_loss: 3232893817.8630\n",
      "Epoch 1508/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1779392458.1448 - val_loss: 3243769854.8311\n",
      "Epoch 1509/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1778616786.6614 - val_loss: 3241253115.0320\n",
      "Epoch 1510/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1779345510.9511 - val_loss: 3245559539.7260\n",
      "Epoch 1511/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1778255149.0881 - val_loss: 3235121027.7991\n",
      "Epoch 1512/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1778552553.9569 - val_loss: 3243770997.7717\n",
      "Epoch 1513/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1777866470.4501 - val_loss: 3241663766.5023\n",
      "Epoch 1514/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1777955258.3640 - val_loss: 3232467682.1918\n",
      "Epoch 1515/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1778536646.6380 - val_loss: 3246541864.0365\n",
      "Epoch 1516/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1777453856.5636 - val_loss: 3240895798.0639\n",
      "Epoch 1517/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1778897345.1272 - val_loss: 3244338501.2603\n",
      "Epoch 1518/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1779914524.3053 - val_loss: 3233591402.0822\n",
      "Epoch 1519/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1777302556.8063 - val_loss: 3242036328.6210\n",
      "Epoch 1520/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1777219542.5440 - val_loss: 3244904259.5068\n",
      "Epoch 1521/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1777312194.3796 - val_loss: 3241109601.3151\n",
      "Epoch 1522/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1778636099.1311 - val_loss: 3231011352.5479\n",
      "Epoch 1523/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1776523321.6125 - val_loss: 3243905212.4932\n",
      "Epoch 1524/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1780718393.8630 - val_loss: 3249801975.5251\n",
      "Epoch 1525/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1777410411.5851 - val_loss: 3242421392.3653\n",
      "Epoch 1526/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1777307300.8219 - val_loss: 3236517124.3836\n",
      "Epoch 1527/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1779334002.7241 - val_loss: 3229476679.5982\n",
      "Epoch 1528/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1776888547.1937 - val_loss: 3242693876.3105\n",
      "Epoch 1529/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1777056288.5636 - val_loss: 3245001865.0594\n",
      "Epoch 1530/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1776676254.8102 - val_loss: 3243092838.2831\n",
      "Epoch 1531/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1778305689.8004 - val_loss: 3251017747.8721\n",
      "Epoch 1532/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1776459738.6771 - val_loss: 3242155811.0685\n",
      "Epoch 1533/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1776451214.2779 - val_loss: 3242852098.0457\n",
      "Epoch 1534/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1775819466.6458 - val_loss: 3245802194.1187\n",
      "Epoch 1535/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1775705933.1507 - val_loss: 3243559048.4749\n",
      "Epoch 1536/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1775779248.5949 - val_loss: 3243522403.9452\n",
      "Epoch 1537/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1776110202.7397 - val_loss: 3245349837.7352\n",
      "Epoch 1538/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1775795915.7104 - val_loss: 3247069847.6712\n",
      "Epoch 1539/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1777248130.5049 - val_loss: 3251501763.7991\n",
      "Epoch 1540/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1775873318.0744 - val_loss: 3239499523.5068\n",
      "Epoch 1541/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1777694779.3659 - val_loss: 3250071054.0274\n",
      "Epoch 1542/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1775892667.1155 - val_loss: 3245838384.5114\n",
      "Epoch 1543/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1776173097.8317 - val_loss: 3245302501.1142\n",
      "Epoch 1544/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1777994885.7613 - val_loss: 3239269418.3744\n",
      "Epoch 1545/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1775293792.1879 - val_loss: 3242840025.7169\n",
      "Epoch 1546/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1778050630.1370 - val_loss: 3239098546.2648\n",
      "Epoch 1547/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1776091265.2524 - val_loss: 3260335550.5388\n",
      "Epoch 1548/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1775596728.6106 - val_loss: 3249580816.3653\n",
      "Epoch 1549/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1776629832.1409 - val_loss: 3239119144.9132\n",
      "Epoch 1550/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1775332009.0802 - val_loss: 3252539058.8493\n",
      "Epoch 1551/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1775281763.6947 - val_loss: 3244545822.9772\n",
      "Epoch 1552/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 38us/step - loss: 1775902057.7065 - val_loss: 3252394015.8539\n",
      "Epoch 1553/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1774863333.5734 - val_loss: 3250996801.4612\n",
      "Epoch 1554/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1774426531.0685 - val_loss: 3248307588.9680\n",
      "Epoch 1555/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1774490609.9726 - val_loss: 3243754616.6941\n",
      "Epoch 1556/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1775206118.0744 - val_loss: 3250348123.4703\n",
      "Epoch 1557/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1774870750.4344 - val_loss: 3239703152.5114\n",
      "Epoch 1558/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1774745541.1350 - val_loss: 3248255734.9406\n",
      "Epoch 1559/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1777056878.2153 - val_loss: 3255150545.2420\n",
      "Epoch 1560/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1774204806.7632 - val_loss: 3260826454.7945\n",
      "Epoch 1561/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1773326995.7886 - val_loss: 3251978754.0457\n",
      "Epoch 1562/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1773248101.0724 - val_loss: 3245139006.2466\n",
      "Epoch 1563/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1773767151.9687 - val_loss: 3243090338.4840\n",
      "Epoch 1564/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1774527712.1879 - val_loss: 3260848917.0411\n",
      "Epoch 1565/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1774669753.1115 - val_loss: 3249740770.4840\n",
      "Epoch 1566/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1773934745.0489 - val_loss: 3244276270.1735\n",
      "Epoch 1567/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1773127563.2720 - val_loss: 3255899728.9498\n",
      "Epoch 1568/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1773237049.3620 - val_loss: 3259732179.5799\n",
      "Epoch 1569/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1773821988.5714 - val_loss: 3255651788.5662\n",
      "Epoch 1570/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1772877550.9667 - val_loss: 3249051922.7032\n",
      "Epoch 1571/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1772979990.2935 - val_loss: 3246671527.7443\n",
      "Epoch 1572/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1773812436.6654 - val_loss: 3260381163.2511\n",
      "Epoch 1573/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1771946686.3718 - val_loss: 3247597148.3470\n",
      "Epoch 1574/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1772713228.5245 - val_loss: 3242673798.7215\n",
      "Epoch 1575/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1771734215.6399 - val_loss: 3253200824.1096\n",
      "Epoch 1576/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1772188048.2818 - val_loss: 3250364577.3151\n",
      "Epoch 1577/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1772273620.6654 - val_loss: 3261800790.5023\n",
      "Epoch 1578/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1771546696.1409 - val_loss: 3252351255.6712\n",
      "Epoch 1579/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1771477391.4051 - val_loss: 3252418589.8082\n",
      "Epoch 1580/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1772716835.5695 - val_loss: 3247915976.7671\n",
      "Epoch 1581/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1774715304.8297 - val_loss: 3259537277.3699\n",
      "Epoch 1582/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1771149375.3738 - val_loss: 3254598322.8493\n",
      "Epoch 1583/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1773213027.6947 - val_loss: 3260527158.9406\n",
      "Epoch 1584/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1773049568.9393 - val_loss: 3258580895.5616\n",
      "Epoch 1585/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1771246605.5264 - val_loss: 3241468478.2466\n",
      "Epoch 1586/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1771213266.6614 - val_loss: 3251932847.0502\n",
      "Epoch 1587/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1771033686.6693 - val_loss: 3252541328.6575\n",
      "Epoch 1588/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1770834188.7750 - val_loss: 3252347335.5982\n",
      "Epoch 1589/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1771261771.7730 - val_loss: 3260591408.5114\n",
      "Epoch 1590/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1771594610.2231 - val_loss: 3252599316.1644\n",
      "Epoch 1591/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1772622631.5773 - val_loss: 3262330542.4658\n",
      "Epoch 1592/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1772054830.0900 - val_loss: 3256025501.5160\n",
      "Epoch 1593/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1769946643.0372 - val_loss: 3259048377.5708\n",
      "Epoch 1594/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1769963674.3014 - val_loss: 3259352875.2511\n",
      "Epoch 1595/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1769751258.6771 - val_loss: 3251728487.4521\n",
      "Epoch 1596/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1769749724.9315 - val_loss: 3255015912.6210\n",
      "Epoch 1597/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1769412483.5068 - val_loss: 3255893929.7900\n",
      "Epoch 1598/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1769553150.9980 - val_loss: 3252388303.7808\n",
      "Epoch 1599/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1770173880.3601 - val_loss: 3265613368.1096\n",
      "Epoch 1600/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1768817977.1115 - val_loss: 3252916482.0457\n",
      "Epoch 1601/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1769997530.6771 - val_loss: 3251704526.0274\n",
      "Epoch 1602/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1771121696.0626 - val_loss: 3257679403.2511\n",
      "Epoch 1603/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1768975450.9276 - val_loss: 3262940725.1872\n",
      "Epoch 1604/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1768397125.3855 - val_loss: 3257944893.6621\n",
      "Epoch 1605/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1768997749.9804 - val_loss: 3259229372.2009\n",
      "Epoch 1606/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1770352576.1252 - val_loss: 3255043978.2283\n",
      "Epoch 1607/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1768360540.8063 - val_loss: 3263417248.1461\n",
      "Epoch 1608/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1770100775.8278 - val_loss: 3253226111.1233\n",
      "Epoch 1609/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1769203653.2603 - val_loss: 3270331873.3151\n",
      "Epoch 1610/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1769877073.4090 - val_loss: 3259165410.4840\n",
      "Epoch 1611/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1767879880.6419 - val_loss: 3264751514.8858\n",
      "Epoch 1612/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1768710595.1311 - val_loss: 3254623731.7260\n",
      "Epoch 1613/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1767544453.7613 - val_loss: 3264814998.7945\n",
      "Epoch 1614/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1768277262.0274 - val_loss: 3258264503.2329\n",
      "Epoch 1615/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1767322470.7006 - val_loss: 3268874458.5936\n",
      "Epoch 1616/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 39us/step - loss: 1767898746.3640 - val_loss: 3257820754.7032\n",
      "Epoch 1617/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1766775919.2172 - val_loss: 3267177586.2648\n",
      "Epoch 1618/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1767176051.0998 - val_loss: 3263341351.1598\n",
      "Epoch 1619/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1766791101.3699 - val_loss: 3262306721.8995\n",
      "Epoch 1620/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1767127179.7730 - val_loss: 3254068634.3014\n",
      "Epoch 1621/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1767393028.5088 - val_loss: 3272961754.3014\n",
      "Epoch 1622/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1766459606.2935 - val_loss: 3269090128.3653\n",
      "Epoch 1623/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1766041739.7730 - val_loss: 3256299829.1872\n",
      "Epoch 1624/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1767633199.5930 - val_loss: 3264538706.1187\n",
      "Epoch 1625/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1769041151.2485 - val_loss: 3273969166.6119\n",
      "Epoch 1626/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1765959161.6125 - val_loss: 3258244193.8995\n",
      "Epoch 1627/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1767896342.2935 - val_loss: 3259781822.5388\n",
      "Epoch 1628/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1767055619.2564 - val_loss: 3266182394.4475\n",
      "Epoch 1629/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1767102314.7084 - val_loss: 3255891384.4018\n",
      "Epoch 1630/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1768961600.2505 - val_loss: 3275209311.5616\n",
      "Epoch 1631/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1765752099.5695 - val_loss: 3266661746.2648\n",
      "Epoch 1632/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1764562442.0196 - val_loss: 3259173487.3425\n",
      "Epoch 1633/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1766115447.2329 - val_loss: 3262897045.9178\n",
      "Epoch 1634/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1767012168.2661 - val_loss: 3261725656.8402\n",
      "Epoch 1635/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1766135440.2818 - val_loss: 3280621895.8904\n",
      "Epoch 1636/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1764341001.2681 - val_loss: 3269532822.7945\n",
      "Epoch 1637/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1765995348.6654 - val_loss: 3255144821.4795\n",
      "Epoch 1638/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1764037846.1683 - val_loss: 3265085071.4886\n",
      "Epoch 1639/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1763776465.6595 - val_loss: 3266468661.4795\n",
      "Epoch 1640/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1764130586.0509 - val_loss: 3271644227.7991\n",
      "Epoch 1641/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1763598981.5108 - val_loss: 3268162361.5708\n",
      "Epoch 1642/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1764386058.5205 - val_loss: 3263179370.6667\n",
      "Epoch 1643/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1764545815.5460 - val_loss: 3271009749.3333\n",
      "Epoch 1644/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1763085975.1703 - val_loss: 3267166542.9041\n",
      "Epoch 1645/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1765810641.6595 - val_loss: 3255463097.2785\n",
      "Epoch 1646/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1766755689.2055 - val_loss: 3279123345.2420\n",
      "Epoch 1647/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1762156837.5734 - val_loss: 3267250513.5342\n",
      "Epoch 1648/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1763925372.7436 - val_loss: 3274588375.6712\n",
      "Epoch 1649/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1763137332.8532 - val_loss: 3266917706.2283\n",
      "Epoch 1650/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1762663929.1115 - val_loss: 3271478017.7534\n",
      "Epoch 1651/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1763297608.8924 - val_loss: 3262444162.6301\n",
      "Epoch 1652/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1764134337.8787 - val_loss: 3258902721.1689\n",
      "Epoch 1653/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1762009319.4521 - val_loss: 3280651882.9589\n",
      "Epoch 1654/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1762573444.7593 - val_loss: 3265913111.6712\n",
      "Epoch 1655/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1766580051.6634 - val_loss: 3273661753.5708\n",
      "Epoch 1656/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1761809216.6262 - val_loss: 3259750222.3196\n",
      "Epoch 1657/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1760644708.1957 - val_loss: 3266362269.5160\n",
      "Epoch 1658/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1760961878.4188 - val_loss: 3272479133.5160\n",
      "Epoch 1659/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1761203235.0685 - val_loss: 3265920530.9954\n",
      "Epoch 1660/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1760709839.4051 - val_loss: 3275097772.4201\n",
      "Epoch 1661/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1761058944.2505 - val_loss: 3282579912.1826\n",
      "Epoch 1662/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1761174780.8689 - val_loss: 3273041047.0868\n",
      "Epoch 1663/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1759908121.8004 - val_loss: 3274895912.3288\n",
      "Epoch 1664/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1760681654.1057 - val_loss: 3265359210.3744\n",
      "Epoch 1665/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1759391565.4012 - val_loss: 3274690207.8539\n",
      "Epoch 1666/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1759933322.5205 - val_loss: 3269851265.4612\n",
      "Epoch 1667/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1760820453.6986 - val_loss: 3276538928.5114\n",
      "Epoch 1668/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1758741282.5675 - val_loss: 3273607222.0639\n",
      "Epoch 1669/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1759983334.0744 - val_loss: 3266701427.4338\n",
      "Epoch 1670/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1759313793.0020 - val_loss: 3275080687.3425\n",
      "Epoch 1671/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1758581899.0215 - val_loss: 3278446228.4566\n",
      "Epoch 1672/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1759223043.0059 - val_loss: 3275876202.3744\n",
      "Epoch 1673/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1760127882.5205 - val_loss: 3279768312.4018\n",
      "Epoch 1674/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1758419417.9256 - val_loss: 3267556624.6575\n",
      "Epoch 1675/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1757776375.9843 - val_loss: 3277222717.9543\n",
      "Epoch 1676/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1757338947.7573 - val_loss: 3275122911.8539\n",
      "Epoch 1677/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1757540198.4501 - val_loss: 3275598546.7032\n",
      "Epoch 1678/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1758298437.0098 - val_loss: 3273002867.7260\n",
      "Epoch 1679/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1756743187.0372 - val_loss: 3275364013.2968\n",
      "Epoch 1680/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 38us/step - loss: 1758699280.2818 - val_loss: 3274672286.3927\n",
      "Epoch 1681/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1756545690.4266 - val_loss: 3272696858.5936\n",
      "Epoch 1682/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1756120749.7143 - val_loss: 3277563910.4292\n",
      "Epoch 1683/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1756527897.0489 - val_loss: 3273849662.5388\n",
      "Epoch 1684/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1755950492.3053 - val_loss: 3275647359.7078\n",
      "Epoch 1685/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1756414766.5910 - val_loss: 3267577633.6073\n",
      "Epoch 1686/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1756150178.0665 - val_loss: 3283850331.7626\n",
      "Epoch 1687/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1755945725.4951 - val_loss: 3269378855.7443\n",
      "Epoch 1688/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1755085875.8513 - val_loss: 3274159737.8630\n",
      "Epoch 1689/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1755296309.6047 - val_loss: 3277670467.5068\n",
      "Epoch 1690/10000\n",
      "1022/1022 [==============================] - 0s 91us/step - loss: 1754865346.1292 - val_loss: 3279495867.6164\n",
      "Epoch 1691/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1754496961.2524 - val_loss: 3280248770.0457\n",
      "Epoch 1692/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1754476284.4932 - val_loss: 3278215636.1644\n",
      "Epoch 1693/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1754212137.8317 - val_loss: 3283256709.8447\n",
      "Epoch 1694/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1755463557.1350 - val_loss: 3274949293.0046\n",
      "Epoch 1695/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1755482771.5382 - val_loss: 3288691030.2100\n",
      "Epoch 1696/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1753908154.3640 - val_loss: 3272693062.1370\n",
      "Epoch 1697/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1753025096.8924 - val_loss: 3278332794.4475\n",
      "Epoch 1698/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1752878682.9276 - val_loss: 3281556773.6986\n",
      "Epoch 1699/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1752338395.1781 - val_loss: 3283022181.6986\n",
      "Epoch 1700/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1752401977.7378 - val_loss: 3279385732.0913\n",
      "Epoch 1701/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1753009010.9746 - val_loss: 3282671168.0000\n",
      "Epoch 1702/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1751348154.3640 - val_loss: 3282679589.1142\n",
      "Epoch 1703/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1751638639.9687 - val_loss: 3288846109.8082\n",
      "Epoch 1704/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1750746818.3796 - val_loss: 3280794475.5434\n",
      "Epoch 1705/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1751887838.9354 - val_loss: 3274281474.6301\n",
      "Epoch 1706/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1751865980.7436 - val_loss: 3289349693.9543\n",
      "Epoch 1707/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1750059828.9785 - val_loss: 3284690176.5845\n",
      "Epoch 1708/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1749490961.0333 - val_loss: 3282490670.7580\n",
      "Epoch 1709/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1749854996.9159 - val_loss: 3277666449.8265\n",
      "Epoch 1710/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1749223411.2250 - val_loss: 3280957404.9315\n",
      "Epoch 1711/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1749984336.6575 - val_loss: 3291384456.7671\n",
      "Epoch 1712/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1748680972.0235 - val_loss: 3287933453.4429\n",
      "Epoch 1713/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1749454758.3249 - val_loss: 3289997598.9772\n",
      "Epoch 1714/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1747852249.5499 - val_loss: 3283996804.9680\n",
      "Epoch 1715/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1748508687.0294 - val_loss: 3277016168.3288\n",
      "Epoch 1716/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1748825256.8297 - val_loss: 3288646200.1096\n",
      "Epoch 1717/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1747668260.8219 - val_loss: 3285660468.6027\n",
      "Epoch 1718/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1746809497.2994 - val_loss: 3276472138.8128\n",
      "Epoch 1719/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1748639826.6614 - val_loss: 3292047170.9224\n",
      "Epoch 1720/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1746546520.4227 - val_loss: 3280944790.2100\n",
      "Epoch 1721/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1746523709.8708 - val_loss: 3287925533.5160\n",
      "Epoch 1722/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1745130297.6125 - val_loss: 3285313464.1096\n",
      "Epoch 1723/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1745881834.7084 - val_loss: 3279070201.2785\n",
      "Epoch 1724/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1746224059.8669 - val_loss: 3293184495.6347\n",
      "Epoch 1725/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1744729950.6849 - val_loss: 3291291661.1507\n",
      "Epoch 1726/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1743804368.4070 - val_loss: 3283086800.3653\n",
      "Epoch 1727/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1743617793.2524 - val_loss: 3290261831.8904\n",
      "Epoch 1728/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1743646754.3170 - val_loss: 3282018024.9132\n",
      "Epoch 1729/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1743147834.1135 - val_loss: 3300209272.1096\n",
      "Epoch 1730/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1742539103.4364 - val_loss: 3289008042.6667\n",
      "Epoch 1731/10000\n",
      "1022/1022 [==============================] - 0s 65us/step - loss: 1741820393.7065 - val_loss: 3285959124.7489\n",
      "Epoch 1732/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1741837040.4697 - val_loss: 3290561298.7032\n",
      "Epoch 1733/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1742473740.7750 - val_loss: 3288822277.2603\n",
      "Epoch 1734/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1741169672.7671 - val_loss: 3290676274.2648\n",
      "Epoch 1735/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1742196611.0059 - val_loss: 3300923314.2648\n",
      "Epoch 1736/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1744190746.0509 - val_loss: 3278598337.7534\n",
      "Epoch 1737/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1739454922.8963 - val_loss: 3286240392.7671\n",
      "Epoch 1738/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1741235792.6575 - val_loss: 3300947375.3425\n",
      "Epoch 1739/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1739123285.6673 - val_loss: 3288433227.6895\n",
      "Epoch 1740/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1738331777.7534 - val_loss: 3289437336.5479\n",
      "Epoch 1741/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1738974693.4481 - val_loss: 3303368991.5616\n",
      "Epoch 1742/10000\n",
      "1022/1022 [==============================] - 0s 66us/step - loss: 1738213979.4286 - val_loss: 3300936258.9224\n",
      "Epoch 1743/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1738401872.1566 - val_loss: 3285928705.7534\n",
      "Epoch 1744/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 39us/step - loss: 1737576970.5205 - val_loss: 3287909037.2968\n",
      "Epoch 1745/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1736246434.8180 - val_loss: 3299251663.1963\n",
      "Epoch 1746/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1736851138.1292 - val_loss: 3287153576.0365\n",
      "Epoch 1747/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1735478942.5597 - val_loss: 3299615761.8265\n",
      "Epoch 1748/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1735516712.5793 - val_loss: 3304491987.5799\n",
      "Epoch 1749/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1735983178.6458 - val_loss: 3286071980.4201\n",
      "Epoch 1750/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1735944440.7358 - val_loss: 3302560681.2055\n",
      "Epoch 1751/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1733878980.5088 - val_loss: 3301158601.0594\n",
      "Epoch 1752/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1733847491.6321 - val_loss: 3291060244.1644\n",
      "Epoch 1753/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1733653372.1174 - val_loss: 3298760033.3151\n",
      "Epoch 1754/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1734272910.4031 - val_loss: 3300126654.5388\n",
      "Epoch 1755/10000\n",
      "1022/1022 [==============================] - 0s 73us/step - loss: 1731227774.6223 - val_loss: 3294708741.8447\n",
      "Epoch 1756/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1731121016.4853 - val_loss: 3294444013.5890\n",
      "Epoch 1757/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1732175137.0646 - val_loss: 3303119513.4247\n",
      "Epoch 1758/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1730704588.6497 - val_loss: 3292781419.8356\n",
      "Epoch 1759/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1729275700.8532 - val_loss: 3295823832.8402\n",
      "Epoch 1760/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1728821830.3875 - val_loss: 3302289239.0868\n",
      "Epoch 1761/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1728861476.8219 - val_loss: 3302330416.5114\n",
      "Epoch 1762/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1727949622.8571 - val_loss: 3302110134.0639\n",
      "Epoch 1763/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1728915693.2133 - val_loss: 3300956747.3973\n",
      "Epoch 1764/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1726504038.3249 - val_loss: 3306523648.8767\n",
      "Epoch 1765/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1727259299.8200 - val_loss: 3310693228.7123\n",
      "Epoch 1766/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1725641819.4286 - val_loss: 3299154322.7032\n",
      "Epoch 1767/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1727604323.6947 - val_loss: 3302709736.0365\n",
      "Epoch 1768/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1727909284.3209 - val_loss: 3299990015.4155\n",
      "Epoch 1769/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1726112109.9648 - val_loss: 3294832099.9452\n",
      "Epoch 1770/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1724403622.0744 - val_loss: 3309164057.4247\n",
      "Epoch 1771/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1723891963.9922 - val_loss: 3302906855.7443\n",
      "Epoch 1772/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1722479593.2055 - val_loss: 3299786798.4658\n",
      "Epoch 1773/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1722193492.6654 - val_loss: 3300347724.5662\n",
      "Epoch 1774/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1721358898.5988 - val_loss: 3299311850.6667\n",
      "Epoch 1775/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1721986831.5303 - val_loss: 3314927516.0548\n",
      "Epoch 1776/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1720734579.4755 - val_loss: 3301986541.0046\n",
      "Epoch 1777/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1720331085.1507 - val_loss: 3301770538.0822\n",
      "Epoch 1778/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1719330069.0411 - val_loss: 3307600429.8813\n",
      "Epoch 1779/10000\n",
      "1022/1022 [==============================] - 0s 90us/step - loss: 1718227473.2838 - val_loss: 3305752810.6667\n",
      "Epoch 1780/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1718193268.6027 - val_loss: 3309803728.3653\n",
      "Epoch 1781/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1719425005.9648 - val_loss: 3299728763.6164\n",
      "Epoch 1782/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1716318827.7104 - val_loss: 3314601031.0137\n",
      "Epoch 1783/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1716544552.9550 - val_loss: 3310455360.0000\n",
      "Epoch 1784/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1715214111.0607 - val_loss: 3308823697.2420\n",
      "Epoch 1785/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1714465695.8121 - val_loss: 3309721899.5434\n",
      "Epoch 1786/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1715581943.1076 - val_loss: 3311247194.8858\n",
      "Epoch 1787/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1714106875.2407 - val_loss: 3304325449.3516\n",
      "Epoch 1788/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1713315342.6536 - val_loss: 3302214531.5068\n",
      "Epoch 1789/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1711870003.8513 - val_loss: 3307453195.1050\n",
      "Epoch 1790/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1711785333.9804 - val_loss: 3312476135.7443\n",
      "Epoch 1791/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1712391559.6399 - val_loss: 3300260184.5479\n",
      "Epoch 1792/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1710027526.6380 - val_loss: 3315177032.4749\n",
      "Epoch 1793/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1709471139.0685 - val_loss: 3316626767.1963\n",
      "Epoch 1794/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1708978661.9491 - val_loss: 3313148664.4018\n",
      "Epoch 1795/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1708304368.9706 - val_loss: 3305588008.3288\n",
      "Epoch 1796/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1708013954.2544 - val_loss: 3314682222.7580\n",
      "Epoch 1797/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1707285120.2505 - val_loss: 3314555573.1872\n",
      "Epoch 1798/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1706870198.3562 - val_loss: 3313747415.3790\n",
      "Epoch 1799/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1705590224.4070 - val_loss: 3311435090.9954\n",
      "Epoch 1800/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1705369243.0528 - val_loss: 3321969556.4566\n",
      "Epoch 1801/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1706587720.8924 - val_loss: 3305499565.8813\n",
      "Epoch 1802/10000\n",
      "1022/1022 [==============================] - 0s 80us/step - loss: 1704232172.4618 - val_loss: 3325469550.1735\n",
      "Epoch 1803/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1702816121.7378 - val_loss: 3319830255.6347\n",
      "Epoch 1804/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1702970502.5127 - val_loss: 3315947348.7489\n",
      "Epoch 1805/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1701408394.0196 - val_loss: 3315413513.9361\n",
      "Epoch 1806/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1702302842.7397 - val_loss: 3321249647.9269\n",
      "Epoch 1807/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1701222039.7965 - val_loss: 3310946823.0137\n",
      "Epoch 1808/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 37us/step - loss: 1699460946.4110 - val_loss: 3322288362.0822\n",
      "Epoch 1809/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1699838846.2466 - val_loss: 3332393903.0502\n",
      "Epoch 1810/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1698941769.5186 - val_loss: 3311864500.0183\n",
      "Epoch 1811/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1698646533.5108 - val_loss: 3316783864.9863\n",
      "Epoch 1812/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1697241172.6654 - val_loss: 3319583022.4658\n",
      "Epoch 1813/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1696228099.2564 - val_loss: 3327810383.4886\n",
      "Epoch 1814/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1694939124.4775 - val_loss: 3324303130.3014\n",
      "Epoch 1815/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1694085899.7730 - val_loss: 3319562119.8904\n",
      "Epoch 1816/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1693661727.0607 - val_loss: 3321649290.8128\n",
      "Epoch 1817/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1693237020.6810 - val_loss: 3326314213.9909\n",
      "Epoch 1818/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1692658216.8297 - val_loss: 3324291676.0548\n",
      "Epoch 1819/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1692633925.6360 - val_loss: 3320661483.5434\n",
      "Epoch 1820/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1690839511.9217 - val_loss: 3330698690.0457\n",
      "Epoch 1821/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1690644267.0841 - val_loss: 3324848118.6484\n",
      "Epoch 1822/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1690084419.8826 - val_loss: 3338245950.2466\n",
      "Epoch 1823/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1691763013.6360 - val_loss: 3329454860.8584\n",
      "Epoch 1824/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1690045171.4755 - val_loss: 3328750089.3516\n",
      "Epoch 1825/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1688179163.9295 - val_loss: 3333646987.3973\n",
      "Epoch 1826/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1687719917.2133 - val_loss: 3333267711.4155\n",
      "Epoch 1827/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1687205765.8865 - val_loss: 3341041726.2466\n",
      "Epoch 1828/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1686303887.7808 - val_loss: 3331220477.6621\n",
      "Epoch 1829/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1686261026.0665 - val_loss: 3335177924.9680\n",
      "Epoch 1830/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1686279444.7906 - val_loss: 3332520313.5708\n",
      "Epoch 1831/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1687614722.0039 - val_loss: 3343709446.4292\n",
      "Epoch 1832/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1684244039.1389 - val_loss: 3332937799.5982\n",
      "Epoch 1833/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1683702842.3640 - val_loss: 3339823927.8174\n",
      "Epoch 1834/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1682763964.1174 - val_loss: 3336266200.2557\n",
      "Epoch 1835/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1682163583.4990 - val_loss: 3332606876.0548\n",
      "Epoch 1836/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1681061394.5362 - val_loss: 3348043290.0091\n",
      "Epoch 1837/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1681660975.0920 - val_loss: 3346515833.8630\n",
      "Epoch 1838/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1681167147.0841 - val_loss: 3335566271.4155\n",
      "Epoch 1839/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1680627574.2309 - val_loss: 3352784160.1461\n",
      "Epoch 1840/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1679585291.0215 - val_loss: 3339540012.1279\n",
      "Epoch 1841/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1678467980.2740 - val_loss: 3348847458.1918\n",
      "Epoch 1842/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1679920706.1292 - val_loss: 3338341707.9817\n",
      "Epoch 1843/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1676582181.0724 - val_loss: 3353326500.5297\n",
      "Epoch 1844/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1678010202.1761 - val_loss: 3349410211.6530\n",
      "Epoch 1845/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1679363680.9393 - val_loss: 3359496104.0365\n",
      "Epoch 1846/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1676869262.4031 - val_loss: 3358792173.0046\n",
      "Epoch 1847/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1675500563.0372 - val_loss: 3348757152.1461\n",
      "Epoch 1848/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1674979313.7221 - val_loss: 3358202803.4338\n",
      "Epoch 1849/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1674246389.7299 - val_loss: 3352161594.1553\n",
      "Epoch 1850/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1674270923.8982 - val_loss: 3353166512.8037\n",
      "Epoch 1851/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1676806215.2642 - val_loss: 3345165705.9361\n",
      "Epoch 1852/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1671877680.5949 - val_loss: 3357429797.6986\n",
      "Epoch 1853/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1672189074.9119 - val_loss: 3360013317.5525\n",
      "Epoch 1854/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1672729060.9472 - val_loss: 3358012525.2968\n",
      "Epoch 1855/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1671333620.8532 - val_loss: 3368331121.6804\n",
      "Epoch 1856/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1672070132.4775 - val_loss: 3352803973.5525\n",
      "Epoch 1857/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1669522007.4207 - val_loss: 3367505193.7900\n",
      "Epoch 1858/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1670528626.9746 - val_loss: 3363389460.1644\n",
      "Epoch 1859/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1668994772.4149 - val_loss: 3366097562.5936\n",
      "Epoch 1860/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1669720692.9785 - val_loss: 3365417426.4110\n",
      "Epoch 1861/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1668662589.6204 - val_loss: 3374658617.2785\n",
      "Epoch 1862/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1667753617.5342 - val_loss: 3370162989.5890\n",
      "Epoch 1863/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1667703759.1546 - val_loss: 3362858130.1187\n",
      "Epoch 1864/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1667433727.7495 - val_loss: 3363559317.6256\n",
      "Epoch 1865/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1666956217.3620 - val_loss: 3374948615.3059\n",
      "Epoch 1866/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1667042116.6341 - val_loss: 3367915332.3836\n",
      "Epoch 1867/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1666815810.1292 - val_loss: 3379852976.5114\n",
      "Epoch 1868/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1665988695.6712 - val_loss: 3372106393.7169\n",
      "Epoch 1869/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1666342323.3503 - val_loss: 3363583977.7900\n",
      "Epoch 1870/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1666353156.7593 - val_loss: 3386030461.9543\n",
      "Epoch 1871/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1664879823.4051 - val_loss: 3363532331.5434\n",
      "Epoch 1872/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 37us/step - loss: 1665854680.9237 - val_loss: 3365128935.7443\n",
      "Epoch 1873/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1665546045.6204 - val_loss: 3380583387.4703\n",
      "Epoch 1874/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1662878450.2231 - val_loss: 3378796546.0457\n",
      "Epoch 1875/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1662836412.3679 - val_loss: 3379688234.9589\n",
      "Epoch 1876/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1661944089.2994 - val_loss: 3375109618.2648\n",
      "Epoch 1877/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1661501256.6419 - val_loss: 3373856568.4018\n",
      "Epoch 1878/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1661891806.9354 - val_loss: 3383145272.6941\n",
      "Epoch 1879/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1662031687.3894 - val_loss: 3373646920.4749\n",
      "Epoch 1880/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1659946273.0646 - val_loss: 3380951767.0868\n",
      "Epoch 1881/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1659884986.1135 - val_loss: 3380349332.4566\n",
      "Epoch 1882/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1660228140.0861 - val_loss: 3382310772.6027\n",
      "Epoch 1883/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1659273544.8924 - val_loss: 3384676622.0274\n",
      "Epoch 1884/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1659728198.3875 - val_loss: 3394078085.2603\n",
      "Epoch 1885/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1658997674.9589 - val_loss: 3383123508.3105\n",
      "Epoch 1886/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1658250852.0705 - val_loss: 3388437592.8402\n",
      "Epoch 1887/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1658271314.1605 - val_loss: 3386391545.5708\n",
      "Epoch 1888/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1657547241.5812 - val_loss: 3390424318.8311\n",
      "Epoch 1889/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1658206313.4560 - val_loss: 3378804911.0502\n",
      "Epoch 1890/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1659169161.2681 - val_loss: 3402502284.5662\n",
      "Epoch 1891/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1656753916.7436 - val_loss: 3386914486.9406\n",
      "Epoch 1892/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1657310929.5342 - val_loss: 3388004158.8311\n",
      "Epoch 1893/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1655966099.0372 - val_loss: 3406032872.9132\n",
      "Epoch 1894/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1656374204.8689 - val_loss: 3400812354.0457\n",
      "Epoch 1895/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1656344294.1996 - val_loss: 3387267110.5753\n",
      "Epoch 1896/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1656564027.6164 - val_loss: 3386760518.4292\n",
      "Epoch 1897/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1654399848.9550 - val_loss: 3399339771.0320\n",
      "Epoch 1898/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1654266856.7045 - val_loss: 3406666651.7626\n",
      "Epoch 1899/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1654570464.1879 - val_loss: 3404583299.2146\n",
      "Epoch 1900/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1657675466.8963 - val_loss: 3406212138.9589\n",
      "Epoch 1901/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1654364921.2368 - val_loss: 3394261544.6210\n",
      "Epoch 1902/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1653162605.9648 - val_loss: 3401324282.1553\n",
      "Epoch 1903/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1653679205.1977 - val_loss: 3410620453.1142\n",
      "Epoch 1904/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1652678576.3444 - val_loss: 3396730003.8721\n",
      "Epoch 1905/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1652373809.5969 - val_loss: 3402013938.2648\n",
      "Epoch 1906/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1652442534.3249 - val_loss: 3405716114.4110\n",
      "Epoch 1907/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1652655816.3914 - val_loss: 3403123811.0685\n",
      "Epoch 1908/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1651667075.2564 - val_loss: 3405199023.3425\n",
      "Epoch 1909/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1651066026.8337 - val_loss: 3410874769.2420\n",
      "Epoch 1910/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1651874172.2427 - val_loss: 3410841897.7900\n",
      "Epoch 1911/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1650919650.4423 - val_loss: 3414556918.6484\n",
      "Epoch 1912/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1651491323.7417 - val_loss: 3412618953.3516\n",
      "Epoch 1913/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1652870354.9119 - val_loss: 3392039106.6301\n",
      "Epoch 1914/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1653362420.2270 - val_loss: 3413289537.4612\n",
      "Epoch 1915/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1650140230.6380 - val_loss: 3414092901.6986\n",
      "Epoch 1916/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1649185802.5205 - val_loss: 3411750404.6758\n",
      "Epoch 1917/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1650402887.8904 - val_loss: 3415579294.9772\n",
      "Epoch 1918/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1648809050.4266 - val_loss: 3416553004.7123\n",
      "Epoch 1919/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1649728470.6693 - val_loss: 3414152652.5662\n",
      "Epoch 1920/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1650359667.7260 - val_loss: 3407856208.3653\n",
      "Epoch 1921/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1647659588.7593 - val_loss: 3421993163.9817\n",
      "Epoch 1922/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1648630077.3699 - val_loss: 3417103442.1187\n",
      "Epoch 1923/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1649040387.2564 - val_loss: 3407512654.3196\n",
      "Epoch 1924/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1646566565.5734 - val_loss: 3416748984.6941\n",
      "Epoch 1925/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1646969042.9119 - val_loss: 3431112763.9087\n",
      "Epoch 1926/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1652680357.8239 - val_loss: 3406016654.3196\n",
      "Epoch 1927/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1646948857.9883 - val_loss: 3426566464.0000\n",
      "Epoch 1928/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1646380303.2798 - val_loss: 3427735414.9406\n",
      "Epoch 1929/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1647081369.2994 - val_loss: 3428358791.5982\n",
      "Epoch 1930/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1645148098.6301 - val_loss: 3415186040.9863\n",
      "Epoch 1931/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1645920365.2133 - val_loss: 3424722999.2329\n",
      "Epoch 1932/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1646912919.2955 - val_loss: 3425524426.8128\n",
      "Epoch 1933/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1644745036.3992 - val_loss: 3420823702.7945\n",
      "Epoch 1934/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1647538949.0098 - val_loss: 3421741959.3059\n",
      "Epoch 1935/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1644482107.6164 - val_loss: 3422934154.8128\n",
      "Epoch 1936/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 36us/step - loss: 1644601059.6947 - val_loss: 3432408309.1872\n",
      "Epoch 1937/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1643748494.2779 - val_loss: 3430199844.5297\n",
      "Epoch 1938/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1645608013.9022 - val_loss: 3424100017.6804\n",
      "Epoch 1939/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1643626320.9080 - val_loss: 3425549206.7945\n",
      "Epoch 1940/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1644085317.1350 - val_loss: 3429651083.3973\n",
      "Epoch 1941/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1642460140.2114 - val_loss: 3432314183.0137\n",
      "Epoch 1942/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1642620972.0861 - val_loss: 3426614624.4384\n",
      "Epoch 1943/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1642948554.7710 - val_loss: 3427438903.8174\n",
      "Epoch 1944/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1642160511.2485 - val_loss: 3430606749.2237\n",
      "Epoch 1945/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1642998777.2368 - val_loss: 3445386073.1324\n",
      "Epoch 1946/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1641531939.9452 - val_loss: 3437638654.8311\n",
      "Epoch 1947/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1640713774.5910 - val_loss: 3440274523.4703\n",
      "Epoch 1948/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1641222468.3836 - val_loss: 3445466286.4658\n",
      "Epoch 1949/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1639815976.3288 - val_loss: 3427996673.1689\n",
      "Epoch 1950/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1640686705.7221 - val_loss: 3436673035.9817\n",
      "Epoch 1951/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1640432262.0117 - val_loss: 3444503375.7808\n",
      "Epoch 1952/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1639721448.2035 - val_loss: 3441781392.3653\n",
      "Epoch 1953/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1639989628.9941 - val_loss: 3436865872.6575\n",
      "Epoch 1954/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1639670975.3738 - val_loss: 3436964548.6758\n",
      "Epoch 1955/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1639177697.6908 - val_loss: 3448658149.1142\n",
      "Epoch 1956/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1638640032.6888 - val_loss: 3445399383.0868\n",
      "Epoch 1957/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1637985697.0646 - val_loss: 3446307060.3105\n",
      "Epoch 1958/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1637998893.7143 - val_loss: 3441708711.1598\n",
      "Epoch 1959/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1638183476.8532 - val_loss: 3447522375.8904\n",
      "Epoch 1960/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1638787706.7397 - val_loss: 3437660366.9041\n",
      "Epoch 1961/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1637143580.0548 - val_loss: 3438165956.9680\n",
      "Epoch 1962/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1636805240.7358 - val_loss: 3446777252.5297\n",
      "Epoch 1963/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1636825656.6106 - val_loss: 3450042163.4338\n",
      "Epoch 1964/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1637183077.6986 - val_loss: 3453770799.0502\n",
      "Epoch 1965/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1636460756.6654 - val_loss: 3446929819.1781\n",
      "Epoch 1966/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1636379952.5949 - val_loss: 3449266128.9498\n",
      "Epoch 1967/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1636031139.5695 - val_loss: 3452277226.3744\n",
      "Epoch 1968/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1635865356.5245 - val_loss: 3447412515.9452\n",
      "Epoch 1969/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1635981291.7104 - val_loss: 3459962962.4110\n",
      "Epoch 1970/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1636982737.6595 - val_loss: 3447375924.6027\n",
      "Epoch 1971/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1635647895.5460 - val_loss: 3461768432.5114\n",
      "Epoch 1972/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1634231376.1566 - val_loss: 3461653609.7900\n",
      "Epoch 1973/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1634341072.4070 - val_loss: 3449516119.3790\n",
      "Epoch 1974/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1634344883.9765 - val_loss: 3458341394.7032\n",
      "Epoch 1975/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1633783876.0078 - val_loss: 3460188302.9041\n",
      "Epoch 1976/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1634116152.9863 - val_loss: 3455311996.2009\n",
      "Epoch 1977/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1635257752.7984 - val_loss: 3476102071.2329\n",
      "Epoch 1978/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1635513613.0254 - val_loss: 3444499856.9498\n",
      "Epoch 1979/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1633299679.9374 - val_loss: 3460547628.1279\n",
      "Epoch 1980/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1632087013.4481 - val_loss: 3462270305.8995\n",
      "Epoch 1981/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1631420794.4892 - val_loss: 3457149876.8950\n",
      "Epoch 1982/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1632424686.9667 - val_loss: 3454485007.1963\n",
      "Epoch 1983/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1633250509.2759 - val_loss: 3468042050.3379\n",
      "Epoch 1984/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1631609931.6477 - val_loss: 3455052808.1826\n",
      "Epoch 1985/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1631370812.7436 - val_loss: 3463276818.1187\n",
      "Epoch 1986/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1631502545.9100 - val_loss: 3469626159.0502\n",
      "Epoch 1987/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1630581861.8239 - val_loss: 3459277222.5753\n",
      "Epoch 1988/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1630998102.4188 - val_loss: 3462424371.4338\n",
      "Epoch 1989/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1629606702.8415 - val_loss: 3462368870.8676\n",
      "Epoch 1990/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1629575566.0274 - val_loss: 3470743840.1461\n",
      "Epoch 1991/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1629503546.6145 - val_loss: 3469141250.9224\n",
      "Epoch 1992/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1629836744.8924 - val_loss: 3457108744.1826\n",
      "Epoch 1993/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1628769940.2896 - val_loss: 3472775973.4064\n",
      "Epoch 1994/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1628297865.0176 - val_loss: 3474483164.6393\n",
      "Epoch 1995/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1627971523.1311 - val_loss: 3471807115.3973\n",
      "Epoch 1996/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1627982359.1076 - val_loss: 3470655434.8128\n",
      "Epoch 1997/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1629314965.2916 - val_loss: 3467836358.7215\n",
      "Epoch 1998/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1627513019.1155 - val_loss: 3468651441.9726\n",
      "Epoch 1999/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1626854577.3464 - val_loss: 3470850620.7854\n",
      "Epoch 2000/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 37us/step - loss: 1627543821.0254 - val_loss: 3470435469.1507\n",
      "Epoch 2001/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1627321699.6947 - val_loss: 3474742063.0502\n",
      "Epoch 2002/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1626810435.6321 - val_loss: 3468903414.0639\n",
      "Epoch 2003/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1626872754.5988 - val_loss: 3480798429.8082\n",
      "Epoch 2004/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1626624121.4873 - val_loss: 3478649479.3059\n",
      "Epoch 2005/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1625810837.6673 - val_loss: 3465525847.9635\n",
      "Epoch 2006/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1625926178.5675 - val_loss: 3465960221.8082\n",
      "Epoch 2007/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1626189791.6869 - val_loss: 3482133341.5160\n",
      "Epoch 2008/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1625617281.7534 - val_loss: 3468330386.9954\n",
      "Epoch 2009/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1624320991.9374 - val_loss: 3478904832.8767\n",
      "Epoch 2010/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1624532644.8219 - val_loss: 3473322484.3105\n",
      "Epoch 2011/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1624311662.7162 - val_loss: 3481625879.3790\n",
      "Epoch 2012/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1625362963.0372 - val_loss: 3497169422.0274\n",
      "Epoch 2013/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1625644563.0372 - val_loss: 3483409123.6530\n",
      "Epoch 2014/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1624727780.9472 - val_loss: 3477839766.2100\n",
      "Epoch 2015/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1623540827.1781 - val_loss: 3484666564.3836\n",
      "Epoch 2016/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1622587801.0489 - val_loss: 3480005629.9543\n",
      "Epoch 2017/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1623650886.2622 - val_loss: 3481451830.9406\n",
      "Epoch 2018/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1622358605.6517 - val_loss: 3489265291.6895\n",
      "Epoch 2019/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1622083713.0020 - val_loss: 3489045389.1507\n",
      "Epoch 2020/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1622117454.4031 - val_loss: 3476107423.2694\n",
      "Epoch 2021/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1621528374.3562 - val_loss: 3486386728.9132\n",
      "Epoch 2022/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1621812751.6556 - val_loss: 3482081571.6530\n",
      "Epoch 2023/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1621672211.2877 - val_loss: 3495475846.7215\n",
      "Epoch 2024/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1620792014.9041 - val_loss: 3485811047.7443\n",
      "Epoch 2025/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1620936819.2250 - val_loss: 3478160425.2055\n",
      "Epoch 2026/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1620083358.0587 - val_loss: 3488655986.8493\n",
      "Epoch 2027/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1620186356.9785 - val_loss: 3491548461.0046\n",
      "Epoch 2028/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1620054125.9648 - val_loss: 3484948284.2009\n",
      "Epoch 2029/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1619686207.1233 - val_loss: 3483559680.2922\n",
      "Epoch 2030/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1620559288.6106 - val_loss: 3497947857.8265\n",
      "Epoch 2031/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1622741707.1468 - val_loss: 3474096160.4384\n",
      "Epoch 2032/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1618812915.9765 - val_loss: 3485450472.9132\n",
      "Epoch 2033/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1619130600.9550 - val_loss: 3498797712.9498\n",
      "Epoch 2034/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1618971501.7143 - val_loss: 3489381663.8539\n",
      "Epoch 2035/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1619003185.9726 - val_loss: 3489823859.1416\n",
      "Epoch 2036/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1619275626.4579 - val_loss: 3503130836.7489\n",
      "Epoch 2037/10000\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 1617478038.1683 - val_loss: 3490111014.5753\n",
      "Epoch 2038/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1618568335.2798 - val_loss: 3502466056.1826\n",
      "Epoch 2039/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1616978434.5049 - val_loss: 3489324917.1872\n",
      "Epoch 2040/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1616618634.1448 - val_loss: 3495008262.1370\n",
      "Epoch 2041/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1616539918.1526 - val_loss: 3491576843.3973\n",
      "Epoch 2042/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1615691823.8434 - val_loss: 3496184726.2100\n",
      "Epoch 2043/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1615632931.0685 - val_loss: 3495794582.5023\n",
      "Epoch 2044/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1615933308.7436 - val_loss: 3491021432.6941\n",
      "Epoch 2045/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1617360148.0391 - val_loss: 3512282517.9178\n",
      "Epoch 2046/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1616230935.5460 - val_loss: 3500392504.4018\n",
      "Epoch 2047/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1614253652.6654 - val_loss: 3494882998.6484\n",
      "Epoch 2048/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1614754993.4716 - val_loss: 3496361355.9817\n",
      "Epoch 2049/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1618127532.8376 - val_loss: 3519714984.9132\n",
      "Epoch 2050/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1614442783.4364 - val_loss: 3498102755.3607\n",
      "Epoch 2051/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1615666439.0137 - val_loss: 3506500552.7671\n",
      "Epoch 2052/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1613558669.7769 - val_loss: 3504573401.1324\n",
      "Epoch 2053/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1613383353.8630 - val_loss: 3491143602.8493\n",
      "Epoch 2054/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1615555402.6458 - val_loss: 3491511442.7032\n",
      "Epoch 2055/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1612795209.8943 - val_loss: 3506929637.1142\n",
      "Epoch 2056/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1613385356.7750 - val_loss: 3494574824.6210\n",
      "Epoch 2057/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1611668051.4129 - val_loss: 3500659784.1826\n",
      "Epoch 2058/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1611539314.9746 - val_loss: 3504725210.0091\n",
      "Epoch 2059/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1612950479.7808 - val_loss: 3510951389.8082\n",
      "Epoch 2060/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1610926700.7123 - val_loss: 3507807160.6941\n",
      "Epoch 2061/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1611801761.8160 - val_loss: 3502335375.7808\n",
      "Epoch 2062/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1611276935.0137 - val_loss: 3510561843.4338\n",
      "Epoch 2063/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1610798726.8885 - val_loss: 3507966929.5342\n",
      "Epoch 2064/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 56us/step - loss: 1610581302.1057 - val_loss: 3509337780.8950\n",
      "Epoch 2065/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1612191004.6810 - val_loss: 3512068729.5708\n",
      "Epoch 2066/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1609775206.9511 - val_loss: 3510049546.2283\n",
      "Epoch 2067/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1609910854.6380 - val_loss: 3502469370.7397\n",
      "Epoch 2068/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1609926121.9569 - val_loss: 3512513393.3881\n",
      "Epoch 2069/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1609693738.3327 - val_loss: 3508214267.3242\n",
      "Epoch 2070/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1608993432.7984 - val_loss: 3509127816.4749\n",
      "Epoch 2071/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1608330979.5695 - val_loss: 3516113509.1142\n",
      "Epoch 2072/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1608432660.1644 - val_loss: 3513453389.4429\n",
      "Epoch 2073/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1607980214.8571 - val_loss: 3518116944.0731\n",
      "Epoch 2074/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1607505844.8532 - val_loss: 3513678349.7352\n",
      "Epoch 2075/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1609148374.4188 - val_loss: 3504501544.0365\n",
      "Epoch 2076/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1608086250.0822 - val_loss: 3520306862.1735\n",
      "Epoch 2077/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1607358689.4403 - val_loss: 3522358343.5982\n",
      "Epoch 2078/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1608856192.2505 - val_loss: 3504272698.7397\n",
      "Epoch 2079/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1605840806.3249 - val_loss: 3526052834.4840\n",
      "Epoch 2080/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1606132259.0685 - val_loss: 3526622610.9954\n",
      "Epoch 2081/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1605866922.8337 - val_loss: 3520688853.9178\n",
      "Epoch 2082/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1607016982.5440 - val_loss: 3510863429.5525\n",
      "Epoch 2083/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1606712009.3933 - val_loss: 3530559878.4292\n",
      "Epoch 2084/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1606175974.8258 - val_loss: 3529683375.6347\n",
      "Epoch 2085/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1604846957.2133 - val_loss: 3514412307.5799\n",
      "Epoch 2086/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1605019583.1233 - val_loss: 3515844584.0365\n",
      "Epoch 2087/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1604033390.9667 - val_loss: 3516096099.0685\n",
      "Epoch 2088/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1604574009.3620 - val_loss: 3518535754.2283\n",
      "Epoch 2089/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1604944852.9159 - val_loss: 3520075875.6530\n",
      "Epoch 2090/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1603514329.4247 - val_loss: 3523476046.6119\n",
      "Epoch 2091/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1603875951.2172 - val_loss: 3534009876.1644\n",
      "Epoch 2092/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1602363596.2740 - val_loss: 3523103372.2740\n",
      "Epoch 2093/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1602895302.8885 - val_loss: 3528853169.9726\n",
      "Epoch 2094/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1603705354.7710 - val_loss: 3522099729.5342\n",
      "Epoch 2095/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1602982425.4247 - val_loss: 3526593293.4429\n",
      "Epoch 2096/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1602717798.3249 - val_loss: 3533564432.9498\n",
      "Epoch 2097/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1603692391.0763 - val_loss: 3515443567.6347\n",
      "Epoch 2098/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1602772908.0861 - val_loss: 3523758724.0913\n",
      "Epoch 2099/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1601047474.5988 - val_loss: 3533073499.7626\n",
      "Epoch 2100/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1600759646.3092 - val_loss: 3531250482.5571\n",
      "Epoch 2101/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1601302862.2779 - val_loss: 3537272302.1735\n",
      "Epoch 2102/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1601076408.6106 - val_loss: 3523504528.9498\n",
      "Epoch 2103/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1602634639.7808 - val_loss: 3533231747.7991\n",
      "Epoch 2104/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1599809286.0117 - val_loss: 3527385604.0913\n",
      "Epoch 2105/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1600010941.4951 - val_loss: 3528365492.3105\n",
      "Epoch 2106/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1599136801.5656 - val_loss: 3530280479.8539\n",
      "Epoch 2107/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1599011433.4560 - val_loss: 3533077862.2831\n",
      "Epoch 2108/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1598777426.4110 - val_loss: 3534782978.0457\n",
      "Epoch 2109/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1599006425.6751 - val_loss: 3527823881.9361\n",
      "Epoch 2110/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1599788089.1115 - val_loss: 3534743681.4612\n",
      "Epoch 2111/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1599874766.9041 - val_loss: 3545579732.7489\n",
      "Epoch 2112/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1597977743.2798 - val_loss: 3540791624.1826\n",
      "Epoch 2113/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1598477136.1566 - val_loss: 3524022495.2694\n",
      "Epoch 2114/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1597913307.0528 - val_loss: 3543587176.9132\n",
      "Epoch 2115/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1599030117.4481 - val_loss: 3542428240.9498\n",
      "Epoch 2116/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1596158541.2759 - val_loss: 3532630272.2922\n",
      "Epoch 2117/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1596693822.6223 - val_loss: 3530436513.0228\n",
      "Epoch 2118/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1596051820.9628 - val_loss: 3538467019.6895\n",
      "Epoch 2119/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1597498101.9804 - val_loss: 3538277178.1553\n",
      "Epoch 2120/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1597010851.5695 - val_loss: 3534935419.0320\n",
      "Epoch 2121/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1596587772.9941 - val_loss: 3545213393.5342\n",
      "Epoch 2122/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1595525997.7143 - val_loss: 3535080432.8037\n",
      "Epoch 2123/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1597714812.9941 - val_loss: 3530197304.6941\n",
      "Epoch 2124/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1595142885.1977 - val_loss: 3553331610.3014\n",
      "Epoch 2125/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1595017046.9198 - val_loss: 3548999192.5479\n",
      "Epoch 2126/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1594316935.2642 - val_loss: 3536027775.7078\n",
      "Epoch 2127/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1594114787.1937 - val_loss: 3546254181.9909\n",
      "Epoch 2128/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 38us/step - loss: 1594593957.3229 - val_loss: 3543689627.1781\n",
      "Epoch 2129/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1593845208.4227 - val_loss: 3539524442.3014\n",
      "Epoch 2130/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1593693346.5675 - val_loss: 3544203373.8813\n",
      "Epoch 2131/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1593192901.6360 - val_loss: 3547980816.0731\n",
      "Epoch 2132/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1593306549.8552 - val_loss: 3560498042.4475\n",
      "Epoch 2133/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1592249784.1096 - val_loss: 3545608259.2146\n",
      "Epoch 2134/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1592953090.2544 - val_loss: 3537349095.7443\n",
      "Epoch 2135/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1594330023.8278 - val_loss: 3564184430.7580\n",
      "Epoch 2136/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1591387563.4599 - val_loss: 3545801519.9269\n",
      "Epoch 2137/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1591552802.5675 - val_loss: 3549223395.3607\n",
      "Epoch 2138/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1591403850.5205 - val_loss: 3545643515.3242\n",
      "Epoch 2139/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1591765305.8630 - val_loss: 3540219181.0046\n",
      "Epoch 2140/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1590587119.9687 - val_loss: 3554630222.9041\n",
      "Epoch 2141/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1591736594.2857 - val_loss: 3566322679.5251\n",
      "Epoch 2142/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1590565107.2250 - val_loss: 3553973044.6027\n",
      "Epoch 2143/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1589440773.3855 - val_loss: 3548078955.5434\n",
      "Epoch 2144/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1590527182.5284 - val_loss: 3538897477.5525\n",
      "Epoch 2145/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1589380102.5127 - val_loss: 3556303928.4018\n",
      "Epoch 2146/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1589806810.1761 - val_loss: 3565678326.6484\n",
      "Epoch 2147/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1589494777.9883 - val_loss: 3545196318.9772\n",
      "Epoch 2148/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1588877042.7241 - val_loss: 3554449785.2785\n",
      "Epoch 2149/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1589320337.6595 - val_loss: 3559991139.3607\n",
      "Epoch 2150/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1588681553.1585 - val_loss: 3562422794.2283\n",
      "Epoch 2151/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1588594357.4795 - val_loss: 3553543470.1735\n",
      "Epoch 2152/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1587978719.1859 - val_loss: 3557871497.3516\n",
      "Epoch 2153/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1587948346.3640 - val_loss: 3555419194.4475\n",
      "Epoch 2154/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1586757121.5029 - val_loss: 3553159553.1689\n",
      "Epoch 2155/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1586798036.4149 - val_loss: 3555283655.8904\n",
      "Epoch 2156/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1586552550.7006 - val_loss: 3564792651.6895\n",
      "Epoch 2157/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1586476381.6830 - val_loss: 3568909741.2968\n",
      "Epoch 2158/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1587358193.2211 - val_loss: 3564019024.0731\n",
      "Epoch 2159/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1588512782.5284 - val_loss: 3545253988.9680\n",
      "Epoch 2160/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1588077958.0117 - val_loss: 3562654487.0868\n",
      "Epoch 2161/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1586134452.7280 - val_loss: 3570460723.7260\n",
      "Epoch 2162/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1585286243.6947 - val_loss: 3562961014.6484\n",
      "Epoch 2163/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1585471309.6517 - val_loss: 3572246468.9680\n",
      "Epoch 2164/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1585149731.3190 - val_loss: 3554389998.0274\n",
      "Epoch 2165/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1585961133.2133 - val_loss: 3559723184.8037\n",
      "Epoch 2166/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1584954239.2485 - val_loss: 3577531576.9863\n",
      "Epoch 2167/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1583656689.0959 - val_loss: 3570832587.9817\n",
      "Epoch 2168/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1583199843.0685 - val_loss: 3560323491.5068\n",
      "Epoch 2169/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1584381154.4423 - val_loss: 3576775695.7808\n",
      "Epoch 2170/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1582727481.1115 - val_loss: 3564874597.6986\n",
      "Epoch 2171/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1583130879.6243 - val_loss: 3561110738.7032\n",
      "Epoch 2172/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1583881513.5812 - val_loss: 3561534916.0913\n",
      "Epoch 2173/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1584161973.4795 - val_loss: 3583845396.1644\n",
      "Epoch 2174/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1582049487.1546 - val_loss: 3565861040.5114\n",
      "Epoch 2175/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1582012204.5871 - val_loss: 3577157957.5525\n",
      "Epoch 2176/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1582846666.6458 - val_loss: 3572983575.0868\n",
      "Epoch 2177/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1581061049.8630 - val_loss: 3577780952.2557\n",
      "Epoch 2178/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1580952735.4364 - val_loss: 3573897947.1781\n",
      "Epoch 2179/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1581300405.8552 - val_loss: 3570276680.1826\n",
      "Epoch 2180/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1580741379.0059 - val_loss: 3567005634.1918\n",
      "Epoch 2181/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1580380463.2172 - val_loss: 3577951803.0320\n",
      "Epoch 2182/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1580065609.1429 - val_loss: 3575469264.0731\n",
      "Epoch 2183/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1581798082.2544 - val_loss: 3583887370.5205\n",
      "Epoch 2184/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1580657864.8924 - val_loss: 3560936761.2785\n",
      "Epoch 2185/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1579526135.2329 - val_loss: 3572301428.4566\n",
      "Epoch 2186/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1579002205.1820 - val_loss: 3577731391.7078\n",
      "Epoch 2187/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1578812130.4423 - val_loss: 3587928186.7397\n",
      "Epoch 2188/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1579720759.1076 - val_loss: 3583283150.6119\n",
      "Epoch 2189/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1579753699.9452 - val_loss: 3574320765.8082\n",
      "Epoch 2190/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1578719219.3503 - val_loss: 3571066558.2466\n",
      "Epoch 2191/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1579653571.3816 - val_loss: 3585807236.0913\n",
      "Epoch 2192/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 38us/step - loss: 1577647057.7847 - val_loss: 3582624877.8813\n",
      "Epoch 2193/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1577702118.4501 - val_loss: 3581755918.0274\n",
      "Epoch 2194/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1577740844.3366 - val_loss: 3588371702.3562\n",
      "Epoch 2195/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1577364489.7691 - val_loss: 3580072300.5662\n",
      "Epoch 2196/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1578792737.4403 - val_loss: 3575787197.9543\n",
      "Epoch 2197/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1576449152.5010 - val_loss: 3585229342.6849\n",
      "Epoch 2198/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1577706673.5969 - val_loss: 3580273845.1872\n",
      "Epoch 2199/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1575950722.7554 - val_loss: 3575974615.8174\n",
      "Epoch 2200/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1576233130.9589 - val_loss: 3580135058.9954\n",
      "Epoch 2201/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1574975920.3444 - val_loss: 3589740237.4429\n",
      "Epoch 2202/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1575831638.0431 - val_loss: 3579949833.7900\n",
      "Epoch 2203/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1574821167.0920 - val_loss: 3579884503.2329\n",
      "Epoch 2204/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1574720308.8532 - val_loss: 3586902842.7397\n",
      "Epoch 2205/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1574495931.1155 - val_loss: 3589540094.5388\n",
      "Epoch 2206/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1574874675.0998 - val_loss: 3586952314.1553\n",
      "Epoch 2207/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1574482177.2524 - val_loss: 3596550643.7260\n",
      "Epoch 2208/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1573431779.9452 - val_loss: 3586635925.7717\n",
      "Epoch 2209/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1573482784.0626 - val_loss: 3578295828.1644\n",
      "Epoch 2210/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1573085944.7358 - val_loss: 3593753136.2192\n",
      "Epoch 2211/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1573613759.6243 - val_loss: 3595779862.2100\n",
      "Epoch 2212/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1573453296.7202 - val_loss: 3581060385.0228\n",
      "Epoch 2213/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1571993621.7926 - val_loss: 3590061195.6895\n",
      "Epoch 2214/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1572432872.7045 - val_loss: 3597877933.8813\n",
      "Epoch 2215/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1573390599.2642 - val_loss: 3591152085.0411\n",
      "Epoch 2216/10000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1572087878.8885 - val_loss: 3589041197.2968\n",
      "Epoch 2217/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1571664681.3307 - val_loss: 3593121225.6438\n",
      "Epoch 2218/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1570589983.1859 - val_loss: 3591434793.6438\n",
      "Epoch 2219/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1570885332.0391 - val_loss: 3593538416.3653\n",
      "Epoch 2220/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1570154512.4070 - val_loss: 3590717403.6164\n",
      "Epoch 2221/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1573146582.1683 - val_loss: 3599092133.1142\n",
      "Epoch 2222/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1570641719.9843 - val_loss: 3589305235.1416\n",
      "Epoch 2223/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1569546421.3542 - val_loss: 3591781198.9041\n",
      "Epoch 2224/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1569440131.2564 - val_loss: 3592765235.4338\n",
      "Epoch 2225/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1570868925.8708 - val_loss: 3591901867.3973\n",
      "Epoch 2226/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1570520424.2035 - val_loss: 3604965817.2785\n",
      "Epoch 2227/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1570605119.8748 - val_loss: 3585917852.6393\n",
      "Epoch 2228/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1568611973.2603 - val_loss: 3596115288.8402\n",
      "Epoch 2229/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1568045200.5323 - val_loss: 3596254861.8813\n",
      "Epoch 2230/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1568275868.8063 - val_loss: 3602821211.9087\n",
      "Epoch 2231/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1567750102.6693 - val_loss: 3599657993.6438\n",
      "Epoch 2232/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1567850703.5303 - val_loss: 3597134655.5616\n",
      "Epoch 2233/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1568698525.4325 - val_loss: 3602491442.5571\n",
      "Epoch 2234/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1566947193.2368 - val_loss: 3599701444.2374\n",
      "Epoch 2235/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1567571078.7632 - val_loss: 3602540283.7626\n",
      "Epoch 2236/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1571092540.8689 - val_loss: 3585151329.6073\n",
      "Epoch 2237/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1567077734.5753 - val_loss: 3614049851.3242\n",
      "Epoch 2238/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1566042591.0607 - val_loss: 3600187273.4977\n",
      "Epoch 2239/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1565411052.2114 - val_loss: 3603065290.5205\n",
      "Epoch 2240/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1568903134.6849 - val_loss: 3595651310.7580\n",
      "Epoch 2241/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1565300358.7632 - val_loss: 3601799150.9041\n",
      "Epoch 2242/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1567025202.8493 - val_loss: 3612605074.1187\n",
      "Epoch 2243/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1564585742.2779 - val_loss: 3605745794.3379\n",
      "Epoch 2244/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1564467030.9198 - val_loss: 3608766514.4110\n",
      "Epoch 2245/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1564194266.6771 - val_loss: 3603619437.1507\n",
      "Epoch 2246/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1564898359.3581 - val_loss: 3611438581.3333\n",
      "Epoch 2247/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1564859602.9119 - val_loss: 3599164863.4155\n",
      "Epoch 2248/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1565279845.4481 - val_loss: 3613608047.0502\n",
      "Epoch 2249/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1563857350.3875 - val_loss: 3600383596.2740\n",
      "Epoch 2250/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1564197251.2564 - val_loss: 3606104250.1553\n",
      "Epoch 2251/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1563893860.9472 - val_loss: 3618212682.3744\n",
      "Epoch 2252/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1563143966.8102 - val_loss: 3608981663.1233\n",
      "Epoch 2253/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1563814820.3209 - val_loss: 3610734257.2420\n",
      "Epoch 2254/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1562241962.8337 - val_loss: 3601748613.1142\n",
      "Epoch 2255/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1562678395.7417 - val_loss: 3610610120.9132\n",
      "Epoch 2256/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 37us/step - loss: 1561545553.6595 - val_loss: 3613797436.2009\n",
      "Epoch 2257/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1561638846.6223 - val_loss: 3611335645.6621\n",
      "Epoch 2258/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1562235574.6067 - val_loss: 3620447300.9680\n",
      "Epoch 2259/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1562499555.5695 - val_loss: 3603648445.9543\n",
      "Epoch 2260/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1560479861.7299 - val_loss: 3606090037.7717\n",
      "Epoch 2261/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1564226434.5049 - val_loss: 3626653511.3059\n",
      "Epoch 2262/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1561509212.1800 - val_loss: 3600600770.4840\n",
      "Epoch 2263/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1559692171.7730 - val_loss: 3615407983.4886\n",
      "Epoch 2264/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1562626019.4442 - val_loss: 3605296458.5205\n",
      "Epoch 2265/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1563488765.7456 - val_loss: 3624138499.2146\n",
      "Epoch 2266/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1561190337.6282 - val_loss: 3616105962.0822\n",
      "Epoch 2267/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1559759832.6732 - val_loss: 3612262372.8219\n",
      "Epoch 2268/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1558899462.0117 - val_loss: 3621190211.0685\n",
      "Epoch 2269/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1558223647.0607 - val_loss: 3621445888.4384\n",
      "Epoch 2270/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1558884317.4325 - val_loss: 3620260766.2466\n",
      "Epoch 2271/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1559296146.4110 - val_loss: 3611275821.2968\n",
      "Epoch 2272/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1565557845.1663 - val_loss: 3620903958.5023\n",
      "Epoch 2273/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1557660778.7084 - val_loss: 3620549413.4064\n",
      "Epoch 2274/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1557413587.9139 - val_loss: 3615723133.5160\n",
      "Epoch 2275/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1558222750.5597 - val_loss: 3617066908.4932\n",
      "Epoch 2276/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1557230928.1566 - val_loss: 3619556389.6986\n",
      "Epoch 2277/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1557197900.5245 - val_loss: 3614175232.7306\n",
      "Epoch 2278/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1556255480.4853 - val_loss: 3628208703.2694\n",
      "Epoch 2279/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1556104298.7084 - val_loss: 3619232643.0685\n",
      "Epoch 2280/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1556860003.1937 - val_loss: 3627395223.3790\n",
      "Epoch 2281/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1556381824.1252 - val_loss: 3621766399.5616\n",
      "Epoch 2282/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1556078348.5245 - val_loss: 3616151715.9452\n",
      "Epoch 2283/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1555822826.7084 - val_loss: 3628339012.5297\n",
      "Epoch 2284/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1557348752.0313 - val_loss: 3620184274.1187\n",
      "Epoch 2285/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1557439004.1800 - val_loss: 3638277632.8767\n",
      "Epoch 2286/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1554060831.0607 - val_loss: 3622740954.0091\n",
      "Epoch 2287/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1554020090.4892 - val_loss: 3623171846.8676\n",
      "Epoch 2288/10000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1554725900.2740 - val_loss: 3623424158.5388\n",
      "Epoch 2289/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1554457311.6869 - val_loss: 3622460931.6530\n",
      "Epoch 2290/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1553792646.0117 - val_loss: 3635077154.4840\n",
      "Epoch 2291/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1554534781.4951 - val_loss: 3631749686.3562\n",
      "Epoch 2292/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1554154076.6810 - val_loss: 3625432629.7717\n",
      "Epoch 2293/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1554624186.2387 - val_loss: 3630392206.7580\n",
      "Epoch 2294/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1552594925.7143 - val_loss: 3636488326.5753\n",
      "Epoch 2295/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1553267562.9589 - val_loss: 3645538197.7717\n",
      "Epoch 2296/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1551693932.7123 - val_loss: 3622920490.5205\n",
      "Epoch 2297/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1552767374.7789 - val_loss: 3632320829.6621\n",
      "Epoch 2298/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1552119708.0548 - val_loss: 3633320175.0502\n",
      "Epoch 2299/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1552070626.5675 - val_loss: 3635293254.7215\n",
      "Epoch 2300/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1552015886.2779 - val_loss: 3624699575.2329\n",
      "Epoch 2301/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1553820507.8043 - val_loss: 3637999131.6164\n",
      "Epoch 2302/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1551954458.3014 - val_loss: 3617576278.9406\n",
      "Epoch 2303/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1552210089.9569 - val_loss: 3635159237.8447\n",
      "Epoch 2304/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1551796049.6595 - val_loss: 3629839889.9726\n",
      "Epoch 2305/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1550457571.4442 - val_loss: 3621881075.8721\n",
      "Epoch 2306/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1551474797.9022 - val_loss: 3634856648.4749\n",
      "Epoch 2307/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1550634464.1879 - val_loss: 3637370217.6438\n",
      "Epoch 2308/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1550590604.5245 - val_loss: 3640491923.1416\n",
      "Epoch 2309/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1548661702.7632 - val_loss: 3626609564.9315\n",
      "Epoch 2310/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1549190512.2192 - val_loss: 3631290465.3151\n",
      "Epoch 2311/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1548564983.1076 - val_loss: 3632358181.4064\n",
      "Epoch 2312/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1549385982.8728 - val_loss: 3644742015.8539\n",
      "Epoch 2313/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1548639636.7280 - val_loss: 3632092745.7900\n",
      "Epoch 2314/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1547657162.3953 - val_loss: 3641672315.7626\n",
      "Epoch 2315/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1547506064.0313 - val_loss: 3641914096.8037\n",
      "Epoch 2316/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1548615566.5284 - val_loss: 3651188379.6164\n",
      "Epoch 2317/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1546925803.2094 - val_loss: 3635489128.0365\n",
      "Epoch 2318/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1548426917.0724 - val_loss: 3633602912.4384\n",
      "Epoch 2319/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1548024621.5890 - val_loss: 3641019483.9087\n",
      "Epoch 2320/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 37us/step - loss: 1548106558.6223 - val_loss: 3663088703.7078\n",
      "Epoch 2321/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1546390839.7339 - val_loss: 3639716774.8676\n",
      "Epoch 2322/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1547034118.7632 - val_loss: 3635464979.4338\n",
      "Epoch 2323/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1546297883.9295 - val_loss: 3655292469.6256\n",
      "Epoch 2324/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1547797135.5303 - val_loss: 3631890044.4932\n",
      "Epoch 2325/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1544777952.1879 - val_loss: 3642469374.1005\n",
      "Epoch 2326/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1546073686.9198 - val_loss: 3654103601.9726\n",
      "Epoch 2327/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1544418575.4051 - val_loss: 3654938943.2694\n",
      "Epoch 2328/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1544559662.0900 - val_loss: 3640683514.0091\n",
      "Epoch 2329/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1544957959.3894 - val_loss: 3646926932.0183\n",
      "Epoch 2330/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1544197639.3894 - val_loss: 3639146168.2557\n",
      "Epoch 2331/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1546780097.6282 - val_loss: 3650486821.8447\n",
      "Epoch 2332/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1544727480.1096 - val_loss: 3635784853.7717\n",
      "Epoch 2333/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1544801808.0313 - val_loss: 3650017961.4977\n",
      "Epoch 2334/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1542957313.2524 - val_loss: 3647518029.4429\n",
      "Epoch 2335/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1543490262.9198 - val_loss: 3655564592.3653\n",
      "Epoch 2336/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1542888432.2192 - val_loss: 3646671547.6164\n",
      "Epoch 2337/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1543554780.4305 - val_loss: 3658730800.3653\n",
      "Epoch 2338/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1542476688.7828 - val_loss: 3652060348.9315\n",
      "Epoch 2339/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1545306301.1194 - val_loss: 3648623663.6347\n",
      "Epoch 2340/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1541812917.2290 - val_loss: 3643736673.4612\n",
      "Epoch 2341/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1543049237.2916 - val_loss: 3655878297.1324\n",
      "Epoch 2342/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1541399846.5753 - val_loss: 3650435400.1826\n",
      "Epoch 2343/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1542285039.4677 - val_loss: 3661322112.4384\n",
      "Epoch 2344/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1540650242.2544 - val_loss: 3654553479.7443\n",
      "Epoch 2345/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1540608652.0235 - val_loss: 3650185245.3699\n",
      "Epoch 2346/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1542360102.8258 - val_loss: 3660450781.8082\n",
      "Epoch 2347/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1540095165.6204 - val_loss: 3654319574.7945\n",
      "Epoch 2348/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1540104967.0137 - val_loss: 3663138380.7123\n",
      "Epoch 2349/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1539293739.8356 - val_loss: 3657748017.8265\n",
      "Epoch 2350/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1542388881.2838 - val_loss: 3675203912.7671\n",
      "Epoch 2351/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1538893974.0431 - val_loss: 3656307093.0411\n",
      "Epoch 2352/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1538739368.0783 - val_loss: 3658380047.9269\n",
      "Epoch 2353/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1538354608.4697 - val_loss: 3657768004.2374\n",
      "Epoch 2354/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1537835022.2779 - val_loss: 3663349114.1553\n",
      "Epoch 2355/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1538810159.0920 - val_loss: 3663043598.4658\n",
      "Epoch 2356/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1539889342.6223 - val_loss: 3655551980.1279\n",
      "Epoch 2357/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1537701876.7280 - val_loss: 3664488035.3607\n",
      "Epoch 2358/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1539716277.6047 - val_loss: 3664543474.1187\n",
      "Epoch 2359/10000\n",
      "1022/1022 [==============================] - 0s 72us/step - loss: 1538632618.4579 - val_loss: 3680051232.0000\n",
      "Epoch 2360/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1537661086.5597 - val_loss: 3658516999.8904\n",
      "Epoch 2361/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1536804428.2740 - val_loss: 3671242140.0548\n",
      "Epoch 2362/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1536108851.9765 - val_loss: 3664911084.2740\n",
      "Epoch 2363/10000\n",
      "1022/1022 [==============================] - 0s 72us/step - loss: 1536115607.1703 - val_loss: 3661239377.3881\n",
      "Epoch 2364/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1537673166.1526 - val_loss: 3667952954.4475\n",
      "Epoch 2365/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1536469332.1644 - val_loss: 3666813738.0822\n",
      "Epoch 2366/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1535201861.2603 - val_loss: 3665676047.7808\n",
      "Epoch 2367/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1535274485.9804 - val_loss: 3665328695.5251\n",
      "Epoch 2368/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1536681926.8885 - val_loss: 3669499851.3973\n",
      "Epoch 2369/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1535318482.4110 - val_loss: 3668566994.7032\n",
      "Epoch 2370/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1534984702.8728 - val_loss: 3661394630.4292\n",
      "Epoch 2371/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1535307515.9922 - val_loss: 3678047868.4932\n",
      "Epoch 2372/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1534119186.7867 - val_loss: 3665257349.5525\n",
      "Epoch 2373/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1537175436.0235 - val_loss: 3683361309.9543\n",
      "Epoch 2374/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1534067687.2016 - val_loss: 3655585149.5160\n",
      "Epoch 2375/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1533360301.3386 - val_loss: 3662441538.0457\n",
      "Epoch 2376/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1533165069.9022 - val_loss: 3672722605.4429\n",
      "Epoch 2377/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1533434860.4618 - val_loss: 3673423372.8584\n",
      "Epoch 2378/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1533871460.9472 - val_loss: 3680927611.4703\n",
      "Epoch 2379/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1535274025.2055 - val_loss: 3672331759.6347\n",
      "Epoch 2380/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1531645094.0744 - val_loss: 3674679051.8356\n",
      "Epoch 2381/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1533178986.2074 - val_loss: 3690234858.2283\n",
      "Epoch 2382/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1532367219.6008 - val_loss: 3675290764.5662\n",
      "Epoch 2383/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1531633694.5597 - val_loss: 3681768914.1187\n",
      "Epoch 2384/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 48us/step - loss: 1530820093.2446 - val_loss: 3680020751.7808\n",
      "Epoch 2385/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1530888931.4442 - val_loss: 3673298606.0274\n",
      "Epoch 2386/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1532417374.9354 - val_loss: 3690690157.4429\n",
      "Epoch 2387/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1534036378.5519 - val_loss: 3662485459.1416\n",
      "Epoch 2388/10000\n",
      "1022/1022 [==============================] - 0s 70us/step - loss: 1529835965.3699 - val_loss: 3689207572.3105\n",
      "Epoch 2389/10000\n",
      "1022/1022 [==============================] - 0s 69us/step - loss: 1530716437.8552 - val_loss: 3680289603.6530\n",
      "Epoch 2390/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1529659224.1722 - val_loss: 3685359888.0731\n",
      "Epoch 2391/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1530178807.2329 - val_loss: 3680398901.1872\n",
      "Epoch 2392/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1529819871.4364 - val_loss: 3688543667.8721\n",
      "Epoch 2393/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1530231416.7358 - val_loss: 3688320403.1416\n",
      "Epoch 2394/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1529749925.0724 - val_loss: 3681457401.2785\n",
      "Epoch 2395/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1529359199.9374 - val_loss: 3685246996.6027\n",
      "Epoch 2396/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1529027124.6027 - val_loss: 3672515162.7397\n",
      "Epoch 2397/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1527773378.8806 - val_loss: 3684572192.8767\n",
      "Epoch 2398/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1527670564.8219 - val_loss: 3682653039.9269\n",
      "Epoch 2399/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1529520502.9824 - val_loss: 3688704300.4201\n",
      "Epoch 2400/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1527625163.8982 - val_loss: 3678786770.8493\n",
      "Epoch 2401/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1527173335.4207 - val_loss: 3686357757.2237\n",
      "Epoch 2402/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1526628518.8258 - val_loss: 3678505230.3196\n",
      "Epoch 2403/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1527074926.9667 - val_loss: 3687604930.9224\n",
      "Epoch 2404/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1527514631.3894 - val_loss: 3693611878.5753\n",
      "Epoch 2405/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1526459181.5890 - val_loss: 3696903021.7352\n",
      "Epoch 2406/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1526677537.5656 - val_loss: 3679051402.6667\n",
      "Epoch 2407/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1525579659.2094 - val_loss: 3697048752.3653\n",
      "Epoch 2408/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1526959968.6888 - val_loss: 3685490196.7489\n",
      "Epoch 2409/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1526948084.9785 - val_loss: 3689311287.3790\n",
      "Epoch 2410/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1525203247.8434 - val_loss: 3700487732.7489\n",
      "Epoch 2411/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1524811295.0607 - val_loss: 3693294654.5388\n",
      "Epoch 2412/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1525043608.1722 - val_loss: 3689421126.1370\n",
      "Epoch 2413/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1526861193.2681 - val_loss: 3692988804.0913\n",
      "Epoch 2414/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1525202599.8278 - val_loss: 3697475125.9178\n",
      "Epoch 2415/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1526753383.4521 - val_loss: 3684561634.6301\n",
      "Epoch 2416/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1523981523.7886 - val_loss: 3696131178.8128\n",
      "Epoch 2417/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1523841861.3855 - val_loss: 3695484881.5342\n",
      "Epoch 2418/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1524617678.4031 - val_loss: 3688893965.5890\n",
      "Epoch 2419/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1524814250.3327 - val_loss: 3703287933.5160\n",
      "Epoch 2420/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1522611425.4403 - val_loss: 3694158894.1735\n",
      "Epoch 2421/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1523612202.3327 - val_loss: 3691679767.3790\n",
      "Epoch 2422/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1522062376.2035 - val_loss: 3705369626.7397\n",
      "Epoch 2423/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1522248968.3914 - val_loss: 3702030980.9680\n",
      "Epoch 2424/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1522159704.6732 - val_loss: 3709603354.7397\n",
      "Epoch 2425/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1521506229.6047 - val_loss: 3699564011.8356\n",
      "Epoch 2426/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1521592559.3425 - val_loss: 3691487349.3333\n",
      "Epoch 2427/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1522388788.1018 - val_loss: 3695611981.5890\n",
      "Epoch 2428/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1521299176.4540 - val_loss: 3694458588.3470\n",
      "Epoch 2429/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1522277736.2035 - val_loss: 3711041588.8950\n",
      "Epoch 2430/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1520711419.8669 - val_loss: 3713437187.2146\n",
      "Epoch 2431/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1520666089.7065 - val_loss: 3704377793.3151\n",
      "Epoch 2432/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1522430254.0900 - val_loss: 3689304203.8356\n",
      "Epoch 2433/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1519273726.4971 - val_loss: 3711628156.6393\n",
      "Epoch 2434/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1521877400.0470 - val_loss: 3723735747.5068\n",
      "Epoch 2435/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1519072624.3444 - val_loss: 3698624691.5799\n",
      "Epoch 2436/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1518894900.1018 - val_loss: 3697260688.3653\n",
      "Epoch 2437/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1519059256.1096 - val_loss: 3706196032.8767\n",
      "Epoch 2438/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1519196657.4716 - val_loss: 3706505415.8904\n",
      "Epoch 2439/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1519614628.9472 - val_loss: 3715269168.2192\n",
      "Epoch 2440/10000\n",
      "1022/1022 [==============================] - 0s 68us/step - loss: 1518718813.8082 - val_loss: 3702279856.3653\n",
      "Epoch 2441/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1517899859.6634 - val_loss: 3705576093.6621\n",
      "Epoch 2442/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1518028595.0998 - val_loss: 3709440098.7763\n",
      "Epoch 2443/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1518256474.4266 - val_loss: 3714600927.5616\n",
      "Epoch 2444/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1517906195.6634 - val_loss: 3709496348.3470\n",
      "Epoch 2445/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1520112733.4325 - val_loss: 3704865469.9543\n",
      "Epoch 2446/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1517935918.3405 - val_loss: 3717923749.5525\n",
      "Epoch 2447/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1518656674.0665 - val_loss: 3708117724.2009\n",
      "Epoch 2448/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 64us/step - loss: 1516274708.7906 - val_loss: 3712415511.8174\n",
      "Epoch 2449/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1517061467.6791 - val_loss: 3728684878.3196\n",
      "Epoch 2450/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1517120919.9217 - val_loss: 3715147709.6621\n",
      "Epoch 2451/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1517085602.3170 - val_loss: 3708239204.3836\n",
      "Epoch 2452/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1516283937.3151 - val_loss: 3714819604.8950\n",
      "Epoch 2453/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1515993585.7221 - val_loss: 3722040111.0502\n",
      "Epoch 2454/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1515210977.1898 - val_loss: 3723340946.7032\n",
      "Epoch 2455/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1515652334.0900 - val_loss: 3707738823.4521\n",
      "Epoch 2456/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1515140066.8180 - val_loss: 3717642388.8950\n",
      "Epoch 2457/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1517633746.9119 - val_loss: 3718397696.2922\n",
      "Epoch 2458/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1514748124.6810 - val_loss: 3726769517.2968\n",
      "Epoch 2459/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1515262366.8102 - val_loss: 3718527905.4612\n",
      "Epoch 2460/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1514391471.3425 - val_loss: 3717536932.0913\n",
      "Epoch 2461/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1514407764.5401 - val_loss: 3724150906.5936\n",
      "Epoch 2462/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1513728974.9041 - val_loss: 3715386098.2648\n",
      "Epoch 2463/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1514738418.3483 - val_loss: 3723913995.9817\n",
      "Epoch 2464/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1514054475.8982 - val_loss: 3722811821.2968\n",
      "Epoch 2465/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1512868870.7632 - val_loss: 3718551075.0685\n",
      "Epoch 2466/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1512686271.1233 - val_loss: 3719162725.1142\n",
      "Epoch 2467/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1513743597.3386 - val_loss: 3724405619.4338\n",
      "Epoch 2468/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1512163054.4658 - val_loss: 3716549482.9589\n",
      "Epoch 2469/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1513029501.2446 - val_loss: 3714551982.7580\n",
      "Epoch 2470/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1511735925.4795 - val_loss: 3725897960.9132\n",
      "Epoch 2471/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1511659669.5421 - val_loss: 3730767418.1553\n",
      "Epoch 2472/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1511233296.5323 - val_loss: 3728128463.7808\n",
      "Epoch 2473/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1512873044.7906 - val_loss: 3728140078.6119\n",
      "Epoch 2474/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1511258726.4501 - val_loss: 3721290336.2922\n",
      "Epoch 2475/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1510554149.3229 - val_loss: 3728590486.6484\n",
      "Epoch 2476/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1510559144.7045 - val_loss: 3733872456.6210\n",
      "Epoch 2477/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1510295458.5049 - val_loss: 3723994508.2740\n",
      "Epoch 2478/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1510610481.5969 - val_loss: 3727857509.2603\n",
      "Epoch 2479/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1510311007.8121 - val_loss: 3733229591.8174\n",
      "Epoch 2480/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1509565797.9491 - val_loss: 3732278942.5388\n",
      "Epoch 2481/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1511996243.4129 - val_loss: 3729750643.8721\n",
      "Epoch 2482/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1510169013.8552 - val_loss: 3730458289.2420\n",
      "Epoch 2483/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1509359934.6223 - val_loss: 3736002801.6804\n",
      "Epoch 2484/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1509517446.0117 - val_loss: 3752424766.1005\n",
      "Epoch 2485/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1509219915.6477 - val_loss: 3729581036.1279\n",
      "Epoch 2486/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1508932308.9159 - val_loss: 3740005866.2283\n",
      "Epoch 2487/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1509692130.4423 - val_loss: 3731346974.5388\n",
      "Epoch 2488/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1508051345.0333 - val_loss: 3739945361.0959\n",
      "Epoch 2489/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1510756254.3092 - val_loss: 3747962857.3516\n",
      "Epoch 2490/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1508275927.4207 - val_loss: 3732561145.7169\n",
      "Epoch 2491/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1507920786.9119 - val_loss: 3737851760.9498\n",
      "Epoch 2492/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1508124696.2975 - val_loss: 3738937857.6073\n",
      "Epoch 2493/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1507607670.4814 - val_loss: 3738237343.1233\n",
      "Epoch 2494/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1507787264.0000 - val_loss: 3732743145.0594\n",
      "Epoch 2495/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1506781495.1076 - val_loss: 3737650984.6210\n",
      "Epoch 2496/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1506807441.2838 - val_loss: 3747263459.7991\n",
      "Epoch 2497/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1506384835.1311 - val_loss: 3746968148.6027\n",
      "Epoch 2498/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1505872209.5342 - val_loss: 3738905543.7443\n",
      "Epoch 2499/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1507148982.3562 - val_loss: 3735681296.0731\n",
      "Epoch 2500/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1506821142.9198 - val_loss: 3737107457.4612\n",
      "Epoch 2501/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1507816360.8297 - val_loss: 3745252786.5571\n",
      "Epoch 2502/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1506047226.9902 - val_loss: 3733151159.6712\n",
      "Epoch 2503/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1505560233.9569 - val_loss: 3749543351.2329\n",
      "Epoch 2504/10000\n",
      "1022/1022 [==============================] - 0s 66us/step - loss: 1509646802.9119 - val_loss: 3733376919.9635\n",
      "Epoch 2505/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1504654759.3268 - val_loss: 3748238931.5799\n",
      "Epoch 2506/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1505336941.7143 - val_loss: 3752247458.3379\n",
      "Epoch 2507/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1504996617.8317 - val_loss: 3749740972.2740\n",
      "Epoch 2508/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1504387787.0215 - val_loss: 3758731694.3196\n",
      "Epoch 2509/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1504595191.9843 - val_loss: 3734573805.1507\n",
      "Epoch 2510/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1503503836.3053 - val_loss: 3748212066.9224\n",
      "Epoch 2511/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1503654161.0333 - val_loss: 3745717854.3927\n",
      "Epoch 2512/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 53us/step - loss: 1503904983.4207 - val_loss: 3752135616.2922\n",
      "Epoch 2513/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1504359045.6360 - val_loss: 3752941050.7397\n",
      "Epoch 2514/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1503363436.9628 - val_loss: 3751763866.3014\n",
      "Epoch 2515/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1504263106.3796 - val_loss: 3749303650.6301\n",
      "Epoch 2516/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1504492358.8885 - val_loss: 3763846996.1644\n",
      "Epoch 2517/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1502287099.9922 - val_loss: 3760910134.3562\n",
      "Epoch 2518/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1503010721.3151 - val_loss: 3750181883.6164\n",
      "Epoch 2519/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1502306509.4012 - val_loss: 3757108459.3973\n",
      "Epoch 2520/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1502009097.7691 - val_loss: 3752228444.2009\n",
      "Epoch 2521/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1504724393.2055 - val_loss: 3759372009.0594\n",
      "Epoch 2522/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1501602429.6204 - val_loss: 3753542927.9269\n",
      "Epoch 2523/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1504328340.1644 - val_loss: 3736257264.0731\n",
      "Epoch 2524/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1504145052.3053 - val_loss: 3771993203.5799\n",
      "Epoch 2525/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1502469991.9530 - val_loss: 3761059774.6849\n",
      "Epoch 2526/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1500352363.2094 - val_loss: 3750825155.5068\n",
      "Epoch 2527/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1500875012.5088 - val_loss: 3748138675.1416\n",
      "Epoch 2528/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1501116848.5949 - val_loss: 3764827499.6895\n",
      "Epoch 2529/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1500315775.4990 - val_loss: 3763418892.1279\n",
      "Epoch 2530/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1502023112.8924 - val_loss: 3755346804.3105\n",
      "Epoch 2531/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1501181543.7652 - val_loss: 3775921302.9406\n",
      "Epoch 2532/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1499958141.7456 - val_loss: 3764365249.4612\n",
      "Epoch 2533/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1500401052.3053 - val_loss: 3759885027.0685\n",
      "Epoch 2534/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1500099174.1996 - val_loss: 3754672321.6073\n",
      "Epoch 2535/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1501140249.0489 - val_loss: 3752715019.6895\n",
      "Epoch 2536/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1500413176.8611 - val_loss: 3763153002.2283\n",
      "Epoch 2537/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1499097442.3170 - val_loss: 3765252810.9589\n",
      "Epoch 2538/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1499404002.9432 - val_loss: 3768079623.4521\n",
      "Epoch 2539/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1499626582.0431 - val_loss: 3752157627.9087\n",
      "Epoch 2540/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1499588538.8650 - val_loss: 3778826753.7534\n",
      "Epoch 2541/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1499438744.0470 - val_loss: 3753647366.2831\n",
      "Epoch 2542/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1498233694.8102 - val_loss: 3759918861.4429\n",
      "Epoch 2543/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1498659278.1526 - val_loss: 3766247938.4840\n",
      "Epoch 2544/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1497205080.4227 - val_loss: 3775839159.0868\n",
      "Epoch 2545/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1497069766.1370 - val_loss: 3772657131.5434\n",
      "Epoch 2546/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1497090075.3033 - val_loss: 3764531971.9452\n",
      "Epoch 2547/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1498398018.1292 - val_loss: 3761688233.9361\n",
      "Epoch 2548/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1497735037.7456 - val_loss: 3766876184.9863\n",
      "Epoch 2549/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1497213356.3366 - val_loss: 3772799151.9269\n",
      "Epoch 2550/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1496482627.1311 - val_loss: 3775466842.5936\n",
      "Epoch 2551/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1496746298.6145 - val_loss: 3770977168.3653\n",
      "Epoch 2552/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1496875212.0235 - val_loss: 3770632749.0046\n",
      "Epoch 2553/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1496342697.8317 - val_loss: 3776832473.2785\n",
      "Epoch 2554/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1496397138.7867 - val_loss: 3773923419.7626\n",
      "Epoch 2555/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1496237689.7378 - val_loss: 3774282654.9772\n",
      "Epoch 2556/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1496785204.2270 - val_loss: 3781346395.7626\n",
      "Epoch 2557/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1496072683.9609 - val_loss: 3777146752.5845\n",
      "Epoch 2558/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1495947688.3288 - val_loss: 3769298251.6895\n",
      "Epoch 2559/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1495133707.2720 - val_loss: 3770345462.6484\n",
      "Epoch 2560/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1495503438.6536 - val_loss: 3773094537.2055\n",
      "Epoch 2561/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1495473962.8337 - val_loss: 3768198893.0046\n",
      "Epoch 2562/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1496008162.6928 - val_loss: 3776399543.5251\n",
      "Epoch 2563/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1494748850.0978 - val_loss: 3780291849.0594\n",
      "Epoch 2564/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1496043952.0939 - val_loss: 3793665196.7123\n",
      "Epoch 2565/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1493990316.3366 - val_loss: 3775324519.7443\n",
      "Epoch 2566/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1496470685.8082 - val_loss: 3781971242.3744\n",
      "Epoch 2567/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1494491990.2309 - val_loss: 3771065510.8676\n",
      "Epoch 2568/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1493680815.4677 - val_loss: 3778754449.6804\n",
      "Epoch 2569/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1493711146.5832 - val_loss: 3790747417.8630\n",
      "Epoch 2570/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1493809712.8454 - val_loss: 3786539045.2603\n",
      "Epoch 2571/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1493508130.5675 - val_loss: 3777866088.9132\n",
      "Epoch 2572/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1495839590.1996 - val_loss: 3772127635.2877\n",
      "Epoch 2573/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1493606434.5675 - val_loss: 3764328021.1872\n",
      "Epoch 2574/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1492687341.2133 - val_loss: 3777199571.1416\n",
      "Epoch 2575/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1492601477.7613 - val_loss: 3787086016.0000\n",
      "Epoch 2576/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 63us/step - loss: 1493014001.1585 - val_loss: 3792929557.7717\n",
      "Epoch 2577/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1492090487.9843 - val_loss: 3786276555.9817\n",
      "Epoch 2578/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1492618173.2446 - val_loss: 3779175039.8539\n",
      "Epoch 2579/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1492704880.5949 - val_loss: 3786473323.8356\n",
      "Epoch 2580/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1492057779.0998 - val_loss: 3783582758.2831\n",
      "Epoch 2581/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1492900651.0841 - val_loss: 3782423982.4658\n",
      "Epoch 2582/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1492798318.7162 - val_loss: 3787444814.4658\n",
      "Epoch 2583/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1491392668.5558 - val_loss: 3787422093.4429\n",
      "Epoch 2584/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1492507282.4110 - val_loss: 3783176491.3973\n",
      "Epoch 2585/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1492386305.0020 - val_loss: 3792184077.0046\n",
      "Epoch 2586/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1492210901.9178 - val_loss: 3790238821.2603\n",
      "Epoch 2587/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1492442613.8552 - val_loss: 3785431218.8493\n",
      "Epoch 2588/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1491513082.2387 - val_loss: 3777798214.1370\n",
      "Epoch 2589/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1490939172.1957 - val_loss: 3806540649.3516\n",
      "Epoch 2590/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1489797476.3209 - val_loss: 3791988763.9087\n",
      "Epoch 2591/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1491390242.0665 - val_loss: 3774771492.6758\n",
      "Epoch 2592/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1491453774.6536 - val_loss: 3789121862.5753\n",
      "Epoch 2593/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1491094351.1546 - val_loss: 3799753540.0913\n",
      "Epoch 2594/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1490539905.0020 - val_loss: 3793086572.1279\n",
      "Epoch 2595/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1490668209.0959 - val_loss: 3780737211.4703\n",
      "Epoch 2596/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1489495477.8552 - val_loss: 3792621128.9132\n",
      "Epoch 2597/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1489701646.5284 - val_loss: 3787534276.3836\n",
      "Epoch 2598/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1489490709.7926 - val_loss: 3803857920.8767\n",
      "Epoch 2599/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1492565576.3914 - val_loss: 3785800493.1507\n",
      "Epoch 2600/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1489747806.1840 - val_loss: 3813927656.4749\n",
      "Epoch 2601/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1489058618.1135 - val_loss: 3789408343.0868\n",
      "Epoch 2602/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1488254832.9706 - val_loss: 3796603778.9224\n",
      "Epoch 2603/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1488673469.4951 - val_loss: 3792668212.6027\n",
      "Epoch 2604/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1489777169.7847 - val_loss: 3813778487.3790\n",
      "Epoch 2605/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1490378785.0646 - val_loss: 3801086006.2100\n",
      "Epoch 2606/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1488727001.9256 - val_loss: 3787231681.0228\n",
      "Epoch 2607/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1489482036.8532 - val_loss: 3810047181.8813\n",
      "Epoch 2608/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1489681730.3796 - val_loss: 3803060804.8219\n",
      "Epoch 2609/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1488149639.7652 - val_loss: 3789723043.2146\n",
      "Epoch 2610/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1486820799.8748 - val_loss: 3799922972.3470\n",
      "Epoch 2611/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1490132028.7436 - val_loss: 3803655677.3699\n",
      "Epoch 2612/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1487642292.4775 - val_loss: 3802401038.1735\n",
      "Epoch 2613/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1488700416.5010 - val_loss: 3810874404.8219\n",
      "Epoch 2614/10000\n",
      "1022/1022 [==============================] - 0s 69us/step - loss: 1488921271.6086 - val_loss: 3784666332.0548\n",
      "Epoch 2615/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1486921319.7025 - val_loss: 3813006479.6347\n",
      "Epoch 2616/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1486540287.3738 - val_loss: 3800375493.8447\n",
      "Epoch 2617/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1487180901.9491 - val_loss: 3805006004.7489\n",
      "Epoch 2618/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1486911165.6204 - val_loss: 3817781121.6073\n",
      "Epoch 2619/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1486492297.7691 - val_loss: 3815335642.1553\n",
      "Epoch 2620/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1486361503.1859 - val_loss: 3793191104.5845\n",
      "Epoch 2621/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1485546586.9276 - val_loss: 3801307857.6804\n",
      "Epoch 2622/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1486251591.8904 - val_loss: 3799339626.2283\n",
      "Epoch 2623/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1487104438.3562 - val_loss: 3810634185.2055\n",
      "Epoch 2624/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1485715772.6184 - val_loss: 3806967468.5662\n",
      "Epoch 2625/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1486667791.2798 - val_loss: 3815937682.2648\n",
      "Epoch 2626/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1485690770.2857 - val_loss: 3806560469.4795\n",
      "Epoch 2627/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1486637459.0372 - val_loss: 3797267769.1324\n",
      "Epoch 2628/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1485131551.5616 - val_loss: 3811166910.8311\n",
      "Epoch 2629/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1484351036.1174 - val_loss: 3817523789.8813\n",
      "Epoch 2630/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1487176552.2035 - val_loss: 3803209944.4018\n",
      "Epoch 2631/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1485412541.8708 - val_loss: 3817848687.0502\n",
      "Epoch 2632/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1488176106.0822 - val_loss: 3798919679.5616\n",
      "Epoch 2633/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1485290329.6751 - val_loss: 3811814068.4566\n",
      "Epoch 2634/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1484755835.9922 - val_loss: 3825910550.5023\n",
      "Epoch 2635/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1484167450.6771 - val_loss: 3827355802.0091\n",
      "Epoch 2636/10000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1486119875.7573 - val_loss: 3796848799.5616\n",
      "Epoch 2637/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1483544873.2055 - val_loss: 3820612870.2831\n",
      "Epoch 2638/10000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1483540779.3346 - val_loss: 3810839166.8311\n",
      "Epoch 2639/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1483115890.4736 - val_loss: 3819395619.3607\n",
      "Epoch 2640/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 47us/step - loss: 1484339431.7025 - val_loss: 3807683196.0548\n",
      "Epoch 2641/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1484038560.6888 - val_loss: 3816386504.9132\n",
      "Epoch 2642/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1483187975.0137 - val_loss: 3817268054.3562\n",
      "Epoch 2643/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1483584548.0705 - val_loss: 3808865991.8904\n",
      "Epoch 2644/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1484437296.8454 - val_loss: 3816061486.1735\n",
      "Epoch 2645/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1483189855.4364 - val_loss: 3835100312.8402\n",
      "Epoch 2646/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1483375192.7984 - val_loss: 3807683868.9315\n",
      "Epoch 2647/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1482458511.2798 - val_loss: 3813268356.6758\n",
      "Epoch 2648/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1482227833.2368 - val_loss: 3822971643.0320\n",
      "Epoch 2649/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1484215368.8924 - val_loss: 3816707122.8493\n",
      "Epoch 2650/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1482259713.2524 - val_loss: 3829839522.4840\n",
      "Epoch 2651/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1483095669.7299 - val_loss: 3819929526.3562\n",
      "Epoch 2652/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1482553757.8082 - val_loss: 3821906183.3059\n",
      "Epoch 2653/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1482353972.9785 - val_loss: 3816646193.9726\n",
      "Epoch 2654/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1484003572.9785 - val_loss: 3831403954.8493\n",
      "Epoch 2655/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1481346494.6223 - val_loss: 3816888407.0868\n",
      "Epoch 2656/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1481861806.3405 - val_loss: 3831558251.3973\n",
      "Epoch 2657/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1482909226.5832 - val_loss: 3815686797.4429\n",
      "Epoch 2658/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1482347895.4834 - val_loss: 3825477356.8584\n",
      "Epoch 2659/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1481111567.5303 - val_loss: 3825694347.1050\n",
      "Epoch 2660/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1480390051.8200 - val_loss: 3829415878.2831\n",
      "Epoch 2661/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1481002602.0822 - val_loss: 3822256845.1507\n",
      "Epoch 2662/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1482037964.0235 - val_loss: 3822304140.8584\n",
      "Epoch 2663/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1480296518.1370 - val_loss: 3831129167.4886\n",
      "Epoch 2664/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1480643242.0822 - val_loss: 3837766949.9909\n",
      "Epoch 2665/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1481880723.7886 - val_loss: 3818329251.3607\n",
      "Epoch 2666/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1481389972.0391 - val_loss: 3840531671.5251\n",
      "Epoch 2667/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1480369695.9374 - val_loss: 3837756757.6256\n",
      "Epoch 2668/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1480524141.7143 - val_loss: 3834013966.3196\n",
      "Epoch 2669/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1479372599.6086 - val_loss: 3826749501.9543\n",
      "Epoch 2670/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1480079771.6791 - val_loss: 3828526901.9178\n",
      "Epoch 2671/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1480508301.9022 - val_loss: 3836774438.5753\n",
      "Epoch 2672/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1479293339.8043 - val_loss: 3822114141.0776\n",
      "Epoch 2673/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1479142310.3249 - val_loss: 3831328710.4292\n",
      "Epoch 2674/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1482580269.5890 - val_loss: 3842179882.8128\n",
      "Epoch 2675/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1486156640.1879 - val_loss: 3817630688.4384\n",
      "Epoch 2676/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1478750576.8454 - val_loss: 3833132039.7443\n",
      "Epoch 2677/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1479769889.8160 - val_loss: 3843324516.6758\n",
      "Epoch 2678/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1480169500.8063 - val_loss: 3836262409.2055\n",
      "Epoch 2679/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1478990387.8513 - val_loss: 3833660435.1416\n",
      "Epoch 2680/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1479238469.0098 - val_loss: 3834109320.4749\n",
      "Epoch 2681/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1479750817.0646 - val_loss: 3835888817.0959\n",
      "Epoch 2682/10000\n",
      "1022/1022 [==============================] - 0s 70us/step - loss: 1478536252.3679 - val_loss: 3838844854.2100\n",
      "Epoch 2683/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1479287578.5519 - val_loss: 3839537031.7443\n",
      "Epoch 2684/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1480788451.1937 - val_loss: 3841446927.0502\n",
      "Epoch 2685/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1478747028.7906 - val_loss: 3838390728.4749\n",
      "Epoch 2686/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1478860814.2779 - val_loss: 3849790583.8174\n",
      "Epoch 2687/10000\n",
      "1022/1022 [==============================] - 0s 63us/step - loss: 1480534808.0470 - val_loss: 3831033477.2603\n",
      "Epoch 2688/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1478531010.6301 - val_loss: 3839667635.5799\n",
      "Epoch 2689/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1481950211.5068 - val_loss: 3865534091.6895\n",
      "Epoch 2690/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1477625275.1155 - val_loss: 3834368700.6393\n",
      "Epoch 2691/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1478006158.2779 - val_loss: 3834285915.4703\n",
      "Epoch 2692/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1477135355.7417 - val_loss: 3836997057.1689\n",
      "Epoch 2693/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1477456968.1409 - val_loss: 3846242729.9361\n",
      "Epoch 2694/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1478687804.6184 - val_loss: 3842117626.8858\n",
      "Epoch 2695/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1477783407.9687 - val_loss: 3844777463.9635\n",
      "Epoch 2696/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1477195068.7436 - val_loss: 3836230277.2603\n",
      "Epoch 2697/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1476486338.3796 - val_loss: 3838040221.8082\n",
      "Epoch 2698/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1477157379.7573 - val_loss: 3849737806.4658\n",
      "Epoch 2699/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1478043845.6360 - val_loss: 3840313327.1963\n",
      "Epoch 2700/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1477288878.8415 - val_loss: 3839087668.4566\n",
      "Epoch 2701/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1476905633.3151 - val_loss: 3838225376.2922\n",
      "Epoch 2702/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1476500413.6204 - val_loss: 3834148737.1689\n",
      "Epoch 2703/10000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1477403081.8943 - val_loss: 3858281045.3333\n",
      "Epoch 2704/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 54us/step - loss: 1477137562.5519 - val_loss: 3837564285.8082\n",
      "Epoch 2705/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1476175586.9432 - val_loss: 3839668836.5297\n",
      "Epoch 2706/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1476549094.0744 - val_loss: 3846886943.7078\n",
      "Epoch 2707/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1475704022.7945 - val_loss: 3846442277.9909\n",
      "Epoch 2708/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1476605005.4012 - val_loss: 3846036022.5023\n",
      "Epoch 2709/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1475645389.9022 - val_loss: 3849982743.6712\n",
      "Epoch 2710/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1475639982.8415 - val_loss: 3844619996.3470\n",
      "Epoch 2711/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1477210472.7045 - val_loss: 3851346355.8721\n",
      "Epoch 2712/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1476498050.1292 - val_loss: 3859518970.7397\n",
      "Epoch 2713/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1475538534.7006 - val_loss: 3848169116.6393\n",
      "Epoch 2714/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1475795719.5147 - val_loss: 3851884238.3196\n",
      "Epoch 2715/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1475066884.5088 - val_loss: 3846554582.5023\n",
      "Epoch 2716/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1475334836.1018 - val_loss: 3847189808.6575\n",
      "Epoch 2717/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1475191761.4090 - val_loss: 3847288905.2055\n",
      "Epoch 2718/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1474725223.4521 - val_loss: 3847303143.0137\n",
      "Epoch 2719/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1475053952.2505 - val_loss: 3858040113.6804\n",
      "Epoch 2720/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1477384029.3072 - val_loss: 3840015675.0320\n",
      "Epoch 2721/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1474723224.0470 - val_loss: 3858510221.1507\n",
      "Epoch 2722/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1474527056.1566 - val_loss: 3862527784.4749\n",
      "Epoch 2723/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1476861659.4286 - val_loss: 3843774871.0868\n",
      "Epoch 2724/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1474467470.4031 - val_loss: 3849472735.7078\n",
      "Epoch 2725/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1474531445.2290 - val_loss: 3846674267.4703\n",
      "Epoch 2726/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1473965698.0039 - val_loss: 3858461912.8402\n",
      "Epoch 2727/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1475507186.2231 - val_loss: 3868424664.6941\n",
      "Epoch 2728/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1474150433.5656 - val_loss: 3854921485.2968\n",
      "Epoch 2729/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1475168603.1781 - val_loss: 3851627448.4018\n",
      "Epoch 2730/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1473986294.2309 - val_loss: 3850555264.0000\n",
      "Epoch 2731/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1473619925.1663 - val_loss: 3856855172.2374\n",
      "Epoch 2732/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1473153135.7182 - val_loss: 3855679503.9269\n",
      "Epoch 2733/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1474174960.7202 - val_loss: 3849295263.8539\n",
      "Epoch 2734/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1473647145.5812 - val_loss: 3861743828.3105\n",
      "Epoch 2735/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1473175282.7241 - val_loss: 3856943708.3470\n",
      "Epoch 2736/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1473417372.3053 - val_loss: 3858291561.0594\n",
      "Epoch 2737/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1475492191.6869 - val_loss: 3843314819.6530\n",
      "Epoch 2738/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1474623692.6497 - val_loss: 3857207729.2420\n",
      "Epoch 2739/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1473368609.8160 - val_loss: 3853486743.8174\n",
      "Epoch 2740/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1473890420.2270 - val_loss: 3870731188.4566\n",
      "Epoch 2741/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1473413665.8160 - val_loss: 3842413292.8584\n",
      "Epoch 2742/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1473824879.7182 - val_loss: 3851783313.5342\n",
      "Epoch 2743/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1473195493.8239 - val_loss: 3863192900.5297\n",
      "Epoch 2744/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1473486265.1115 - val_loss: 3845711385.5708\n",
      "Epoch 2745/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1474040715.1468 - val_loss: 3854199125.9178\n",
      "Epoch 2746/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1472432558.8415 - val_loss: 3861922083.2146\n",
      "Epoch 2747/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1471678225.7847 - val_loss: 3855275395.9452\n",
      "Epoch 2748/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1472386827.3973 - val_loss: 3851167443.4338\n",
      "Epoch 2749/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1472717311.4990 - val_loss: 3870689848.5479\n",
      "Epoch 2750/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1472017995.5225 - val_loss: 3857117755.7626\n",
      "Epoch 2751/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1472447088.0939 - val_loss: 3858518039.0868\n",
      "Epoch 2752/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1472596949.4168 - val_loss: 3859196527.6347\n",
      "Epoch 2753/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1472178082.0665 - val_loss: 3868378528.4384\n",
      "Epoch 2754/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1473238299.5538 - val_loss: 3875486258.5571\n",
      "Epoch 2755/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1471777270.9824 - val_loss: 3854839463.5982\n",
      "Epoch 2756/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1471919061.0411 - val_loss: 3859274711.3790\n",
      "Epoch 2757/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1472612401.0959 - val_loss: 3847065511.1598\n",
      "Epoch 2758/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1471781007.9061 - val_loss: 3855488632.1096\n",
      "Epoch 2759/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1470685119.8748 - val_loss: 3862913089.7534\n",
      "Epoch 2760/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1471321546.8963 - val_loss: 3858071646.6849\n",
      "Epoch 2761/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1471712483.9452 - val_loss: 3865934011.1781\n",
      "Epoch 2762/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1471356035.7573 - val_loss: 3858397096.6210\n",
      "Epoch 2763/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1471064803.9452 - val_loss: 3859243722.6667\n",
      "Epoch 2764/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1471629411.1937 - val_loss: 3860359929.2785\n",
      "Epoch 2765/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1472184766.6223 - val_loss: 3856318623.4155\n",
      "Epoch 2766/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1469877962.3953 - val_loss: 3879091374.0274\n",
      "Epoch 2767/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1472384933.8239 - val_loss: 3869128289.3151\n",
      "Epoch 2768/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 57us/step - loss: 1473537248.0626 - val_loss: 3886134697.9361\n",
      "Epoch 2769/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1472528489.2055 - val_loss: 3850188158.1005\n",
      "Epoch 2770/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1472097035.3973 - val_loss: 3866075100.3470\n",
      "Epoch 2771/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1470469596.1800 - val_loss: 3868071060.0183\n",
      "Epoch 2772/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1471080710.0117 - val_loss: 3879766837.4795\n",
      "Epoch 2773/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1469662470.7632 - val_loss: 3867464399.0502\n",
      "Epoch 2774/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1469832993.5656 - val_loss: 3869708744.9132\n",
      "Epoch 2775/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1470511317.4168 - val_loss: 3859288787.2877\n",
      "Epoch 2776/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1474118943.0607 - val_loss: 3876777669.9909\n",
      "Epoch 2777/10000\n",
      "1022/1022 [==============================] - 0s 69us/step - loss: 1472117714.9119 - val_loss: 3858965558.5023\n",
      "Epoch 2778/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1471207961.5499 - val_loss: 3882364629.4795\n",
      "Epoch 2779/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1474319886.1526 - val_loss: 3858079327.2694\n",
      "Epoch 2780/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1470886854.0117 - val_loss: 3871039189.0411\n",
      "Epoch 2781/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1471327524.8219 - val_loss: 3866356251.4703\n",
      "Epoch 2782/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1469443950.6536 - val_loss: 3872471251.1416\n",
      "Epoch 2783/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1469980425.7691 - val_loss: 3860325665.0228\n",
      "Epoch 2784/10000\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 1470720308.1018 - val_loss: 3883002327.6712\n",
      "Epoch 2785/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1469254863.7808 - val_loss: 3864354887.8904\n",
      "Epoch 2786/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1469793709.0881 - val_loss: 3860162045.5160\n",
      "Epoch 2787/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1469847482.7397 - val_loss: 3866470593.4612\n",
      "Epoch 2788/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1469378970.3014 - val_loss: 3873410371.9452\n",
      "Epoch 2789/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1469488051.6008 - val_loss: 3865103190.0639\n",
      "Epoch 2790/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1469826440.0157 - val_loss: 3859726966.5023\n",
      "Epoch 2791/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1469826578.6614 - val_loss: 3879726373.5525\n",
      "Epoch 2792/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1471878500.6967 - val_loss: 3879134328.2557\n",
      "Epoch 2793/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1471622370.6928 - val_loss: 3869822825.9361\n",
      "Epoch 2794/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1471888396.1487 - val_loss: 3889167325.8082\n",
      "Epoch 2795/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1471413752.4853 - val_loss: 3886203571.1416\n",
      "Epoch 2796/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1467510331.1155 - val_loss: 3869690210.1918\n",
      "Epoch 2797/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1469624612.3209 - val_loss: 3866556977.9726\n",
      "Epoch 2798/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1468719002.3014 - val_loss: 3869521307.0320\n",
      "Epoch 2799/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1468932721.2211 - val_loss: 3882228370.2648\n",
      "Epoch 2800/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1468728413.1820 - val_loss: 3879111653.6986\n",
      "Epoch 2801/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1467807170.1292 - val_loss: 3872356179.1416\n",
      "Epoch 2802/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1468192751.4677 - val_loss: 3873410601.0594\n",
      "Epoch 2803/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1468692435.0372 - val_loss: 3868084877.7352\n",
      "Epoch 2804/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1471000339.0372 - val_loss: 3896371153.9726\n",
      "Epoch 2805/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1467904099.0685 - val_loss: 3868714149.4064\n",
      "Epoch 2806/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1471018742.9824 - val_loss: 3863910085.9909\n",
      "Epoch 2807/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1467663223.8591 - val_loss: 3893397238.7945\n",
      "Epoch 2808/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1468710163.2877 - val_loss: 3872893188.9680\n",
      "Epoch 2809/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1468366945.4403 - val_loss: 3871980928.7306\n",
      "Epoch 2810/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1470165341.1820 - val_loss: 3887137800.0365\n",
      "Epoch 2811/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1467613765.1350 - val_loss: 3876833202.1187\n",
      "Epoch 2812/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1467499249.9726 - val_loss: 3879032164.6758\n",
      "Epoch 2813/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1467537743.1546 - val_loss: 3883010674.2648\n",
      "Epoch 2814/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1467857114.0509 - val_loss: 3878908769.8995\n",
      "Epoch 2815/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1467320882.5988 - val_loss: 3881202638.0274\n",
      "Epoch 2816/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1468243968.5010 - val_loss: 3875439836.6393\n",
      "Epoch 2817/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1467353051.5538 - val_loss: 3872165121.7534\n",
      "Epoch 2818/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1468364088.3601 - val_loss: 3878175693.5890\n",
      "Epoch 2819/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1467146636.0235 - val_loss: 3889396018.7032\n",
      "Epoch 2820/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1466921162.7710 - val_loss: 3881180239.7808\n",
      "Epoch 2821/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1466474535.9530 - val_loss: 3881271094.6484\n",
      "Epoch 2822/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1467563502.7162 - val_loss: 3873048283.0320\n",
      "Epoch 2823/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1467389601.0646 - val_loss: 3874371416.8402\n",
      "Epoch 2824/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1467849509.4481 - val_loss: 3874123090.5571\n",
      "Epoch 2825/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1467380289.6282 - val_loss: 3897376691.8721\n",
      "Epoch 2826/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1466667501.3386 - val_loss: 3879581746.8493\n",
      "Epoch 2827/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1466325494.8571 - val_loss: 3879659838.9772\n",
      "Epoch 2828/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1468320192.8767 - val_loss: 3872475228.4932\n",
      "Epoch 2829/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1467366716.6184 - val_loss: 3897098518.6484\n",
      "Epoch 2830/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1466819666.6614 - val_loss: 3879319862.5023\n",
      "Epoch 2831/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1467631678.7476 - val_loss: 3882645841.6804\n",
      "Epoch 2832/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 53us/step - loss: 1468013801.5812 - val_loss: 3886352350.8311\n",
      "Epoch 2833/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1466700510.8102 - val_loss: 3881911530.6667\n",
      "Epoch 2834/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1466063497.5186 - val_loss: 3894292104.4749\n",
      "Epoch 2835/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1466731291.0528 - val_loss: 3883468650.6667\n",
      "Epoch 2836/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1468955532.3992 - val_loss: 3873036657.9726\n",
      "Epoch 2837/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1466503004.4305 - val_loss: 3896249333.4795\n",
      "Epoch 2838/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1466890444.6497 - val_loss: 3882478146.4840\n",
      "Epoch 2839/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1468557779.4129 - val_loss: 3885523452.2009\n",
      "Epoch 2840/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1467953594.8650 - val_loss: 3892554532.3836\n",
      "Epoch 2841/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1465697499.1781 - val_loss: 3882382882.6301\n",
      "Epoch 2842/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1466415180.1487 - val_loss: 3883074261.3333\n",
      "Epoch 2843/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1466241188.4462 - val_loss: 3879338303.4155\n",
      "Epoch 2844/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1467315352.5479 - val_loss: 3899825769.7900\n",
      "Epoch 2845/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1465472336.9080 - val_loss: 3889053306.7397\n",
      "Epoch 2846/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1465963222.9198 - val_loss: 3891959471.7808\n",
      "Epoch 2847/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1464742453.2290 - val_loss: 3882289539.3607\n",
      "Epoch 2848/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1465428858.3014 - val_loss: 3875778420.4566\n",
      "Epoch 2849/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1466801458.5988 - val_loss: 3888553535.8539\n",
      "Epoch 2850/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1464791354.3640 - val_loss: 3889460490.0822\n",
      "Epoch 2851/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1466239831.6712 - val_loss: 3883870382.9041\n",
      "Epoch 2852/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1465926607.2798 - val_loss: 3893560087.0868\n",
      "Epoch 2853/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1464758614.5440 - val_loss: 3885680853.7717\n",
      "Epoch 2854/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1465071468.0861 - val_loss: 3890971677.2237\n",
      "Epoch 2855/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1464766704.1252 - val_loss: 3892433905.0959\n",
      "Epoch 2856/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1465265397.6047 - val_loss: 3890188765.8082\n",
      "Epoch 2857/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1464813557.7299 - val_loss: 3885604068.2374\n",
      "Epoch 2858/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1466280060.3679 - val_loss: 3882951379.5799\n",
      "Epoch 2859/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1465831501.4012 - val_loss: 3897932918.0639\n",
      "Epoch 2860/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1465396725.2290 - val_loss: 3892469745.8265\n",
      "Epoch 2861/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1465134475.6477 - val_loss: 3882524354.3379\n",
      "Epoch 2862/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1463876618.7710 - val_loss: 3887500069.2603\n",
      "Epoch 2863/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1464224449.2524 - val_loss: 3884743029.4795\n",
      "Epoch 2864/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1466588860.3679 - val_loss: 3894249276.7854\n",
      "Epoch 2865/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1464147336.5166 - val_loss: 3886415269.8447\n",
      "Epoch 2866/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1464754782.9354 - val_loss: 3894248502.3562\n",
      "Epoch 2867/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1463935056.9080 - val_loss: 3893089949.0776\n",
      "Epoch 2868/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1463918042.6771 - val_loss: 3889270775.2329\n",
      "Epoch 2869/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1463774848.1252 - val_loss: 3887714201.5708\n",
      "Epoch 2870/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1464697969.2211 - val_loss: 3901628848.9498\n",
      "Epoch 2871/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1463739661.1507 - val_loss: 3891545657.8630\n",
      "Epoch 2872/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1464711529.7065 - val_loss: 3879603334.1370\n",
      "Epoch 2873/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1463648713.1429 - val_loss: 3906806872.4018\n",
      "Epoch 2874/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1464870199.9843 - val_loss: 3890532808.4749\n",
      "Epoch 2875/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1464129509.8239 - val_loss: 3896432139.3973\n",
      "Epoch 2876/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1464267987.4129 - val_loss: 3883601802.5205\n",
      "Epoch 2877/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1462797457.2838 - val_loss: 3891607669.9178\n",
      "Epoch 2878/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1464699409.9100 - val_loss: 3885197134.0274\n",
      "Epoch 2879/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1464039746.1292 - val_loss: 3888149042.7032\n",
      "Epoch 2880/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1462663580.3053 - val_loss: 3903510068.7489\n",
      "Epoch 2881/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1463955249.5969 - val_loss: 3893860041.9361\n",
      "Epoch 2882/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1464375268.9472 - val_loss: 3906528196.0913\n",
      "Epoch 2883/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1464866740.4775 - val_loss: 3886885266.7032\n",
      "Epoch 2884/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1462888014.6536 - val_loss: 3890596920.1096\n",
      "Epoch 2885/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1463500083.0998 - val_loss: 3904507980.1279\n",
      "Epoch 2886/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1462802155.4599 - val_loss: 3902814458.5936\n",
      "Epoch 2887/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1462728378.8650 - val_loss: 3894082860.7123\n",
      "Epoch 2888/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1463760705.8787 - val_loss: 3893113615.6347\n",
      "Epoch 2889/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1465627992.7984 - val_loss: 3896707141.9909\n",
      "Epoch 2890/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1462533348.3209 - val_loss: 3898906098.8493\n",
      "Epoch 2891/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1462570459.0528 - val_loss: 3892518447.7808\n",
      "Epoch 2892/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1464036931.5068 - val_loss: 3904038915.5068\n",
      "Epoch 2893/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1463002553.3620 - val_loss: 3892487649.6073\n",
      "Epoch 2894/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1462787424.9393 - val_loss: 3893236221.2237\n",
      "Epoch 2895/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1462897092.3836 - val_loss: 3887566730.5205\n",
      "Epoch 2896/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 46us/step - loss: 1462852142.8415 - val_loss: 3895814086.7215\n",
      "Epoch 2897/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1465737627.3033 - val_loss: 3884911436.7123\n",
      "Epoch 2898/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1462038689.5656 - val_loss: 3903278997.6256\n",
      "Epoch 2899/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1461879066.8023 - val_loss: 3897456269.8813\n",
      "Epoch 2900/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1462193706.5832 - val_loss: 3891775880.1826\n",
      "Epoch 2901/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1462328279.1703 - val_loss: 3904688592.0731\n",
      "Epoch 2902/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1461943531.2094 - val_loss: 3896602591.1233\n",
      "Epoch 2903/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1462206536.1409 - val_loss: 3888109526.2100\n",
      "Epoch 2904/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1461749499.6164 - val_loss: 3891693640.9132\n",
      "Epoch 2905/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1461960029.9335 - val_loss: 3894524165.5525\n",
      "Epoch 2906/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1463452533.9804 - val_loss: 3914645732.8219\n",
      "Epoch 2907/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1464149204.7906 - val_loss: 3883743749.9909\n",
      "Epoch 2908/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1462833113.9256 - val_loss: 3892245451.1050\n",
      "Epoch 2909/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1461578844.1800 - val_loss: 3900038938.5936\n",
      "Epoch 2910/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1462897817.2994 - val_loss: 3909952717.1507\n",
      "Epoch 2911/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1461096318.7476 - val_loss: 3893768930.0457\n",
      "Epoch 2912/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1462229816.9863 - val_loss: 3902176843.3973\n",
      "Epoch 2913/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1462037745.0959 - val_loss: 3897976877.8813\n",
      "Epoch 2914/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1464738204.8063 - val_loss: 3882218435.0685\n",
      "Epoch 2915/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1461200939.9609 - val_loss: 3906279883.8356\n",
      "Epoch 2916/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1461015831.7965 - val_loss: 3892487895.8174\n",
      "Epoch 2917/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1460486785.1898 - val_loss: 3900252754.5571\n",
      "Epoch 2918/10000\n",
      "1022/1022 [==============================] - 0s 65us/step - loss: 1461478445.5890 - val_loss: 3906228363.3973\n",
      "Epoch 2919/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1460770074.5519 - val_loss: 3903418773.6256\n",
      "Epoch 2920/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1460515546.9276 - val_loss: 3899525860.3836\n",
      "Epoch 2921/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1461387087.6556 - val_loss: 3886510598.2831\n",
      "Epoch 2922/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1461420296.2661 - val_loss: 3898793265.6804\n",
      "Epoch 2923/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1460516664.6106 - val_loss: 3904801115.4703\n",
      "Epoch 2924/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1461574760.9550 - val_loss: 3893204584.9132\n",
      "Epoch 2925/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1460596490.2701 - val_loss: 3897909899.3973\n",
      "Epoch 2926/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1462196842.2074 - val_loss: 3886807427.6530\n",
      "Epoch 2927/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1460586577.5969 - val_loss: 3901835324.0548\n",
      "Epoch 2928/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1460982223.9061 - val_loss: 3893533658.1553\n",
      "Epoch 2929/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1462007182.2779 - val_loss: 3902902351.9269\n",
      "Epoch 2930/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1460802252.2740 - val_loss: 3903044751.1963\n",
      "Epoch 2931/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1461459683.8200 - val_loss: 3902855069.2237\n",
      "Epoch 2932/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1460414845.1194 - val_loss: 3899182242.9224\n",
      "Epoch 2933/10000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1460658692.3836 - val_loss: 3899994788.9680\n",
      "Epoch 2934/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1461256290.4423 - val_loss: 3910992733.8082\n",
      "Epoch 2935/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1462186646.5440 - val_loss: 3886095377.8265\n",
      "Epoch 2936/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1461920528.7202 - val_loss: 3899311238.1370\n",
      "Epoch 2937/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1460028356.0078 - val_loss: 3895507969.8995\n",
      "Epoch 2938/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1460307834.9902 - val_loss: 3909008580.9680\n",
      "Epoch 2939/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1460288729.4247 - val_loss: 3907714603.1050\n",
      "Epoch 2940/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1460120464.0313 - val_loss: 3884877599.2694\n",
      "Epoch 2941/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1460495327.4364 - val_loss: 3897773682.9954\n",
      "Epoch 2942/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1460289404.2427 - val_loss: 3890494269.3699\n",
      "Epoch 2943/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1459239603.6008 - val_loss: 3903648993.7534\n",
      "Epoch 2944/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1464659498.3327 - val_loss: 3891759937.8995\n",
      "Epoch 2945/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1458845170.2231 - val_loss: 3916790509.5890\n",
      "Epoch 2946/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1461505618.5362 - val_loss: 3899716288.1461\n",
      "Epoch 2947/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1461169096.8924 - val_loss: 3908872566.6484\n",
      "Epoch 2948/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1459591481.6125 - val_loss: 3906407177.0594\n",
      "Epoch 2949/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1459671082.0822 - val_loss: 3892965536.7306\n",
      "Epoch 2950/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1459775560.1409 - val_loss: 3904411825.6804\n",
      "Epoch 2951/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1459901147.8669 - val_loss: 3894168717.4429\n",
      "Epoch 2952/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1460359693.0254 - val_loss: 3901440704.5845\n",
      "Epoch 2953/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1459448761.8630 - val_loss: 3905595713.0228\n",
      "Epoch 2954/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1459849118.0587 - val_loss: 3899543856.8037\n",
      "Epoch 2955/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1458779096.4227 - val_loss: 3897310950.8676\n",
      "Epoch 2956/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1458890858.9589 - val_loss: 3898146877.0776\n",
      "Epoch 2957/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1459683349.6673 - val_loss: 3901061037.7352\n",
      "Epoch 2958/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1459876488.2661 - val_loss: 3899254365.9543\n",
      "Epoch 2959/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1459718560.3131 - val_loss: 3896792195.3607\n",
      "Epoch 2960/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 41us/step - loss: 1459105625.1742 - val_loss: 3905890238.6849\n",
      "Epoch 2961/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1459096425.3307 - val_loss: 3903294327.3790\n",
      "Epoch 2962/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1459123639.1076 - val_loss: 3902411902.9772\n",
      "Epoch 2963/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1459000375.1076 - val_loss: 3894915114.2283\n",
      "Epoch 2964/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1458759950.0274 - val_loss: 3900470322.2648\n",
      "Epoch 2965/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1464347949.2133 - val_loss: 3894617574.7215\n",
      "Epoch 2966/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1462273823.5616 - val_loss: 3914470639.7808\n",
      "Epoch 2967/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1461706585.9256 - val_loss: 3919921974.0639\n",
      "Epoch 2968/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1459419113.7065 - val_loss: 3895147056.5114\n",
      "Epoch 2969/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1457923291.9295 - val_loss: 3893287803.7626\n",
      "Epoch 2970/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1459319148.4618 - val_loss: 3891817873.2420\n",
      "Epoch 2971/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1458519825.0333 - val_loss: 3917832494.3196\n",
      "Epoch 2972/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1460677414.7006 - val_loss: 3910479368.1826\n",
      "Epoch 2973/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1459908846.2153 - val_loss: 3901791278.1735\n",
      "Epoch 2974/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1458573799.4521 - val_loss: 3900734776.6941\n",
      "Epoch 2975/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1459115035.3033 - val_loss: 3918198065.8265\n",
      "Epoch 2976/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1459620536.1096 - val_loss: 3887686002.8493\n",
      "Epoch 2977/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1460159815.3894 - val_loss: 3895643384.4018\n",
      "Epoch 2978/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1458197244.4932 - val_loss: 3910457723.4703\n",
      "Epoch 2979/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1458652027.7417 - val_loss: 3908407549.9543\n",
      "Epoch 2980/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1458723222.5440 - val_loss: 3911241422.4658\n",
      "Epoch 2981/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1457722438.6380 - val_loss: 3905689380.3836\n",
      "Epoch 2982/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1459640474.0509 - val_loss: 3896497394.8493\n",
      "Epoch 2983/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1458385415.0137 - val_loss: 3917128620.5662\n",
      "Epoch 2984/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1457688832.5010 - val_loss: 3899336876.7123\n",
      "Epoch 2985/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1457586171.1155 - val_loss: 3901229915.6164\n",
      "Epoch 2986/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1458361840.4697 - val_loss: 3906986092.5662\n",
      "Epoch 2987/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1458276513.0646 - val_loss: 3910483715.2146\n",
      "Epoch 2988/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1458993510.7006 - val_loss: 3909840720.2192\n",
      "Epoch 2989/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1458564997.7613 - val_loss: 3899509093.2603\n",
      "Epoch 2990/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1457501345.8160 - val_loss: 3897272917.6256\n",
      "Epoch 2991/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1458258774.9198 - val_loss: 3894152746.9589\n",
      "Epoch 2992/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1458226974.3092 - val_loss: 3906531605.4795\n",
      "Epoch 2993/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1457711151.3425 - val_loss: 3894289236.8950\n",
      "Epoch 2994/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1458485642.0196 - val_loss: 3912363740.2009\n",
      "Epoch 2995/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1457556262.8258 - val_loss: 3901566063.1963\n",
      "Epoch 2996/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1458005877.2290 - val_loss: 3909238663.4521\n",
      "Epoch 2997/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1457585803.3973 - val_loss: 3895941288.9132\n",
      "Epoch 2998/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1458055986.0978 - val_loss: 3908130854.1370\n",
      "Epoch 2999/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1459697947.3033 - val_loss: 3894110653.5160\n",
      "Epoch 3000/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1457077702.8885 - val_loss: 3913575732.1644\n",
      "Epoch 3001/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1457403010.5049 - val_loss: 3906004821.9178\n",
      "Epoch 3002/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1457197859.5695 - val_loss: 3904059088.3653\n",
      "Epoch 3003/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1457172003.1311 - val_loss: 3896276062.5388\n",
      "Epoch 3004/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1458230747.0528 - val_loss: 3898217473.7534\n",
      "Epoch 3005/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1457050925.8395 - val_loss: 3911156486.2831\n",
      "Epoch 3006/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1458200327.5147 - val_loss: 3898212771.7991\n",
      "Epoch 3007/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1456754081.6908 - val_loss: 3902063036.9315\n",
      "Epoch 3008/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1456649500.9315 - val_loss: 3919443939.6530\n",
      "Epoch 3009/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1456615705.4247 - val_loss: 3903206302.1005\n",
      "Epoch 3010/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1456945079.7339 - val_loss: 3902745253.6986\n",
      "Epoch 3011/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1457969873.4090 - val_loss: 3894283928.6941\n",
      "Epoch 3012/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1455712202.6458 - val_loss: 3915059130.4475\n",
      "Epoch 3013/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1459472181.6047 - val_loss: 3902306912.2922\n",
      "Epoch 3014/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1456452688.0313 - val_loss: 3909579801.1324\n",
      "Epoch 3015/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1456633302.9198 - val_loss: 3907483724.1279\n",
      "Epoch 3016/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1456352115.9765 - val_loss: 3914390880.1461\n",
      "Epoch 3017/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1457375248.0313 - val_loss: 3906810989.1507\n",
      "Epoch 3018/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1456237300.7280 - val_loss: 3909512593.8265\n",
      "Epoch 3019/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1456075736.9237 - val_loss: 3903525186.4840\n",
      "Epoch 3020/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1456412740.6967 - val_loss: 3905217685.1872\n",
      "Epoch 3021/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1455812045.9022 - val_loss: 3903891190.3562\n",
      "Epoch 3022/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1457342048.6888 - val_loss: 3898944715.9817\n",
      "Epoch 3023/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1456273245.3072 - val_loss: 3903559566.7580\n",
      "Epoch 3024/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 43us/step - loss: 1456764509.1820 - val_loss: 3907215361.3151\n",
      "Epoch 3025/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1455726984.7671 - val_loss: 3914061521.9726\n",
      "Epoch 3026/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1455756515.6947 - val_loss: 3910329764.9680\n",
      "Epoch 3027/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1455992328.0157 - val_loss: 3903749927.7443\n",
      "Epoch 3028/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1457038482.6614 - val_loss: 3903731616.7306\n",
      "Epoch 3029/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1456427522.0039 - val_loss: 3901075203.7991\n",
      "Epoch 3030/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1459307178.9589 - val_loss: 3913304614.4292\n",
      "Epoch 3031/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1456780908.7123 - val_loss: 3909107785.4977\n",
      "Epoch 3032/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1455833485.9022 - val_loss: 3902360028.3470\n",
      "Epoch 3033/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1455402881.0020 - val_loss: 3909808501.3333\n",
      "Epoch 3034/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1455784730.0509 - val_loss: 3906889720.2557\n",
      "Epoch 3035/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1456312272.6575 - val_loss: 3901765219.9452\n",
      "Epoch 3036/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1455371211.6477 - val_loss: 3896284128.4384\n",
      "Epoch 3037/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1455205480.0783 - val_loss: 3901846611.4338\n",
      "Epoch 3038/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1456291383.8591 - val_loss: 3908453710.9041\n",
      "Epoch 3039/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1455293381.6360 - val_loss: 3895944317.9543\n",
      "Epoch 3040/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1455404370.6614 - val_loss: 3905815584.2922\n",
      "Epoch 3041/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1456681653.8552 - val_loss: 3893170101.6256\n",
      "Epoch 3042/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1457880865.6908 - val_loss: 3907039510.7945\n",
      "Epoch 3043/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1455197443.2564 - val_loss: 3901907044.0913\n",
      "Epoch 3044/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1454811286.2935 - val_loss: 3907809733.9909\n",
      "Epoch 3045/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1455245854.0587 - val_loss: 3898180073.2055\n",
      "Epoch 3046/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1456121818.6771 - val_loss: 3908920194.9224\n",
      "Epoch 3047/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1455645256.6419 - val_loss: 3901072843.3973\n",
      "Epoch 3048/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1458033010.4736 - val_loss: 3899340634.7397\n",
      "Epoch 3049/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1455345560.9863 - val_loss: 3911219577.1324\n",
      "Epoch 3050/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1455033654.1057 - val_loss: 3902059781.9909\n",
      "Epoch 3051/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1455150364.0548 - val_loss: 3910391206.4292\n",
      "Epoch 3052/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1454952673.4403 - val_loss: 3906061596.4932\n",
      "Epoch 3053/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1456115154.9119 - val_loss: 3915593547.5434\n",
      "Epoch 3054/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1454958273.8787 - val_loss: 3898133597.8082\n",
      "Epoch 3055/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1456078932.1644 - val_loss: 3893377188.5297\n",
      "Epoch 3056/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1455938666.2074 - val_loss: 3919702982.2831\n",
      "Epoch 3057/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1459772843.9609 - val_loss: 3895076835.2146\n",
      "Epoch 3058/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1456520828.2427 - val_loss: 3920677924.3836\n",
      "Epoch 3059/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1454033561.2994 - val_loss: 3902329732.9680\n",
      "Epoch 3060/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1454899347.6634 - val_loss: 3893559671.6712\n",
      "Epoch 3061/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1456412711.2016 - val_loss: 3912166244.0913\n",
      "Epoch 3062/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1454883576.1096 - val_loss: 3902613972.8950\n",
      "Epoch 3063/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1454669976.2975 - val_loss: 3901036993.3151\n",
      "Epoch 3064/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1455606379.5851 - val_loss: 3899308415.2694\n",
      "Epoch 3065/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1454873060.8219 - val_loss: 3905898467.5068\n",
      "Epoch 3066/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1455923634.5988 - val_loss: 3904739832.5479\n",
      "Epoch 3067/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1454276250.3014 - val_loss: 3899484831.8539\n",
      "Epoch 3068/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1454786261.6673 - val_loss: 3915794993.8265\n",
      "Epoch 3069/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1454241249.2524 - val_loss: 3905889541.2603\n",
      "Epoch 3070/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1454404520.8297 - val_loss: 3911732688.8037\n",
      "Epoch 3071/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1454181593.4247 - val_loss: 3895909634.0457\n",
      "Epoch 3072/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1454616459.5225 - val_loss: 3905191963.4703\n",
      "Epoch 3073/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1455731426.4423 - val_loss: 3915929633.7534\n",
      "Epoch 3074/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1455191053.0254 - val_loss: 3901048311.9635\n",
      "Epoch 3075/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1454414335.2485 - val_loss: 3902223471.7808\n",
      "Epoch 3076/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1454523836.1174 - val_loss: 3891261201.0959\n",
      "Epoch 3077/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1454038510.4658 - val_loss: 3903260752.2192\n",
      "Epoch 3078/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1453582898.5988 - val_loss: 3903857524.0183\n",
      "Epoch 3079/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1454205305.7378 - val_loss: 3906442238.6849\n",
      "Epoch 3080/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1453730936.8611 - val_loss: 3900017339.9087\n",
      "Epoch 3081/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1454418801.7221 - val_loss: 3908928122.8858\n",
      "Epoch 3082/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1455155846.5127 - val_loss: 3899237365.4795\n",
      "Epoch 3083/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1453581417.7065 - val_loss: 3904145894.7215\n",
      "Epoch 3084/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1454785802.5205 - val_loss: 3918820224.0000\n",
      "Epoch 3085/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1454252740.0078 - val_loss: 3890880423.4521\n",
      "Epoch 3086/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1455523361.5656 - val_loss: 3915265588.7489\n",
      "Epoch 3087/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1453719815.5147 - val_loss: 3906475131.3242\n",
      "Epoch 3088/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 48us/step - loss: 1457552425.0802 - val_loss: 3883087065.8630\n",
      "Epoch 3089/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1453013213.9335 - val_loss: 3913868666.7397\n",
      "Epoch 3090/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1453948751.4051 - val_loss: 3911338318.9041\n",
      "Epoch 3091/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1456166450.3483 - val_loss: 3893481538.6301\n",
      "Epoch 3092/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1453692528.7202 - val_loss: 3903948069.9909\n",
      "Epoch 3093/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1454154190.0274 - val_loss: 3909520033.0228\n",
      "Epoch 3094/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1453055634.5362 - val_loss: 3897554561.1689\n",
      "Epoch 3095/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1454457652.6027 - val_loss: 3909171453.6621\n",
      "Epoch 3096/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1454547893.8552 - val_loss: 3889614419.1416\n",
      "Epoch 3097/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1453528924.3053 - val_loss: 3905919238.2831\n",
      "Epoch 3098/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1453309975.5460 - val_loss: 3905368308.1644\n",
      "Epoch 3099/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1452748114.6614 - val_loss: 3902866114.7763\n",
      "Epoch 3100/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1454264591.7808 - val_loss: 3893729481.0594\n",
      "Epoch 3101/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1454038917.7613 - val_loss: 3888703357.0776\n",
      "Epoch 3102/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1452733022.4344 - val_loss: 3908088215.5251\n",
      "Epoch 3103/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1453409355.8982 - val_loss: 3906349571.0685\n",
      "Epoch 3104/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1453294879.5616 - val_loss: 3907678583.8174\n",
      "Epoch 3105/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1453097953.5656 - val_loss: 3908234189.5890\n",
      "Epoch 3106/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1456990982.7632 - val_loss: 3889778112.4384\n",
      "Epoch 3107/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1453327999.7495 - val_loss: 3918071854.3196\n",
      "Epoch 3108/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1453993541.7613 - val_loss: 3909868122.3014\n",
      "Epoch 3109/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1453527654.3249 - val_loss: 3910888823.6712\n",
      "Epoch 3110/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1456565482.4579 - val_loss: 3885411765.9178\n",
      "Epoch 3111/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1453873239.6712 - val_loss: 3915544472.6941\n",
      "Epoch 3112/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1454344407.9217 - val_loss: 3903215383.8174\n",
      "Epoch 3113/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1453275968.3757 - val_loss: 3894173442.7763\n",
      "Epoch 3114/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1453946914.9432 - val_loss: 3906091893.0411\n",
      "Epoch 3115/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1452782603.1468 - val_loss: 3905822121.9361\n",
      "Epoch 3116/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1457270419.2877 - val_loss: 3884271666.2648\n",
      "Epoch 3117/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1454603475.9139 - val_loss: 3923334529.0228\n",
      "Epoch 3118/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1452942048.9393 - val_loss: 3906138360.6941\n",
      "Epoch 3119/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1453375107.3816 - val_loss: 3903011304.1826\n",
      "Epoch 3120/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1454863933.7456 - val_loss: 3889335012.3836\n",
      "Epoch 3121/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1452542831.6556 - val_loss: 3902688224.5845\n",
      "Epoch 3122/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1454814330.3640 - val_loss: 3899108587.3973\n",
      "Epoch 3123/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1456102829.2759 - val_loss: 3893550386.7032\n",
      "Epoch 3124/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1452127937.3777 - val_loss: 3906715048.0365\n",
      "Epoch 3125/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1455853842.5362 - val_loss: 3930485313.4612\n",
      "Epoch 3126/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1456428456.3288 - val_loss: 3894478231.8174\n",
      "Epoch 3127/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1452262360.1722 - val_loss: 3901566488.6941\n",
      "Epoch 3128/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1452554382.5284 - val_loss: 3916747361.4612\n",
      "Epoch 3129/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1453418320.6575 - val_loss: 3909713645.4429\n",
      "Epoch 3130/10000\n",
      "1022/1022 [==============================] - 0s 78us/step - loss: 1454367469.8395 - val_loss: 3894240537.5708\n",
      "Epoch 3131/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1451872154.8023 - val_loss: 3909160235.6895\n",
      "Epoch 3132/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1452786677.4795 - val_loss: 3911360625.8265\n",
      "Epoch 3133/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1453935110.6380 - val_loss: 3902940300.5662\n",
      "Epoch 3134/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1452193064.0783 - val_loss: 3895483028.6027\n",
      "Epoch 3135/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1451819104.3131 - val_loss: 3896215013.4064\n",
      "Epoch 3136/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1453025235.1624 - val_loss: 3901746481.2420\n",
      "Epoch 3137/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1452142162.4110 - val_loss: 3904643827.5799\n",
      "Epoch 3138/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1453214909.6204 - val_loss: 3894404952.5479\n",
      "Epoch 3139/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1453669821.1194 - val_loss: 3918317846.6484\n",
      "Epoch 3140/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1451933989.5734 - val_loss: 3899034109.9543\n",
      "Epoch 3141/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1452600941.8395 - val_loss: 3889702230.6484\n",
      "Epoch 3142/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1452169337.1115 - val_loss: 3906419433.0594\n",
      "Epoch 3143/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1453098904.0470 - val_loss: 3900815157.9178\n",
      "Epoch 3144/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1452401292.6497 - val_loss: 3903559612.9315\n",
      "Epoch 3145/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1452319855.5930 - val_loss: 3909493389.4429\n",
      "Epoch 3146/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1451635220.5401 - val_loss: 3900925265.6804\n",
      "Epoch 3147/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1453028229.3855 - val_loss: 3890704338.9954\n",
      "Epoch 3148/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1452936047.7182 - val_loss: 3904003258.8858\n",
      "Epoch 3149/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1451941617.5969 - val_loss: 3905578382.9041\n",
      "Epoch 3150/10000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1451230114.3170 - val_loss: 3902835613.2237\n",
      "Epoch 3151/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1452903773.1820 - val_loss: 3917884017.9726\n",
      "Epoch 3152/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 53us/step - loss: 1451276618.6458 - val_loss: 3899477528.8402\n",
      "Epoch 3153/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1451109102.8415 - val_loss: 3901120498.4110\n",
      "Epoch 3154/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1452698258.1605 - val_loss: 3897156372.4566\n",
      "Epoch 3155/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1451727646.1840 - val_loss: 3906791881.0594\n",
      "Epoch 3156/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1451847811.7573 - val_loss: 3901056561.0959\n",
      "Epoch 3157/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1451934957.4638 - val_loss: 3905393364.8950\n",
      "Epoch 3158/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1451711484.4932 - val_loss: 3907523992.1096\n",
      "Epoch 3159/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1453221528.2975 - val_loss: 3893499708.0548\n",
      "Epoch 3160/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1453696446.4971 - val_loss: 3896473217.4612\n",
      "Epoch 3161/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1452745200.4697 - val_loss: 3882442392.9863\n",
      "Epoch 3162/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1452379160.0470 - val_loss: 3912646017.1689\n",
      "Epoch 3163/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1451443093.7926 - val_loss: 3899006531.2146\n",
      "Epoch 3164/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1451307922.2857 - val_loss: 3887709219.6530\n",
      "Epoch 3165/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1451921551.7808 - val_loss: 3892879586.1918\n",
      "Epoch 3166/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1451589340.1800 - val_loss: 3894654111.4155\n",
      "Epoch 3167/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1452595692.4618 - val_loss: 3923619370.9589\n",
      "Epoch 3168/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1452425190.1996 - val_loss: 3911836383.4155\n",
      "Epoch 3169/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1453404997.6360 - val_loss: 3893387431.5982\n",
      "Epoch 3170/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1451474063.0294 - val_loss: 3907121821.0776\n",
      "Epoch 3171/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1450923483.9295 - val_loss: 3893840035.3607\n",
      "Epoch 3172/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1451055764.0391 - val_loss: 3907977505.4612\n",
      "Epoch 3173/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1450798982.2622 - val_loss: 3896767912.9132\n",
      "Epoch 3174/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1450946088.4540 - val_loss: 3897118894.7580\n",
      "Epoch 3175/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1450424282.4266 - val_loss: 3898810951.5982\n",
      "Epoch 3176/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1453882938.7397 - val_loss: 3889680988.6393\n",
      "Epoch 3177/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1450534914.0039 - val_loss: 3904522878.6849\n",
      "Epoch 3178/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1451957243.9922 - val_loss: 3907596429.4429\n",
      "Epoch 3179/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1451213156.9472 - val_loss: 3912324182.0639\n",
      "Epoch 3180/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1451749195.6477 - val_loss: 3904015160.8402\n",
      "Epoch 3181/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1452017728.3757 - val_loss: 3894543410.8493\n",
      "Epoch 3182/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1450493070.4031 - val_loss: 3902144434.4110\n",
      "Epoch 3183/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1450638385.8474 - val_loss: 3893323119.6347\n",
      "Epoch 3184/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1450935189.2916 - val_loss: 3885010748.0548\n",
      "Epoch 3185/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1450824584.1409 - val_loss: 3895617037.1507\n",
      "Epoch 3186/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1449925617.7221 - val_loss: 3909835435.3973\n",
      "Epoch 3187/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1451618033.4716 - val_loss: 3905168220.3470\n",
      "Epoch 3188/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1455380222.2466 - val_loss: 3897153551.3425\n",
      "Epoch 3189/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1451761037.0254 - val_loss: 3908022161.2420\n",
      "Epoch 3190/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1450100273.5969 - val_loss: 3897493495.5251\n",
      "Epoch 3191/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1450845899.3973 - val_loss: 3891533125.4064\n",
      "Epoch 3192/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1451115617.9413 - val_loss: 3907868018.4110\n",
      "Epoch 3193/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1450315722.0196 - val_loss: 3892945779.2877\n",
      "Epoch 3194/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1450537927.3894 - val_loss: 3905172141.7352\n",
      "Epoch 3195/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1451350971.3659 - val_loss: 3893303215.9269\n",
      "Epoch 3196/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1449627574.3562 - val_loss: 3896766247.1598\n",
      "Epoch 3197/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1451181973.9178 - val_loss: 3889894362.8858\n",
      "Epoch 3198/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1450198162.3483 - val_loss: 3907001933.2968\n",
      "Epoch 3199/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1451599386.4266 - val_loss: 3891813761.3151\n",
      "Epoch 3200/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1450557020.6810 - val_loss: 3902386343.3059\n",
      "Epoch 3201/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1450248199.3894 - val_loss: 3905255830.6484\n",
      "Epoch 3202/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1450224125.4951 - val_loss: 3896495157.1872\n",
      "Epoch 3203/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1449361162.3953 - val_loss: 3890984126.8311\n",
      "Epoch 3204/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1449390657.3777 - val_loss: 3891974396.2009\n",
      "Epoch 3205/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1449861717.4168 - val_loss: 3895369336.2557\n",
      "Epoch 3206/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1450066954.0196 - val_loss: 3908396740.9680\n",
      "Epoch 3207/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1449650569.7691 - val_loss: 3898674002.4110\n",
      "Epoch 3208/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1449285441.7534 - val_loss: 3898277740.1279\n",
      "Epoch 3209/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1449373184.2505 - val_loss: 3892168599.8174\n",
      "Epoch 3210/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1449901453.7769 - val_loss: 3890377078.7945\n",
      "Epoch 3211/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1452796459.2094 - val_loss: 3918432376.2557\n",
      "Epoch 3212/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1451325732.0705 - val_loss: 3896459866.0091\n",
      "Epoch 3213/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1449447650.6928 - val_loss: 3904756142.9041\n",
      "Epoch 3214/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1450143238.2622 - val_loss: 3893770164.0183\n",
      "Epoch 3215/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1449701962.6458 - val_loss: 3896491713.4612\n",
      "Epoch 3216/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 52us/step - loss: 1449783496.2661 - val_loss: 3898735901.5160\n",
      "Epoch 3217/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1452133898.2701 - val_loss: 3923315761.9726\n",
      "Epoch 3218/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1449043118.0900 - val_loss: 3883907956.4566\n",
      "Epoch 3219/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1450287086.2153 - val_loss: 3895587594.9589\n",
      "Epoch 3220/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1451228975.3425 - val_loss: 3883374459.6164\n",
      "Epoch 3221/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1448478858.0822 - val_loss: 3903893144.2557\n",
      "Epoch 3222/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1449066138.4266 - val_loss: 3902571315.8721\n",
      "Epoch 3223/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1450518698.4579 - val_loss: 3897477182.6849\n",
      "Epoch 3224/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1449524841.9569 - val_loss: 3899237942.0639\n",
      "Epoch 3225/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1449327185.1585 - val_loss: 3892674548.8950\n",
      "Epoch 3226/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1448863122.2857 - val_loss: 3890567714.0457\n",
      "Epoch 3227/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1449262994.5362 - val_loss: 3895908831.8539\n",
      "Epoch 3228/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1450923798.4814 - val_loss: 3889545196.7123\n",
      "Epoch 3229/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1448434683.2407 - val_loss: 3897304381.6621\n",
      "Epoch 3230/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1449809011.7260 - val_loss: 3892209506.1918\n",
      "Epoch 3231/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1449328383.7495 - val_loss: 3898633285.9909\n",
      "Epoch 3232/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1450033218.6301 - val_loss: 3911220528.2192\n",
      "Epoch 3233/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1449175578.8023 - val_loss: 3885264848.0731\n",
      "Epoch 3234/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1448371036.8063 - val_loss: 3896165911.8174\n",
      "Epoch 3235/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1450092639.4364 - val_loss: 3904449713.3881\n",
      "Epoch 3236/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1449495794.2231 - val_loss: 3888771941.6986\n",
      "Epoch 3237/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1450801240.4227 - val_loss: 3910292892.9315\n",
      "Epoch 3238/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1449549962.0196 - val_loss: 3877749893.9909\n",
      "Epoch 3239/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1448335294.3718 - val_loss: 3895624363.6895\n",
      "Epoch 3240/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1449355571.6008 - val_loss: 3892377664.8767\n",
      "Epoch 3241/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1449162114.5049 - val_loss: 3903670211.9452\n",
      "Epoch 3242/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1448920706.1292 - val_loss: 3898946787.7991\n",
      "Epoch 3243/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1448893950.1213 - val_loss: 3891758773.4795\n",
      "Epoch 3244/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1448067656.8924 - val_loss: 3896714809.5708\n",
      "Epoch 3245/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1449791986.7241 - val_loss: 3899472752.0731\n",
      "Epoch 3246/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1449740351.8748 - val_loss: 3889334667.9817\n",
      "Epoch 3247/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1448208380.4932 - val_loss: 3899850634.3744\n",
      "Epoch 3248/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1451235012.3836 - val_loss: 3878407808.1461\n",
      "Epoch 3249/10000\n",
      "1022/1022 [==============================] - 0s 82us/step - loss: 1450702404.2583 - val_loss: 3914290174.9772\n",
      "Epoch 3250/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1449024002.0039 - val_loss: 3889159602.9954\n",
      "Epoch 3251/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1448279220.8532 - val_loss: 3895515360.7306\n",
      "Epoch 3252/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1449589854.1840 - val_loss: 3892493331.8721\n",
      "Epoch 3253/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1448177360.4070 - val_loss: 3889285137.9726\n",
      "Epoch 3254/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1448001007.9687 - val_loss: 3885209317.5525\n",
      "Epoch 3255/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1448091340.9002 - val_loss: 3884034166.3562\n",
      "Epoch 3256/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1448930099.6008 - val_loss: 3883145131.8356\n",
      "Epoch 3257/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1448439890.6614 - val_loss: 3880414304.7306\n",
      "Epoch 3258/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1449136771.8826 - val_loss: 3893490933.9178\n",
      "Epoch 3259/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1448704865.1898 - val_loss: 3886744583.8904\n",
      "Epoch 3260/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1448182391.2955 - val_loss: 3897551164.4932\n",
      "Epoch 3261/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1448000435.6008 - val_loss: 3901271996.9315\n",
      "Epoch 3262/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1448496703.3738 - val_loss: 3889194049.8995\n",
      "Epoch 3263/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1449577579.9609 - val_loss: 3897293570.7763\n",
      "Epoch 3264/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1449295780.9472 - val_loss: 3883864417.6073\n",
      "Epoch 3265/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1447878791.0137 - val_loss: 3878078864.5114\n",
      "Epoch 3266/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1448498044.3679 - val_loss: 3886558426.8858\n",
      "Epoch 3267/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1448608980.6654 - val_loss: 3884610918.4292\n",
      "Epoch 3268/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1448942318.9667 - val_loss: 3895148503.6712\n",
      "Epoch 3269/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1447615711.1859 - val_loss: 3876339239.5982\n",
      "Epoch 3270/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1451505342.7476 - val_loss: 3898196715.9817\n",
      "Epoch 3271/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1448001399.2329 - val_loss: 3874793425.0959\n",
      "Epoch 3272/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1448341060.6341 - val_loss: 3887296994.6301\n",
      "Epoch 3273/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1449099785.1429 - val_loss: 3878992113.5342\n",
      "Epoch 3274/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1450772116.9159 - val_loss: 3884846948.9680\n",
      "Epoch 3275/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1449303666.9746 - val_loss: 3886470608.0731\n",
      "Epoch 3276/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1447805906.9119 - val_loss: 3881273338.4475\n",
      "Epoch 3277/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1448424470.6693 - val_loss: 3889784690.2648\n",
      "Epoch 3278/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1447036831.8121 - val_loss: 3885104419.6530\n",
      "Epoch 3279/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1449373105.9726 - val_loss: 3873363717.4064\n",
      "Epoch 3280/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 42us/step - loss: 1447569280.0000 - val_loss: 3893250864.5114\n",
      "Epoch 3281/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1447818243.0059 - val_loss: 3893089653.6256\n",
      "Epoch 3282/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1447689884.8063 - val_loss: 3879116206.0274\n",
      "Epoch 3283/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1447703729.4716 - val_loss: 3889877282.1918\n",
      "Epoch 3284/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1447036396.4618 - val_loss: 3891708521.2055\n",
      "Epoch 3285/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1446951285.7299 - val_loss: 3891113099.9817\n",
      "Epoch 3286/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1447213570.5049 - val_loss: 3888039241.2055\n",
      "Epoch 3287/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1447029826.1292 - val_loss: 3890083016.4749\n",
      "Epoch 3288/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1447176247.9843 - val_loss: 3879560403.2877\n",
      "Epoch 3289/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1447297618.1605 - val_loss: 3886982524.0548\n",
      "Epoch 3290/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1447596816.7202 - val_loss: 3875058692.9680\n",
      "Epoch 3291/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1446711499.8982 - val_loss: 3885011079.8904\n",
      "Epoch 3292/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1448051986.2857 - val_loss: 3891505982.5388\n",
      "Epoch 3293/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1447658622.1213 - val_loss: 3875957885.5160\n",
      "Epoch 3294/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1446987766.4814 - val_loss: 3878158330.0091\n",
      "Epoch 3295/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1449331634.4736 - val_loss: 3890033439.1233\n",
      "Epoch 3296/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1447530611.8513 - val_loss: 3893091408.5114\n",
      "Epoch 3297/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1449391545.8630 - val_loss: 3870269649.5342\n",
      "Epoch 3298/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1450668178.2857 - val_loss: 3902834477.8813\n",
      "Epoch 3299/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1446739472.2818 - val_loss: 3880653256.4749\n",
      "Epoch 3300/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1446495952.2818 - val_loss: 3877495096.9863\n",
      "Epoch 3301/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1446780191.8121 - val_loss: 3879871668.4566\n",
      "Epoch 3302/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1446545022.2466 - val_loss: 3881521961.3516\n",
      "Epoch 3303/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1448514513.9100 - val_loss: 3881419626.8128\n",
      "Epoch 3304/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1447580163.5068 - val_loss: 3894432785.3881\n",
      "Epoch 3305/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1447776882.2231 - val_loss: 3881556574.8311\n",
      "Epoch 3306/10000\n",
      "1022/1022 [==============================] - 0s 65us/step - loss: 1446688057.3620 - val_loss: 3878338185.7900\n",
      "Epoch 3307/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1447348568.5479 - val_loss: 3880595161.2785\n",
      "Epoch 3308/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1448947037.1820 - val_loss: 3892999339.3973\n",
      "Epoch 3309/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1448399007.4990 - val_loss: 3862601685.6256\n",
      "Epoch 3310/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1447628248.5479 - val_loss: 3876093466.1553\n",
      "Epoch 3311/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1447535870.8728 - val_loss: 3889807523.2146\n",
      "Epoch 3312/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1447273443.3190 - val_loss: 3887288413.5160\n",
      "Epoch 3313/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1446140474.8650 - val_loss: 3882321292.7123\n",
      "Epoch 3314/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1446932841.4560 - val_loss: 3877197806.9041\n",
      "Epoch 3315/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1446445198.7789 - val_loss: 3880822277.9909\n",
      "Epoch 3316/10000\n",
      "1022/1022 [==============================] - 0s 63us/step - loss: 1446888659.4129 - val_loss: 3874707283.2877\n",
      "Epoch 3317/10000\n",
      "1022/1022 [==============================] - 0s 67us/step - loss: 1447106407.7025 - val_loss: 3887364665.2785\n",
      "Epoch 3318/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1446860339.8513 - val_loss: 3890629779.8721\n",
      "Epoch 3319/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1449305834.4579 - val_loss: 3864309648.0731\n",
      "Epoch 3320/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1445760744.0783 - val_loss: 3884342324.3105\n",
      "Epoch 3321/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1447244727.3581 - val_loss: 3887355516.4932\n",
      "Epoch 3322/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1447775898.8023 - val_loss: 3882710465.8995\n",
      "Epoch 3323/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1447414452.6027 - val_loss: 3875583554.0457\n",
      "Epoch 3324/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1445932266.4579 - val_loss: 3881141242.0091\n",
      "Epoch 3325/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1447285239.9843 - val_loss: 3875230210.4840\n",
      "Epoch 3326/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1445674932.2270 - val_loss: 3889706606.9041\n",
      "Epoch 3327/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1446010570.3953 - val_loss: 3892020142.7580\n",
      "Epoch 3328/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1448858156.2114 - val_loss: 3877510868.7489\n",
      "Epoch 3329/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1447020673.1272 - val_loss: 3888278653.0776\n",
      "Epoch 3330/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1446076326.3249 - val_loss: 3871164882.1187\n",
      "Epoch 3331/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1446732377.1742 - val_loss: 3877778824.0365\n",
      "Epoch 3332/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1447183828.7906 - val_loss: 3873394228.3105\n",
      "Epoch 3333/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1446790974.8728 - val_loss: 3888087055.4886\n",
      "Epoch 3334/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1445623651.6947 - val_loss: 3884619536.0731\n",
      "Epoch 3335/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1446083645.4951 - val_loss: 3885713806.7580\n",
      "Epoch 3336/10000\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 1446615724.8376 - val_loss: 3874651282.1187\n",
      "Epoch 3337/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1445668587.9609 - val_loss: 3868454929.9726\n",
      "Epoch 3338/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1446689351.5147 - val_loss: 3866676663.9635\n",
      "Epoch 3339/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1445308470.2309 - val_loss: 3878637962.5205\n",
      "Epoch 3340/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1450855438.0274 - val_loss: 3873970278.1370\n",
      "Epoch 3341/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1446930831.4051 - val_loss: 3882363899.1781\n",
      "Epoch 3342/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1445574735.9061 - val_loss: 3879615238.5753\n",
      "Epoch 3343/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1445782472.3914 - val_loss: 3875916984.1096\n",
      "Epoch 3344/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 58us/step - loss: 1445441811.2877 - val_loss: 3872175211.1050\n",
      "Epoch 3345/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1446114662.1996 - val_loss: 3866498235.3242\n",
      "Epoch 3346/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1445105576.3288 - val_loss: 3877683700.4566\n",
      "Epoch 3347/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1446393127.5773 - val_loss: 3870457132.7123\n",
      "Epoch 3348/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1446138346.4579 - val_loss: 3871092683.2511\n",
      "Epoch 3349/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1445489692.8063 - val_loss: 3877932270.7580\n",
      "Epoch 3350/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1445453147.9295 - val_loss: 3875558058.2283\n",
      "Epoch 3351/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1445740181.0411 - val_loss: 3882444909.1507\n",
      "Epoch 3352/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1446935782.9511 - val_loss: 3881198880.5845\n",
      "Epoch 3353/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1446584421.9491 - val_loss: 3887900357.4064\n",
      "Epoch 3354/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1444928712.2661 - val_loss: 3876104583.7443\n",
      "Epoch 3355/10000\n",
      "1022/1022 [==============================] - 0s 73us/step - loss: 1445796581.4481 - val_loss: 3866630482.2648\n",
      "Epoch 3356/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1445235598.2779 - val_loss: 3865163736.8402\n",
      "Epoch 3357/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1446347925.9804 - val_loss: 3868916534.5023\n",
      "Epoch 3358/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1444894326.7319 - val_loss: 3880256121.1324\n",
      "Epoch 3359/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1444972588.5871 - val_loss: 3874369170.4110\n",
      "Epoch 3360/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1444944130.1292 - val_loss: 3871108307.4338\n",
      "Epoch 3361/10000\n",
      "1022/1022 [==============================] - 0s 63us/step - loss: 1445055242.5205 - val_loss: 3873826358.0639\n",
      "Epoch 3362/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1446367248.5323 - val_loss: 3882965295.3425\n",
      "Epoch 3363/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1445720395.3973 - val_loss: 3873382751.4155\n",
      "Epoch 3364/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1445077596.1800 - val_loss: 3873506943.7078\n",
      "Epoch 3365/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1445605552.9706 - val_loss: 3862666853.2603\n",
      "Epoch 3366/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1445252202.4579 - val_loss: 3868602119.4521\n",
      "Epoch 3367/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1445033471.4990 - val_loss: 3860938030.6119\n",
      "Epoch 3368/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1446576401.9100 - val_loss: 3882837040.0731\n",
      "Epoch 3369/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1445425771.3346 - val_loss: 3872867995.9087\n",
      "Epoch 3370/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1444915570.9746 - val_loss: 3873350851.5068\n",
      "Epoch 3371/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1445297815.0450 - val_loss: 3865230733.0046\n",
      "Epoch 3372/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1445832069.3855 - val_loss: 3869732405.0411\n",
      "Epoch 3373/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1444686488.2975 - val_loss: 3873483632.8037\n",
      "Epoch 3374/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1445908761.0489 - val_loss: 3878812645.1142\n",
      "Epoch 3375/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1444941759.8748 - val_loss: 3857337250.9224\n",
      "Epoch 3376/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1445894945.5656 - val_loss: 3856725075.5799\n",
      "Epoch 3377/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1445627291.9295 - val_loss: 3882183332.9680\n",
      "Epoch 3378/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1447164094.6223 - val_loss: 3875705710.4658\n",
      "Epoch 3379/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1445449603.8826 - val_loss: 3862730554.1553\n",
      "Epoch 3380/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1445316919.7339 - val_loss: 3869982618.4475\n",
      "Epoch 3381/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1449755705.1115 - val_loss: 3885934408.4749\n",
      "Epoch 3382/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1445718273.1272 - val_loss: 3849311674.8858\n",
      "Epoch 3383/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1445922685.2446 - val_loss: 3867739415.2329\n",
      "Epoch 3384/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1445354257.5342 - val_loss: 3862935103.2694\n",
      "Epoch 3385/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1445835288.5479 - val_loss: 3858756905.6438\n",
      "Epoch 3386/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1446606163.9139 - val_loss: 3871749850.0091\n",
      "Epoch 3387/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1444516507.6791 - val_loss: 3861422995.2877\n",
      "Epoch 3388/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1444194966.7945 - val_loss: 3861485708.5662\n",
      "Epoch 3389/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1445364941.9022 - val_loss: 3857911714.6301\n",
      "Epoch 3390/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1447605686.6067 - val_loss: 3886931835.6164\n",
      "Epoch 3391/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1444740730.6145 - val_loss: 3869368552.7671\n",
      "Epoch 3392/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1445119846.1996 - val_loss: 3862675759.6347\n",
      "Epoch 3393/10000\n",
      "1022/1022 [==============================] - 0s 75us/step - loss: 1444511493.7613 - val_loss: 3857486794.9589\n",
      "Epoch 3394/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1447526613.6673 - val_loss: 3884215598.1735\n",
      "Epoch 3395/10000\n",
      "1022/1022 [==============================] - 0s 68us/step - loss: 1444289695.6869 - val_loss: 3854697549.7352\n",
      "Epoch 3396/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1445128237.5890 - val_loss: 3861134508.2740\n",
      "Epoch 3397/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1444394689.0020 - val_loss: 3859775946.2283\n",
      "Epoch 3398/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1449890807.3581 - val_loss: 3871010027.3973\n",
      "Epoch 3399/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1444550370.3170 - val_loss: 3864304115.1416\n",
      "Epoch 3400/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1446779828.6027 - val_loss: 3844866373.6986\n",
      "Epoch 3401/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1443909789.8082 - val_loss: 3867051021.0046\n",
      "Epoch 3402/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1443747430.4501 - val_loss: 3868603156.4566\n",
      "Epoch 3403/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1443809561.2994 - val_loss: 3864916705.3151\n",
      "Epoch 3404/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1448147087.2798 - val_loss: 3871169786.8858\n",
      "Epoch 3405/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1445232451.3816 - val_loss: 3848361072.5114\n",
      "Epoch 3406/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1445820194.8180 - val_loss: 3855980109.1507\n",
      "Epoch 3407/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1444044534.9824 - val_loss: 3865517905.5342\n",
      "Epoch 3408/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 50us/step - loss: 1445422124.5871 - val_loss: 3871277135.3425\n",
      "Epoch 3409/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1444172647.9530 - val_loss: 3873632485.6986\n",
      "Epoch 3410/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1443868168.5166 - val_loss: 3869871393.8995\n",
      "Epoch 3411/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1447298182.0117 - val_loss: 3853111988.8950\n",
      "Epoch 3412/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1448558070.7319 - val_loss: 3889320311.8174\n",
      "Epoch 3413/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1443305929.1429 - val_loss: 3856748828.3470\n",
      "Epoch 3414/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1445659678.0587 - val_loss: 3862944177.5342\n",
      "Epoch 3415/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1444954717.9335 - val_loss: 3854954083.7991\n",
      "Epoch 3416/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1444759907.3190 - val_loss: 3867923066.1553\n",
      "Epoch 3417/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1444835961.2368 - val_loss: 3865407527.1598\n",
      "Epoch 3418/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1444852894.5597 - val_loss: 3855045245.3699\n",
      "Epoch 3419/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1444970424.8611 - val_loss: 3881115610.1553\n",
      "Epoch 3420/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1444158278.8885 - val_loss: 3856239960.1096\n",
      "Epoch 3421/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1446241224.6419 - val_loss: 3866394554.1553\n",
      "Epoch 3422/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1443974676.5401 - val_loss: 3859962342.1370\n",
      "Epoch 3423/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1443916680.8924 - val_loss: 3866123887.0502\n",
      "Epoch 3424/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1445637925.8239 - val_loss: 3870638514.9954\n",
      "Epoch 3425/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1444277405.0568 - val_loss: 3857214664.4749\n",
      "Epoch 3426/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1443739758.7162 - val_loss: 3857329791.4155\n",
      "Epoch 3427/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1444031692.3992 - val_loss: 3859548892.7854\n",
      "Epoch 3428/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1444727759.1546 - val_loss: 3854883291.6164\n",
      "Epoch 3429/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1444072604.5558 - val_loss: 3874269397.1872\n",
      "Epoch 3430/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1448189772.3992 - val_loss: 3850003036.0548\n",
      "Epoch 3431/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1443657869.4012 - val_loss: 3862536146.1187\n",
      "Epoch 3432/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1445445622.7319 - val_loss: 3879699095.8174\n",
      "Epoch 3433/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1444445211.8043 - val_loss: 3856251200.8767\n",
      "Epoch 3434/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1445450731.4599 - val_loss: 3876884234.9589\n",
      "Epoch 3435/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1444231990.6067 - val_loss: 3849100137.9361\n",
      "Epoch 3436/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1443031800.2348 - val_loss: 3861813538.4840\n",
      "Epoch 3437/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1443463352.6106 - val_loss: 3867969779.5799\n",
      "Epoch 3438/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1444191892.2896 - val_loss: 3878182986.3744\n",
      "Epoch 3439/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1444606186.9589 - val_loss: 3856737582.7580\n",
      "Epoch 3440/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1443806976.7515 - val_loss: 3857130316.8584\n",
      "Epoch 3441/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1443703054.2779 - val_loss: 3856450464.8767\n",
      "Epoch 3442/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1443193351.3894 - val_loss: 3860246627.3607\n",
      "Epoch 3443/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1443157675.7104 - val_loss: 3859236042.0822\n",
      "Epoch 3444/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1444844675.7573 - val_loss: 3870439027.7260\n",
      "Epoch 3445/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1442890429.1194 - val_loss: 3862609816.6941\n",
      "Epoch 3446/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1443751466.0822 - val_loss: 3864692811.3973\n",
      "Epoch 3447/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1444788713.7065 - val_loss: 3869428267.6895\n",
      "Epoch 3448/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1442726025.7691 - val_loss: 3863858155.5434\n",
      "Epoch 3449/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1445004318.5597 - val_loss: 3857949602.1918\n",
      "Epoch 3450/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1442673521.9726 - val_loss: 3870529693.5160\n",
      "Epoch 3451/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1444293431.1076 - val_loss: 3862966689.0228\n",
      "Epoch 3452/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1443966483.5382 - val_loss: 3875563111.5982\n",
      "Epoch 3453/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1445032085.7926 - val_loss: 3848167399.7443\n",
      "Epoch 3454/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1444815640.0470 - val_loss: 3864642927.7808\n",
      "Epoch 3455/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1442964599.2329 - val_loss: 3857587338.9589\n",
      "Epoch 3456/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1444237654.7945 - val_loss: 3860665844.3105\n",
      "Epoch 3457/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1443332416.1252 - val_loss: 3861987880.3288\n",
      "Epoch 3458/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1445027283.9139 - val_loss: 3872915954.5571\n",
      "Epoch 3459/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1444404869.3855 - val_loss: 3851335493.5525\n",
      "Epoch 3460/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1445605440.3757 - val_loss: 3848766023.1598\n",
      "Epoch 3461/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1443872603.5538 - val_loss: 3873789226.8128\n",
      "Epoch 3462/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1443066445.4012 - val_loss: 3865508308.0183\n",
      "Epoch 3463/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1446770750.6223 - val_loss: 3849291322.1553\n",
      "Epoch 3464/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1442403722.7710 - val_loss: 3865486573.5890\n",
      "Epoch 3465/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1442586853.4481 - val_loss: 3868810065.8265\n",
      "Epoch 3466/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1444373115.7417 - val_loss: 3859926530.0457\n",
      "Epoch 3467/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1443152594.7867 - val_loss: 3870089212.0548\n",
      "Epoch 3468/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1444373427.6008 - val_loss: 3870402662.1370\n",
      "Epoch 3469/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1443273715.9765 - val_loss: 3855327950.3196\n",
      "Epoch 3470/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1442817592.1096 - val_loss: 3862505346.3379\n",
      "Epoch 3471/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1442511505.0333 - val_loss: 3859011472.9498\n",
      "Epoch 3472/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 39us/step - loss: 1444500531.8513 - val_loss: 3851449719.8174\n",
      "Epoch 3473/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1446572267.3346 - val_loss: 3883771629.4429\n",
      "Epoch 3474/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1442284776.6419 - val_loss: 3871106713.2785\n",
      "Epoch 3475/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1442883262.3718 - val_loss: 3857000691.1416\n",
      "Epoch 3476/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1443968849.1585 - val_loss: 3858716462.4658\n",
      "Epoch 3477/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1442996057.1742 - val_loss: 3851608341.7717\n",
      "Epoch 3478/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1443176496.8454 - val_loss: 3864969538.1918\n",
      "Epoch 3479/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1444428993.8787 - val_loss: 3858607056.8037\n",
      "Epoch 3480/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1445079824.0313 - val_loss: 3876154460.9315\n",
      "Epoch 3481/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1442700986.3640 - val_loss: 3865023998.2466\n",
      "Epoch 3482/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1446495302.1370 - val_loss: 3850666707.4338\n",
      "Epoch 3483/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1442211663.1546 - val_loss: 3867592939.1050\n",
      "Epoch 3484/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1443196272.9706 - val_loss: 3863780366.3196\n",
      "Epoch 3485/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1443946952.3914 - val_loss: 3856630582.6484\n",
      "Epoch 3486/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1442652373.9178 - val_loss: 3871770223.7808\n",
      "Epoch 3487/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1443711987.9765 - val_loss: 3879081499.1781\n",
      "Epoch 3488/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1443007083.4599 - val_loss: 3871836183.5251\n",
      "Epoch 3489/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1441955245.0881 - val_loss: 3853417147.4703\n",
      "Epoch 3490/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1443526283.7730 - val_loss: 3857207525.6986\n",
      "Epoch 3491/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1442142209.7534 - val_loss: 3862430874.1553\n",
      "Epoch 3492/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1443334880.8141 - val_loss: 3865846595.2146\n",
      "Epoch 3493/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1442844563.9139 - val_loss: 3870296112.5114\n",
      "Epoch 3494/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1442536360.9550 - val_loss: 3867170676.0183\n",
      "Epoch 3495/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1444449493.1663 - val_loss: 3851038992.6575\n",
      "Epoch 3496/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1443503457.9413 - val_loss: 3852070781.8082\n",
      "Epoch 3497/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1446797041.8474 - val_loss: 3880825836.8584\n",
      "Epoch 3498/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1441572624.0313 - val_loss: 3859310266.0091\n",
      "Epoch 3499/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1443441421.0254 - val_loss: 3855087173.2603\n",
      "Epoch 3500/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1444582883.4442 - val_loss: 3869745956.9680\n",
      "Epoch 3501/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1442659592.3914 - val_loss: 3852926198.2100\n",
      "Epoch 3502/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1442189633.7534 - val_loss: 3870065116.0548\n",
      "Epoch 3503/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1441843769.2368 - val_loss: 3868495106.1918\n",
      "Epoch 3504/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1442447877.6360 - val_loss: 3862576731.0320\n",
      "Epoch 3505/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1451145050.0509 - val_loss: 3850873036.7123\n",
      "Epoch 3506/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1442728007.8904 - val_loss: 3870721197.1507\n",
      "Epoch 3507/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1442386954.7710 - val_loss: 3871404068.3836\n",
      "Epoch 3508/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1442252145.2211 - val_loss: 3860649703.7443\n",
      "Epoch 3509/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1442469242.5519 - val_loss: 3867517277.3699\n",
      "Epoch 3510/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1442517124.5088 - val_loss: 3867661550.7580\n",
      "Epoch 3511/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1443853858.8180 - val_loss: 3875930275.9452\n",
      "Epoch 3512/10000\n",
      "1022/1022 [==============================] - 0s 65us/step - loss: 1442279671.4834 - val_loss: 3864150700.1279\n",
      "Epoch 3513/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1444306599.0763 - val_loss: 3872522114.6301\n",
      "Epoch 3514/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1443498698.8963 - val_loss: 3849904435.4338\n",
      "Epoch 3515/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1441688473.4247 - val_loss: 3857754150.8676\n",
      "Epoch 3516/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1442580655.3425 - val_loss: 3880446827.5434\n",
      "Epoch 3517/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1444172822.0431 - val_loss: 3862303195.7626\n",
      "Epoch 3518/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1442399168.1252 - val_loss: 3871158201.5708\n",
      "Epoch 3519/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1443915004.9941 - val_loss: 3871934763.5434\n",
      "Epoch 3520/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1441523619.5695 - val_loss: 3854219916.8584\n",
      "Epoch 3521/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1441796645.8239 - val_loss: 3851435946.0822\n",
      "Epoch 3522/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1443846001.4716 - val_loss: 3869165379.3607\n",
      "Epoch 3523/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1443378496.3757 - val_loss: 3850111344.5114\n",
      "Epoch 3524/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1442094086.5127 - val_loss: 3867126963.5799\n",
      "Epoch 3525/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1441663570.9119 - val_loss: 3869619036.6393\n",
      "Epoch 3526/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1442195677.6830 - val_loss: 3871701931.5434\n",
      "Epoch 3527/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1441595780.0078 - val_loss: 3865150196.8950\n",
      "Epoch 3528/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1441998264.3601 - val_loss: 3863473997.4429\n",
      "Epoch 3529/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1442874798.5910 - val_loss: 3851840718.6119\n",
      "Epoch 3530/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1443173157.0724 - val_loss: 3853949837.8813\n",
      "Epoch 3531/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1441608087.7965 - val_loss: 3862424671.1233\n",
      "Epoch 3532/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1441595712.4384 - val_loss: 3871019106.7763\n",
      "Epoch 3533/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1444178947.0059 - val_loss: 3855106005.0411\n",
      "Epoch 3534/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1442678863.4051 - val_loss: 3861409804.8584\n",
      "Epoch 3535/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1442142798.1526 - val_loss: 3861395392.2922\n",
      "Epoch 3536/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 63us/step - loss: 1442296815.7182 - val_loss: 3864493907.5799\n",
      "Epoch 3537/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1442146247.3894 - val_loss: 3876728755.8721\n",
      "Epoch 3538/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1443469659.3033 - val_loss: 3866491125.0411\n",
      "Epoch 3539/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1442045389.9022 - val_loss: 3870450472.7671\n",
      "Epoch 3540/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1442095179.5225 - val_loss: 3869536329.3516\n",
      "Epoch 3541/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1441371695.3425 - val_loss: 3854954456.8402\n",
      "Epoch 3542/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1441963279.2798 - val_loss: 3868324446.8311\n",
      "Epoch 3543/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1442736661.2916 - val_loss: 3868397128.7671\n",
      "Epoch 3544/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1441643674.3014 - val_loss: 3851403076.0913\n",
      "Epoch 3545/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1442163499.5851 - val_loss: 3873017339.9087\n",
      "Epoch 3546/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1441433422.5284 - val_loss: 3860387685.6986\n",
      "Epoch 3547/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1441423184.0313 - val_loss: 3859550082.3379\n",
      "Epoch 3548/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1441885165.9648 - val_loss: 3873027858.8493\n",
      "Epoch 3549/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1442934903.9843 - val_loss: 3866894103.5251\n",
      "Epoch 3550/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1441877434.3640 - val_loss: 3850120339.8721\n",
      "Epoch 3551/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1441926180.8219 - val_loss: 3862179914.5205\n",
      "Epoch 3552/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1442170328.0470 - val_loss: 3868938821.1142\n",
      "Epoch 3553/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1441279085.7143 - val_loss: 3853756851.5799\n",
      "Epoch 3554/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1441607061.9178 - val_loss: 3869318764.2740\n",
      "Epoch 3555/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1442368517.5108 - val_loss: 3850246469.8447\n",
      "Epoch 3556/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1441168128.7515 - val_loss: 3869675988.8950\n",
      "Epoch 3557/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1443953253.9491 - val_loss: 3857611492.0913\n",
      "Epoch 3558/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1443186274.6928 - val_loss: 3854048275.8721\n",
      "Epoch 3559/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1440909321.2681 - val_loss: 3873537044.3105\n",
      "Epoch 3560/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1441699322.2387 - val_loss: 3867869016.2557\n",
      "Epoch 3561/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1442856024.1722 - val_loss: 3848380143.3425\n",
      "Epoch 3562/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1441391981.2133 - val_loss: 3866565787.0320\n",
      "Epoch 3563/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1441650192.0313 - val_loss: 3878966829.0046\n",
      "Epoch 3564/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1441833039.1546 - val_loss: 3876149299.2877\n",
      "Epoch 3565/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1440497176.0470 - val_loss: 3860587659.8356\n",
      "Epoch 3566/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1442515507.3503 - val_loss: 3859537035.8356\n",
      "Epoch 3567/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1442867000.3601 - val_loss: 3848842990.9041\n",
      "Epoch 3568/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1443304095.8121 - val_loss: 3853145059.5068\n",
      "Epoch 3569/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1440211140.3836 - val_loss: 3875133632.7306\n",
      "Epoch 3570/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1443103588.2583 - val_loss: 3860561841.8265\n",
      "Epoch 3571/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1441414037.5421 - val_loss: 3873073683.4338\n",
      "Epoch 3572/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1441805241.9883 - val_loss: 3859030929.0959\n",
      "Epoch 3573/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1442028675.2564 - val_loss: 3865650667.3973\n",
      "Epoch 3574/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1440774699.5851 - val_loss: 3871427687.4521\n",
      "Epoch 3575/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1443072427.5851 - val_loss: 3864448827.6164\n",
      "Epoch 3576/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1443069614.3405 - val_loss: 3884423933.6621\n",
      "Epoch 3577/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1443526302.5597 - val_loss: 3855069441.4612\n",
      "Epoch 3578/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1441716506.3014 - val_loss: 3864550821.6986\n",
      "Epoch 3579/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1440905004.8376 - val_loss: 3860989352.1826\n",
      "Epoch 3580/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1443361278.4971 - val_loss: 3856430701.8813\n",
      "Epoch 3581/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1441142125.7143 - val_loss: 3876804415.7078\n",
      "Epoch 3582/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1443269282.4423 - val_loss: 3868950844.6393\n",
      "Epoch 3583/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1441176463.6556 - val_loss: 3856369090.0457\n",
      "Epoch 3584/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1440698867.4755 - val_loss: 3857792359.5982\n",
      "Epoch 3585/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1441120604.1800 - val_loss: 3863182650.7397\n",
      "Epoch 3586/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1442456523.1468 - val_loss: 3858325397.6256\n",
      "Epoch 3587/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1441338602.9589 - val_loss: 3878307835.7626\n",
      "Epoch 3588/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1441322307.6321 - val_loss: 3871364123.4703\n",
      "Epoch 3589/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1440788004.9472 - val_loss: 3859968683.8356\n",
      "Epoch 3590/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1441679089.9726 - val_loss: 3874703472.6575\n",
      "Epoch 3591/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1441897272.8611 - val_loss: 3858777539.7991\n",
      "Epoch 3592/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1443525132.5245 - val_loss: 3873435691.5434\n",
      "Epoch 3593/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1442639494.5127 - val_loss: 3856656270.3196\n",
      "Epoch 3594/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1440849209.7378 - val_loss: 3862127654.1370\n",
      "Epoch 3595/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1441579807.3112 - val_loss: 3864243816.4749\n",
      "Epoch 3596/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1443618954.7710 - val_loss: 3873826900.6027\n",
      "Epoch 3597/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1440618646.4188 - val_loss: 3851316041.0594\n",
      "Epoch 3598/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1441366541.7769 - val_loss: 3862114255.3425\n",
      "Epoch 3599/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1440710441.0802 - val_loss: 3852688871.4521\n",
      "Epoch 3600/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 46us/step - loss: 1441498243.2564 - val_loss: 3868231751.4521\n",
      "Epoch 3601/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1442411754.9589 - val_loss: 3852846449.9726\n",
      "Epoch 3602/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1440606168.2975 - val_loss: 3857345139.2877\n",
      "Epoch 3603/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1441890338.3170 - val_loss: 3883203101.5160\n",
      "Epoch 3604/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1441102564.4462 - val_loss: 3863105785.1324\n",
      "Epoch 3605/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1440377698.4423 - val_loss: 3858269528.9863\n",
      "Epoch 3606/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1444849493.2916 - val_loss: 3842936075.8356\n",
      "Epoch 3607/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1439963942.5753 - val_loss: 3866165012.7489\n",
      "Epoch 3608/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1440493048.7358 - val_loss: 3873480684.4201\n",
      "Epoch 3609/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1441846718.9980 - val_loss: 3854946034.2648\n",
      "Epoch 3610/10000\n",
      "1022/1022 [==============================] - 0s 69us/step - loss: 1440520395.6477 - val_loss: 3874676781.4429\n",
      "Epoch 3611/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1440758721.3777 - val_loss: 3860602024.1826\n",
      "Epoch 3612/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1441427617.9413 - val_loss: 3859375450.0091\n",
      "Epoch 3613/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1441146460.9315 - val_loss: 3864782503.5982\n",
      "Epoch 3614/10000\n",
      "1022/1022 [==============================] - 0s 67us/step - loss: 1441288731.3033 - val_loss: 3870669481.3516\n",
      "Epoch 3615/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1442032515.7573 - val_loss: 3871061058.4840\n",
      "Epoch 3616/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1442403330.2544 - val_loss: 3847226306.9224\n",
      "Epoch 3617/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1441149020.6810 - val_loss: 3854672838.2831\n",
      "Epoch 3618/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1440207793.3464 - val_loss: 3871414631.1598\n",
      "Epoch 3619/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1444282071.9217 - val_loss: 3847305407.5616\n",
      "Epoch 3620/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1441010703.2798 - val_loss: 3875951935.7078\n",
      "Epoch 3621/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1440949795.8200 - val_loss: 3859835146.9589\n",
      "Epoch 3622/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1443267614.3092 - val_loss: 3869421231.9269\n",
      "Epoch 3623/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1443850095.4677 - val_loss: 3855710036.0183\n",
      "Epoch 3624/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1440257372.1800 - val_loss: 3860620198.2831\n",
      "Epoch 3625/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1440283621.6986 - val_loss: 3875447077.8447\n",
      "Epoch 3626/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1441845883.6164 - val_loss: 3868849568.2922\n",
      "Epoch 3627/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1441770329.4247 - val_loss: 3866835603.8721\n",
      "Epoch 3628/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1440158860.7750 - val_loss: 3850645551.1963\n",
      "Epoch 3629/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1441106354.5988 - val_loss: 3859998626.3379\n",
      "Epoch 3630/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1443827647.1233 - val_loss: 3868421794.6301\n",
      "Epoch 3631/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1440230721.1272 - val_loss: 3850081309.6621\n",
      "Epoch 3632/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1440348429.2759 - val_loss: 3856930227.5799\n",
      "Epoch 3633/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1441756535.0450 - val_loss: 3861798033.2420\n",
      "Epoch 3634/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1443974348.2740 - val_loss: 3878210333.6621\n",
      "Epoch 3635/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1440875369.2055 - val_loss: 3854891845.9909\n",
      "Epoch 3636/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1440137710.9667 - val_loss: 3863898606.1735\n",
      "Epoch 3637/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1439750679.0450 - val_loss: 3858665491.2877\n",
      "Epoch 3638/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1441077419.8356 - val_loss: 3849629734.7215\n",
      "Epoch 3639/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1441917436.4932 - val_loss: 3876348445.0776\n",
      "Epoch 3640/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1442517648.7828 - val_loss: 3852701909.4795\n",
      "Epoch 3641/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1440908353.6282 - val_loss: 3869416429.5890\n",
      "Epoch 3642/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1441170318.7789 - val_loss: 3877238132.6027\n",
      "Epoch 3643/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1440663941.6360 - val_loss: 3862724741.8447\n",
      "Epoch 3644/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1440402171.4912 - val_loss: 3850438516.6027\n",
      "Epoch 3645/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1441032371.3503 - val_loss: 3849078324.8950\n",
      "Epoch 3646/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1440769323.8356 - val_loss: 3860414574.9041\n",
      "Epoch 3647/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1440109537.3151 - val_loss: 3866446270.1005\n",
      "Epoch 3648/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1441212083.9765 - val_loss: 3864751808.7306\n",
      "Epoch 3649/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1440746731.8356 - val_loss: 3856061192.4749\n",
      "Epoch 3650/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1441103054.6536 - val_loss: 3862233186.6301\n",
      "Epoch 3651/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1441859017.6438 - val_loss: 3848115507.2877\n",
      "Epoch 3652/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1443005470.8102 - val_loss: 3860653225.4977\n",
      "Epoch 3653/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1440767810.1292 - val_loss: 3870654534.8676\n",
      "Epoch 3654/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1444198632.4540 - val_loss: 3851540737.3151\n",
      "Epoch 3655/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1439611802.8023 - val_loss: 3868727232.1461\n",
      "Epoch 3656/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1440176970.1448 - val_loss: 3867991929.7169\n",
      "Epoch 3657/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1440343517.9335 - val_loss: 3871965952.0000\n",
      "Epoch 3658/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1442320804.8219 - val_loss: 3859327892.3105\n",
      "Epoch 3659/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1440112423.4521 - val_loss: 3862917774.1735\n",
      "Epoch 3660/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1440292582.4501 - val_loss: 3867818752.1461\n",
      "Epoch 3661/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1441607043.1311 - val_loss: 3851447666.8493\n",
      "Epoch 3662/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1440083130.6145 - val_loss: 3874159406.1735\n",
      "Epoch 3663/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1441943758.4031 - val_loss: 3874611292.4932\n",
      "Epoch 3664/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 60us/step - loss: 1440249626.3014 - val_loss: 3856754006.5023\n",
      "Epoch 3665/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1440116154.3640 - val_loss: 3859497424.2192\n",
      "Epoch 3666/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1440412003.6947 - val_loss: 3850307958.9406\n",
      "Epoch 3667/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1441370340.1957 - val_loss: 3851719876.3836\n",
      "Epoch 3668/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1439570463.3112 - val_loss: 3861108757.6256\n",
      "Epoch 3669/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1440866619.1155 - val_loss: 3855152972.4201\n",
      "Epoch 3670/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1440488068.0078 - val_loss: 3875854197.1872\n",
      "Epoch 3671/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1439802110.7476 - val_loss: 3853626521.2785\n",
      "Epoch 3672/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1439617911.9843 - val_loss: 3861291813.1142\n",
      "Epoch 3673/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1439938643.9139 - val_loss: 3863412180.7489\n",
      "Epoch 3674/10000\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 1441007475.2250 - val_loss: 3869263805.3699\n",
      "Epoch 3675/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1439465998.0274 - val_loss: 3871409553.3881\n",
      "Epoch 3676/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1439824289.8160 - val_loss: 3852903900.2009\n",
      "Epoch 3677/10000\n",
      "1022/1022 [==============================] - 0s 65us/step - loss: 1440175420.3679 - val_loss: 3850377902.7580\n",
      "Epoch 3678/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1439309328.4070 - val_loss: 3857658738.1187\n",
      "Epoch 3679/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1439165482.5832 - val_loss: 3868202993.0959\n",
      "Epoch 3680/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1439839266.8180 - val_loss: 3870993525.0411\n",
      "Epoch 3681/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1440071058.0352 - val_loss: 3852351676.7854\n",
      "Epoch 3682/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1441564998.5127 - val_loss: 3871232337.2420\n",
      "Epoch 3683/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1441482780.8063 - val_loss: 3856727680.4384\n",
      "Epoch 3684/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1440062123.3346 - val_loss: 3863797836.2740\n",
      "Epoch 3685/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1439307729.4090 - val_loss: 3852734875.3242\n",
      "Epoch 3686/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1441871086.4658 - val_loss: 3854259519.4155\n",
      "Epoch 3687/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1440552293.9491 - val_loss: 3846288949.3333\n",
      "Epoch 3688/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1443850387.2877 - val_loss: 3885439310.3196\n",
      "Epoch 3689/10000\n",
      "1022/1022 [==============================] - 0s 67us/step - loss: 1441345197.2133 - val_loss: 3853437617.2420\n",
      "Epoch 3690/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1439660160.7515 - val_loss: 3856215914.9589\n",
      "Epoch 3691/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1440494562.9432 - val_loss: 3869151107.2146\n",
      "Epoch 3692/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1441073407.2485 - val_loss: 3855645943.2329\n",
      "Epoch 3693/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1440658366.4971 - val_loss: 3853618137.5708\n",
      "Epoch 3694/10000\n",
      "1022/1022 [==============================] - 0s 63us/step - loss: 1440340438.5440 - val_loss: 3870317876.6027\n",
      "Epoch 3695/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1439093351.7025 - val_loss: 3850664360.9132\n",
      "Epoch 3696/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1439374240.3131 - val_loss: 3858832142.7580\n",
      "Epoch 3697/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1441807604.2270 - val_loss: 3870160777.2055\n",
      "Epoch 3698/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1440771138.8806 - val_loss: 3871904119.2329\n",
      "Epoch 3699/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1442875002.7397 - val_loss: 3847198552.4018\n",
      "Epoch 3700/10000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1439245724.0548 - val_loss: 3869707287.9635\n",
      "Epoch 3701/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1440712988.0548 - val_loss: 3844429657.1324\n",
      "Epoch 3702/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1438995760.8454 - val_loss: 3862654270.1005\n",
      "Epoch 3703/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1440413409.4403 - val_loss: 3862295819.1050\n",
      "Epoch 3704/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1441457867.2720 - val_loss: 3848907537.8265\n",
      "Epoch 3705/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1440398532.3836 - val_loss: 3866099930.3014\n",
      "Epoch 3706/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1440462636.8376 - val_loss: 3865948130.3379\n",
      "Epoch 3707/10000\n",
      "1022/1022 [==============================] - 0s 66us/step - loss: 1440819166.9354 - val_loss: 3869263667.2877\n",
      "Epoch 3708/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1439761148.1800 - val_loss: 3842150471.8904\n",
      "Epoch 3709/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1439140093.2446 - val_loss: 3857634396.7854\n",
      "Epoch 3710/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1441508580.4462 - val_loss: 3861795300.9680\n",
      "Epoch 3711/10000\n",
      "1022/1022 [==============================] - 0s 66us/step - loss: 1440132839.8278 - val_loss: 3854960470.3562\n",
      "Epoch 3712/10000\n",
      "1022/1022 [==============================] - 0s 65us/step - loss: 1439612336.3444 - val_loss: 3852961694.1005\n",
      "Epoch 3713/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1439533166.2153 - val_loss: 3869835096.1096\n",
      "Epoch 3714/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1439637474.4423 - val_loss: 3861605124.8219\n",
      "Epoch 3715/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1438867833.9883 - val_loss: 3853938569.9361\n",
      "Epoch 3716/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1440342503.9530 - val_loss: 3836823274.8128\n",
      "Epoch 3717/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1438759522.4423 - val_loss: 3849899988.4566\n",
      "Epoch 3718/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1440648659.1624 - val_loss: 3867299299.0685\n",
      "Epoch 3719/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1438787608.5479 - val_loss: 3859257381.5525\n",
      "Epoch 3720/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1441304994.6928 - val_loss: 3848180921.5708\n",
      "Epoch 3721/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1439941984.5636 - val_loss: 3866127486.8311\n",
      "Epoch 3722/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1439589426.7241 - val_loss: 3866943039.7078\n",
      "Epoch 3723/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1444139208.1409 - val_loss: 3836963853.8813\n",
      "Epoch 3724/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1440089039.0294 - val_loss: 3871259418.0091\n",
      "Epoch 3725/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1439323707.6164 - val_loss: 3857157055.5616\n",
      "Epoch 3726/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1439436626.4110 - val_loss: 3860321937.8265\n",
      "Epoch 3727/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1439878547.0372 - val_loss: 3862456952.6941\n",
      "Epoch 3728/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 48us/step - loss: 1440043661.9022 - val_loss: 3841686448.2192\n",
      "Epoch 3729/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1440522160.0939 - val_loss: 3851989063.7443\n",
      "Epoch 3730/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1440051890.0978 - val_loss: 3853114682.0091\n",
      "Epoch 3731/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1440208342.0431 - val_loss: 3867201607.1598\n",
      "Epoch 3732/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1438886138.8650 - val_loss: 3856474018.4840\n",
      "Epoch 3733/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1439903608.9863 - val_loss: 3845269456.5114\n",
      "Epoch 3734/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1440094697.9569 - val_loss: 3858026262.7945\n",
      "Epoch 3735/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1439370356.8532 - val_loss: 3852216738.0457\n",
      "Epoch 3736/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1441527907.9452 - val_loss: 3867336727.6712\n",
      "Epoch 3737/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1443122928.7202 - val_loss: 3841973220.3836\n",
      "Epoch 3738/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1439564163.8826 - val_loss: 3872790788.9680\n",
      "Epoch 3739/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1441191553.5029 - val_loss: 3872950943.4155\n",
      "Epoch 3740/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1439035281.5342 - val_loss: 3856784948.4566\n",
      "Epoch 3741/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1438720568.1096 - val_loss: 3849524883.1416\n",
      "Epoch 3742/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1439620146.8493 - val_loss: 3849871009.7534\n",
      "Epoch 3743/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1438777106.0352 - val_loss: 3845952478.9772\n",
      "Epoch 3744/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1438651892.4775 - val_loss: 3866535287.5251\n",
      "Epoch 3745/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1439431844.8219 - val_loss: 3863737937.6804\n",
      "Epoch 3746/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1438323885.0881 - val_loss: 3856070683.3242\n",
      "Epoch 3747/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1438847965.4325 - val_loss: 3856843401.4977\n",
      "Epoch 3748/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1440284342.3562 - val_loss: 3852061626.1553\n",
      "Epoch 3749/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1440071148.4618 - val_loss: 3873482051.0685\n",
      "Epoch 3750/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1441244663.7339 - val_loss: 3870590321.8265\n",
      "Epoch 3751/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1438203715.6321 - val_loss: 3843228775.1598\n",
      "Epoch 3752/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1438504337.7847 - val_loss: 3850502111.2694\n",
      "Epoch 3753/10000\n",
      "1022/1022 [==============================] - 0s 67us/step - loss: 1439193911.6086 - val_loss: 3864697613.7352\n",
      "Epoch 3754/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1441159786.9589 - val_loss: 3849782312.6210\n",
      "Epoch 3755/10000\n",
      "1022/1022 [==============================] - 0s 75us/step - loss: 1438820846.7162 - val_loss: 3860417230.4658\n",
      "Epoch 3756/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1438799915.3346 - val_loss: 3855997121.1689\n",
      "Epoch 3757/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1440057496.7984 - val_loss: 3859772160.4384\n",
      "Epoch 3758/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1439387001.4873 - val_loss: 3842645530.1553\n",
      "Epoch 3759/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1438201906.9746 - val_loss: 3852251391.5616\n",
      "Epoch 3760/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1438981432.8611 - val_loss: 3871424220.6393\n",
      "Epoch 3761/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1439385347.2564 - val_loss: 3852944024.5479\n",
      "Epoch 3762/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1438094139.6164 - val_loss: 3856229854.3927\n",
      "Epoch 3763/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1440843559.8278 - val_loss: 3859534264.8402\n",
      "Epoch 3764/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1439151249.2838 - val_loss: 3841242683.6164\n",
      "Epoch 3765/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1439481936.9706 - val_loss: 3858597850.4475\n",
      "Epoch 3766/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1438408392.1409 - val_loss: 3858548295.4521\n",
      "Epoch 3767/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1437909705.8943 - val_loss: 3851194045.8082\n",
      "Epoch 3768/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1438793331.8513 - val_loss: 3844612066.7763\n",
      "Epoch 3769/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1440434608.8454 - val_loss: 3857122015.2694\n",
      "Epoch 3770/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1438294610.9119 - val_loss: 3844606948.0913\n",
      "Epoch 3771/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1438478923.3973 - val_loss: 3857032332.5662\n",
      "Epoch 3772/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1438533993.4560 - val_loss: 3850378586.4475\n",
      "Epoch 3773/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1438467195.9922 - val_loss: 3853063695.1963\n",
      "Epoch 3774/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1438464708.8845 - val_loss: 3863185532.7854\n",
      "Epoch 3775/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1438930803.4755 - val_loss: 3842716460.2740\n",
      "Epoch 3776/10000\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 1438908220.1174 - val_loss: 3859327093.6256\n",
      "Epoch 3777/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1439501591.5460 - val_loss: 3863181715.4338\n",
      "Epoch 3778/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1440716853.2290 - val_loss: 3842996947.5799\n",
      "Epoch 3779/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1440061347.8200 - val_loss: 3841133274.4475\n",
      "Epoch 3780/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1437775949.4012 - val_loss: 3851638392.9863\n",
      "Epoch 3781/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1438797852.5558 - val_loss: 3853792813.7352\n",
      "Epoch 3782/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1438197754.7397 - val_loss: 3850262189.4429\n",
      "Epoch 3783/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1439754454.6693 - val_loss: 3861872218.7397\n",
      "Epoch 3784/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1437720709.2603 - val_loss: 3843485158.5753\n",
      "Epoch 3785/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1439589282.5675 - val_loss: 3854874877.6621\n",
      "Epoch 3786/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1437822656.0000 - val_loss: 3849542372.2374\n",
      "Epoch 3787/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1438252039.2642 - val_loss: 3853606566.1370\n",
      "Epoch 3788/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1437973697.1272 - val_loss: 3843928649.0594\n",
      "Epoch 3789/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1442916326.9511 - val_loss: 3869274347.6895\n",
      "Epoch 3790/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1437649125.5734 - val_loss: 3844271763.8721\n",
      "Epoch 3791/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1438205243.4912 - val_loss: 3845965047.8174\n",
      "Epoch 3792/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 60us/step - loss: 1440852386.5675 - val_loss: 3838151760.3653\n",
      "Epoch 3793/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1438035149.4012 - val_loss: 3847871173.9909\n",
      "Epoch 3794/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1440823588.5088 - val_loss: 3849893929.4977\n",
      "Epoch 3795/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1438900115.6634 - val_loss: 3856616928.8767\n",
      "Epoch 3796/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1438776927.1859 - val_loss: 3867497330.7032\n",
      "Epoch 3797/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1440212545.2524 - val_loss: 3845344313.4247\n",
      "Epoch 3798/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1439361044.0391 - val_loss: 3871999407.0502\n",
      "Epoch 3799/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1438731125.8552 - val_loss: 3842428737.8995\n",
      "Epoch 3800/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1437567761.9100 - val_loss: 3855219103.8539\n",
      "Epoch 3801/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1437729264.2192 - val_loss: 3847644827.0320\n",
      "Epoch 3802/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1441047475.3503 - val_loss: 3861023296.5845\n",
      "Epoch 3803/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1438040007.8904 - val_loss: 3835245861.8447\n",
      "Epoch 3804/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1437983357.2446 - val_loss: 3846715840.0000\n",
      "Epoch 3805/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1438161064.0783 - val_loss: 3854848450.7763\n",
      "Epoch 3806/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1439884162.2544 - val_loss: 3840925610.3744\n",
      "Epoch 3807/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1437486960.2192 - val_loss: 3844431884.2740\n",
      "Epoch 3808/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1440194941.6204 - val_loss: 3868308465.2420\n",
      "Epoch 3809/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1439312250.2387 - val_loss: 3836407096.9863\n",
      "Epoch 3810/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1437444108.9002 - val_loss: 3853035923.8721\n",
      "Epoch 3811/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1438647178.7710 - val_loss: 3846134324.3105\n",
      "Epoch 3812/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1439030332.3679 - val_loss: 3859285291.6895\n",
      "Epoch 3813/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1438051926.1683 - val_loss: 3854190244.0913\n",
      "Epoch 3814/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1437119829.5421 - val_loss: 3845540621.5890\n",
      "Epoch 3815/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1439794754.6301 - val_loss: 3837203147.1050\n",
      "Epoch 3816/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1437872270.4031 - val_loss: 3853312423.5982\n",
      "Epoch 3817/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1437735582.0587 - val_loss: 3853603161.7169\n",
      "Epoch 3818/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1438328413.9335 - val_loss: 3846971656.7671\n",
      "Epoch 3819/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1442163021.4012 - val_loss: 3861297263.9269\n",
      "Epoch 3820/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1437531582.8728 - val_loss: 3850311787.9817\n",
      "Epoch 3821/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1438490272.0626 - val_loss: 3841475466.0822\n",
      "Epoch 3822/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1438276906.3327 - val_loss: 3849236119.0868\n",
      "Epoch 3823/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1437316414.8728 - val_loss: 3850231407.1963\n",
      "Epoch 3824/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1437314294.9824 - val_loss: 3854915928.6941\n",
      "Epoch 3825/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1437662311.9530 - val_loss: 3851914180.0913\n",
      "Epoch 3826/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1437289577.2055 - val_loss: 3846888753.8265\n",
      "Epoch 3827/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1438386236.2427 - val_loss: 3851666217.7900\n",
      "Epoch 3828/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1438632062.8728 - val_loss: 3848000829.3699\n",
      "Epoch 3829/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1439780515.4442 - val_loss: 3844415591.4521\n",
      "Epoch 3830/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1439457804.0235 - val_loss: 3847553590.5023\n",
      "Epoch 3831/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1438610898.7867 - val_loss: 3857959548.4932\n",
      "Epoch 3832/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1438285353.0802 - val_loss: 3856348917.1872\n",
      "Epoch 3833/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1437231158.1057 - val_loss: 3847297784.4018\n",
      "Epoch 3834/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1438257163.5225 - val_loss: 3854436014.1735\n",
      "Epoch 3835/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1437322517.5421 - val_loss: 3836505592.9863\n",
      "Epoch 3836/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1437488463.4051 - val_loss: 3849230102.3562\n",
      "Epoch 3837/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1438339480.2975 - val_loss: 3848504188.7854\n",
      "Epoch 3838/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1438884977.0333 - val_loss: 3848684599.3790\n",
      "Epoch 3839/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1436907343.6556 - val_loss: 3839280785.9726\n",
      "Epoch 3840/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1437154862.8415 - val_loss: 3842267872.8767\n",
      "Epoch 3841/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1437438209.2524 - val_loss: 3846578888.6210\n",
      "Epoch 3842/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1438304179.3503 - val_loss: 3852016124.7854\n",
      "Epoch 3843/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1437321894.5753 - val_loss: 3846721745.5342\n",
      "Epoch 3844/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1437649733.3855 - val_loss: 3856200197.8447\n",
      "Epoch 3845/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1437024279.2955 - val_loss: 3848010632.1826\n",
      "Epoch 3846/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1439637698.3796 - val_loss: 3864100461.8813\n",
      "Epoch 3847/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1438418458.0509 - val_loss: 3848386807.6712\n",
      "Epoch 3848/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1438014333.2446 - val_loss: 3833885739.5434\n",
      "Epoch 3849/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1437800353.0646 - val_loss: 3855224349.6621\n",
      "Epoch 3850/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1438348516.0705 - val_loss: 3836813068.5662\n",
      "Epoch 3851/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1437865456.3444 - val_loss: 3850359556.0913\n",
      "Epoch 3852/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1437710664.6419 - val_loss: 3861355022.7580\n",
      "Epoch 3853/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1437339350.6693 - val_loss: 3843466849.1689\n",
      "Epoch 3854/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1437967021.7143 - val_loss: 3850581702.1370\n",
      "Epoch 3855/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1439274710.9198 - val_loss: 3858412027.9087\n",
      "Epoch 3856/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 39us/step - loss: 1437255403.0841 - val_loss: 3846310811.9087\n",
      "Epoch 3857/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1436921639.8278 - val_loss: 3834769318.7215\n",
      "Epoch 3858/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1439593986.7554 - val_loss: 3826750458.3014\n",
      "Epoch 3859/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1436893001.6438 - val_loss: 3854832718.4658\n",
      "Epoch 3860/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1436901651.0372 - val_loss: 3850196169.3516\n",
      "Epoch 3861/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1437816381.7456 - val_loss: 3846403643.0320\n",
      "Epoch 3862/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1440294118.8258 - val_loss: 3848409012.1644\n",
      "Epoch 3863/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1437083779.2564 - val_loss: 3846952774.8676\n",
      "Epoch 3864/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1438132253.6830 - val_loss: 3839101549.5890\n",
      "Epoch 3865/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1439027438.7162 - val_loss: 3845378976.7306\n",
      "Epoch 3866/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1436612488.0157 - val_loss: 3841014127.7808\n",
      "Epoch 3867/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1437027677.1820 - val_loss: 3844598528.0000\n",
      "Epoch 3868/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1437673030.6380 - val_loss: 3838481857.4612\n",
      "Epoch 3869/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1437227121.3464 - val_loss: 3852524708.6758\n",
      "Epoch 3870/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1437696709.1350 - val_loss: 3857814783.7078\n",
      "Epoch 3871/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1437345875.6634 - val_loss: 3835004066.0457\n",
      "Epoch 3872/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1441063484.8689 - val_loss: 3858201767.7443\n",
      "Epoch 3873/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1437437657.2994 - val_loss: 3839181712.9498\n",
      "Epoch 3874/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1436791189.7926 - val_loss: 3837665131.2511\n",
      "Epoch 3875/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1438791443.1624 - val_loss: 3841576940.7123\n",
      "Epoch 3876/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1437580379.1781 - val_loss: 3850505708.1279\n",
      "Epoch 3877/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1437653779.1624 - val_loss: 3835200462.1735\n",
      "Epoch 3878/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1438629637.0098 - val_loss: 3861616749.4429\n",
      "Epoch 3879/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1437118709.9804 - val_loss: 3837031758.7580\n",
      "Epoch 3880/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1438390429.9335 - val_loss: 3860314936.5479\n",
      "Epoch 3881/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1437360811.9609 - val_loss: 3848140943.9269\n",
      "Epoch 3882/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1436824741.0724 - val_loss: 3836275177.0594\n",
      "Epoch 3883/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1437823790.3405 - val_loss: 3840936736.7306\n",
      "Epoch 3884/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1437975478.3562 - val_loss: 3843978771.1416\n",
      "Epoch 3885/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1439333046.3562 - val_loss: 3865205443.7991\n",
      "Epoch 3886/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1437162929.8474 - val_loss: 3846541490.4110\n",
      "Epoch 3887/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1437327573.4168 - val_loss: 3847375627.9817\n",
      "Epoch 3888/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1437411722.7710 - val_loss: 3837448808.9132\n",
      "Epoch 3889/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1437376369.7221 - val_loss: 3830617466.4475\n",
      "Epoch 3890/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1437255808.8767 - val_loss: 3844061006.9041\n",
      "Epoch 3891/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1437050966.1683 - val_loss: 3842667039.8539\n",
      "Epoch 3892/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1438403484.8063 - val_loss: 3855471326.1005\n",
      "Epoch 3893/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1436770062.0274 - val_loss: 3839760542.5388\n",
      "Epoch 3894/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1438755013.1350 - val_loss: 3830116407.2329\n",
      "Epoch 3895/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1438605563.7417 - val_loss: 3846791222.3562\n",
      "Epoch 3896/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1437660921.3620 - val_loss: 3842158661.6986\n",
      "Epoch 3897/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1437446264.2348 - val_loss: 3854234810.8858\n",
      "Epoch 3898/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1436123485.1820 - val_loss: 3842460570.7397\n",
      "Epoch 3899/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1439706527.6869 - val_loss: 3836340563.8721\n",
      "Epoch 3900/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1439161887.5616 - val_loss: 3853556016.0731\n",
      "Epoch 3901/10000\n",
      "1022/1022 [==============================] - 0s 81us/step - loss: 1437288381.1194 - val_loss: 3838247634.9954\n",
      "Epoch 3902/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1436598164.6654 - val_loss: 3843250349.2968\n",
      "Epoch 3903/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1436636327.5773 - val_loss: 3842000942.9041\n",
      "Epoch 3904/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1436836824.6732 - val_loss: 3831904082.4110\n",
      "Epoch 3905/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1436139846.3875 - val_loss: 3846631219.2877\n",
      "Epoch 3906/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1436572186.4266 - val_loss: 3836530827.9817\n",
      "Epoch 3907/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1437214407.6399 - val_loss: 3844276247.9635\n",
      "Epoch 3908/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1436165445.3855 - val_loss: 3844865586.8493\n",
      "Epoch 3909/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1436699746.5675 - val_loss: 3836194391.2329\n",
      "Epoch 3910/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1437113356.2740 - val_loss: 3844144811.3973\n",
      "Epoch 3911/10000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1436862330.6145 - val_loss: 3850199349.4795\n",
      "Epoch 3912/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1435900280.4853 - val_loss: 3844780432.2192\n",
      "Epoch 3913/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1438188871.6399 - val_loss: 3844219594.3744\n",
      "Epoch 3914/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1437168600.4227 - val_loss: 3823114544.6575\n",
      "Epoch 3915/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1439572521.5812 - val_loss: 3860052915.4338\n",
      "Epoch 3916/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1436750681.4247 - val_loss: 3830107484.7854\n",
      "Epoch 3917/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1436257888.9393 - val_loss: 3832811052.5662\n",
      "Epoch 3918/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1441730925.4638 - val_loss: 3857132051.5799\n",
      "Epoch 3919/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1440425741.5264 - val_loss: 3813651460.3836\n",
      "Epoch 3920/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 49us/step - loss: 1436488598.1683 - val_loss: 3842900603.4703\n",
      "Epoch 3921/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1438572731.8669 - val_loss: 3845681800.9132\n",
      "Epoch 3922/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1436323041.6908 - val_loss: 3845332726.7945\n",
      "Epoch 3923/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1436785825.5656 - val_loss: 3853207946.0822\n",
      "Epoch 3924/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1436139100.1800 - val_loss: 3843141586.4110\n",
      "Epoch 3925/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1437820483.1311 - val_loss: 3830499197.0776\n",
      "Epoch 3926/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1436225397.2290 - val_loss: 3836794160.5114\n",
      "Epoch 3927/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1436635466.1448 - val_loss: 3842097604.8219\n",
      "Epoch 3928/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1437541967.9061 - val_loss: 3831015115.1050\n",
      "Epoch 3929/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1436263633.6595 - val_loss: 3837036514.1918\n",
      "Epoch 3930/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1435721859.7573 - val_loss: 3838605423.9269\n",
      "Epoch 3931/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1436198292.5401 - val_loss: 3849420527.3425\n",
      "Epoch 3932/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1438084142.3405 - val_loss: 3839657028.5297\n",
      "Epoch 3933/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1437781376.6262 - val_loss: 3844768717.2968\n",
      "Epoch 3934/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1438337294.2779 - val_loss: 3857039247.0502\n",
      "Epoch 3935/10000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1435506053.8865 - val_loss: 3838001521.9726\n",
      "Epoch 3936/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1436084557.6517 - val_loss: 3834676257.4612\n",
      "Epoch 3937/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1435889000.4540 - val_loss: 3837413081.8630\n",
      "Epoch 3938/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1435575354.3640 - val_loss: 3840877351.5982\n",
      "Epoch 3939/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1436624018.0352 - val_loss: 3829475516.2009\n",
      "Epoch 3940/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1435275909.7613 - val_loss: 3842497003.8356\n",
      "Epoch 3941/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1436467788.9002 - val_loss: 3839039182.6119\n",
      "Epoch 3942/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1438147621.5734 - val_loss: 3835593060.9680\n",
      "Epoch 3943/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1436547587.3816 - val_loss: 3841662416.6575\n",
      "Epoch 3944/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1436608321.6282 - val_loss: 3853721754.1553\n",
      "Epoch 3945/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1435524130.5675 - val_loss: 3833621326.3196\n",
      "Epoch 3946/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1436232593.7847 - val_loss: 3836576562.9954\n",
      "Epoch 3947/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1436275145.6438 - val_loss: 3837820230.1370\n",
      "Epoch 3948/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1436174985.7691 - val_loss: 3847355876.5297\n",
      "Epoch 3949/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1436630935.5460 - val_loss: 3839916490.9589\n",
      "Epoch 3950/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1435242588.6810 - val_loss: 3839502822.7215\n",
      "Epoch 3951/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1435857942.0431 - val_loss: 3841112970.5205\n",
      "Epoch 3952/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1436067646.6223 - val_loss: 3829982206.5388\n",
      "Epoch 3953/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1436833334.8571 - val_loss: 3843017410.0457\n",
      "Epoch 3954/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1438060219.3659 - val_loss: 3830928576.0000\n",
      "Epoch 3955/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1436433944.5479 - val_loss: 3845538057.3516\n",
      "Epoch 3956/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1437035710.7476 - val_loss: 3827642773.6256\n",
      "Epoch 3957/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1435106465.8160 - val_loss: 3844330471.1598\n",
      "Epoch 3958/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1437511533.8395 - val_loss: 3834109263.0502\n",
      "Epoch 3959/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1436218487.0450 - val_loss: 3849797817.2785\n",
      "Epoch 3960/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1435984458.3953 - val_loss: 3844472337.6804\n",
      "Epoch 3961/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1436254835.6008 - val_loss: 3836292190.9772\n",
      "Epoch 3962/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1435797454.2779 - val_loss: 3843177706.9589\n",
      "Epoch 3963/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1435463155.2250 - val_loss: 3834687117.4429\n",
      "Epoch 3964/10000\n",
      "1022/1022 [==============================] - 0s 67us/step - loss: 1435478169.1742 - val_loss: 3835341137.2420\n",
      "Epoch 3965/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1435280507.7417 - val_loss: 3840152777.7900\n",
      "Epoch 3966/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1436045320.7671 - val_loss: 3836718826.8128\n",
      "Epoch 3967/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1436041498.8023 - val_loss: 3846370689.1689\n",
      "Epoch 3968/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1435562953.3933 - val_loss: 3836868314.7397\n",
      "Epoch 3969/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1435845563.3659 - val_loss: 3834425152.2922\n",
      "Epoch 3970/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1436070136.9863 - val_loss: 3849330379.9817\n",
      "Epoch 3971/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1435554969.1742 - val_loss: 3836383034.0091\n",
      "Epoch 3972/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1435254009.9883 - val_loss: 3839681223.0137\n",
      "Epoch 3973/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1435535429.5108 - val_loss: 3838963691.3973\n",
      "Epoch 3974/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1437285548.0861 - val_loss: 3835348232.7671\n",
      "Epoch 3975/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1435957490.0978 - val_loss: 3840353786.7397\n",
      "Epoch 3976/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1435993217.7534 - val_loss: 3844426142.5388\n",
      "Epoch 3977/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1435199284.3523 - val_loss: 3845262743.0868\n",
      "Epoch 3978/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1438599796.7280 - val_loss: 3824003309.4429\n",
      "Epoch 3979/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1435514233.2368 - val_loss: 3843839776.7306\n",
      "Epoch 3980/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1435696458.1448 - val_loss: 3844687606.7945\n",
      "Epoch 3981/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1435381951.6243 - val_loss: 3834834094.6119\n",
      "Epoch 3982/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1435381872.8454 - val_loss: 3842310149.9909\n",
      "Epoch 3983/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1435017371.8043 - val_loss: 3832016099.2146\n",
      "Epoch 3984/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 46us/step - loss: 1435420580.0705 - val_loss: 3836403062.7945\n",
      "Epoch 3985/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1436230012.9941 - val_loss: 3838383299.7991\n",
      "Epoch 3986/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1436322521.9256 - val_loss: 3833352488.3288\n",
      "Epoch 3987/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1436783508.0391 - val_loss: 3840372974.9041\n",
      "Epoch 3988/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1435862577.5969 - val_loss: 3819402987.8356\n",
      "Epoch 3989/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1437620759.6712 - val_loss: 3842995386.5936\n",
      "Epoch 3990/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1436453398.1683 - val_loss: 3827407837.3699\n",
      "Epoch 3991/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1436482440.1409 - val_loss: 3849208065.7534\n",
      "Epoch 3992/10000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1435446657.5029 - val_loss: 3827380985.5708\n",
      "Epoch 3993/10000\n",
      "1022/1022 [==============================] - 0s 65us/step - loss: 1435613009.0333 - val_loss: 3843831433.4977\n",
      "Epoch 3994/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1435497463.2329 - val_loss: 3829430757.8447\n",
      "Epoch 3995/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1435815131.1781 - val_loss: 3837126100.1644\n",
      "Epoch 3996/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1436121506.8180 - val_loss: 3829799159.5251\n",
      "Epoch 3997/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1435232057.9883 - val_loss: 3846515847.0137\n",
      "Epoch 3998/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1436260481.7534 - val_loss: 3825280178.9954\n",
      "Epoch 3999/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1434420804.3836 - val_loss: 3844187763.5799\n",
      "Epoch 4000/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1436013177.4873 - val_loss: 3846731874.7763\n",
      "Epoch 4001/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1435183824.9080 - val_loss: 3829390811.0320\n",
      "Epoch 4002/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1435343723.8356 - val_loss: 3841974188.1279\n",
      "Epoch 4003/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1437189962.3953 - val_loss: 3824994716.6393\n",
      "Epoch 4004/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1436677200.1566 - val_loss: 3849916708.9680\n",
      "Epoch 4005/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1435061868.5871 - val_loss: 3837982056.6210\n",
      "Epoch 4006/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1434842574.6536 - val_loss: 3837691433.6438\n",
      "Epoch 4007/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1434879929.8630 - val_loss: 3828423069.3699\n",
      "Epoch 4008/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1434974110.4344 - val_loss: 3834523182.1735\n",
      "Epoch 4009/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1435449219.5068 - val_loss: 3835069215.5616\n",
      "Epoch 4010/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1434839805.2446 - val_loss: 3841933667.0685\n",
      "Epoch 4011/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1437097438.4344 - val_loss: 3823792911.7808\n",
      "Epoch 4012/10000\n",
      "1022/1022 [==============================] - ETA: 0s - loss: 2474274560.00 - 0s 46us/step - loss: 1435940195.9452 - val_loss: 3845519546.4475\n",
      "Epoch 4013/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1435359168.8767 - val_loss: 3824405686.0639\n",
      "Epoch 4014/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1435553908.4775 - val_loss: 3830982290.9954\n",
      "Epoch 4015/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1435228870.6380 - val_loss: 3839370406.4292\n",
      "Epoch 4016/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1436021255.7652 - val_loss: 3837609845.1872\n",
      "Epoch 4017/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1435255101.2446 - val_loss: 3841091875.3607\n",
      "Epoch 4018/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1436072601.8004 - val_loss: 3841153342.2466\n",
      "Epoch 4019/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1436373366.7319 - val_loss: 3847537297.9726\n",
      "Epoch 4020/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1435472519.8904 - val_loss: 3832638434.3379\n",
      "Epoch 4021/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1434996439.6712 - val_loss: 3833995576.9863\n",
      "Epoch 4022/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1435228549.0098 - val_loss: 3837604322.9224\n",
      "Epoch 4023/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1434724355.7573 - val_loss: 3838721034.2283\n",
      "Epoch 4024/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1434838722.8806 - val_loss: 3837115719.5982\n",
      "Epoch 4025/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1435963693.3386 - val_loss: 3836361070.3196\n",
      "Epoch 4026/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1434602036.8532 - val_loss: 3837711008.0000\n",
      "Epoch 4027/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1435811450.6145 - val_loss: 3826022805.1872\n",
      "Epoch 4028/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1435013714.1605 - val_loss: 3837126454.6484\n",
      "Epoch 4029/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1436491047.8278 - val_loss: 3846704160.0000\n",
      "Epoch 4030/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1435976869.4481 - val_loss: 3836313911.3790\n",
      "Epoch 4031/10000\n",
      "1022/1022 [==============================] - 0s 72us/step - loss: 1435810459.4286 - val_loss: 3829613901.4429\n",
      "Epoch 4032/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1439608316.6184 - val_loss: 3848872984.8402\n",
      "Epoch 4033/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1434876232.1409 - val_loss: 3821757595.4703\n",
      "Epoch 4034/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1435018437.6360 - val_loss: 3831338873.7169\n",
      "Epoch 4035/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1436181156.8219 - val_loss: 3850770507.6895\n",
      "Epoch 4036/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1435839961.9256 - val_loss: 3827675476.3105\n",
      "Epoch 4037/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1434176251.9922 - val_loss: 3839156768.1461\n",
      "Epoch 4038/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1435725358.5910 - val_loss: 3843181956.9680\n",
      "Epoch 4039/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1435018937.8630 - val_loss: 3842806768.3653\n",
      "Epoch 4040/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1434551457.5656 - val_loss: 3834238877.2237\n",
      "Epoch 4041/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1435191436.5245 - val_loss: 3824024469.1872\n",
      "Epoch 4042/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1435506951.6399 - val_loss: 3830661676.2740\n",
      "Epoch 4043/10000\n",
      "1022/1022 [==============================] - 0s 63us/step - loss: 1438699275.5225 - val_loss: 3841488454.5753\n",
      "Epoch 4044/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1436029285.9491 - val_loss: 3831961701.6986\n",
      "Epoch 4045/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1434356300.1487 - val_loss: 3843540596.4566\n",
      "Epoch 4046/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1437216675.3190 - val_loss: 3836501137.0959\n",
      "Epoch 4047/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1436232880.5949 - val_loss: 3824701660.2009\n",
      "Epoch 4048/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 52us/step - loss: 1434422040.6732 - val_loss: 3837042384.0731\n",
      "Epoch 4049/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1434518794.5205 - val_loss: 3840108761.8630\n",
      "Epoch 4050/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1437508795.8669 - val_loss: 3839271869.2237\n",
      "Epoch 4051/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1435112375.1076 - val_loss: 3830552818.4110\n",
      "Epoch 4052/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1434770020.4462 - val_loss: 3834748614.2831\n",
      "Epoch 4053/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1435295425.0020 - val_loss: 3840163240.3288\n",
      "Epoch 4054/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1434242656.6888 - val_loss: 3823770580.7489\n",
      "Epoch 4055/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1434079672.1096 - val_loss: 3831149362.7032\n",
      "Epoch 4056/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1434307258.6145 - val_loss: 3833132428.5662\n",
      "Epoch 4057/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1435162895.1546 - val_loss: 3836910132.6027\n",
      "Epoch 4058/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1434993415.1389 - val_loss: 3835826390.5023\n",
      "Epoch 4059/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1435176470.0431 - val_loss: 3825657092.8219\n",
      "Epoch 4060/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1434737345.3777 - val_loss: 3831071488.5845\n",
      "Epoch 4061/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1435365998.9667 - val_loss: 3841504620.5662\n",
      "Epoch 4062/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1434687818.7710 - val_loss: 3838467842.6301\n",
      "Epoch 4063/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1434443859.1624 - val_loss: 3832068379.9087\n",
      "Epoch 4064/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1433882728.7045 - val_loss: 3833256819.8721\n",
      "Epoch 4065/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1434391748.8845 - val_loss: 3845204682.3744\n",
      "Epoch 4066/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1435726760.5793 - val_loss: 3829486124.7123\n",
      "Epoch 4067/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1435070703.0920 - val_loss: 3838072630.7945\n",
      "Epoch 4068/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1434768768.7515 - val_loss: 3845365736.6210\n",
      "Epoch 4069/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1434458722.6928 - val_loss: 3831942106.4475\n",
      "Epoch 4070/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1434284088.8611 - val_loss: 3839151323.9087\n",
      "Epoch 4071/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1433866754.2544 - val_loss: 3826589904.9498\n",
      "Epoch 4072/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1435173613.2133 - val_loss: 3825182406.8676\n",
      "Epoch 4073/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1434636466.8493 - val_loss: 3831836378.3014\n",
      "Epoch 4074/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1435133274.4266 - val_loss: 3851097327.6347\n",
      "Epoch 4075/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1433984633.3620 - val_loss: 3840197256.0365\n",
      "Epoch 4076/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1434233775.3425 - val_loss: 3821846748.9315\n",
      "Epoch 4077/10000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1434170106.4892 - val_loss: 3825863802.7397\n",
      "Epoch 4078/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1435040514.2544 - val_loss: 3844302296.9863\n",
      "Epoch 4079/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1435302118.1996 - val_loss: 3829694492.9315\n",
      "Epoch 4080/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1434237681.7221 - val_loss: 3840175329.3151\n",
      "Epoch 4081/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1433819654.2622 - val_loss: 3828201505.6073\n",
      "Epoch 4082/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1433611518.1213 - val_loss: 3832464439.9635\n",
      "Epoch 4083/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1435837497.6125 - val_loss: 3834009286.5753\n",
      "Epoch 4084/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1434636134.4501 - val_loss: 3819522978.0457\n",
      "Epoch 4085/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1436002044.2427 - val_loss: 3843840261.5525\n",
      "Epoch 4086/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1437407892.7906 - val_loss: 3821468200.1826\n",
      "Epoch 4087/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1434534703.5930 - val_loss: 3829203459.2146\n",
      "Epoch 4088/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1434550180.4462 - val_loss: 3821616607.7078\n",
      "Epoch 4089/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1434763465.3933 - val_loss: 3847541343.4155\n",
      "Epoch 4090/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1433904334.0274 - val_loss: 3840234444.4201\n",
      "Epoch 4091/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1434374369.6908 - val_loss: 3829552449.4612\n",
      "Epoch 4092/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1433879598.4658 - val_loss: 3836915317.9178\n",
      "Epoch 4093/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1433460707.3190 - val_loss: 3829530678.7945\n",
      "Epoch 4094/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1434255553.1272 - val_loss: 3823072717.1507\n",
      "Epoch 4095/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1436332734.3718 - val_loss: 3849290869.0411\n",
      "Epoch 4096/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1434847806.3718 - val_loss: 3815633544.4749\n",
      "Epoch 4097/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1434122232.2348 - val_loss: 3835577129.2055\n",
      "Epoch 4098/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1435139818.2074 - val_loss: 3832550994.8493\n",
      "Epoch 4099/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1433637050.4892 - val_loss: 3822108508.3470\n",
      "Epoch 4100/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1434314692.1331 - val_loss: 3837945485.4429\n",
      "Epoch 4101/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1433860914.7241 - val_loss: 3823045794.0457\n",
      "Epoch 4102/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1433331041.9413 - val_loss: 3831591801.5708\n",
      "Epoch 4103/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1433159486.8728 - val_loss: 3831013798.4292\n",
      "Epoch 4104/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1434357115.6164 - val_loss: 3832945525.0411\n",
      "Epoch 4105/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1434121369.9256 - val_loss: 3827953949.6621\n",
      "Epoch 4106/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1433833236.9159 - val_loss: 3827757836.7123\n",
      "Epoch 4107/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1434075414.9198 - val_loss: 3843034818.6301\n",
      "Epoch 4108/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1434237765.3855 - val_loss: 3829043446.5023\n",
      "Epoch 4109/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1434810422.6067 - val_loss: 3836057381.6986\n",
      "Epoch 4110/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1433244896.5636 - val_loss: 3825452377.1324\n",
      "Epoch 4111/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1434029264.2818 - val_loss: 3836191099.3242\n",
      "Epoch 4112/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 44us/step - loss: 1435206123.0841 - val_loss: 3837785716.0183\n",
      "Epoch 4113/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1436812237.4012 - val_loss: 3818169612.1279\n",
      "Epoch 4114/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1437538748.8689 - val_loss: 3845973397.1872\n",
      "Epoch 4115/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1433820234.1448 - val_loss: 3819882813.9543\n",
      "Epoch 4116/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1434199826.7867 - val_loss: 3838414273.8995\n",
      "Epoch 4117/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1434519082.8337 - val_loss: 3827511126.7945\n",
      "Epoch 4118/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1434446802.9119 - val_loss: 3849047646.6849\n",
      "Epoch 4119/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1436176010.0196 - val_loss: 3839566475.1050\n",
      "Epoch 4120/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1433161300.6654 - val_loss: 3822155886.4658\n",
      "Epoch 4121/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1433497663.1233 - val_loss: 3830368451.6530\n",
      "Epoch 4122/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1434908614.3875 - val_loss: 3827838496.0000\n",
      "Epoch 4123/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1433635074.0039 - val_loss: 3825463154.4110\n",
      "Epoch 4124/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1434557595.0528 - val_loss: 3822113099.9817\n",
      "Epoch 4125/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1434329293.9022 - val_loss: 3837339902.1005\n",
      "Epoch 4126/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1434118513.2211 - val_loss: 3822601097.7900\n",
      "Epoch 4127/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1436362902.6693 - val_loss: 3830535719.5982\n",
      "Epoch 4128/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1435191478.7319 - val_loss: 3821149011.5799\n",
      "Epoch 4129/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1432730969.2994 - val_loss: 3831408035.9452\n",
      "Epoch 4130/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1433425337.6125 - val_loss: 3836209445.2603\n",
      "Epoch 4131/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1433050481.9726 - val_loss: 3830434953.2055\n",
      "Epoch 4132/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1433365907.2877 - val_loss: 3831311724.2740\n",
      "Epoch 4133/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1433397159.7025 - val_loss: 3825351595.5434\n",
      "Epoch 4134/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1433416612.8219 - val_loss: 3832102224.9498\n",
      "Epoch 4135/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1435802092.4618 - val_loss: 3824682624.5845\n",
      "Epoch 4136/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1433312983.9217 - val_loss: 3838226449.9726\n",
      "Epoch 4137/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1435700016.0939 - val_loss: 3848496128.2922\n",
      "Epoch 4138/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1432797375.1233 - val_loss: 3834860954.4475\n",
      "Epoch 4139/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1433830785.1272 - val_loss: 3835669158.7215\n",
      "Epoch 4140/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1434695015.2016 - val_loss: 3825756826.8858\n",
      "Epoch 4141/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1433648679.8278 - val_loss: 3832506129.0959\n",
      "Epoch 4142/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1433293469.8082 - val_loss: 3825655453.2237\n",
      "Epoch 4143/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1433305037.9022 - val_loss: 3824658732.8584\n",
      "Epoch 4144/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1433491855.4051 - val_loss: 3819809908.4566\n",
      "Epoch 4145/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1434788006.5753 - val_loss: 3825767690.0822\n",
      "Epoch 4146/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1432951950.7789 - val_loss: 3831064169.9361\n",
      "Epoch 4147/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1433150223.2798 - val_loss: 3829829015.9635\n",
      "Epoch 4148/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1433672146.4110 - val_loss: 3831095037.0776\n",
      "Epoch 4149/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1433883690.3327 - val_loss: 3842149136.0731\n",
      "Epoch 4150/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1434140004.4462 - val_loss: 3823179005.9543\n",
      "Epoch 4151/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1432941193.7691 - val_loss: 3830403001.2785\n",
      "Epoch 4152/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1432720903.6399 - val_loss: 3831559728.0731\n",
      "Epoch 4153/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1435645201.5342 - val_loss: 3847733123.0685\n",
      "Epoch 4154/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1434076247.9217 - val_loss: 3825213125.4064\n",
      "Epoch 4155/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1433153918.2466 - val_loss: 3826464018.8493\n",
      "Epoch 4156/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1433047274.9589 - val_loss: 3822870056.3288\n",
      "Epoch 4157/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1433624478.0587 - val_loss: 3839126228.1644\n",
      "Epoch 4158/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1433202985.0802 - val_loss: 3827995311.3425\n",
      "Epoch 4159/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1434982053.5734 - val_loss: 3826387991.9635\n",
      "Epoch 4160/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1433406401.0020 - val_loss: 3842672803.6530\n",
      "Epoch 4161/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1435860795.3659 - val_loss: 3815975740.6393\n",
      "Epoch 4162/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1433819781.2603 - val_loss: 3848757763.5068\n",
      "Epoch 4163/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1434099116.4618 - val_loss: 3831152312.2557\n",
      "Epoch 4164/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1435542781.4951 - val_loss: 3837041593.4247\n",
      "Epoch 4165/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1433740948.7906 - val_loss: 3828253540.2374\n",
      "Epoch 4166/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1432950342.1370 - val_loss: 3831754191.7808\n",
      "Epoch 4167/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1433522311.5147 - val_loss: 3838960220.6393\n",
      "Epoch 4168/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1432554022.5127 - val_loss: 3824553890.6301\n",
      "Epoch 4169/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1433495470.0900 - val_loss: 3826909285.1142\n",
      "Epoch 4170/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1435238315.5851 - val_loss: 3850146929.3881\n",
      "Epoch 4171/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1433991600.3444 - val_loss: 3830489848.9863\n",
      "Epoch 4172/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1435183584.1879 - val_loss: 3811870141.5160\n",
      "Epoch 4173/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1433684267.5851 - val_loss: 3837563624.0365\n",
      "Epoch 4174/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1434145414.2622 - val_loss: 3828763693.8813\n",
      "Epoch 4175/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1433253710.1526 - val_loss: 3822672184.4018\n",
      "Epoch 4176/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 40us/step - loss: 1434899909.3855 - val_loss: 3825413139.8721\n",
      "Epoch 4177/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1434871866.1135 - val_loss: 3844714186.9589\n",
      "Epoch 4178/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1432515066.9902 - val_loss: 3832929257.0594\n",
      "Epoch 4179/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1433985412.7593 - val_loss: 3819260413.2237\n",
      "Epoch 4180/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1432895725.7143 - val_loss: 3820504034.6301\n",
      "Epoch 4181/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1433556573.8082 - val_loss: 3816442571.3973\n",
      "Epoch 4182/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1434229982.5597 - val_loss: 3830541152.1461\n",
      "Epoch 4183/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1432799221.9804 - val_loss: 3824673151.8539\n",
      "Epoch 4184/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1433568375.2329 - val_loss: 3822143075.7991\n",
      "Epoch 4185/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1432799544.3601 - val_loss: 3834679857.9726\n",
      "Epoch 4186/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1433241545.3933 - val_loss: 3827050165.7717\n",
      "Epoch 4187/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1432324490.5205 - val_loss: 3834966532.2374\n",
      "Epoch 4188/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1432843179.0841 - val_loss: 3824343788.1279\n",
      "Epoch 4189/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1434456931.8200 - val_loss: 3824436088.2557\n",
      "Epoch 4190/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1432848972.7750 - val_loss: 3824053134.4658\n",
      "Epoch 4191/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1432797074.5362 - val_loss: 3832393541.1142\n",
      "Epoch 4192/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1433803499.2094 - val_loss: 3817760234.5205\n",
      "Epoch 4193/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1433696738.1918 - val_loss: 3825406288.2192\n",
      "Epoch 4194/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1432950449.9726 - val_loss: 3824285542.1370\n",
      "Epoch 4195/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1432829480.3288 - val_loss: 3834421901.7352\n",
      "Epoch 4196/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1434942236.0548 - val_loss: 3819593633.1689\n",
      "Epoch 4197/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1432763903.4990 - val_loss: 3834451323.7626\n",
      "Epoch 4198/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1433679008.3131 - val_loss: 3824153664.0000\n",
      "Epoch 4199/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1433216461.6517 - val_loss: 3824857449.7900\n",
      "Epoch 4200/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1433156557.4012 - val_loss: 3845286445.0046\n",
      "Epoch 4201/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1432114101.2290 - val_loss: 3833352324.2374\n",
      "Epoch 4202/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1432525797.9491 - val_loss: 3829706061.0046\n",
      "Epoch 4203/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1432213696.0000 - val_loss: 3823357013.7717\n",
      "Epoch 4204/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1433251444.4775 - val_loss: 3820100375.6712\n",
      "Epoch 4205/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1432116378.9276 - val_loss: 3834284706.3379\n",
      "Epoch 4206/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1432317122.6301 - val_loss: 3833407428.9680\n",
      "Epoch 4207/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1432956714.3327 - val_loss: 3834605054.5388\n",
      "Epoch 4208/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1432640148.5401 - val_loss: 3825531090.7032\n",
      "Epoch 4209/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1432852993.8787 - val_loss: 3829241383.3059\n",
      "Epoch 4210/10000\n",
      "1022/1022 [==============================] - 0s 67us/step - loss: 1432703038.6223 - val_loss: 3827778119.4521\n",
      "Epoch 4211/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1433214378.8337 - val_loss: 3831519634.2648\n",
      "Epoch 4212/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1432896924.3053 - val_loss: 3829716200.3288\n",
      "Epoch 4213/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1432473072.2818 - val_loss: 3829008620.5662\n",
      "Epoch 4214/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1432805888.7515 - val_loss: 3837910221.2968\n",
      "Epoch 4215/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1432643318.1057 - val_loss: 3817528375.5251\n",
      "Epoch 4216/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1432668369.1585 - val_loss: 3831015247.7808\n",
      "Epoch 4217/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1432736801.6908 - val_loss: 3821278600.0365\n",
      "Epoch 4218/10000\n",
      "1022/1022 [==============================] - 0s 66us/step - loss: 1433680403.7886 - val_loss: 3821632599.6712\n",
      "Epoch 4219/10000\n",
      "1022/1022 [==============================] - 0s 66us/step - loss: 1432094797.9022 - val_loss: 3835635682.9224\n",
      "Epoch 4220/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1432348151.9843 - val_loss: 3828264086.0639\n",
      "Epoch 4221/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1433928974.2779 - val_loss: 3838405339.0320\n",
      "Epoch 4222/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1433245914.6771 - val_loss: 3817385507.9452\n",
      "Epoch 4223/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1432486514.9746 - val_loss: 3829559754.9589\n",
      "Epoch 4224/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1433231442.4110 - val_loss: 3843452911.1963\n",
      "Epoch 4225/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1434777830.4501 - val_loss: 3815526806.6484\n",
      "Epoch 4226/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1433504939.4599 - val_loss: 3845238643.2877\n",
      "Epoch 4227/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1431593190.7006 - val_loss: 3827002607.0502\n",
      "Epoch 4228/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1434277266.7867 - val_loss: 3823800431.9269\n",
      "Epoch 4229/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1432642967.1703 - val_loss: 3823008130.9224\n",
      "Epoch 4230/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1432905240.5479 - val_loss: 3837100454.5753\n",
      "Epoch 4231/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1431716195.0059 - val_loss: 3835413114.4475\n",
      "Epoch 4232/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1435220133.3229 - val_loss: 3825327244.7123\n",
      "Epoch 4233/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1431526580.8532 - val_loss: 3831085994.8128\n",
      "Epoch 4234/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1436141921.6908 - val_loss: 3851565036.4201\n",
      "Epoch 4235/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1432344938.4579 - val_loss: 3818280016.9498\n",
      "Epoch 4236/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1432561290.8337 - val_loss: 3827561903.9269\n",
      "Epoch 4237/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1433707311.0920 - val_loss: 3821956473.8630\n",
      "Epoch 4238/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1431783067.0528 - val_loss: 3823462928.9498\n",
      "Epoch 4239/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1432537516.8376 - val_loss: 3830029734.1370\n",
      "Epoch 4240/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 54us/step - loss: 1432038398.8728 - val_loss: 3822535002.1553\n",
      "Epoch 4241/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1432887923.7260 - val_loss: 3837211253.4795\n",
      "Epoch 4242/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1432202212.1957 - val_loss: 3825508890.1553\n",
      "Epoch 4243/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1433870267.3659 - val_loss: 3844540154.8858\n",
      "Epoch 4244/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1431940194.6928 - val_loss: 3822847489.4612\n",
      "Epoch 4245/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1432150311.5773 - val_loss: 3829247288.1096\n",
      "Epoch 4246/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1432578125.6517 - val_loss: 3821871253.6256\n",
      "Epoch 4247/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1436160084.6654 - val_loss: 3846488621.0046\n",
      "Epoch 4248/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1433054825.7065 - val_loss: 3815780017.2420\n",
      "Epoch 4249/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1432167032.4853 - val_loss: 3820969529.1324\n",
      "Epoch 4250/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1432465322.5832 - val_loss: 3817650597.5525\n",
      "Epoch 4251/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1432018219.0841 - val_loss: 3833505079.8174\n",
      "Epoch 4252/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1433099246.0900 - val_loss: 3829792405.1872\n",
      "Epoch 4253/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1431283656.2661 - val_loss: 3824491625.6438\n",
      "Epoch 4254/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1431584909.5264 - val_loss: 3824494679.6712\n",
      "Epoch 4255/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1432789165.0881 - val_loss: 3819930623.2694\n",
      "Epoch 4256/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1431335512.6732 - val_loss: 3825708496.5114\n",
      "Epoch 4257/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1431717254.2622 - val_loss: 3825986970.0091\n",
      "Epoch 4258/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1431619716.6341 - val_loss: 3833307121.2420\n",
      "Epoch 4259/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1432271993.3620 - val_loss: 3824493262.1735\n",
      "Epoch 4260/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1432078305.3151 - val_loss: 3837063805.0776\n",
      "Epoch 4261/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1431574282.5205 - val_loss: 3831439484.9315\n",
      "Epoch 4262/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1432242084.5714 - val_loss: 3822372754.7032\n",
      "Epoch 4263/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1432450631.0137 - val_loss: 3833079478.7945\n",
      "Epoch 4264/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1432514163.2250 - val_loss: 3824403086.0274\n",
      "Epoch 4265/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1432731635.2250 - val_loss: 3833170397.9543\n",
      "Epoch 4266/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1431851993.0489 - val_loss: 3828011620.3836\n",
      "Epoch 4267/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1431839933.3699 - val_loss: 3824468149.7717\n",
      "Epoch 4268/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1431696050.2231 - val_loss: 3824753046.9406\n",
      "Epoch 4269/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1434036888.7984 - val_loss: 3833005280.2922\n",
      "Epoch 4270/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1432673818.0509 - val_loss: 3819540537.7169\n",
      "Epoch 4271/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1431508273.0959 - val_loss: 3823700010.0822\n",
      "Epoch 4272/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1432146710.0431 - val_loss: 3827872170.6667\n",
      "Epoch 4273/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1432552576.0000 - val_loss: 3827837443.0685\n",
      "Epoch 4274/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1433116650.7084 - val_loss: 3841502446.9041\n",
      "Epoch 4275/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1434060346.8650 - val_loss: 3816386362.7397\n",
      "Epoch 4276/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1431545486.0274 - val_loss: 3824101540.0913\n",
      "Epoch 4277/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1431356105.6438 - val_loss: 3833087334.1370\n",
      "Epoch 4278/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1431324441.5499 - val_loss: 3834177189.6986\n",
      "Epoch 4279/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1431760320.6262 - val_loss: 3824063889.0959\n",
      "Epoch 4280/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1432389993.8317 - val_loss: 3824942523.0320\n",
      "Epoch 4281/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1431167236.5088 - val_loss: 3834905311.5616\n",
      "Epoch 4282/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1432506479.2172 - val_loss: 3823581689.4247\n",
      "Epoch 4283/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1432035147.3973 - val_loss: 3827059658.8128\n",
      "Epoch 4284/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1433065272.3601 - val_loss: 3823492076.5662\n",
      "Epoch 4285/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1431533120.7515 - val_loss: 3833103084.8584\n",
      "Epoch 4286/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1431466065.0333 - val_loss: 3836776210.5571\n",
      "Epoch 4287/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1431459684.6967 - val_loss: 3839319251.7260\n",
      "Epoch 4288/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1430982598.6380 - val_loss: 3826700185.7169\n",
      "Epoch 4289/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1431381313.7534 - val_loss: 3833401915.6164\n",
      "Epoch 4290/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1431254037.4168 - val_loss: 3826027678.6849\n",
      "Epoch 4291/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1434400184.8611 - val_loss: 3842258191.4886\n",
      "Epoch 4292/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1431075032.5479 - val_loss: 3822686602.5205\n",
      "Epoch 4293/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1431067653.0098 - val_loss: 3833153153.1689\n",
      "Epoch 4294/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1431208223.8121 - val_loss: 3834868573.3699\n",
      "Epoch 4295/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1431328290.3170 - val_loss: 3829199461.4064\n",
      "Epoch 4296/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1431892954.1761 - val_loss: 3822590525.2237\n",
      "Epoch 4297/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1433067019.2720 - val_loss: 3840177718.0639\n",
      "Epoch 4298/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1430673700.6967 - val_loss: 3823736141.8813\n",
      "Epoch 4299/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1430895298.6301 - val_loss: 3822802896.2192\n",
      "Epoch 4300/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1432298228.3523 - val_loss: 3834094648.9863\n",
      "Epoch 4301/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1430947425.6908 - val_loss: 3832153456.0731\n",
      "Epoch 4302/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1431488795.5538 - val_loss: 3835444634.3014\n",
      "Epoch 4303/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1431250577.5342 - val_loss: 3819631789.7352\n",
      "Epoch 4304/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 54us/step - loss: 1431532991.8748 - val_loss: 3819400333.7352\n",
      "Epoch 4305/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1431510642.2231 - val_loss: 3819385176.6941\n",
      "Epoch 4306/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1431503050.5205 - val_loss: 3828655114.6667\n",
      "Epoch 4307/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1433037182.9980 - val_loss: 3839084135.3059\n",
      "Epoch 4308/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1431664563.3503 - val_loss: 3825530557.6621\n",
      "Epoch 4309/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1431415662.7162 - val_loss: 3820171880.4749\n",
      "Epoch 4310/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1432841644.3366 - val_loss: 3828957828.2374\n",
      "Epoch 4311/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1432563048.5166 - val_loss: 3815852363.8356\n",
      "Epoch 4312/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1432852426.8963 - val_loss: 3843170340.6758\n",
      "Epoch 4313/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1431586581.0411 - val_loss: 3826929583.7808\n",
      "Epoch 4314/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1431370873.2368 - val_loss: 3815414691.3607\n",
      "Epoch 4315/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1431627392.3757 - val_loss: 3828050563.3607\n",
      "Epoch 4316/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1432350634.0822 - val_loss: 3841506701.0046\n",
      "Epoch 4317/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1431434928.3444 - val_loss: 3819390133.9178\n",
      "Epoch 4318/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1432587890.2231 - val_loss: 3820391497.4977\n",
      "Epoch 4319/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1432099613.0568 - val_loss: 3834996342.2100\n",
      "Epoch 4320/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1431070230.9198 - val_loss: 3819691645.8082\n",
      "Epoch 4321/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1431106757.8865 - val_loss: 3827991132.2009\n",
      "Epoch 4322/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1430787187.7260 - val_loss: 3826400494.0274\n",
      "Epoch 4323/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1436476043.7730 - val_loss: 3818121295.0502\n",
      "Epoch 4324/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1431607688.6419 - val_loss: 3844213765.1142\n",
      "Epoch 4325/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1432724377.2994 - val_loss: 3826585886.5388\n",
      "Epoch 4326/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1430312415.4364 - val_loss: 3828491900.3470\n",
      "Epoch 4327/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1431792492.9628 - val_loss: 3831348720.8037\n",
      "Epoch 4328/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1435416420.9472 - val_loss: 3844077351.5982\n",
      "Epoch 4329/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1431723880.9550 - val_loss: 3817216697.7169\n",
      "Epoch 4330/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1431828218.2387 - val_loss: 3821307773.2237\n",
      "Epoch 4331/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1430481812.7906 - val_loss: 3818210985.2055\n",
      "Epoch 4332/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1430282714.9276 - val_loss: 3827112576.1461\n",
      "Epoch 4333/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1431205006.4031 - val_loss: 3837523020.2740\n",
      "Epoch 4334/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1430350456.8611 - val_loss: 3828506159.3425\n",
      "Epoch 4335/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1431725983.3112 - val_loss: 3824407979.3973\n",
      "Epoch 4336/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1431782362.6145 - val_loss: 3830983612.6393\n",
      "Epoch 4337/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1430778114.7554 - val_loss: 3836854764.5662\n",
      "Epoch 4338/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1431152419.0685 - val_loss: 3833192398.1735\n",
      "Epoch 4339/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1431174039.4207 - val_loss: 3824312937.7900\n",
      "Epoch 4340/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1431093574.1370 - val_loss: 3844219206.7215\n",
      "Epoch 4341/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1430130568.5166 - val_loss: 3831333302.7945\n",
      "Epoch 4342/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1432891627.9609 - val_loss: 3821261650.1187\n",
      "Epoch 4343/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1434336963.6321 - val_loss: 3841093917.0776\n",
      "Epoch 4344/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1430937422.0274 - val_loss: 3839693586.2648\n",
      "Epoch 4345/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1430304840.2661 - val_loss: 3833977767.5982\n",
      "Epoch 4346/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1430417769.8317 - val_loss: 3835028873.3516\n",
      "Epoch 4347/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1430132532.7280 - val_loss: 3823895144.1826\n",
      "Epoch 4348/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1431377649.9726 - val_loss: 3825437959.1598\n",
      "Epoch 4349/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1430342560.0626 - val_loss: 3836142551.8174\n",
      "Epoch 4350/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1430953062.7006 - val_loss: 3835015885.2968\n",
      "Epoch 4351/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1430362509.5264 - val_loss: 3832764419.3607\n",
      "Epoch 4352/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1431376441.4873 - val_loss: 3827765075.1416\n",
      "Epoch 4353/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1431167200.8141 - val_loss: 3839566702.6119\n",
      "Epoch 4354/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1430608975.9061 - val_loss: 3821440052.7489\n",
      "Epoch 4355/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1432793285.6360 - val_loss: 3812164242.5571\n",
      "Epoch 4356/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1431017669.2603 - val_loss: 3837932819.4338\n",
      "Epoch 4357/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1433321717.3542 - val_loss: 3821641914.3014\n",
      "Epoch 4358/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1431630836.9785 - val_loss: 3831537478.5753\n",
      "Epoch 4359/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1431139818.2074 - val_loss: 3823069865.0594\n",
      "Epoch 4360/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1430742218.1448 - val_loss: 3841227270.4292\n",
      "Epoch 4361/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1429713428.0391 - val_loss: 3829729458.7032\n",
      "Epoch 4362/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1430545726.3718 - val_loss: 3826474875.1781\n",
      "Epoch 4363/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1430399114.5205 - val_loss: 3821332488.4749\n",
      "Epoch 4364/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1429649765.8239 - val_loss: 3828333220.5297\n",
      "Epoch 4365/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1431674959.2798 - val_loss: 3846351386.0091\n",
      "Epoch 4366/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1429909108.7280 - val_loss: 3821878202.3014\n",
      "Epoch 4367/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1430222284.7750 - val_loss: 3819184525.1507\n",
      "Epoch 4368/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 59us/step - loss: 1430550188.0861 - val_loss: 3818799488.2922\n",
      "Epoch 4369/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1430504417.9413 - val_loss: 3846714691.6530\n",
      "Epoch 4370/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1431198820.9472 - val_loss: 3819693061.8447\n",
      "Epoch 4371/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1432173236.9785 - val_loss: 3841021093.1142\n",
      "Epoch 4372/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1429713545.3933 - val_loss: 3824290793.3516\n",
      "Epoch 4373/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1430352344.4227 - val_loss: 3823980752.5114\n",
      "Epoch 4374/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1429750587.9922 - val_loss: 3829586935.5251\n",
      "Epoch 4375/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1430242516.2896 - val_loss: 3833644867.0685\n",
      "Epoch 4376/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1429614014.3718 - val_loss: 3827952280.4018\n",
      "Epoch 4377/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1429941310.6849 - val_loss: 3824881681.5342\n",
      "Epoch 4378/10000\n",
      "1022/1022 [==============================] - 0s 82us/step - loss: 1430607970.1918 - val_loss: 3830535167.4155\n",
      "Epoch 4379/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1431084000.6888 - val_loss: 3836273795.2146\n",
      "Epoch 4380/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1429932692.0391 - val_loss: 3821695842.1918\n",
      "Epoch 4381/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1430567801.6125 - val_loss: 3821857293.5890\n",
      "Epoch 4382/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1429605415.5773 - val_loss: 3839836130.3379\n",
      "Epoch 4383/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1429832377.8630 - val_loss: 3841688021.3333\n",
      "Epoch 4384/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1430883133.1194 - val_loss: 3822799474.9954\n",
      "Epoch 4385/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1430241127.9530 - val_loss: 3840195154.5571\n",
      "Epoch 4386/10000\n",
      "1022/1022 [==============================] - 0s 66us/step - loss: 1429591115.7730 - val_loss: 3831096094.6849\n",
      "Epoch 4387/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1430117222.1996 - val_loss: 3826329684.4566\n",
      "Epoch 4388/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1431320356.3209 - val_loss: 3833715254.2100\n",
      "Epoch 4389/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1430306992.7202 - val_loss: 3827834472.6210\n",
      "Epoch 4390/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1429919392.9393 - val_loss: 3832257460.1644\n",
      "Epoch 4391/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1429972108.5245 - val_loss: 3814859930.7397\n",
      "Epoch 4392/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1429366169.5499 - val_loss: 3828909476.8219\n",
      "Epoch 4393/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1429218899.4129 - val_loss: 3828494038.5023\n",
      "Epoch 4394/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1430681645.0881 - val_loss: 3815947573.1872\n",
      "Epoch 4395/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1431319346.0978 - val_loss: 3830688014.9041\n",
      "Epoch 4396/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1430268841.0802 - val_loss: 3823892434.2648\n",
      "Epoch 4397/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1429958121.8943 - val_loss: 3820088773.4064\n",
      "Epoch 4398/10000\n",
      "1022/1022 [==============================] - 0s 65us/step - loss: 1429171668.9159 - val_loss: 3833671268.0913\n",
      "Epoch 4399/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1428853238.9824 - val_loss: 3829705752.5479\n",
      "Epoch 4400/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1429121651.0998 - val_loss: 3819788658.2648\n",
      "Epoch 4401/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1429329622.6693 - val_loss: 3832262999.0868\n",
      "Epoch 4402/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1429487043.8826 - val_loss: 3818593758.1005\n",
      "Epoch 4403/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1428875562.9589 - val_loss: 3820890780.4932\n",
      "Epoch 4404/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1429353275.1155 - val_loss: 3814750211.6530\n",
      "Epoch 4405/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1428091639.9843 - val_loss: 3827255048.3288\n",
      "Epoch 4406/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1430376612.3836 - val_loss: 3829528452.5297\n",
      "Epoch 4407/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1429029713.9726 - val_loss: 3833363966.2466\n",
      "Epoch 4408/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1429975979.2094 - val_loss: 3824038959.1963\n",
      "Epoch 4409/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1428443108.1957 - val_loss: 3835031252.0183\n",
      "Epoch 4410/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1430417475.3816 - val_loss: 3830568286.3927\n",
      "Epoch 4411/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1429950291.1624 - val_loss: 3819179915.8356\n",
      "Epoch 4412/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1430362104.4853 - val_loss: 3809603292.7854\n",
      "Epoch 4413/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1432063497.0176 - val_loss: 3852352562.8493\n",
      "Epoch 4414/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1428190599.0137 - val_loss: 3825463191.6712\n",
      "Epoch 4415/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1427944775.5773 - val_loss: 3827810405.2603\n",
      "Epoch 4416/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1428410475.0215 - val_loss: 3823890240.7306\n",
      "Epoch 4417/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1428591439.1546 - val_loss: 3837305916.2009\n",
      "Epoch 4418/10000\n",
      "1022/1022 [==============================] - 0s 73us/step - loss: 1427890989.8395 - val_loss: 3827411850.3744\n",
      "Epoch 4419/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1427837317.8865 - val_loss: 3829856004.5297\n",
      "Epoch 4420/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1427919308.6497 - val_loss: 3831894643.8721\n",
      "Epoch 4421/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1428335691.5225 - val_loss: 3840821310.5388\n",
      "Epoch 4422/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1429071844.6967 - val_loss: 3823714032.9498\n",
      "Epoch 4423/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1428061373.2446 - val_loss: 3839839139.6530\n",
      "Epoch 4424/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1430848759.2329 - val_loss: 3827805450.9589\n",
      "Epoch 4425/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1427529072.5949 - val_loss: 3841857861.8447\n",
      "Epoch 4426/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1429553773.9648 - val_loss: 3824372294.8676\n",
      "Epoch 4427/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1429097525.9804 - val_loss: 3836549130.3744\n",
      "Epoch 4428/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1428248731.8043 - val_loss: 3828927876.0913\n",
      "Epoch 4429/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1432425221.6360 - val_loss: 3859587583.5616\n",
      "Epoch 4430/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1429536871.7025 - val_loss: 3820401561.2785\n",
      "Epoch 4431/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1428212857.4873 - val_loss: 3841273494.9406\n",
      "Epoch 4432/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 58us/step - loss: 1429843914.3953 - val_loss: 3823878724.8219\n",
      "Epoch 4433/10000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1427156132.8219 - val_loss: 3844727491.5068\n",
      "Epoch 4434/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1427447534.7162 - val_loss: 3845005810.8493\n",
      "Epoch 4435/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1427512493.5890 - val_loss: 3843183169.0228\n",
      "Epoch 4436/10000\n",
      "1022/1022 [==============================] - 0s 66us/step - loss: 1427399140.9472 - val_loss: 3846602514.7032\n",
      "Epoch 4437/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1427985422.5284 - val_loss: 3827543172.5297\n",
      "Epoch 4438/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1426885727.6869 - val_loss: 3838388629.1872\n",
      "Epoch 4439/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1427028225.7534 - val_loss: 3836843984.2192\n",
      "Epoch 4440/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1429105382.3249 - val_loss: 3849409336.1096\n",
      "Epoch 4441/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1426824212.0391 - val_loss: 3841613601.1689\n",
      "Epoch 4442/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1429601312.0626 - val_loss: 3821382502.7215\n",
      "Epoch 4443/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1430257405.2446 - val_loss: 3859631338.6667\n",
      "Epoch 4444/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1427370612.4775 - val_loss: 3843378582.5023\n",
      "Epoch 4445/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1427663246.7789 - val_loss: 3846047558.8676\n",
      "Epoch 4446/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1429269159.8278 - val_loss: 3830699381.6256\n",
      "Epoch 4447/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1428398171.9295 - val_loss: 3832670979.0685\n",
      "Epoch 4448/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1427001858.2544 - val_loss: 3843607332.5297\n",
      "Epoch 4449/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1427898664.7045 - val_loss: 3843345240.6941\n",
      "Epoch 4450/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1427598507.3346 - val_loss: 3838907054.1735\n",
      "Epoch 4451/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1427001637.9491 - val_loss: 3849466605.7352\n",
      "Epoch 4452/10000\n",
      "1022/1022 [==============================] - 0s 69us/step - loss: 1426949994.2074 - val_loss: 3846120863.4155\n",
      "Epoch 4453/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1428679409.9726 - val_loss: 3857356789.9178\n",
      "Epoch 4454/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1428436968.9550 - val_loss: 3833878177.0228\n",
      "Epoch 4455/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1426590741.6673 - val_loss: 3844396220.0548\n",
      "Epoch 4456/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1427721828.4462 - val_loss: 3838922366.6849\n",
      "Epoch 4457/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1426993052.4305 - val_loss: 3838933702.8676\n",
      "Epoch 4458/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1426633625.8004 - val_loss: 3844405256.0365\n",
      "Epoch 4459/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1427106991.8434 - val_loss: 3854110454.2100\n",
      "Epoch 4460/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1426369089.6282 - val_loss: 3848108869.5525\n",
      "Epoch 4461/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1428511025.5969 - val_loss: 3845247085.1507\n",
      "Epoch 4462/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1429368654.7789 - val_loss: 3840826732.1279\n",
      "Epoch 4463/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1426066288.2192 - val_loss: 3844557780.6027\n",
      "Epoch 4464/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1426415243.0215 - val_loss: 3853018174.5388\n",
      "Epoch 4465/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1425888823.3581 - val_loss: 3847686784.4384\n",
      "Epoch 4466/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1428171621.6986 - val_loss: 3866990560.1461\n",
      "Epoch 4467/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1427406870.0431 - val_loss: 3830894256.6575\n",
      "Epoch 4468/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1425815816.5166 - val_loss: 3841513204.3105\n",
      "Epoch 4469/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1426403675.3033 - val_loss: 3855069883.7626\n",
      "Epoch 4470/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1426331402.5205 - val_loss: 3853224781.8813\n",
      "Epoch 4471/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1427662401.8787 - val_loss: 3846635998.5388\n",
      "Epoch 4472/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1426839642.9276 - val_loss: 3848705249.8995\n",
      "Epoch 4473/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1426555863.0450 - val_loss: 3841767378.2648\n",
      "Epoch 4474/10000\n",
      "1022/1022 [==============================] - 0s 74us/step - loss: 1427061587.6634 - val_loss: 3846509639.0137\n",
      "Epoch 4475/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1425908991.3738 - val_loss: 3850334447.9269\n",
      "Epoch 4476/10000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1427027393.1272 - val_loss: 3865668765.2237\n",
      "Epoch 4477/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1426257038.6536 - val_loss: 3852483267.6530\n",
      "Epoch 4478/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1427795836.7436 - val_loss: 3849496676.0913\n",
      "Epoch 4479/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1426104318.3718 - val_loss: 3853563785.2055\n",
      "Epoch 4480/10000\n",
      "1022/1022 [==============================] - 0s 67us/step - loss: 1428032225.9413 - val_loss: 3849571885.7352\n",
      "Epoch 4481/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1427015064.0470 - val_loss: 3842581346.7763\n",
      "Epoch 4482/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1425784812.4618 - val_loss: 3853423080.1826\n",
      "Epoch 4483/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1426160579.6321 - val_loss: 3859127897.4247\n",
      "Epoch 4484/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1425310550.9198 - val_loss: 3854696048.6575\n",
      "Epoch 4485/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1426230189.7143 - val_loss: 3850289717.3333\n",
      "Epoch 4486/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1427032271.4051 - val_loss: 3842655742.2466\n",
      "Epoch 4487/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1425498805.8552 - val_loss: 3850949825.6073\n",
      "Epoch 4488/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1425265154.0039 - val_loss: 3853688686.0274\n",
      "Epoch 4489/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1425678744.2975 - val_loss: 3856835056.5114\n",
      "Epoch 4490/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1426216848.2818 - val_loss: 3851624881.5342\n",
      "Epoch 4491/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1428701061.2603 - val_loss: 3839132710.2831\n",
      "Epoch 4492/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1425329718.6067 - val_loss: 3865703413.3333\n",
      "Epoch 4493/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1427508579.6947 - val_loss: 3841886501.8447\n",
      "Epoch 4494/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1425204093.2446 - val_loss: 3854916273.2420\n",
      "Epoch 4495/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1425156246.2935 - val_loss: 3862074795.1050\n",
      "Epoch 4496/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 50us/step - loss: 1425337136.8454 - val_loss: 3861215471.7808\n",
      "Epoch 4497/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1425022882.6301 - val_loss: 3849860527.0502\n",
      "Epoch 4498/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1424990564.6967 - val_loss: 3850560886.7945\n",
      "Epoch 4499/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1425389312.2505 - val_loss: 3853495182.3196\n",
      "Epoch 4500/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1425810874.8650 - val_loss: 3868402639.7808\n",
      "Epoch 4501/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1425452130.3170 - val_loss: 3848200892.4932\n",
      "Epoch 4502/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1428131631.0920 - val_loss: 3866935305.3516\n",
      "Epoch 4503/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1424635829.9804 - val_loss: 3856425816.9863\n",
      "Epoch 4504/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1424637306.1135 - val_loss: 3850330804.8950\n",
      "Epoch 4505/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1425840524.1487 - val_loss: 3853590922.2283\n",
      "Epoch 4506/10000\n",
      "1022/1022 [==============================] - 0s 63us/step - loss: 1424981069.1507 - val_loss: 3841825297.8265\n",
      "Epoch 4507/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1425904407.5460 - val_loss: 3863899901.5160\n",
      "Epoch 4508/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1424336739.8200 - val_loss: 3856659536.2192\n",
      "Epoch 4509/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1425064236.5871 - val_loss: 3848598678.5023\n",
      "Epoch 4510/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1424732454.5753 - val_loss: 3860986407.5982\n",
      "Epoch 4511/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1424065901.2133 - val_loss: 3853263413.3333\n",
      "Epoch 4512/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1427092691.6634 - val_loss: 3873671944.6210\n",
      "Epoch 4513/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1424223245.7769 - val_loss: 3848059509.6256\n",
      "Epoch 4514/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1425085042.3483 - val_loss: 3860789198.4658\n",
      "Epoch 4515/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1426598439.0763 - val_loss: 3855490883.0685\n",
      "Epoch 4516/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1426194731.0841 - val_loss: 3872904821.6256\n",
      "Epoch 4517/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1425745765.3229 - val_loss: 3852149473.8995\n",
      "Epoch 4518/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1426265878.5440 - val_loss: 3878218925.1507\n",
      "Epoch 4519/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1424041080.2975 - val_loss: 3854915570.1187\n",
      "Epoch 4520/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1427131612.4305 - val_loss: 3843528764.3470\n",
      "Epoch 4521/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1424639657.9569 - val_loss: 3861005967.1963\n",
      "Epoch 4522/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1424824039.5773 - val_loss: 3864769216.1461\n",
      "Epoch 4523/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1424649735.0137 - val_loss: 3871039080.6210\n",
      "Epoch 4524/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1423942843.8669 - val_loss: 3863736329.6438\n",
      "Epoch 4525/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1424009687.1703 - val_loss: 3854754708.3105\n",
      "Epoch 4526/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1424289905.4716 - val_loss: 3857376815.3425\n",
      "Epoch 4527/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1424392793.9256 - val_loss: 3858331323.4703\n",
      "Epoch 4528/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1424270147.1311 - val_loss: 3862359581.2237\n",
      "Epoch 4529/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1423796645.8239 - val_loss: 3866956214.6484\n",
      "Epoch 4530/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1424796954.1761 - val_loss: 3861620213.1872\n",
      "Epoch 4531/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1426283459.3816 - val_loss: 3863671334.7215\n",
      "Epoch 4532/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1424922915.5695 - val_loss: 3855132189.9543\n",
      "Epoch 4533/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1425058769.9100 - val_loss: 3871699565.2968\n",
      "Epoch 4534/10000\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 1425201999.5303 - val_loss: 3858050070.5023\n",
      "Epoch 4535/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1424059137.2524 - val_loss: 3856278374.5753\n",
      "Epoch 4536/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1423833497.2994 - val_loss: 3861776331.8356\n",
      "Epoch 4537/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1424602262.5440 - val_loss: 3872119217.3881\n",
      "Epoch 4538/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1426457001.3307 - val_loss: 3860572907.3973\n",
      "Epoch 4539/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1424890296.6106 - val_loss: 3880172418.6301\n",
      "Epoch 4540/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1425923513.9883 - val_loss: 3877436578.1918\n",
      "Epoch 4541/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1424961676.0235 - val_loss: 3867162401.1689\n",
      "Epoch 4542/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1424467913.8943 - val_loss: 3868681177.2785\n",
      "Epoch 4543/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1423651050.2701 - val_loss: 3858956987.7626\n",
      "Epoch 4544/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1423907381.9804 - val_loss: 3863228638.9772\n",
      "Epoch 4545/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1424056423.4521 - val_loss: 3861163831.8174\n",
      "Epoch 4546/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1424065834.0822 - val_loss: 3865028802.9224\n",
      "Epoch 4547/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1423909592.1722 - val_loss: 3863311253.1872\n",
      "Epoch 4548/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1424232158.9354 - val_loss: 3874264284.6393\n",
      "Epoch 4549/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1423652494.6536 - val_loss: 3863353660.4932\n",
      "Epoch 4550/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1423730778.6771 - val_loss: 3868161055.7078\n",
      "Epoch 4551/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1423168417.8160 - val_loss: 3870059535.3425\n",
      "Epoch 4552/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1424221303.2329 - val_loss: 3865515542.2100\n",
      "Epoch 4553/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1423461313.8787 - val_loss: 3871212071.1598\n",
      "Epoch 4554/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1424230967.1076 - val_loss: 3875181203.8721\n",
      "Epoch 4555/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1423105527.5460 - val_loss: 3866485076.3105\n",
      "Epoch 4556/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1423109322.6458 - val_loss: 3860430844.4932\n",
      "Epoch 4557/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1424119789.2133 - val_loss: 3871532232.9132\n",
      "Epoch 4558/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1424325811.7260 - val_loss: 3850280109.7352\n",
      "Epoch 4559/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1422810624.0000 - val_loss: 3866916797.8082\n",
      "Epoch 4560/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 49us/step - loss: 1423103730.9746 - val_loss: 3863450455.0868\n",
      "Epoch 4561/10000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1426688262.7632 - val_loss: 3877326958.6119\n",
      "Epoch 4562/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1423170723.5695 - val_loss: 3867993444.3836\n",
      "Epoch 4563/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1424454119.4521 - val_loss: 3859403158.3562\n",
      "Epoch 4564/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1425954615.3581 - val_loss: 3881897239.9635\n",
      "Epoch 4565/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1424516687.1546 - val_loss: 3855918049.1689\n",
      "Epoch 4566/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1423148693.0411 - val_loss: 3863062208.2922\n",
      "Epoch 4567/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1422709507.2564 - val_loss: 3867461553.5342\n",
      "Epoch 4568/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1423745567.8121 - val_loss: 3874666754.0457\n",
      "Epoch 4569/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1423567104.7515 - val_loss: 3856262500.3836\n",
      "Epoch 4570/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1425383147.8356 - val_loss: 3886009621.3333\n",
      "Epoch 4571/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1423699263.1233 - val_loss: 3873500431.6347\n",
      "Epoch 4572/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1422924527.2172 - val_loss: 3858696260.8219\n",
      "Epoch 4573/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1422987438.3405 - val_loss: 3866943449.5708\n",
      "Epoch 4574/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1423325510.1370 - val_loss: 3861196439.9635\n",
      "Epoch 4575/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1423864352.8141 - val_loss: 3872796317.2237\n",
      "Epoch 4576/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1426072527.6556 - val_loss: 3887587425.4612\n",
      "Epoch 4577/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1427339807.6869 - val_loss: 3861428093.3699\n",
      "Epoch 4578/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1422654723.8826 - val_loss: 3873194572.8584\n",
      "Epoch 4579/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1422704502.7319 - val_loss: 3872218908.7854\n",
      "Epoch 4580/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1423242658.8180 - val_loss: 3861314263.8174\n",
      "Epoch 4581/10000\n",
      "1022/1022 [==============================] - 0s 79us/step - loss: 1422653165.4012 - val_loss: 3878505192.6210\n",
      "Epoch 4582/10000\n",
      "1022/1022 [==============================] - 0s 68us/step - loss: 1421873709.5890 - val_loss: 3872082476.8584\n",
      "Epoch 4583/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1422406324.6027 - val_loss: 3869403322.5936\n",
      "Epoch 4584/10000\n",
      "1022/1022 [==============================] - 0s 65us/step - loss: 1422282867.2250 - val_loss: 3868783811.2146\n",
      "Epoch 4585/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1426011978.5205 - val_loss: 3884763883.5434\n",
      "Epoch 4586/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1422015345.4716 - val_loss: 3865972667.6164\n",
      "Epoch 4587/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1423674916.6967 - val_loss: 3870107396.9680\n",
      "Epoch 4588/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1422344019.6634 - val_loss: 3885949301.1872\n",
      "Epoch 4589/10000\n",
      "1022/1022 [==============================] - 0s 67us/step - loss: 1421986831.7808 - val_loss: 3867203178.8128\n",
      "Epoch 4590/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1422038424.0470 - val_loss: 3877306096.0731\n",
      "Epoch 4591/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1423913975.9843 - val_loss: 3877549538.9224\n",
      "Epoch 4592/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1422535127.1703 - val_loss: 3876824933.8447\n",
      "Epoch 4593/10000\n",
      "1022/1022 [==============================] - 0s 68us/step - loss: 1422520796.1800 - val_loss: 3877040320.8767\n",
      "Epoch 4594/10000\n",
      "1022/1022 [==============================] - 0s 84us/step - loss: 1425073742.2779 - val_loss: 3872049306.8858\n",
      "Epoch 4595/10000\n",
      "1022/1022 [==============================] - 0s 76us/step - loss: 1423618730.8337 - val_loss: 3876080504.4018\n",
      "Epoch 4596/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1424036944.4070 - val_loss: 3858740209.2420\n",
      "Epoch 4597/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1422298902.5440 - val_loss: 3880058748.2009\n",
      "Epoch 4598/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1421843001.9883 - val_loss: 3882429064.6210\n",
      "Epoch 4599/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1422001634.1918 - val_loss: 3873098475.9817\n",
      "Epoch 4600/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1422508735.6243 - val_loss: 3889765614.4658\n",
      "Epoch 4601/10000\n",
      "1022/1022 [==============================] - 0s 72us/step - loss: 1424813056.2505 - val_loss: 3873793327.6347\n",
      "Epoch 4602/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1422719243.7730 - val_loss: 3872755669.0411\n",
      "Epoch 4603/10000\n",
      "1022/1022 [==============================] - 0s 111us/step - loss: 1422762358.2309 - val_loss: 3894863451.3242\n",
      "Epoch 4604/10000\n",
      "1022/1022 [==============================] - 0s 76us/step - loss: 1422281267.8513 - val_loss: 3876840108.1279\n",
      "Epoch 4605/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1423120433.8474 - val_loss: 3884499762.8493\n",
      "Epoch 4606/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1423172268.8376 - val_loss: 3874583706.5936\n",
      "Epoch 4607/10000\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 1421378336.8141 - val_loss: 3882629409.8995\n",
      "Epoch 4608/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1421631756.2740 - val_loss: 3873791742.2466\n",
      "Epoch 4609/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1423061783.6712 - val_loss: 3875767194.4475\n",
      "Epoch 4610/10000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1421353358.5284 - val_loss: 3877127445.1872\n",
      "Epoch 4611/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1422486555.5538 - val_loss: 3881710366.3927\n",
      "Epoch 4612/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1421800184.6106 - val_loss: 3879303065.7169\n",
      "Epoch 4613/10000\n",
      "1022/1022 [==============================] - 0s 63us/step - loss: 1422319719.0763 - val_loss: 3871402280.3288\n",
      "Epoch 4614/10000\n",
      "1022/1022 [==============================] - 0s 65us/step - loss: 1423767531.0841 - val_loss: 3889364135.5982\n",
      "Epoch 4615/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1421746769.4090 - val_loss: 3871548771.2146\n",
      "Epoch 4616/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1420927104.1879 - val_loss: 3879043790.3196\n",
      "Epoch 4617/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1421488796.8063 - val_loss: 3882151918.0274\n",
      "Epoch 4618/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1423395251.3503 - val_loss: 3885714194.7032\n",
      "Epoch 4619/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1421127867.3659 - val_loss: 3880633695.1233\n",
      "Epoch 4620/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1420863261.0568 - val_loss: 3881957401.1324\n",
      "Epoch 4621/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1420915783.3894 - val_loss: 3880095801.8630\n",
      "Epoch 4622/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1421518834.7241 - val_loss: 3877090000.6575\n",
      "Epoch 4623/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1422051339.2720 - val_loss: 3891235363.9452\n",
      "Epoch 4624/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 48us/step - loss: 1421637090.3170 - val_loss: 3876540743.1598\n",
      "Epoch 4625/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1421507415.6712 - val_loss: 3879023458.7763\n",
      "Epoch 4626/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1421061514.0196 - val_loss: 3879349401.2785\n",
      "Epoch 4627/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1422010805.8552 - val_loss: 3889415373.7352\n",
      "Epoch 4628/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1421709407.1859 - val_loss: 3885447297.0228\n",
      "Epoch 4629/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1422744819.2250 - val_loss: 3893192376.8402\n",
      "Epoch 4630/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1420362050.1292 - val_loss: 3881738435.9452\n",
      "Epoch 4631/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1422996958.4344 - val_loss: 3880233440.2922\n",
      "Epoch 4632/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1421709258.6458 - val_loss: 3892142566.2831\n",
      "Epoch 4633/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1421054365.3072 - val_loss: 3877099396.6758\n",
      "Epoch 4634/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1422747835.1155 - val_loss: 3871856139.5434\n",
      "Epoch 4635/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1420272832.3757 - val_loss: 3894134948.2374\n",
      "Epoch 4636/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1422588077.3386 - val_loss: 3894458147.9452\n",
      "Epoch 4637/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1421646507.0841 - val_loss: 3894672862.1005\n",
      "Epoch 4638/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1421513224.7671 - val_loss: 3893332901.2603\n",
      "Epoch 4639/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1421196555.2720 - val_loss: 3875886551.8174\n",
      "Epoch 4640/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1420915253.1037 - val_loss: 3887181469.5160\n",
      "Epoch 4641/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1420962586.3014 - val_loss: 3878010897.6804\n",
      "Epoch 4642/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1420807206.8258 - val_loss: 3884976682.5205\n",
      "Epoch 4643/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1422663032.2348 - val_loss: 3898067224.2557\n",
      "Epoch 4644/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1420175973.9491 - val_loss: 3890075543.8174\n",
      "Epoch 4645/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1420951651.3190 - val_loss: 3876270095.1963\n",
      "Epoch 4646/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1423519593.7065 - val_loss: 3902349893.1142\n",
      "Epoch 4647/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1422479050.3953 - val_loss: 3890967623.5982\n",
      "Epoch 4648/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1421094143.3738 - val_loss: 3881113384.4749\n",
      "Epoch 4649/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1420390344.6419 - val_loss: 3885543230.3927\n",
      "Epoch 4650/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1420817848.3601 - val_loss: 3886524536.5479\n",
      "Epoch 4651/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1422347381.2290 - val_loss: 3905945730.1918\n",
      "Epoch 4652/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1421167303.3894 - val_loss: 3872937119.8539\n",
      "Epoch 4653/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1421117522.1605 - val_loss: 3897118407.4521\n",
      "Epoch 4654/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1421228283.6791 - val_loss: 3891200328.3288\n",
      "Epoch 4655/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1421754219.2094 - val_loss: 3878016841.0594\n",
      "Epoch 4656/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1422055218.5988 - val_loss: 3895880392.4749\n",
      "Epoch 4657/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1422977786.9902 - val_loss: 3885208875.2511\n",
      "Epoch 4658/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1421619816.7045 - val_loss: 3882869072.3653\n",
      "Epoch 4659/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1420869571.8826 - val_loss: 3890670522.8858\n",
      "Epoch 4660/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1422168024.6732 - val_loss: 3880998889.4977\n",
      "Epoch 4661/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1421356898.0665 - val_loss: 3885756878.7580\n",
      "Epoch 4662/10000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1420665175.6712 - val_loss: 3883351197.6621\n",
      "Epoch 4663/10000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1420541412.5714 - val_loss: 3891010021.6986\n",
      "Epoch 4664/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1420306550.4814 - val_loss: 3903246073.2785\n",
      "Epoch 4665/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1421431189.7926 - val_loss: 3914846768.0731\n",
      "Epoch 4666/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1421116265.9569 - val_loss: 3893853610.0822\n",
      "Epoch 4667/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1420709212.3053 - val_loss: 3891986411.8356\n",
      "Epoch 4668/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1422535879.3894 - val_loss: 3877563195.3242\n",
      "Epoch 4669/10000\n",
      "1022/1022 [==============================] - 0s 78us/step - loss: 1421314927.0294 - val_loss: 3889056394.6667\n",
      "Epoch 4670/10000\n",
      "1022/1022 [==============================] - 0s 72us/step - loss: 1421739524.7593 - val_loss: 3899532286.9772\n",
      "Epoch 4671/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1419665334.1057 - val_loss: 3887637681.8265\n",
      "Epoch 4672/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1421143529.2055 - val_loss: 3906407063.0868\n",
      "Epoch 4673/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1419513531.9922 - val_loss: 3880912317.0776\n",
      "Epoch 4674/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1421217074.8493 - val_loss: 3881515611.3242\n",
      "Epoch 4675/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1422492163.0059 - val_loss: 3909366229.1872\n",
      "Epoch 4676/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1421699604.5401 - val_loss: 3885978022.2831\n",
      "Epoch 4677/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1423848699.2407 - val_loss: 3894437405.5160\n",
      "Epoch 4678/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1419584719.2798 - val_loss: 3894122076.6393\n",
      "Epoch 4679/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1421041247.1859 - val_loss: 3885316936.1826\n",
      "Epoch 4680/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1419557874.0978 - val_loss: 3895840497.2420\n",
      "Epoch 4681/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1421127145.0802 - val_loss: 3897049872.9498\n",
      "Epoch 4682/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1419611193.1115 - val_loss: 3899456665.8630\n",
      "Epoch 4683/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1421146907.8043 - val_loss: 3907289098.5205\n",
      "Epoch 4684/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1422287909.3229 - val_loss: 3885148454.8676\n",
      "Epoch 4685/10000\n",
      "1022/1022 [==============================] - 0s 63us/step - loss: 1420497364.5401 - val_loss: 3896948799.8539\n",
      "Epoch 4686/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1419913900.7123 - val_loss: 3900206926.0274\n",
      "Epoch 4687/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1419932910.4658 - val_loss: 3898508668.2009\n",
      "Epoch 4688/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 37us/step - loss: 1421316604.3679 - val_loss: 3891770370.7763\n",
      "Epoch 4689/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1420334954.9589 - val_loss: 3889121330.8493\n",
      "Epoch 4690/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1420763101.8082 - val_loss: 3887227872.2922\n",
      "Epoch 4691/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1420608026.3014 - val_loss: 3897667578.1553\n",
      "Epoch 4692/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1420394874.0509 - val_loss: 3903185523.4338\n",
      "Epoch 4693/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1420083899.3659 - val_loss: 3892943007.5616\n",
      "Epoch 4694/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1421368276.4149 - val_loss: 3913187827.2877\n",
      "Epoch 4695/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1419665068.2114 - val_loss: 3896677241.7169\n",
      "Epoch 4696/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1419814699.4599 - val_loss: 3891425650.9954\n",
      "Epoch 4697/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1421306936.4853 - val_loss: 3896962066.2648\n",
      "Epoch 4698/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1419495132.8063 - val_loss: 3902699839.8539\n",
      "Epoch 4699/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1419651404.6497 - val_loss: 3901365029.4064\n",
      "Epoch 4700/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1420526855.2642 - val_loss: 3899329051.6164\n",
      "Epoch 4701/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1420591314.4110 - val_loss: 3888351549.6621\n",
      "Epoch 4702/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1419922952.3914 - val_loss: 3901519554.6301\n",
      "Epoch 4703/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1419959354.3640 - val_loss: 3899939276.1279\n",
      "Epoch 4704/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1419311688.3914 - val_loss: 3895723004.3470\n",
      "Epoch 4705/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1419600800.0626 - val_loss: 3900123224.2557\n",
      "Epoch 4706/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1419433438.9354 - val_loss: 3898324207.3425\n",
      "Epoch 4707/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1420839544.6106 - val_loss: 3909691494.1370\n",
      "Epoch 4708/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1419069648.1566 - val_loss: 3904272750.1735\n",
      "Epoch 4709/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1419469927.2016 - val_loss: 3886567129.4247\n",
      "Epoch 4710/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1419506506.1448 - val_loss: 3895199094.5023\n",
      "Epoch 4711/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1420206142.6223 - val_loss: 3911381107.2877\n",
      "Epoch 4712/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1422131549.2446 - val_loss: 3886285421.8813\n",
      "Epoch 4713/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1418287209.9569 - val_loss: 3904748096.0000\n",
      "Epoch 4714/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1419738778.5519 - val_loss: 3901148210.9954\n",
      "Epoch 4715/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1420812180.5401 - val_loss: 3899986721.3151\n",
      "Epoch 4716/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1419609443.6947 - val_loss: 3904009857.1689\n",
      "Epoch 4717/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1420405435.1155 - val_loss: 3894855469.5890\n",
      "Epoch 4718/10000\n",
      "1022/1022 [==============================] - 0s 75us/step - loss: 1420903477.7299 - val_loss: 3913728355.6530\n",
      "Epoch 4719/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1422794239.2485 - val_loss: 3905678017.0228\n",
      "Epoch 4720/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1419476653.4638 - val_loss: 3895096868.8219\n",
      "Epoch 4721/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1419665037.9022 - val_loss: 3895864676.8219\n",
      "Epoch 4722/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1419125347.0685 - val_loss: 3898812668.2009\n",
      "Epoch 4723/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1419895713.8160 - val_loss: 3889186391.9635\n",
      "Epoch 4724/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1419388129.9413 - val_loss: 3905510031.0502\n",
      "Epoch 4725/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1419404503.1703 - val_loss: 3901593477.1142\n",
      "Epoch 4726/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1421531761.9726 - val_loss: 3916140166.7215\n",
      "Epoch 4727/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1420811423.5616 - val_loss: 3903555564.1279\n",
      "Epoch 4728/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1419398733.4012 - val_loss: 3896445119.4155\n",
      "Epoch 4729/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1419862409.7691 - val_loss: 3899049762.3379\n",
      "Epoch 4730/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1418742765.9648 - val_loss: 3912204429.1507\n",
      "Epoch 4731/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1419975267.4442 - val_loss: 3898481678.0274\n",
      "Epoch 4732/10000\n",
      "1022/1022 [==============================] - 0s 76us/step - loss: 1419846887.5773 - val_loss: 3906236235.3973\n",
      "Epoch 4733/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1419407866.2387 - val_loss: 3907277509.6986\n",
      "Epoch 4734/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1418948245.1663 - val_loss: 3902029610.3744\n",
      "Epoch 4735/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1418896898.8806 - val_loss: 3909063624.6210\n",
      "Epoch 4736/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1418551893.1663 - val_loss: 3901760816.3653\n",
      "Epoch 4737/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1418969464.3601 - val_loss: 3902989262.0274\n",
      "Epoch 4738/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1418751959.6712 - val_loss: 3900567846.8676\n",
      "Epoch 4739/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1419457336.2348 - val_loss: 3913021996.2740\n",
      "Epoch 4740/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1419145049.9256 - val_loss: 3895608500.8950\n",
      "Epoch 4741/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1419306283.5851 - val_loss: 3908798612.0183\n",
      "Epoch 4742/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1418823218.4736 - val_loss: 3904513010.9954\n",
      "Epoch 4743/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1419218789.6986 - val_loss: 3896818402.6301\n",
      "Epoch 4744/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1419795931.5538 - val_loss: 3901996027.6164\n",
      "Epoch 4745/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1419967541.6047 - val_loss: 3919705468.2009\n",
      "Epoch 4746/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1418894282.6458 - val_loss: 3900025969.2420\n",
      "Epoch 4747/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1418339370.9589 - val_loss: 3905760534.9406\n",
      "Epoch 4748/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1419660287.3738 - val_loss: 3910006922.9589\n",
      "Epoch 4749/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1419656545.4403 - val_loss: 3890039896.5479\n",
      "Epoch 4750/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1419245005.4012 - val_loss: 3893194951.8904\n",
      "Epoch 4751/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1419606030.2779 - val_loss: 3923803609.4247\n",
      "Epoch 4752/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 42us/step - loss: 1418803810.4423 - val_loss: 3915941149.9543\n",
      "Epoch 4753/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1419996621.5264 - val_loss: 3910602578.5571\n",
      "Epoch 4754/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1419995443.3503 - val_loss: 3899044580.6758\n",
      "Epoch 4755/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1419057902.2153 - val_loss: 3912123904.4384\n",
      "Epoch 4756/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1418427520.0000 - val_loss: 3901040727.8174\n",
      "Epoch 4757/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1418704308.6027 - val_loss: 3892888305.6804\n",
      "Epoch 4758/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1419235457.5029 - val_loss: 3905438389.3333\n",
      "Epoch 4759/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1418357602.5675 - val_loss: 3907870613.9178\n",
      "Epoch 4760/10000\n",
      "1022/1022 [==============================] - 0s 67us/step - loss: 1418723046.9511 - val_loss: 3912853809.3881\n",
      "Epoch 4761/10000\n",
      "1022/1022 [==============================] - 0s 68us/step - loss: 1419663125.1663 - val_loss: 3908108143.3425\n",
      "Epoch 4762/10000\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 1420965652.5401 - val_loss: 3901591107.9452\n",
      "Epoch 4763/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1419889288.7671 - val_loss: 3911481170.5571\n",
      "Epoch 4764/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1418026172.2427 - val_loss: 3907589628.4932\n",
      "Epoch 4765/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1419355846.8258 - val_loss: 3909745462.0639\n",
      "Epoch 4766/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1418368325.5108 - val_loss: 3908951478.5023\n",
      "Epoch 4767/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1418356808.2661 - val_loss: 3906226063.4886\n",
      "Epoch 4768/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1419229329.9726 - val_loss: 3906734228.8950\n",
      "Epoch 4769/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1418257555.7886 - val_loss: 3909248656.3653\n",
      "Epoch 4770/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1418959747.2564 - val_loss: 3920407583.8539\n",
      "Epoch 4771/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1418721592.6106 - val_loss: 3912335963.9087\n",
      "Epoch 4772/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1418463461.8239 - val_loss: 3892368767.5616\n",
      "Epoch 4773/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1417828298.0196 - val_loss: 3900725333.4795\n",
      "Epoch 4774/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1418887758.6536 - val_loss: 3901875138.4840\n",
      "Epoch 4775/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1418187778.0039 - val_loss: 3909393195.9817\n",
      "Epoch 4776/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1418205043.9765 - val_loss: 3917683549.9543\n",
      "Epoch 4777/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1418552294.4501 - val_loss: 3898674891.3973\n",
      "Epoch 4778/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1419158057.5812 - val_loss: 3904729491.1416\n",
      "Epoch 4779/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1418961816.4227 - val_loss: 3901149329.0959\n",
      "Epoch 4780/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1418569607.5147 - val_loss: 3916652225.4612\n",
      "Epoch 4781/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1418892453.3229 - val_loss: 3908498769.2420\n",
      "Epoch 4782/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1418400318.1213 - val_loss: 3915861533.6621\n",
      "Epoch 4783/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1418488213.5421 - val_loss: 3906729830.8676\n",
      "Epoch 4784/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1419199510.0431 - val_loss: 3910357026.0457\n",
      "Epoch 4785/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1418468104.2661 - val_loss: 3904720839.1598\n",
      "Epoch 4786/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1418811503.2172 - val_loss: 3926385561.1324\n",
      "Epoch 4787/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1420440063.2485 - val_loss: 3909321568.1461\n",
      "Epoch 4788/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1418644882.2857 - val_loss: 3925620031.5616\n",
      "Epoch 4789/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1417135331.1937 - val_loss: 3906340995.3607\n",
      "Epoch 4790/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1418271260.8063 - val_loss: 3912927395.6530\n",
      "Epoch 4791/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1419252473.4873 - val_loss: 3900112021.7717\n",
      "Epoch 4792/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1418821449.7691 - val_loss: 3921631142.4292\n",
      "Epoch 4793/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1418273095.1389 - val_loss: 3899106697.0594\n",
      "Epoch 4794/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1418245510.2622 - val_loss: 3901247262.5388\n",
      "Epoch 4795/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1418543794.8493 - val_loss: 3910964377.5708\n",
      "Epoch 4796/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1417922770.0352 - val_loss: 3913453288.4749\n",
      "Epoch 4797/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1418539767.9843 - val_loss: 3913101563.3242\n",
      "Epoch 4798/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1417552520.6419 - val_loss: 3912287560.9132\n",
      "Epoch 4799/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1418241364.0391 - val_loss: 3907404298.9589\n",
      "Epoch 4800/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1418030785.6282 - val_loss: 3916771983.3425\n",
      "Epoch 4801/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1418165400.6732 - val_loss: 3910866266.5936\n",
      "Epoch 4802/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1422589838.0274 - val_loss: 3916569253.4064\n",
      "Epoch 4803/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1421205471.3112 - val_loss: 3902975073.7534\n",
      "Epoch 4804/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1417825764.8219 - val_loss: 3898207412.4566\n",
      "Epoch 4805/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1418133921.0646 - val_loss: 3910965854.1005\n",
      "Epoch 4806/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1417283034.8023 - val_loss: 3907377465.4247\n",
      "Epoch 4807/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1418559539.7260 - val_loss: 3906894923.8356\n",
      "Epoch 4808/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1417845517.6517 - val_loss: 3908625292.7123\n",
      "Epoch 4809/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1418932328.9550 - val_loss: 3925195447.5251\n",
      "Epoch 4810/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1419555061.4795 - val_loss: 3904515035.6164\n",
      "Epoch 4811/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1421398109.6830 - val_loss: 3923128754.8493\n",
      "Epoch 4812/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1417983284.1018 - val_loss: 3906537118.3927\n",
      "Epoch 4813/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1419167577.4247 - val_loss: 3891536078.1735\n",
      "Epoch 4814/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1416549627.9922 - val_loss: 3909241549.2968\n",
      "Epoch 4815/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1417470726.5127 - val_loss: 3913884250.8858\n",
      "Epoch 4816/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 38us/step - loss: 1416788098.8806 - val_loss: 3910494689.6073\n",
      "Epoch 4817/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1417221558.8571 - val_loss: 3912225786.8858\n",
      "Epoch 4818/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1418445448.2661 - val_loss: 3921762115.3607\n",
      "Epoch 4819/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1416522446.1526 - val_loss: 3903063428.2374\n",
      "Epoch 4820/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1417441062.0744 - val_loss: 3905828874.3744\n",
      "Epoch 4821/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1417232397.5264 - val_loss: 3907537859.6530\n",
      "Epoch 4822/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1421436158.9980 - val_loss: 3920257435.7626\n",
      "Epoch 4823/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1416965934.5910 - val_loss: 3908904149.4795\n",
      "Epoch 4824/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1416765049.6125 - val_loss: 3917481975.8174\n",
      "Epoch 4825/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1417966691.8826 - val_loss: 3901220648.9132\n",
      "Epoch 4826/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1416268975.3425 - val_loss: 3910055135.2694\n",
      "Epoch 4827/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1417894540.5245 - val_loss: 3918082376.3288\n",
      "Epoch 4828/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1416755408.7828 - val_loss: 3913213534.2466\n",
      "Epoch 4829/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1419650886.6380 - val_loss: 3898243804.9315\n",
      "Epoch 4830/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1416493964.2740 - val_loss: 3921593063.7443\n",
      "Epoch 4831/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1418254644.9785 - val_loss: 3914383051.5434\n",
      "Epoch 4832/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1416500498.0352 - val_loss: 3926616639.1233\n",
      "Epoch 4833/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1417465805.6517 - val_loss: 3917752073.3516\n",
      "Epoch 4834/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1418242057.6438 - val_loss: 3909871999.1233\n",
      "Epoch 4835/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1416875446.2309 - val_loss: 3924887103.8539\n",
      "Epoch 4836/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1417703467.0841 - val_loss: 3909536431.7808\n",
      "Epoch 4837/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1417067041.1898 - val_loss: 3926844480.1461\n",
      "Epoch 4838/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1416730520.6732 - val_loss: 3912568460.7123\n",
      "Epoch 4839/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1417488909.1507 - val_loss: 3911690370.7763\n",
      "Epoch 4840/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1417215552.8767 - val_loss: 3925262976.2922\n",
      "Epoch 4841/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1416917149.3072 - val_loss: 3933346892.2740\n",
      "Epoch 4842/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1417857088.6262 - val_loss: 3909021920.4384\n",
      "Epoch 4843/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1418463537.0959 - val_loss: 3924112946.5571\n",
      "Epoch 4844/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1418064251.4912 - val_loss: 3925589229.7352\n",
      "Epoch 4845/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1417020244.2896 - val_loss: 3904387175.0137\n",
      "Epoch 4846/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1416535602.0978 - val_loss: 3918279980.5662\n",
      "Epoch 4847/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1417430455.3581 - val_loss: 3923463718.2831\n",
      "Epoch 4848/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1417294305.0646 - val_loss: 3924800746.3744\n",
      "Epoch 4849/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1416672650.0196 - val_loss: 3930934824.9132\n",
      "Epoch 4850/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1417173125.5108 - val_loss: 3906721307.3242\n",
      "Epoch 4851/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1416000636.2427 - val_loss: 3916905720.1096\n",
      "Epoch 4852/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1416659122.3483 - val_loss: 3914795657.3516\n",
      "Epoch 4853/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1416401489.4090 - val_loss: 3918680415.4155\n",
      "Epoch 4854/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1416353411.5068 - val_loss: 3931632494.0274\n",
      "Epoch 4855/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1416822802.0352 - val_loss: 3919053341.5160\n",
      "Epoch 4856/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1417740555.7730 - val_loss: 3919742696.7671\n",
      "Epoch 4857/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1415943959.5460 - val_loss: 3928355771.7626\n",
      "Epoch 4858/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1416103659.9609 - val_loss: 3931758063.0502\n",
      "Epoch 4859/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1416325381.0098 - val_loss: 3929992542.1005\n",
      "Epoch 4860/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1416589535.4364 - val_loss: 3910375018.9589\n",
      "Epoch 4861/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1415553770.4579 - val_loss: 3925505709.7352\n",
      "Epoch 4862/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1417195957.3542 - val_loss: 3941963954.1187\n",
      "Epoch 4863/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1419038633.2055 - val_loss: 3910051564.8584\n",
      "Epoch 4864/10000\n",
      "1022/1022 [==============================] - 0s 63us/step - loss: 1417537437.3072 - val_loss: 3914696306.9954\n",
      "Epoch 4865/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1416783003.1781 - val_loss: 3931089840.3653\n",
      "Epoch 4866/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1416273757.4325 - val_loss: 3921749208.9863\n",
      "Epoch 4867/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1418548400.0939 - val_loss: 3913505994.5205\n",
      "Epoch 4868/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1418965193.8943 - val_loss: 3924233041.3881\n",
      "Epoch 4869/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1416263145.4560 - val_loss: 3912941992.1826\n",
      "Epoch 4870/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1415989045.8552 - val_loss: 3935231508.8950\n",
      "Epoch 4871/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1415315821.2133 - val_loss: 3931877679.4886\n",
      "Epoch 4872/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1417078106.6771 - val_loss: 3915391625.2055\n",
      "Epoch 4873/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1419769334.2309 - val_loss: 3920973469.6621\n",
      "Epoch 4874/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1416229730.1918 - val_loss: 3934692715.8356\n",
      "Epoch 4875/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1417029905.2838 - val_loss: 3940406467.3607\n",
      "Epoch 4876/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1416736877.9648 - val_loss: 3916847633.0959\n",
      "Epoch 4877/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1416286433.5656 - val_loss: 3924968407.3790\n",
      "Epoch 4878/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1415385021.6204 - val_loss: 3931774676.4566\n",
      "Epoch 4879/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1416360006.3875 - val_loss: 3927539464.4749\n",
      "Epoch 4880/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 41us/step - loss: 1417453586.9119 - val_loss: 3939453359.6347\n",
      "Epoch 4881/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1415306373.3855 - val_loss: 3924088475.7626\n",
      "Epoch 4882/10000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1416443040.0626 - val_loss: 3920899329.1689\n",
      "Epoch 4883/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1417061037.8395 - val_loss: 3931815204.8219\n",
      "Epoch 4884/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1415758417.0959 - val_loss: 3921644895.8539\n",
      "Epoch 4885/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1416317732.5714 - val_loss: 3918391694.0274\n",
      "Epoch 4886/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1415337045.4168 - val_loss: 3931210603.8356\n",
      "Epoch 4887/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1415391089.2211 - val_loss: 3930654512.3653\n",
      "Epoch 4888/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1415409360.4070 - val_loss: 3921088848.5114\n",
      "Epoch 4889/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1416837166.3405 - val_loss: 3914745374.5388\n",
      "Epoch 4890/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1415567595.7104 - val_loss: 3936697272.9863\n",
      "Epoch 4891/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1416122673.0959 - val_loss: 3929562155.3973\n",
      "Epoch 4892/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1415483565.8395 - val_loss: 3930929391.3425\n",
      "Epoch 4893/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1414791204.9472 - val_loss: 3924178737.9726\n",
      "Epoch 4894/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1415500848.8454 - val_loss: 3923409224.6210\n",
      "Epoch 4895/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1415302520.3601 - val_loss: 3922747102.6849\n",
      "Epoch 4896/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1415406993.1585 - val_loss: 3920450386.1187\n",
      "Epoch 4897/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1415099295.3112 - val_loss: 3939796116.0183\n",
      "Epoch 4898/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1415267911.8904 - val_loss: 3934293268.6027\n",
      "Epoch 4899/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1416192666.5519 - val_loss: 3935008133.9909\n",
      "Epoch 4900/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1414982318.5910 - val_loss: 3926742187.2511\n",
      "Epoch 4901/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1415720901.3855 - val_loss: 3922252270.7580\n",
      "Epoch 4902/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1416255769.2368 - val_loss: 3935858921.7900\n",
      "Epoch 4903/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1415533780.9159 - val_loss: 3931863828.7489\n",
      "Epoch 4904/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1415923695.9687 - val_loss: 3927907165.0776\n",
      "Epoch 4905/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1416556748.1487 - val_loss: 3914023614.9772\n",
      "Epoch 4906/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1414932008.5793 - val_loss: 3927065791.5616\n",
      "Epoch 4907/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1415581704.3914 - val_loss: 3937749145.1324\n",
      "Epoch 4908/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1414818927.2172 - val_loss: 3936229788.7854\n",
      "Epoch 4909/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1415045007.9061 - val_loss: 3933611884.1279\n",
      "Epoch 4910/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1414673510.4501 - val_loss: 3924257505.8995\n",
      "Epoch 4911/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1415072230.8258 - val_loss: 3931014145.3151\n",
      "Epoch 4912/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1414737446.0744 - val_loss: 3922116836.9680\n",
      "Epoch 4913/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1415597343.8121 - val_loss: 3932078782.6849\n",
      "Epoch 4914/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1415273823.1859 - val_loss: 3927352470.0639\n",
      "Epoch 4915/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1419377705.0802 - val_loss: 3906196280.6941\n",
      "Epoch 4916/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1413763617.9413 - val_loss: 3931852192.5845\n",
      "Epoch 4917/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1415022006.6067 - val_loss: 3936651034.7397\n",
      "Epoch 4918/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1415066677.1037 - val_loss: 3933893467.7626\n",
      "Epoch 4919/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1414769361.9100 - val_loss: 3926471286.3562\n",
      "Epoch 4920/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1414619519.2485 - val_loss: 3931945537.8995\n",
      "Epoch 4921/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1415567289.1115 - val_loss: 3921039652.8219\n",
      "Epoch 4922/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1417301393.0333 - val_loss: 3946359152.6575\n",
      "Epoch 4923/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1415017732.1331 - val_loss: 3928956522.6667\n",
      "Epoch 4924/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1416285239.3581 - val_loss: 3922227870.3927\n",
      "Epoch 4925/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1416068699.9295 - val_loss: 3952711573.0411\n",
      "Epoch 4926/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1415366151.2642 - val_loss: 3932346491.1781\n",
      "Epoch 4927/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1414962302.4971 - val_loss: 3933843597.7352\n",
      "Epoch 4928/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1415453593.8004 - val_loss: 3930342475.9817\n",
      "Epoch 4929/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1414370247.2642 - val_loss: 3941917517.4429\n",
      "Epoch 4930/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1414012848.4697 - val_loss: 3933790265.8630\n",
      "Epoch 4931/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1415392494.4658 - val_loss: 3920396232.6210\n",
      "Epoch 4932/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1414138470.7006 - val_loss: 3931085697.8995\n",
      "Epoch 4933/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1415666479.0920 - val_loss: 3938226016.0000\n",
      "Epoch 4934/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1414641500.6810 - val_loss: 3929483546.3014\n",
      "Epoch 4935/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1416174601.5186 - val_loss: 3936579744.8767\n",
      "Epoch 4936/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1415838529.3777 - val_loss: 3929978149.6986\n",
      "Epoch 4937/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1414464356.0705 - val_loss: 3941269509.1142\n",
      "Epoch 4938/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1414391508.6654 - val_loss: 3931017058.1918\n",
      "Epoch 4939/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1414497699.0685 - val_loss: 3941465468.4932\n",
      "Epoch 4940/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1416180424.8924 - val_loss: 3926126001.0959\n",
      "Epoch 4941/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1415699302.7006 - val_loss: 3923624356.2374\n",
      "Epoch 4942/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1415728931.4442 - val_loss: 3935381067.6895\n",
      "Epoch 4943/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1415561028.6341 - val_loss: 3945816458.3744\n",
      "Epoch 4944/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 37us/step - loss: 1414598812.6184 - val_loss: 3935794989.2968\n",
      "Epoch 4945/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1414120987.0528 - val_loss: 3935746185.0594\n",
      "Epoch 4946/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1413988275.3503 - val_loss: 3930049560.4018\n",
      "Epoch 4947/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1414861490.5988 - val_loss: 3928186329.7169\n",
      "Epoch 4948/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1414451913.5186 - val_loss: 3944601052.3470\n",
      "Epoch 4949/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1414436468.9785 - val_loss: 3932153715.1416\n",
      "Epoch 4950/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1413967484.4932 - val_loss: 3942467228.3470\n",
      "Epoch 4951/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1414875276.7750 - val_loss: 3933557723.4703\n",
      "Epoch 4952/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1416277659.4286 - val_loss: 3946654644.4566\n",
      "Epoch 4953/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1414404063.1859 - val_loss: 3927930772.7489\n",
      "Epoch 4954/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1414919093.0411 - val_loss: 3932458998.6484\n",
      "Epoch 4955/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1414592048.0939 - val_loss: 3946875655.4521\n",
      "Epoch 4956/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1414209691.0528 - val_loss: 3920429255.3059\n",
      "Epoch 4957/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1413775597.9648 - val_loss: 3933575220.4566\n",
      "Epoch 4958/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1414854985.3933 - val_loss: 3936696184.2557\n",
      "Epoch 4959/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1414815113.7691 - val_loss: 3927550996.1644\n",
      "Epoch 4960/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1413615170.8806 - val_loss: 3932969217.7534\n",
      "Epoch 4961/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1418605956.0078 - val_loss: 3948910767.9269\n",
      "Epoch 4962/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1414445256.7671 - val_loss: 3932755879.3059\n",
      "Epoch 4963/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1413749173.9804 - val_loss: 3936867029.6256\n",
      "Epoch 4964/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1417445417.5812 - val_loss: 3929317363.4338\n",
      "Epoch 4965/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1414231462.3875 - val_loss: 3937220608.1461\n",
      "Epoch 4966/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1415935101.7456 - val_loss: 3931543509.0411\n",
      "Epoch 4967/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1413382786.2544 - val_loss: 3939193118.6849\n",
      "Epoch 4968/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1415768091.9295 - val_loss: 3955768345.2785\n",
      "Epoch 4969/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1413947268.2583 - val_loss: 3932243852.5662\n",
      "Epoch 4970/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1413705457.7221 - val_loss: 3940250349.5890\n",
      "Epoch 4971/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1414440529.4090 - val_loss: 3931092850.1187\n",
      "Epoch 4972/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1414009345.0020 - val_loss: 3939062320.9498\n",
      "Epoch 4973/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1414386675.6008 - val_loss: 3940396617.9361\n",
      "Epoch 4974/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1414780980.2270 - val_loss: 3935041387.3973\n",
      "Epoch 4975/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1414751347.4755 - val_loss: 3937217500.4932\n",
      "Epoch 4976/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1414639933.9961 - val_loss: 3940409211.3242\n",
      "Epoch 4977/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1414016140.2114 - val_loss: 3935503941.6986\n",
      "Epoch 4978/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1413974656.6262 - val_loss: 3951498781.6621\n",
      "Epoch 4979/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1413284983.2329 - val_loss: 3937043920.5114\n",
      "Epoch 4980/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1414546993.8474 - val_loss: 3933493924.9680\n",
      "Epoch 4981/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1417369889.1898 - val_loss: 3955070273.3151\n",
      "Epoch 4982/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1413055900.3053 - val_loss: 3935960388.5297\n",
      "Epoch 4983/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1413546577.6595 - val_loss: 3929436042.9589\n",
      "Epoch 4984/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1414462159.9061 - val_loss: 3923203822.0274\n",
      "Epoch 4985/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1413792638.2466 - val_loss: 3940638554.4475\n",
      "Epoch 4986/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1415684973.7143 - val_loss: 3940711987.8721\n",
      "Epoch 4987/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1415215100.7436 - val_loss: 3923444304.2192\n",
      "Epoch 4988/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1413307173.3229 - val_loss: 3942602163.8721\n",
      "Epoch 4989/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1414154826.8963 - val_loss: 3938725231.7808\n",
      "Epoch 4990/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1415002790.8258 - val_loss: 3934843191.3790\n",
      "Epoch 4991/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1413538675.4755 - val_loss: 3943137143.3790\n",
      "Epoch 4992/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1415123571.7260 - val_loss: 3939223810.4840\n",
      "Epoch 4993/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1413338382.1526 - val_loss: 3952089553.9726\n",
      "Epoch 4994/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1414927237.2603 - val_loss: 3954040765.5160\n",
      "Epoch 4995/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1415314241.8787 - val_loss: 3950284271.9269\n",
      "Epoch 4996/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1414025680.1566 - val_loss: 3945992940.2740\n",
      "Epoch 4997/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1414616354.0665 - val_loss: 3934231702.0639\n",
      "Epoch 4998/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1414815173.1350 - val_loss: 3941881631.2694\n",
      "Epoch 4999/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1413733173.4795 - val_loss: 3940624335.7808\n",
      "Epoch 5000/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1414083497.0802 - val_loss: 3947028500.4566\n",
      "Epoch 5001/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1413397561.9883 - val_loss: 3939512312.1096\n",
      "Epoch 5002/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1413430511.9687 - val_loss: 3949068621.7352\n",
      "Epoch 5003/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1414734361.9256 - val_loss: 3926483053.2968\n",
      "Epoch 5004/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1414060720.8454 - val_loss: 3942976623.3425\n",
      "Epoch 5005/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1413223484.6184 - val_loss: 3937620309.9178\n",
      "Epoch 5006/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1412858443.8982 - val_loss: 3945576063.7078\n",
      "Epoch 5007/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1413002899.0372 - val_loss: 3939698211.5068\n",
      "Epoch 5008/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 37us/step - loss: 1413215045.7613 - val_loss: 3942188274.7032\n",
      "Epoch 5009/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1413317785.8004 - val_loss: 3939247782.2831\n",
      "Epoch 5010/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1414304175.8434 - val_loss: 3945230469.8447\n",
      "Epoch 5011/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1414948252.4305 - val_loss: 3952914980.8219\n",
      "Epoch 5012/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1413809899.7104 - val_loss: 3927808560.9498\n",
      "Epoch 5013/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1413908213.7299 - val_loss: 3943441580.7123\n",
      "Epoch 5014/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1412817490.1605 - val_loss: 3940582212.0913\n",
      "Epoch 5015/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1413431413.9804 - val_loss: 3948807733.4795\n",
      "Epoch 5016/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1416084431.1546 - val_loss: 3956819707.9087\n",
      "Epoch 5017/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1413328367.8434 - val_loss: 3927387830.7945\n",
      "Epoch 5018/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1414182110.6849 - val_loss: 3924769587.4338\n",
      "Epoch 5019/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1415434890.7710 - val_loss: 3943456456.4749\n",
      "Epoch 5020/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1413507184.9706 - val_loss: 3937313883.6164\n",
      "Epoch 5021/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1412850972.0548 - val_loss: 3946913829.8447\n",
      "Epoch 5022/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1413077604.1331 - val_loss: 3935120220.9315\n",
      "Epoch 5023/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1413006923.1468 - val_loss: 3949167282.9954\n",
      "Epoch 5024/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1415215649.8160 - val_loss: 3927946341.6986\n",
      "Epoch 5025/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1412660267.5851 - val_loss: 3939861806.6119\n",
      "Epoch 5026/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1412551169.7534 - val_loss: 3940111020.4201\n",
      "Epoch 5027/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1413059689.3307 - val_loss: 3943021568.5845\n",
      "Epoch 5028/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1412964587.8356 - val_loss: 3940728977.8265\n",
      "Epoch 5029/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1413205306.7397 - val_loss: 3953570077.3699\n",
      "Epoch 5030/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1412736497.9726 - val_loss: 3939648101.2603\n",
      "Epoch 5031/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1412661053.3699 - val_loss: 3940695173.6986\n",
      "Epoch 5032/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1412686111.8121 - val_loss: 3937930856.1826\n",
      "Epoch 5033/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1412849911.2329 - val_loss: 3945349634.0457\n",
      "Epoch 5034/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1412226829.4012 - val_loss: 3939037383.3059\n",
      "Epoch 5035/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1416158415.7808 - val_loss: 3933553801.0594\n",
      "Epoch 5036/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1414077601.8160 - val_loss: 3953669589.4795\n",
      "Epoch 5037/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1412698629.5108 - val_loss: 3947354855.7443\n",
      "Epoch 5038/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1412374566.8258 - val_loss: 3948250307.2146\n",
      "Epoch 5039/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1413738040.7358 - val_loss: 3946917026.4840\n",
      "Epoch 5040/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1414953781.6047 - val_loss: 3951411235.9452\n",
      "Epoch 5041/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1411327016.0783 - val_loss: 3930794692.9680\n",
      "Epoch 5042/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1413524406.9824 - val_loss: 3926488742.8676\n",
      "Epoch 5043/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1412008889.6125 - val_loss: 3943880912.9498\n",
      "Epoch 5044/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1412450214.8258 - val_loss: 3940999408.0731\n",
      "Epoch 5045/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1413633082.6145 - val_loss: 3943675961.4247\n",
      "Epoch 5046/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1413386988.5871 - val_loss: 3944489131.2511\n",
      "Epoch 5047/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1414687526.8258 - val_loss: 3949850611.1416\n",
      "Epoch 5048/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1413072025.4247 - val_loss: 3941531209.7900\n",
      "Epoch 5049/10000\n",
      "1022/1022 [==============================] - 0s 66us/step - loss: 1412719716.8219 - val_loss: 3932348924.7854\n",
      "Epoch 5050/10000\n",
      "1022/1022 [==============================] - 0s 73us/step - loss: 1412825894.7006 - val_loss: 3933899270.7215\n",
      "Epoch 5051/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1411953649.4716 - val_loss: 3947825457.6804\n",
      "Epoch 5052/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1413003433.3307 - val_loss: 3950827112.3288\n",
      "Epoch 5053/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1413013245.7456 - val_loss: 3944486117.5525\n",
      "Epoch 5054/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1412246630.1996 - val_loss: 3948170543.0502\n",
      "Epoch 5055/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1413188495.2798 - val_loss: 3953779506.4110\n",
      "Epoch 5056/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1412128612.8845 - val_loss: 3943521040.5114\n",
      "Epoch 5057/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1412607676.7436 - val_loss: 3927713659.4703\n",
      "Epoch 5058/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1412647968.8141 - val_loss: 3931288337.6804\n",
      "Epoch 5059/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1412386087.4521 - val_loss: 3954033101.1507\n",
      "Epoch 5060/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1412090550.4814 - val_loss: 3943052683.5434\n",
      "Epoch 5061/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1412931980.1487 - val_loss: 3945568399.1963\n",
      "Epoch 5062/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1414765849.8004 - val_loss: 3945988469.3333\n",
      "Epoch 5063/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1413030266.2387 - val_loss: 3936617637.2603\n",
      "Epoch 5064/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1413087388.8063 - val_loss: 3941234838.2100\n",
      "Epoch 5065/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1412982045.0568 - val_loss: 3943027435.8356\n",
      "Epoch 5066/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1412630800.0313 - val_loss: 3947325805.7352\n",
      "Epoch 5067/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1413335678.7476 - val_loss: 3949822343.7443\n",
      "Epoch 5068/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1412082470.8258 - val_loss: 3946618313.3516\n",
      "Epoch 5069/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1414046133.6047 - val_loss: 3933896032.4384\n",
      "Epoch 5070/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1411961928.3914 - val_loss: 3934717105.8265\n",
      "Epoch 5071/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1412912278.0431 - val_loss: 3937156311.9635\n",
      "Epoch 5072/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 37us/step - loss: 1411955946.7084 - val_loss: 3942998297.4247\n",
      "Epoch 5073/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1412990798.1526 - val_loss: 3961599627.5434\n",
      "Epoch 5074/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1412434295.2329 - val_loss: 3935173741.0046\n",
      "Epoch 5075/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1412764572.4305 - val_loss: 3950260263.1598\n",
      "Epoch 5076/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1413144866.3170 - val_loss: 3933223272.0365\n",
      "Epoch 5077/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1412953928.7671 - val_loss: 3954705627.9087\n",
      "Epoch 5078/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1411639745.1272 - val_loss: 3943192077.1507\n",
      "Epoch 5079/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1414331138.0039 - val_loss: 3934156383.1233\n",
      "Epoch 5080/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1411661256.3914 - val_loss: 3940830244.5297\n",
      "Epoch 5081/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1413329493.9178 - val_loss: 3952399167.5616\n",
      "Epoch 5082/10000\n",
      "1022/1022 [==============================] - 0s 69us/step - loss: 1415548669.4951 - val_loss: 3936339481.4247\n",
      "Epoch 5083/10000\n",
      "1022/1022 [==============================] - 0s 65us/step - loss: 1412118883.7573 - val_loss: 3967145679.7808\n",
      "Epoch 5084/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1412350956.5871 - val_loss: 3955153226.3744\n",
      "Epoch 5085/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1412124293.2603 - val_loss: 3935299847.4521\n",
      "Epoch 5086/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1411753905.0959 - val_loss: 3945512052.0183\n",
      "Epoch 5087/10000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1414072010.1448 - val_loss: 3953575084.2740\n",
      "Epoch 5088/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1411505091.8826 - val_loss: 3948649419.8356\n",
      "Epoch 5089/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1412144372.2270 - val_loss: 3942174701.8813\n",
      "Epoch 5090/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1412430532.8845 - val_loss: 3943100961.8995\n",
      "Epoch 5091/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1412185370.3014 - val_loss: 3959517596.7854\n",
      "Epoch 5092/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1411854353.2838 - val_loss: 3948797582.6119\n",
      "Epoch 5093/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1412005975.6712 - val_loss: 3948532433.6804\n",
      "Epoch 5094/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1411629876.7280 - val_loss: 3948216381.9543\n",
      "Epoch 5095/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1411369949.9335 - val_loss: 3944766146.7763\n",
      "Epoch 5096/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1412145509.4481 - val_loss: 3947095829.4795\n",
      "Epoch 5097/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1412533147.1781 - val_loss: 3944352295.0137\n",
      "Epoch 5098/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1412885332.0391 - val_loss: 3950244485.6986\n",
      "Epoch 5099/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1412167353.4873 - val_loss: 3963365947.1781\n",
      "Epoch 5100/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1411773233.3464 - val_loss: 3939478299.4703\n",
      "Epoch 5101/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1414545822.3092 - val_loss: 3942771654.5753\n",
      "Epoch 5102/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1410849802.7710 - val_loss: 3947381270.3562\n",
      "Epoch 5103/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1411874391.7965 - val_loss: 3939174604.4201\n",
      "Epoch 5104/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1412412436.0391 - val_loss: 3960965296.2192\n",
      "Epoch 5105/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1411968278.4188 - val_loss: 3945516521.0594\n",
      "Epoch 5106/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1412149006.0274 - val_loss: 3945535173.5525\n",
      "Epoch 5107/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1411890078.3718 - val_loss: 3944895173.1142\n",
      "Epoch 5108/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1411424176.5949 - val_loss: 3944917143.3790\n",
      "Epoch 5109/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1411459515.1155 - val_loss: 3946198259.4338\n",
      "Epoch 5110/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1412252275.3503 - val_loss: 3941806855.4521\n",
      "Epoch 5111/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1411444936.1409 - val_loss: 3939699989.3333\n",
      "Epoch 5112/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1413682997.6047 - val_loss: 3963243192.6941\n",
      "Epoch 5113/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1413401420.1487 - val_loss: 3928517870.0274\n",
      "Epoch 5114/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1410437622.7319 - val_loss: 3943834075.9087\n",
      "Epoch 5115/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1411573284.5714 - val_loss: 3946231284.3105\n",
      "Epoch 5116/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1410758563.0685 - val_loss: 3949838499.6530\n",
      "Epoch 5117/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1413449941.1663 - val_loss: 3950770550.7945\n",
      "Epoch 5118/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1411153007.9687 - val_loss: 3955825932.2740\n",
      "Epoch 5119/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1411762239.1233 - val_loss: 3952353018.7397\n",
      "Epoch 5120/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1411673538.6301 - val_loss: 3958651733.7717\n",
      "Epoch 5121/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1414313907.3503 - val_loss: 3972544834.9224\n",
      "Epoch 5122/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1410860361.0176 - val_loss: 3940839761.2420\n",
      "Epoch 5123/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1411969901.7143 - val_loss: 3941567049.6438\n",
      "Epoch 5124/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1412266506.3953 - val_loss: 3948499359.8539\n",
      "Epoch 5125/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1410901143.0450 - val_loss: 3948406302.3927\n",
      "Epoch 5126/10000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1411271763.0372 - val_loss: 3936370458.3014\n",
      "Epoch 5127/10000\n",
      "1022/1022 [==============================] - 0s 86us/step - loss: 1412766226.9119 - val_loss: 3941298392.5479\n",
      "Epoch 5128/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1410730953.1429 - val_loss: 3944009345.4612\n",
      "Epoch 5129/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1411414443.0841 - val_loss: 3959100216.6941\n",
      "Epoch 5130/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1412735279.2172 - val_loss: 3940910702.9041\n",
      "Epoch 5131/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1410733709.0254 - val_loss: 3955455439.0502\n",
      "Epoch 5132/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1410839476.8532 - val_loss: 3944952128.8767\n",
      "Epoch 5133/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1411188049.4090 - val_loss: 3947075783.3059\n",
      "Epoch 5134/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1412627224.0470 - val_loss: 3947185376.1461\n",
      "Epoch 5135/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1411812938.7710 - val_loss: 3959834520.5479\n",
      "Epoch 5136/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 79us/step - loss: 1411538267.9295 - val_loss: 3953067577.5708\n",
      "Epoch 5137/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1411160447.6243 - val_loss: 3950490993.3881\n",
      "Epoch 5138/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1411585549.9022 - val_loss: 3949116848.0731\n",
      "Epoch 5139/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1411711583.1859 - val_loss: 3959899345.3881\n",
      "Epoch 5140/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1410988516.1957 - val_loss: 3937971240.9132\n",
      "Epoch 5141/10000\n",
      "1022/1022 [==============================] - 0s 66us/step - loss: 1411311127.2955 - val_loss: 3941730468.5297\n",
      "Epoch 5142/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1411405064.0157 - val_loss: 3939301837.0046\n",
      "Epoch 5143/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1413941316.1331 - val_loss: 3963353095.8904\n",
      "Epoch 5144/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1410577322.3327 - val_loss: 3946303056.0731\n",
      "Epoch 5145/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1411943566.9041 - val_loss: 3938892674.3379\n",
      "Epoch 5146/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1411371054.8415 - val_loss: 3959359136.5845\n",
      "Epoch 5147/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1410865551.7808 - val_loss: 3950506817.3151\n",
      "Epoch 5148/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1410546393.4247 - val_loss: 3957456881.2420\n",
      "Epoch 5149/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1411999382.7945 - val_loss: 3939716713.4977\n",
      "Epoch 5150/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1411352061.2446 - val_loss: 3965520831.4155\n",
      "Epoch 5151/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1411126758.7006 - val_loss: 3944751410.7032\n",
      "Epoch 5152/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1410289259.9609 - val_loss: 3948012084.7489\n",
      "Epoch 5153/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1412734340.0078 - val_loss: 3963521745.0959\n",
      "Epoch 5154/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1411241855.8748 - val_loss: 3949276088.1096\n",
      "Epoch 5155/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1410751199.6869 - val_loss: 3961729130.5205\n",
      "Epoch 5156/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1411534773.8552 - val_loss: 3964474444.1279\n",
      "Epoch 5157/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1410459304.8297 - val_loss: 3942975753.6438\n",
      "Epoch 5158/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1415448538.9276 - val_loss: 3968274163.7260\n",
      "Epoch 5159/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1410358100.1644 - val_loss: 3949741922.3379\n",
      "Epoch 5160/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1410220066.8180 - val_loss: 3950001300.0183\n",
      "Epoch 5161/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1410575329.8160 - val_loss: 3953780839.1598\n",
      "Epoch 5162/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1409802061.0254 - val_loss: 3948947562.3744\n",
      "Epoch 5163/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1410372418.7554 - val_loss: 3947682033.3881\n",
      "Epoch 5164/10000\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 1411279591.7025 - val_loss: 3952883932.9315\n",
      "Epoch 5165/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1411074802.9746 - val_loss: 3955560251.4703\n",
      "Epoch 5166/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1410505838.5910 - val_loss: 3940140795.4703\n",
      "Epoch 5167/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1413090702.5284 - val_loss: 3945520542.2466\n",
      "Epoch 5168/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1410790293.9178 - val_loss: 3948844088.4018\n",
      "Epoch 5169/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1411205836.9002 - val_loss: 3950065234.1187\n",
      "Epoch 5170/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1412171757.2133 - val_loss: 3945115163.3242\n",
      "Epoch 5171/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1411281549.2759 - val_loss: 3962818121.3516\n",
      "Epoch 5172/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1412381489.4090 - val_loss: 3936532695.6712\n",
      "Epoch 5173/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1410203790.5284 - val_loss: 3947115158.3562\n",
      "Epoch 5174/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1411403194.8650 - val_loss: 3962616650.9589\n",
      "Epoch 5175/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1410585344.6262 - val_loss: 3958433767.4521\n",
      "Epoch 5176/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1411787738.1761 - val_loss: 3948126300.7854\n",
      "Epoch 5177/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1412219122.2231 - val_loss: 3940432541.9543\n",
      "Epoch 5178/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1410405786.8023 - val_loss: 3965180272.3653\n",
      "Epoch 5179/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1410711787.7104 - val_loss: 3961426572.7123\n",
      "Epoch 5180/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1410269888.6262 - val_loss: 3954956072.9132\n",
      "Epoch 5181/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1411253339.6791 - val_loss: 3936244316.4932\n",
      "Epoch 5182/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1410399809.6282 - val_loss: 3950621410.4840\n",
      "Epoch 5183/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1410206553.6751 - val_loss: 3951040008.1826\n",
      "Epoch 5184/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1409825518.4658 - val_loss: 3956732144.2192\n",
      "Epoch 5185/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1410437776.5323 - val_loss: 3941750429.2237\n",
      "Epoch 5186/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1410599582.5597 - val_loss: 3962969444.8219\n",
      "Epoch 5187/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1409816178.5988 - val_loss: 3953965835.8356\n",
      "Epoch 5188/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1409910328.1096 - val_loss: 3948466157.8813\n",
      "Epoch 5189/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1409868859.8669 - val_loss: 3949277226.3744\n",
      "Epoch 5190/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1410638780.3679 - val_loss: 3963425004.8584\n",
      "Epoch 5191/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1409731152.2818 - val_loss: 3950559236.6758\n",
      "Epoch 5192/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1410795683.0685 - val_loss: 3943230256.8037\n",
      "Epoch 5193/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1411353588.7280 - val_loss: 3953821719.9635\n",
      "Epoch 5194/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1409512956.6184 - val_loss: 3953943642.7397\n",
      "Epoch 5195/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1410347272.3914 - val_loss: 3962600869.4064\n",
      "Epoch 5196/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1410194675.4755 - val_loss: 3965234827.8356\n",
      "Epoch 5197/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1409116248.0470 - val_loss: 3947349833.7900\n",
      "Epoch 5198/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1409842821.7613 - val_loss: 3946851832.1096\n",
      "Epoch 5199/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1413267868.8063 - val_loss: 3969594766.7580\n",
      "Epoch 5200/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 42us/step - loss: 1410057294.9041 - val_loss: 3941521233.5342\n",
      "Epoch 5201/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1411148941.6517 - val_loss: 3949504746.9589\n",
      "Epoch 5202/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1414097481.6438 - val_loss: 3959902111.5616\n",
      "Epoch 5203/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1410292167.1389 - val_loss: 3943454696.1826\n",
      "Epoch 5204/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1410739841.0020 - val_loss: 3958912572.3470\n",
      "Epoch 5205/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1410385947.3033 - val_loss: 3945365901.0046\n",
      "Epoch 5206/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1409202603.3346 - val_loss: 3954392976.2192\n",
      "Epoch 5207/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1410999403.3346 - val_loss: 3950802008.2557\n",
      "Epoch 5208/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1411381394.1605 - val_loss: 3963344733.8082\n",
      "Epoch 5209/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1410653550.7162 - val_loss: 3952989662.3927\n",
      "Epoch 5210/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1410758312.3288 - val_loss: 3941570064.2192\n",
      "Epoch 5211/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1410060501.0411 - val_loss: 3957958119.0137\n",
      "Epoch 5212/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1410276137.3307 - val_loss: 3947553561.4247\n",
      "Epoch 5213/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1409152317.9961 - val_loss: 3954062058.2283\n",
      "Epoch 5214/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1410724832.4384 - val_loss: 3972662137.5708\n",
      "Epoch 5215/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1409397339.6791 - val_loss: 3950706605.4429\n",
      "Epoch 5216/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1410569153.1272 - val_loss: 3953298695.3059\n",
      "Epoch 5217/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1409675086.4031 - val_loss: 3950295702.9406\n",
      "Epoch 5218/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1409460618.0196 - val_loss: 3953625481.0594\n",
      "Epoch 5219/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1409271238.3875 - val_loss: 3960388143.3425\n",
      "Epoch 5220/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1410095146.0822 - val_loss: 3941949850.1553\n",
      "Epoch 5221/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1409603312.4697 - val_loss: 3954325011.1416\n",
      "Epoch 5222/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1409955588.2583 - val_loss: 3953779141.2603\n",
      "Epoch 5223/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1411342867.5382 - val_loss: 3960755149.2968\n",
      "Epoch 5224/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1409302439.4521 - val_loss: 3962736597.0411\n",
      "Epoch 5225/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1409929367.5460 - val_loss: 3948655661.1507\n",
      "Epoch 5226/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1409491482.8023 - val_loss: 3958842916.9680\n",
      "Epoch 5227/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1410413519.9061 - val_loss: 3956582843.0320\n",
      "Epoch 5228/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1409985518.7162 - val_loss: 3956799805.6621\n",
      "Epoch 5229/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1410146874.9902 - val_loss: 3960615958.2100\n",
      "Epoch 5230/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1410872236.0861 - val_loss: 3950196067.2146\n",
      "Epoch 5231/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1409366937.4247 - val_loss: 3952110292.8950\n",
      "Epoch 5232/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1410181858.1918 - val_loss: 3949575752.6210\n",
      "Epoch 5233/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1410437730.9432 - val_loss: 3962785265.3881\n",
      "Epoch 5234/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1410105168.9080 - val_loss: 3960421407.4155\n",
      "Epoch 5235/10000\n",
      "1022/1022 [==============================] - 0s 86us/step - loss: 1409133003.3973 - val_loss: 3953461730.7763\n",
      "Epoch 5236/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1410924945.7847 - val_loss: 3956931559.7443\n",
      "Epoch 5237/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1411013615.4677 - val_loss: 3939069205.7717\n",
      "Epoch 5238/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1411938298.9902 - val_loss: 3970027812.9680\n",
      "Epoch 5239/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1409339573.6047 - val_loss: 3949306016.5845\n",
      "Epoch 5240/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1409840551.0763 - val_loss: 3959843055.7808\n",
      "Epoch 5241/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1410083470.9041 - val_loss: 3943097354.6667\n",
      "Epoch 5242/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1408763760.9706 - val_loss: 3959256469.0411\n",
      "Epoch 5243/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1410917608.0783 - val_loss: 3965094924.2740\n",
      "Epoch 5244/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1409715397.6360 - val_loss: 3952047240.4749\n",
      "Epoch 5245/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1412153872.9080 - val_loss: 3950416715.5434\n",
      "Epoch 5246/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1408917906.6614 - val_loss: 3950165338.7397\n",
      "Epoch 5247/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1409129545.7691 - val_loss: 3960933963.8356\n",
      "Epoch 5248/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1408932436.9159 - val_loss: 3951373251.7991\n",
      "Epoch 5249/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1410973493.8552 - val_loss: 3945770694.1370\n",
      "Epoch 5250/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1412933324.5245 - val_loss: 3958737003.9817\n",
      "Epoch 5251/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1411785090.0039 - val_loss: 3957301690.8858\n",
      "Epoch 5252/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1409663804.2427 - val_loss: 3945338561.8995\n",
      "Epoch 5253/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1409415188.4149 - val_loss: 3950012742.7215\n",
      "Epoch 5254/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1408755671.3581 - val_loss: 3967975434.0822\n",
      "Epoch 5255/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1409661145.9256 - val_loss: 3955011959.2329\n",
      "Epoch 5256/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1408889242.3014 - val_loss: 3960816821.6256\n",
      "Epoch 5257/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1409536410.2387 - val_loss: 3956108923.3242\n",
      "Epoch 5258/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1410449321.0802 - val_loss: 3944077876.7489\n",
      "Epoch 5259/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1409473865.6438 - val_loss: 3974000201.3516\n",
      "Epoch 5260/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1410482695.5147 - val_loss: 3966617492.4566\n",
      "Epoch 5261/10000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1409413922.1918 - val_loss: 3957369632.5845\n",
      "Epoch 5262/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1409726400.8767 - val_loss: 3950925286.5753\n",
      "Epoch 5263/10000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1409384231.3268 - val_loss: 3958421081.7169\n",
      "Epoch 5264/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 35us/step - loss: 1409325621.7299 - val_loss: 3958991663.3425\n",
      "Epoch 5265/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1408755858.2857 - val_loss: 3952487186.9954\n",
      "Epoch 5266/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1409026233.1115 - val_loss: 3951222526.1005\n",
      "Epoch 5267/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1409806206.4971 - val_loss: 3961889653.0411\n",
      "Epoch 5268/10000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1409703138.8180 - val_loss: 3940139563.2511\n",
      "Epoch 5269/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1409899676.8063 - val_loss: 3966277303.3790\n",
      "Epoch 5270/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1410069436.2427 - val_loss: 3962008397.4429\n",
      "Epoch 5271/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1409143942.3875 - val_loss: 3947596074.3744\n",
      "Epoch 5272/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1410803823.9687 - val_loss: 3944355685.6986\n",
      "Epoch 5273/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1411225448.7045 - val_loss: 3947956445.0776\n",
      "Epoch 5274/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1412485860.6967 - val_loss: 3963599185.3881\n",
      "Epoch 5275/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1408600501.1037 - val_loss: 3955973527.3790\n",
      "Epoch 5276/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1409881518.0900 - val_loss: 3957468957.6621\n",
      "Epoch 5277/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1411281540.5088 - val_loss: 3953787328.5845\n",
      "Epoch 5278/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1409990103.2955 - val_loss: 3966733128.1826\n",
      "Epoch 5279/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1408793264.5949 - val_loss: 3966738589.0776\n",
      "Epoch 5280/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1409135720.2035 - val_loss: 3963490043.1781\n",
      "Epoch 5281/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1409089152.0000 - val_loss: 3958863251.5799\n",
      "Epoch 5282/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1409629181.8708 - val_loss: 3970517572.6758\n",
      "Epoch 5283/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1408287863.8591 - val_loss: 3961115919.4886\n",
      "Epoch 5284/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1408168341.5421 - val_loss: 3957772492.1279\n",
      "Epoch 5285/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1409612778.7710 - val_loss: 3949954107.1781\n",
      "Epoch 5286/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1408213797.1350 - val_loss: 3957224509.5160\n",
      "Epoch 5287/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1409311596.9628 - val_loss: 3955636944.8037\n",
      "Epoch 5288/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1408911998.9980 - val_loss: 3956824816.5114\n",
      "Epoch 5289/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1409794791.2016 - val_loss: 3959203004.4932\n",
      "Epoch 5290/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1409339473.1585 - val_loss: 3976377848.8402\n",
      "Epoch 5291/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1408394037.1037 - val_loss: 3955751179.8356\n",
      "Epoch 5292/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1410477774.0274 - val_loss: 3944996972.2740\n",
      "Epoch 5293/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1408154262.2935 - val_loss: 3957756402.4110\n",
      "Epoch 5294/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1408757362.2231 - val_loss: 3966314922.2283\n",
      "Epoch 5295/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1410069356.9628 - val_loss: 3954011288.5479\n",
      "Epoch 5296/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1409127134.3092 - val_loss: 3966928343.9635\n",
      "Epoch 5297/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1409181673.5812 - val_loss: 3950797310.5388\n",
      "Epoch 5298/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1410715472.2818 - val_loss: 3958981067.8356\n",
      "Epoch 5299/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1409807966.3092 - val_loss: 3952426504.3288\n",
      "Epoch 5300/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1408043357.4325 - val_loss: 3957037204.6027\n",
      "Epoch 5301/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1408828927.2485 - val_loss: 3971580929.8995\n",
      "Epoch 5302/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1408651303.8278 - val_loss: 3955076935.7443\n",
      "Epoch 5303/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1408302141.4951 - val_loss: 3960855239.0137\n",
      "Epoch 5304/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1408187366.0744 - val_loss: 3963039520.1461\n",
      "Epoch 5305/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1411433007.8434 - val_loss: 3977355785.9361\n",
      "Epoch 5306/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1411116405.4795 - val_loss: 3958088171.1050\n",
      "Epoch 5307/10000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1409964437.7926 - val_loss: 3972766022.7215\n",
      "Epoch 5308/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1410817962.0822 - val_loss: 3945699834.0091\n",
      "Epoch 5309/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1408536179.2250 - val_loss: 3956342155.6895\n",
      "Epoch 5310/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1409114022.5753 - val_loss: 3959861894.1370\n",
      "Epoch 5311/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1408374389.7299 - val_loss: 3965446836.7489\n",
      "Epoch 5312/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1408227547.9295 - val_loss: 3964817785.5708\n",
      "Epoch 5313/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1410084226.5049 - val_loss: 3957742616.8402\n",
      "Epoch 5314/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1408342168.0470 - val_loss: 3949711385.2785\n",
      "Epoch 5315/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1408624277.7926 - val_loss: 3960516170.2283\n",
      "Epoch 5316/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1408087033.4873 - val_loss: 3959186282.3744\n",
      "Epoch 5317/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1408385986.8806 - val_loss: 3959377039.1963\n",
      "Epoch 5318/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1408905613.2759 - val_loss: 3965263154.8493\n",
      "Epoch 5319/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1408936731.3033 - val_loss: 3947845863.8904\n",
      "Epoch 5320/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1407819046.7006 - val_loss: 3953659963.6164\n",
      "Epoch 5321/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1410145584.5949 - val_loss: 3978453741.7352\n",
      "Epoch 5322/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1410613458.4110 - val_loss: 3941842153.6438\n",
      "Epoch 5323/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1408860712.8297 - val_loss: 3958667548.7854\n",
      "Epoch 5324/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1407819458.3796 - val_loss: 3962754889.4977\n",
      "Epoch 5325/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1407867164.5871 - val_loss: 3958660825.4247\n",
      "Epoch 5326/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1408687274.3327 - val_loss: 3951719214.3196\n",
      "Epoch 5327/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1408598561.9413 - val_loss: 3956241214.5388\n",
      "Epoch 5328/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 36us/step - loss: 1408233530.9902 - val_loss: 3968580302.3196\n",
      "Epoch 5329/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1407844275.3503 - val_loss: 3962121879.3790\n",
      "Epoch 5330/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1408311105.3777 - val_loss: 3963082138.7397\n",
      "Epoch 5331/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1411125096.4540 - val_loss: 3956983797.3333\n",
      "Epoch 5332/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1408504372.1018 - val_loss: 3949934030.0274\n",
      "Epoch 5333/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1408195834.7397 - val_loss: 3961714412.2740\n",
      "Epoch 5334/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1408340184.0470 - val_loss: 3954193403.6164\n",
      "Epoch 5335/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1408891877.6986 - val_loss: 3955495848.6210\n",
      "Epoch 5336/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1408188219.1781 - val_loss: 3952434730.6667\n",
      "Epoch 5337/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1409464002.8806 - val_loss: 3955250748.2009\n",
      "Epoch 5338/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1407786016.8141 - val_loss: 3959859049.4977\n",
      "Epoch 5339/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1407602586.5519 - val_loss: 3961971677.6621\n",
      "Epoch 5340/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1408385881.1742 - val_loss: 3969243753.3516\n",
      "Epoch 5341/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1407865234.0352 - val_loss: 3962487055.3425\n",
      "Epoch 5342/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1409005004.3992 - val_loss: 3970582288.3653\n",
      "Epoch 5343/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1408392428.2114 - val_loss: 3954449022.6849\n",
      "Epoch 5344/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1408421001.5186 - val_loss: 3972267817.9361\n",
      "Epoch 5345/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1407751762.6614 - val_loss: 3963565146.5936\n",
      "Epoch 5346/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1408178163.7260 - val_loss: 3966095815.0137\n",
      "Epoch 5347/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1408977216.1252 - val_loss: 3974834486.0639\n",
      "Epoch 5348/10000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1410639863.7339 - val_loss: 3948333272.1096\n",
      "Epoch 5349/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1409652370.7867 - val_loss: 3955490976.2922\n",
      "Epoch 5350/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1409264052.1018 - val_loss: 3958807968.1461\n",
      "Epoch 5351/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1411227746.1918 - val_loss: 3981973858.3379\n",
      "Epoch 5352/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1408736143.1546 - val_loss: 3965572986.0091\n",
      "Epoch 5353/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1408023741.3699 - val_loss: 3963725014.2100\n",
      "Epoch 5354/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1410513239.1703 - val_loss: 3951274056.0365\n",
      "Epoch 5355/10000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1407612138.9589 - val_loss: 3970450281.2055\n",
      "Epoch 5356/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1407564574.5597 - val_loss: 3968368633.4247\n",
      "Epoch 5357/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1409745189.0724 - val_loss: 3952416641.1689\n",
      "Epoch 5358/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1407783013.8239 - val_loss: 3976107765.9178\n",
      "Epoch 5359/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1407643640.2348 - val_loss: 3965558861.7352\n",
      "Epoch 5360/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1408263079.4521 - val_loss: 3958589300.7489\n",
      "Epoch 5361/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1408047814.8885 - val_loss: 3958749131.9817\n",
      "Epoch 5362/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1408616411.9295 - val_loss: 3966551572.7489\n",
      "Epoch 5363/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1409750807.2955 - val_loss: 3964178825.2055\n",
      "Epoch 5364/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1408387377.0959 - val_loss: 3966965597.6621\n",
      "Epoch 5365/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1408183792.4697 - val_loss: 3969016832.5845\n",
      "Epoch 5366/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1407581986.4423 - val_loss: 3960060599.0868\n",
      "Epoch 5367/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1409161874.2857 - val_loss: 3967924844.4201\n",
      "Epoch 5368/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1408843028.5401 - val_loss: 3948624897.0228\n",
      "Epoch 5369/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1408769399.3581 - val_loss: 3968878203.0320\n",
      "Epoch 5370/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1407412216.7358 - val_loss: 3965198414.9041\n",
      "Epoch 5371/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1410038994.4110 - val_loss: 3966481249.7534\n",
      "Epoch 5372/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1408106380.0235 - val_loss: 3956911638.7945\n",
      "Epoch 5373/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1410961210.3014 - val_loss: 3970856629.4795\n",
      "Epoch 5374/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1409036850.5988 - val_loss: 3945537834.8128\n",
      "Epoch 5375/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1409411554.3170 - val_loss: 3967730819.3607\n",
      "Epoch 5376/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1407434767.4051 - val_loss: 3957437640.6210\n",
      "Epoch 5377/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1407376148.0391 - val_loss: 3968899507.4338\n",
      "Epoch 5378/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1408860727.6086 - val_loss: 3958585660.4932\n",
      "Epoch 5379/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1407726207.3738 - val_loss: 3977763799.3790\n",
      "Epoch 5380/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1407681424.2818 - val_loss: 3974188087.0868\n",
      "Epoch 5381/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1407226136.5479 - val_loss: 3967794488.8402\n",
      "Epoch 5382/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1408101530.8023 - val_loss: 3961914266.0091\n",
      "Epoch 5383/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1407904591.4051 - val_loss: 3956940015.4886\n",
      "Epoch 5384/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1407400925.1820 - val_loss: 3962655923.2877\n",
      "Epoch 5385/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1409300007.5773 - val_loss: 3963509521.5342\n",
      "Epoch 5386/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1407163557.3229 - val_loss: 3972438994.1187\n",
      "Epoch 5387/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1408061072.6575 - val_loss: 3966073588.3105\n",
      "Epoch 5388/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1407730185.7691 - val_loss: 3954705785.8630\n",
      "Epoch 5389/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1408356341.2290 - val_loss: 3968871134.3927\n",
      "Epoch 5390/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1410005454.9041 - val_loss: 3957441451.2511\n",
      "Epoch 5391/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1412178230.3562 - val_loss: 3980860083.2877\n",
      "Epoch 5392/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 35us/step - loss: 1409036402.3483 - val_loss: 3957686556.9315\n",
      "Epoch 5393/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1407850527.9374 - val_loss: 3978067163.7626\n",
      "Epoch 5394/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1407665210.9902 - val_loss: 3961286862.0274\n",
      "Epoch 5395/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1408366888.0783 - val_loss: 3953115384.4018\n",
      "Epoch 5396/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1407239537.7221 - val_loss: 3972657418.0822\n",
      "Epoch 5397/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1408853586.6614 - val_loss: 3962002554.7397\n",
      "Epoch 5398/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1408355626.0822 - val_loss: 3956230019.3607\n",
      "Epoch 5399/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1407261617.0959 - val_loss: 3975702305.4612\n",
      "Epoch 5400/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1406940366.9041 - val_loss: 3969015364.0913\n",
      "Epoch 5401/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1410564171.6477 - val_loss: 3950035232.1461\n",
      "Epoch 5402/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1410706180.5088 - val_loss: 3987399397.9909\n",
      "Epoch 5403/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1407796787.3503 - val_loss: 3959575538.7032\n",
      "Epoch 5404/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1408717007.4051 - val_loss: 3980497053.8082\n",
      "Epoch 5405/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1408529819.8669 - val_loss: 3964592439.3790\n",
      "Epoch 5406/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1411206513.8474 - val_loss: 3989453338.8858\n",
      "Epoch 5407/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1411857835.2094 - val_loss: 3956816396.8584\n",
      "Epoch 5408/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1407883791.0294 - val_loss: 3960976647.7443\n",
      "Epoch 5409/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1407887003.0528 - val_loss: 3961542944.7306\n",
      "Epoch 5410/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1409280709.6360 - val_loss: 3954434220.8584\n",
      "Epoch 5411/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1408837969.6595 - val_loss: 3987903343.4886\n",
      "Epoch 5412/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1407888876.3992 - val_loss: 3973586894.3196\n",
      "Epoch 5413/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1407122257.4090 - val_loss: 3974841960.1826\n",
      "Epoch 5414/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1407579165.5577 - val_loss: 3967455308.4201\n",
      "Epoch 5415/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1406983390.4344 - val_loss: 3963149804.8584\n",
      "Epoch 5416/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1407145082.2387 - val_loss: 3973325841.5342\n",
      "Epoch 5417/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1407020678.8885 - val_loss: 3969860144.9498\n",
      "Epoch 5418/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1407304811.8356 - val_loss: 3970798616.4018\n",
      "Epoch 5419/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1407551752.0157 - val_loss: 3963850662.7215\n",
      "Epoch 5420/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1409069577.7691 - val_loss: 3989349234.4110\n",
      "Epoch 5421/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1406818291.4755 - val_loss: 3956622681.1324\n",
      "Epoch 5422/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1408414478.7789 - val_loss: 3956764774.4292\n",
      "Epoch 5423/10000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1408612177.1585 - val_loss: 3979227799.9635\n",
      "Epoch 5424/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1407170073.8004 - val_loss: 3976331241.3516\n",
      "Epoch 5425/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1407015517.4325 - val_loss: 3968819059.5799\n",
      "Epoch 5426/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1407005638.3875 - val_loss: 3965472084.0183\n",
      "Epoch 5427/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1406885782.2935 - val_loss: 3966710945.8995\n",
      "Epoch 5428/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1409905278.4971 - val_loss: 3953376304.6575\n",
      "Epoch 5429/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1409474296.4853 - val_loss: 3980047079.4521\n",
      "Epoch 5430/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1407057376.6888 - val_loss: 3971484095.1233\n",
      "Epoch 5431/10000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1406282319.6556 - val_loss: 3968522759.4521\n",
      "Epoch 5432/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1407041068.3366 - val_loss: 3963820475.4703\n",
      "Epoch 5433/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1406844705.3151 - val_loss: 3979963648.1461\n",
      "Epoch 5434/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1407264617.4560 - val_loss: 3981919487.2694\n",
      "Epoch 5435/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1406693899.2720 - val_loss: 3964952150.9406\n",
      "Epoch 5436/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1407192290.6301 - val_loss: 3973948915.1416\n",
      "Epoch 5437/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1407794432.0000 - val_loss: 3976543581.5160\n",
      "Epoch 5438/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1409836027.7417 - val_loss: 3952871938.7763\n",
      "Epoch 5439/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1407950942.1840 - val_loss: 3975550351.0502\n",
      "Epoch 5440/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1406832386.8806 - val_loss: 3969729931.9817\n",
      "Epoch 5441/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1406727032.2348 - val_loss: 3969965501.0776\n",
      "Epoch 5442/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1407507793.1585 - val_loss: 3967539365.2603\n",
      "Epoch 5443/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1408317853.3072 - val_loss: 3979022856.7671\n",
      "Epoch 5444/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1406966581.9804 - val_loss: 3974861826.7763\n",
      "Epoch 5445/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1406857930.3953 - val_loss: 3967814981.8447\n",
      "Epoch 5446/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1406358177.8160 - val_loss: 3972337902.6119\n",
      "Epoch 5447/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1406744103.2016 - val_loss: 3966643742.9772\n",
      "Epoch 5448/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1408974032.4070 - val_loss: 3984901277.0776\n",
      "Epoch 5449/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1410708958.1840 - val_loss: 3956963623.0137\n",
      "Epoch 5450/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1405634198.6693 - val_loss: 3977671529.6438\n",
      "Epoch 5451/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1407804748.6497 - val_loss: 3974013170.4110\n",
      "Epoch 5452/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1406748392.2035 - val_loss: 3972258456.1096\n",
      "Epoch 5453/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1406165818.7397 - val_loss: 3980408613.4064\n",
      "Epoch 5454/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1407230323.3503 - val_loss: 3970642087.5982\n",
      "Epoch 5455/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1407079087.0920 - val_loss: 3977365245.9543\n",
      "Epoch 5456/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 40us/step - loss: 1408274355.3503 - val_loss: 3978671655.8904\n",
      "Epoch 5457/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1407517451.7730 - val_loss: 3975149789.0776\n",
      "Epoch 5458/10000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1407653834.3953 - val_loss: 3965890355.7260\n",
      "Epoch 5459/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1406489916.2427 - val_loss: 3980358613.7717\n",
      "Epoch 5460/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1407084244.7906 - val_loss: 3977208984.4018\n",
      "Epoch 5461/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1406722640.9080 - val_loss: 3980651810.6301\n",
      "Epoch 5462/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1406412055.5460 - val_loss: 3980523547.4703\n",
      "Epoch 5463/10000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1407263783.8278 - val_loss: 3972158812.7854\n",
      "Epoch 5464/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1406842201.8004 - val_loss: 3972578303.1233\n",
      "Epoch 5465/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1406303665.3464 - val_loss: 3974128032.5845\n",
      "Epoch 5466/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1407449943.4207 - val_loss: 3965904174.4658\n",
      "Epoch 5467/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1407375524.5714 - val_loss: 3980019829.6256\n",
      "Epoch 5468/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1409531307.5851 - val_loss: 3966437408.1461\n",
      "Epoch 5469/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1409190457.9883 - val_loss: 3966012522.9589\n",
      "Epoch 5470/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1408238886.3249 - val_loss: 3991990013.3699\n",
      "Epoch 5471/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1406114304.3757 - val_loss: 3978165987.3607\n",
      "Epoch 5472/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1406874286.8415 - val_loss: 3974710268.3470\n",
      "Epoch 5473/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1406201276.7436 - val_loss: 3976714168.5479\n",
      "Epoch 5474/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1406057861.0098 - val_loss: 3971289799.1598\n",
      "Epoch 5475/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1406717136.9080 - val_loss: 3970311995.3242\n",
      "Epoch 5476/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1407118544.4070 - val_loss: 3974419676.7854\n",
      "Epoch 5477/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1406942696.5793 - val_loss: 3978642179.3607\n",
      "Epoch 5478/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1409951573.1663 - val_loss: 3948867262.9772\n",
      "Epoch 5479/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1408819937.4403 - val_loss: 3989712364.8584\n",
      "Epoch 5480/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1408393440.6888 - val_loss: 3957333437.8082\n",
      "Epoch 5481/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1406054896.2192 - val_loss: 3969724867.7991\n",
      "Epoch 5482/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1405221755.7417 - val_loss: 3981889415.4521\n",
      "Epoch 5483/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1405499673.5499 - val_loss: 3978215041.1689\n",
      "Epoch 5484/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1406052512.3131 - val_loss: 3975886063.4886\n",
      "Epoch 5485/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1405836363.8982 - val_loss: 3976383537.6804\n",
      "Epoch 5486/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1407760147.7886 - val_loss: 3984640383.5616\n",
      "Epoch 5487/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1405486923.1468 - val_loss: 3970889021.8082\n",
      "Epoch 5488/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1406319783.0763 - val_loss: 3981372861.0776\n",
      "Epoch 5489/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1406262930.9119 - val_loss: 3975303177.7900\n",
      "Epoch 5490/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1405098126.1526 - val_loss: 3974538278.8676\n",
      "Epoch 5491/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1405920570.6145 - val_loss: 3986065696.1461\n",
      "Epoch 5492/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1405825044.9159 - val_loss: 3968448533.4795\n",
      "Epoch 5493/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1405954939.4912 - val_loss: 3981545410.7763\n",
      "Epoch 5494/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1405208900.6341 - val_loss: 3977868950.6484\n",
      "Epoch 5495/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1405391294.3718 - val_loss: 3976922549.6256\n",
      "Epoch 5496/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1406752597.1663 - val_loss: 3958040649.0594\n",
      "Epoch 5497/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1406596912.0939 - val_loss: 3967315915.2511\n",
      "Epoch 5498/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1405940631.6712 - val_loss: 3991156637.3699\n",
      "Epoch 5499/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1406298651.4286 - val_loss: 3970621132.8584\n",
      "Epoch 5500/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1405243493.6986 - val_loss: 3984983980.7123\n",
      "Epoch 5501/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1406113062.3249 - val_loss: 3969961519.6347\n",
      "Epoch 5502/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1405486703.9687 - val_loss: 3985752221.6621\n",
      "Epoch 5503/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1405684380.1800 - val_loss: 3974639451.3242\n",
      "Epoch 5504/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1407411094.7945 - val_loss: 3993308014.7580\n",
      "Epoch 5505/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1407010479.3425 - val_loss: 3973736686.9041\n",
      "Epoch 5506/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1405109980.0548 - val_loss: 3981306404.9680\n",
      "Epoch 5507/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1405251322.7397 - val_loss: 3987758871.8174\n",
      "Epoch 5508/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1405308829.8082 - val_loss: 3975619159.9635\n",
      "Epoch 5509/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1406036651.5851 - val_loss: 3974146633.2055\n",
      "Epoch 5510/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1405089921.7534 - val_loss: 3979151295.2694\n",
      "Epoch 5511/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1405269805.0881 - val_loss: 3995157818.3014\n",
      "Epoch 5512/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1405764918.1057 - val_loss: 3970048581.1142\n",
      "Epoch 5513/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1406096724.1644 - val_loss: 3973555888.3653\n",
      "Epoch 5514/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1405432500.7280 - val_loss: 3988771483.3242\n",
      "Epoch 5515/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1404444214.6067 - val_loss: 3980598351.6347\n",
      "Epoch 5516/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1405233166.7789 - val_loss: 3985795431.3059\n",
      "Epoch 5517/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1405436599.8591 - val_loss: 3968764095.1233\n",
      "Epoch 5518/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1407287732.8532 - val_loss: 3988294838.2100\n",
      "Epoch 5519/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1410252296.2661 - val_loss: 3965733110.6484\n",
      "Epoch 5520/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 39us/step - loss: 1406119943.2642 - val_loss: 3992714951.8904\n",
      "Epoch 5521/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1405929667.6321 - val_loss: 3976942192.9498\n",
      "Epoch 5522/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1405180842.5832 - val_loss: 3985953195.2511\n",
      "Epoch 5523/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1404678807.0450 - val_loss: 3978544929.4612\n",
      "Epoch 5524/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1404239063.7965 - val_loss: 3988346998.6484\n",
      "Epoch 5525/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1404326018.5049 - val_loss: 3978502078.1005\n",
      "Epoch 5526/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1405134370.0665 - val_loss: 3982065879.6712\n",
      "Epoch 5527/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1404120759.8591 - val_loss: 3989608603.1781\n",
      "Epoch 5528/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1403736693.7299 - val_loss: 3988315056.2192\n",
      "Epoch 5529/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1404553069.2133 - val_loss: 3989488929.7534\n",
      "Epoch 5530/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1404300279.3581 - val_loss: 3994821406.3927\n",
      "Epoch 5531/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1406980716.3366 - val_loss: 3973824984.2557\n",
      "Epoch 5532/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1405734516.1018 - val_loss: 3981355536.9498\n",
      "Epoch 5533/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1404896464.6575 - val_loss: 3995727211.5434\n",
      "Epoch 5534/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1405780221.9961 - val_loss: 3970636599.2329\n",
      "Epoch 5535/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1405549008.2818 - val_loss: 3992935980.2740\n",
      "Epoch 5536/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1409741567.6243 - val_loss: 4002636865.1689\n",
      "Epoch 5537/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1403984337.4090 - val_loss: 3988158197.0411\n",
      "Epoch 5538/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1404092485.8865 - val_loss: 3983259967.5616\n",
      "Epoch 5539/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1404161495.4207 - val_loss: 3977437854.1005\n",
      "Epoch 5540/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1404634882.1292 - val_loss: 3979933848.4018\n",
      "Epoch 5541/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1404055806.9980 - val_loss: 3988231970.3379\n",
      "Epoch 5542/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1403764520.8297 - val_loss: 3990188893.6621\n",
      "Epoch 5543/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1404514338.5675 - val_loss: 3987239776.8767\n",
      "Epoch 5544/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1404711130.9276 - val_loss: 3979090458.5936\n",
      "Epoch 5545/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1406427165.0568 - val_loss: 3989597955.0685\n",
      "Epoch 5546/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1403904509.6204 - val_loss: 3986451366.8676\n",
      "Epoch 5547/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1403320325.2603 - val_loss: 3995091882.0822\n",
      "Epoch 5548/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1404346310.6380 - val_loss: 3997005098.3744\n",
      "Epoch 5549/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1403166554.0509 - val_loss: 3983240402.7032\n",
      "Epoch 5550/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1403150739.2877 - val_loss: 3988595216.6575\n",
      "Epoch 5551/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1406972078.8415 - val_loss: 3968320726.9406\n",
      "Epoch 5552/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1404273420.5245 - val_loss: 3997835116.1279\n",
      "Epoch 5553/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1406608678.8258 - val_loss: 3983137638.4292\n",
      "Epoch 5554/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1404558699.2094 - val_loss: 4002745820.2009\n",
      "Epoch 5555/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1402902724.3836 - val_loss: 3994871083.1050\n",
      "Epoch 5556/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1402362002.7867 - val_loss: 3989946573.8813\n",
      "Epoch 5557/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1403010228.8532 - val_loss: 3980642915.2146\n",
      "Epoch 5558/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1403787551.3112 - val_loss: 3999188310.9406\n",
      "Epoch 5559/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1403242224.2192 - val_loss: 3992786009.2785\n",
      "Epoch 5560/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1403332128.8141 - val_loss: 3996623650.6301\n",
      "Epoch 5561/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1402510245.1977 - val_loss: 3986321762.4840\n",
      "Epoch 5562/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1403416990.8102 - val_loss: 3994672721.5342\n",
      "Epoch 5563/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1403183937.5029 - val_loss: 3986708506.8858\n",
      "Epoch 5564/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1402818637.4012 - val_loss: 3989373476.2374\n",
      "Epoch 5565/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1402495965.9335 - val_loss: 3999059384.1096\n",
      "Epoch 5566/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1402242187.5225 - val_loss: 3989721262.0274\n",
      "Epoch 5567/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1403630997.0411 - val_loss: 3985452657.6804\n",
      "Epoch 5568/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1402416074.6458 - val_loss: 3998985277.0776\n",
      "Epoch 5569/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1406299084.9002 - val_loss: 3985498654.1005\n",
      "Epoch 5570/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1403116838.5753 - val_loss: 4001759069.2237\n",
      "Epoch 5571/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1402657071.8434 - val_loss: 4003685307.7626\n",
      "Epoch 5572/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1402131095.6712 - val_loss: 3990949351.0137\n",
      "Epoch 5573/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1404273667.3816 - val_loss: 4000265506.9224\n",
      "Epoch 5574/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1402157312.7515 - val_loss: 3996437011.2877\n",
      "Epoch 5575/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1402627579.4286 - val_loss: 3982788423.7443\n",
      "Epoch 5576/10000\n",
      "1022/1022 [==============================] - 0s 63us/step - loss: 1402833749.1663 - val_loss: 3993750543.1963\n",
      "Epoch 5577/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1404291223.2955 - val_loss: 3986030565.1142\n",
      "Epoch 5578/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1402613011.5382 - val_loss: 3995557720.1096\n",
      "Epoch 5579/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1402850958.7789 - val_loss: 3995781974.7945\n",
      "Epoch 5580/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1402010174.8728 - val_loss: 3995260581.2603\n",
      "Epoch 5581/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1402901464.4227 - val_loss: 3987745150.6849\n",
      "Epoch 5582/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1401749173.3542 - val_loss: 4007139660.5662\n",
      "Epoch 5583/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1404660224.6262 - val_loss: 4012876731.3242\n",
      "Epoch 5584/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 50us/step - loss: 1403213438.4344 - val_loss: 3989432622.4658\n",
      "Epoch 5585/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1402811066.3640 - val_loss: 3995620790.7945\n",
      "Epoch 5586/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1404420261.8239 - val_loss: 3988696756.6027\n",
      "Epoch 5587/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1403407449.5499 - val_loss: 3990162568.7671\n",
      "Epoch 5588/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1403113093.2603 - val_loss: 4013074018.9224\n",
      "Epoch 5589/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1402681252.4462 - val_loss: 3992029305.2785\n",
      "Epoch 5590/10000\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 1402652403.9765 - val_loss: 4009780464.2192\n",
      "Epoch 5591/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1405591392.3131 - val_loss: 4018683631.1963\n",
      "Epoch 5592/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1400424150.5440 - val_loss: 3984184455.4521\n",
      "Epoch 5593/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1402030124.2114 - val_loss: 3990548680.7671\n",
      "Epoch 5594/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1401577725.2446 - val_loss: 3998682886.8676\n",
      "Epoch 5595/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1402799529.8317 - val_loss: 3981733662.6849\n",
      "Epoch 5596/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1402683410.7867 - val_loss: 4005489521.9726\n",
      "Epoch 5597/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1401303590.1370 - val_loss: 4002070335.4155\n",
      "Epoch 5598/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1401193832.9550 - val_loss: 3993723978.9589\n",
      "Epoch 5599/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1401345939.7886 - val_loss: 3999077245.0776\n",
      "Epoch 5600/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1402755983.2172 - val_loss: 4010083630.6119\n",
      "Epoch 5601/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1401385194.4579 - val_loss: 3999545863.1598\n",
      "Epoch 5602/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1401574053.4481 - val_loss: 3992845621.4795\n",
      "Epoch 5603/10000\n",
      "1022/1022 [==============================] - 0s 70us/step - loss: 1402425640.9550 - val_loss: 3986143604.6027\n",
      "Epoch 5604/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1401635931.8043 - val_loss: 3994868683.2511\n",
      "Epoch 5605/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1400782404.5088 - val_loss: 4002118201.7169\n",
      "Epoch 5606/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1401012871.2642 - val_loss: 4004804486.5753\n",
      "Epoch 5607/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1402817349.8865 - val_loss: 3999032457.4977\n",
      "Epoch 5608/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1402054221.9022 - val_loss: 4010419108.3836\n",
      "Epoch 5609/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1402183996.5558 - val_loss: 3998675918.4658\n",
      "Epoch 5610/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1402220306.0352 - val_loss: 4005185525.7717\n",
      "Epoch 5611/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1401535821.6517 - val_loss: 4004262340.2374\n",
      "Epoch 5612/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1404410918.8258 - val_loss: 3993634918.1370\n",
      "Epoch 5613/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1406217189.3229 - val_loss: 4030868434.9954\n",
      "Epoch 5614/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1401202573.7769 - val_loss: 3985894066.2648\n",
      "Epoch 5615/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1401580324.9472 - val_loss: 3992640536.1096\n",
      "Epoch 5616/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1402206805.1663 - val_loss: 3984976410.0091\n",
      "Epoch 5617/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1401936550.0744 - val_loss: 3993694442.6667\n",
      "Epoch 5618/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1401495904.9393 - val_loss: 4020584512.4384\n",
      "Epoch 5619/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1401996789.1037 - val_loss: 4003524067.3607\n",
      "Epoch 5620/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1401384656.4070 - val_loss: 4008451197.9543\n",
      "Epoch 5621/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1401584505.9883 - val_loss: 3992947109.1142\n",
      "Epoch 5622/10000\n",
      "1022/1022 [==============================] - 0s 66us/step - loss: 1403016093.6830 - val_loss: 4000777552.2192\n",
      "Epoch 5623/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1403573284.5714 - val_loss: 4017692382.1005\n",
      "Epoch 5624/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1403078254.9667 - val_loss: 3987695895.0868\n",
      "Epoch 5625/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1400332184.5479 - val_loss: 4004533590.7945\n",
      "Epoch 5626/10000\n",
      "1022/1022 [==============================] - 0s 69us/step - loss: 1402297146.1135 - val_loss: 4000208188.4932\n",
      "Epoch 5627/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1400739412.3523 - val_loss: 4003076618.2283\n",
      "Epoch 5628/10000\n",
      "1022/1022 [==============================] - 0s 65us/step - loss: 1400673537.5029 - val_loss: 3997164525.2968\n",
      "Epoch 5629/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1403624203.7730 - val_loss: 4015029622.3562\n",
      "Epoch 5630/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1400890768.5323 - val_loss: 3995637164.4201\n",
      "Epoch 5631/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1400567172.7593 - val_loss: 4006278519.9635\n",
      "Epoch 5632/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1404062666.8963 - val_loss: 3987724026.1553\n",
      "Epoch 5633/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1400125856.8141 - val_loss: 4008243779.0685\n",
      "Epoch 5634/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1401229827.2564 - val_loss: 4006634678.6484\n",
      "Epoch 5635/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1400632281.4247 - val_loss: 4006770401.1689\n",
      "Epoch 5636/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1400500897.0646 - val_loss: 3997974761.6438\n",
      "Epoch 5637/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1400376237.9648 - val_loss: 4003715677.9543\n",
      "Epoch 5638/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1400625027.6321 - val_loss: 4008844812.8584\n",
      "Epoch 5639/10000\n",
      "1022/1022 [==============================] - 0s 66us/step - loss: 1401548992.0000 - val_loss: 3995338731.3973\n",
      "Epoch 5640/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1401355746.6928 - val_loss: 3996026315.8356\n",
      "Epoch 5641/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1401098464.6888 - val_loss: 4004151006.6849\n",
      "Epoch 5642/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1404192305.0959 - val_loss: 4029257917.9543\n",
      "Epoch 5643/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1400416300.0861 - val_loss: 3999420945.9726\n",
      "Epoch 5644/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1400783930.8650 - val_loss: 4003372276.7489\n",
      "Epoch 5645/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1400457702.1996 - val_loss: 4002454335.7078\n",
      "Epoch 5646/10000\n",
      "1022/1022 [==============================] - 0s 73us/step - loss: 1402256833.3777 - val_loss: 4012358294.3562\n",
      "Epoch 5647/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1403941618.2231 - val_loss: 3987675738.0091\n",
      "Epoch 5648/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 49us/step - loss: 1402405678.0900 - val_loss: 4022286655.2694\n",
      "Epoch 5649/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1400184101.8239 - val_loss: 4003500550.5753\n",
      "Epoch 5650/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1400787312.7202 - val_loss: 4010609898.8128\n",
      "Epoch 5651/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1401224993.8787 - val_loss: 4017172133.1142\n",
      "Epoch 5652/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1400654723.0059 - val_loss: 4002169462.3562\n",
      "Epoch 5653/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1400992272.1566 - val_loss: 4003245417.0594\n",
      "Epoch 5654/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1400306947.7573 - val_loss: 4006643423.8539\n",
      "Epoch 5655/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1403722373.5108 - val_loss: 4003881302.0639\n",
      "Epoch 5656/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1400663482.7397 - val_loss: 4009235527.8904\n",
      "Epoch 5657/10000\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 1400573899.5225 - val_loss: 4017192941.7352\n",
      "Epoch 5658/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1401670679.1703 - val_loss: 4011372960.4384\n",
      "Epoch 5659/10000\n",
      "1022/1022 [==============================] - 0s 68us/step - loss: 1400285208.2975 - val_loss: 4005976208.9498\n",
      "Epoch 5660/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1400962677.7299 - val_loss: 4005132752.5114\n",
      "Epoch 5661/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1400731747.3190 - val_loss: 3998102204.9315\n",
      "Epoch 5662/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1399834907.5538 - val_loss: 4003518542.6119\n",
      "Epoch 5663/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1400454698.0822 - val_loss: 4018470683.0320\n",
      "Epoch 5664/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1400091681.3151 - val_loss: 4002092676.8219\n",
      "Epoch 5665/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1400791483.6164 - val_loss: 4015401281.4612\n",
      "Epoch 5666/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1400738023.4521 - val_loss: 3998829071.4886\n",
      "Epoch 5667/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1399723545.9256 - val_loss: 4011806702.1735\n",
      "Epoch 5668/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1399532442.0509 - val_loss: 4009927558.4292\n",
      "Epoch 5669/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1400061543.7025 - val_loss: 4001825798.1370\n",
      "Epoch 5670/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1402154708.6654 - val_loss: 4020195851.3973\n",
      "Epoch 5671/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1400418970.3014 - val_loss: 4013715701.9178\n",
      "Epoch 5672/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1399677776.1566 - val_loss: 4003509824.1461\n",
      "Epoch 5673/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1401345338.6771 - val_loss: 4010458333.6621\n",
      "Epoch 5674/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1400178166.6067 - val_loss: 3998978458.5936\n",
      "Epoch 5675/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1400147894.3562 - val_loss: 3994570852.9680\n",
      "Epoch 5676/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1401629357.3386 - val_loss: 4018875617.8995\n",
      "Epoch 5677/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1402890114.7554 - val_loss: 3987896515.2146\n",
      "Epoch 5678/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1400948161.3777 - val_loss: 4009059393.1689\n",
      "Epoch 5679/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1400384853.2916 - val_loss: 4000562105.4247\n",
      "Epoch 5680/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1401019022.7789 - val_loss: 4019234067.8721\n",
      "Epoch 5681/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1399330349.3386 - val_loss: 3999885340.0548\n",
      "Epoch 5682/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1400476090.6145 - val_loss: 4005490773.3333\n",
      "Epoch 5683/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1400268540.9941 - val_loss: 4025433020.6393\n",
      "Epoch 5684/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1400174494.3092 - val_loss: 4005085468.2009\n",
      "Epoch 5685/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1400415777.3151 - val_loss: 4001632802.6301\n",
      "Epoch 5686/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1399958608.9080 - val_loss: 4005747595.2511\n",
      "Epoch 5687/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1399319691.1468 - val_loss: 4008851251.2877\n",
      "Epoch 5688/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1399526635.9609 - val_loss: 4011060223.4155\n",
      "Epoch 5689/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1402079802.4892 - val_loss: 4030197827.3607\n",
      "Epoch 5690/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1402438636.4618 - val_loss: 3997165242.4475\n",
      "Epoch 5691/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1399995096.2975 - val_loss: 4004986696.0365\n",
      "Epoch 5692/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1401452435.4129 - val_loss: 4024699657.6438\n",
      "Epoch 5693/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1399566585.1115 - val_loss: 4002098847.5616\n",
      "Epoch 5694/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1399581873.6595 - val_loss: 4002511452.2009\n",
      "Epoch 5695/10000\n",
      "1022/1022 [==============================] - 0s 71us/step - loss: 1399834192.4070 - val_loss: 4008122834.5571\n",
      "Epoch 5696/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1399738893.5264 - val_loss: 4009488920.8402\n",
      "Epoch 5697/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1399834995.9765 - val_loss: 4025004187.3242\n",
      "Epoch 5698/10000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1399680733.1820 - val_loss: 4014188896.5845\n",
      "Epoch 5699/10000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1400347932.0548 - val_loss: 4024023831.3790\n",
      "Epoch 5700/10000\n",
      "1022/1022 [==============================] - 0s 35us/step - loss: 1400086118.4501 - val_loss: 4004754762.2283\n",
      "Epoch 5701/10000\n",
      "1022/1022 [==============================] - 0s 66us/step - loss: 1398718685.9335 - val_loss: 4001774414.3196\n",
      "Epoch 5702/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1400647816.6419 - val_loss: 4015949278.6849\n",
      "Epoch 5703/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1400216720.1566 - val_loss: 3994368520.1826\n",
      "Epoch 5704/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1399908955.8043 - val_loss: 4017879535.7808\n",
      "Epoch 5705/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1399574086.3875 - val_loss: 4003047883.8356\n",
      "Epoch 5706/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1398369310.3092 - val_loss: 4013073341.3699\n",
      "Epoch 5707/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1399078704.3444 - val_loss: 4008243739.0320\n",
      "Epoch 5708/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1399643989.9178 - val_loss: 4009993636.8219\n",
      "Epoch 5709/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1398728910.7789 - val_loss: 4013124547.9452\n",
      "Epoch 5710/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1398806263.2955 - val_loss: 4025366119.7443\n",
      "Epoch 5711/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1398662626.6928 - val_loss: 4015904675.7991\n",
      "Epoch 5712/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 45us/step - loss: 1398821529.2994 - val_loss: 4009489841.3881\n",
      "Epoch 5713/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1398498925.4638 - val_loss: 4003742901.9178\n",
      "Epoch 5714/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1399939323.3659 - val_loss: 4013397472.7306\n",
      "Epoch 5715/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1399743591.7025 - val_loss: 4004289022.9772\n",
      "Epoch 5716/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1404313868.2740 - val_loss: 4024403272.6210\n",
      "Epoch 5717/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1399010141.5577 - val_loss: 4012783967.7078\n",
      "Epoch 5718/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1399474319.7808 - val_loss: 4001305346.0457\n",
      "Epoch 5719/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1398950541.7769 - val_loss: 4010253887.7078\n",
      "Epoch 5720/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1401333902.2779 - val_loss: 4020088861.6621\n",
      "Epoch 5721/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1399438410.6458 - val_loss: 4010219231.8539\n",
      "Epoch 5722/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1399700074.2074 - val_loss: 4026942435.9452\n",
      "Epoch 5723/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1399817932.1487 - val_loss: 3995797130.5205\n",
      "Epoch 5724/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1399385788.9941 - val_loss: 4016074443.5434\n",
      "Epoch 5725/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1398298571.1468 - val_loss: 4010886804.4566\n",
      "Epoch 5726/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1400623847.4521 - val_loss: 4006453387.6895\n",
      "Epoch 5727/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1399145937.4090 - val_loss: 4010489757.8082\n",
      "Epoch 5728/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1399996926.2466 - val_loss: 4015673777.0959\n",
      "Epoch 5729/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1398400409.9256 - val_loss: 4011605880.2557\n",
      "Epoch 5730/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1398873271.9843 - val_loss: 4016704683.8356\n",
      "Epoch 5731/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1397863606.8571 - val_loss: 4016225674.5205\n",
      "Epoch 5732/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1398274114.7554 - val_loss: 4013711031.8174\n",
      "Epoch 5733/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1398139943.0763 - val_loss: 4013342113.3151\n",
      "Epoch 5734/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1398872736.3131 - val_loss: 4002117378.7763\n",
      "Epoch 5735/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1399364852.9785 - val_loss: 4010347971.7991\n",
      "Epoch 5736/10000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1400375360.3757 - val_loss: 4019231337.9361\n",
      "Epoch 5737/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1398104855.5460 - val_loss: 4012904056.6941\n",
      "Epoch 5738/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1398332088.1096 - val_loss: 4009786615.3790\n",
      "Epoch 5739/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1398292721.5969 - val_loss: 4010893298.1187\n",
      "Epoch 5740/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1402394645.5421 - val_loss: 4011606417.0959\n",
      "Epoch 5741/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1398667048.5793 - val_loss: 4021625754.7397\n",
      "Epoch 5742/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1399137502.4344 - val_loss: 3999593178.7397\n",
      "Epoch 5743/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1397948846.5910 - val_loss: 4019608308.1644\n",
      "Epoch 5744/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1398329472.5010 - val_loss: 4022064903.3059\n",
      "Epoch 5745/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1399001462.8571 - val_loss: 4003896140.4201\n",
      "Epoch 5746/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1399230378.8337 - val_loss: 4013205659.7626\n",
      "Epoch 5747/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1398589621.3542 - val_loss: 4020092030.2466\n",
      "Epoch 5748/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1399114172.7436 - val_loss: 4017611268.0913\n",
      "Epoch 5749/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1398136979.4129 - val_loss: 4018545763.7991\n",
      "Epoch 5750/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1398341341.1820 - val_loss: 4009005038.3196\n",
      "Epoch 5751/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1397963270.8885 - val_loss: 4020151030.7945\n",
      "Epoch 5752/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1398269662.1840 - val_loss: 4006027451.6164\n",
      "Epoch 5753/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1397685573.6360 - val_loss: 4017064105.2055\n",
      "Epoch 5754/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1398022025.6438 - val_loss: 4020087406.6119\n",
      "Epoch 5755/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1399504626.9746 - val_loss: 4018357206.6484\n",
      "Epoch 5756/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1397803023.2798 - val_loss: 4005215438.7580\n",
      "Epoch 5757/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1397985552.0313 - val_loss: 4006225218.9224\n",
      "Epoch 5758/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1400118186.8337 - val_loss: 4024980544.0000\n",
      "Epoch 5759/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1398261175.3581 - val_loss: 4009742100.4566\n",
      "Epoch 5760/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1398370354.0978 - val_loss: 4024235843.6530\n",
      "Epoch 5761/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1397623145.3933 - val_loss: 4017077237.4795\n",
      "Epoch 5762/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1398334371.2564 - val_loss: 4003924917.7717\n",
      "Epoch 5763/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1398662107.1781 - val_loss: 4005378914.0457\n",
      "Epoch 5764/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1398332904.7045 - val_loss: 4019728161.0228\n",
      "Epoch 5765/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1398154126.1526 - val_loss: 4012636492.2740\n",
      "Epoch 5766/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1397525077.1663 - val_loss: 4012505559.2329\n",
      "Epoch 5767/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1402257316.8219 - val_loss: 4010125588.4566\n",
      "Epoch 5768/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1398464981.0411 - val_loss: 4015170386.1187\n",
      "Epoch 5769/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1397676472.1096 - val_loss: 4010186850.7763\n",
      "Epoch 5770/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1400096732.1800 - val_loss: 4004817761.0228\n",
      "Epoch 5771/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1397986012.2427 - val_loss: 4030955591.8904\n",
      "Epoch 5772/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1398892980.9785 - val_loss: 4017066685.0776\n",
      "Epoch 5773/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1399246581.4795 - val_loss: 4031836103.0137\n",
      "Epoch 5774/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1398358798.7789 - val_loss: 4011281243.9087\n",
      "Epoch 5775/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1397798523.7417 - val_loss: 4025487435.6895\n",
      "Epoch 5776/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 54us/step - loss: 1398494235.3033 - val_loss: 4011574469.5525\n",
      "Epoch 5777/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1398406994.5362 - val_loss: 4021429991.4521\n",
      "Epoch 5778/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1398015464.9550 - val_loss: 4010817156.9680\n",
      "Epoch 5779/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1398479604.3523 - val_loss: 4024376267.3973\n",
      "Epoch 5780/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1398760449.5029 - val_loss: 4013587480.8402\n",
      "Epoch 5781/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1397518418.9119 - val_loss: 4025307711.4155\n",
      "Epoch 5782/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1397349226.7084 - val_loss: 4014573650.9954\n",
      "Epoch 5783/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1400797053.9961 - val_loss: 4020471182.3196\n",
      "Epoch 5784/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1399019326.6223 - val_loss: 4026279491.3607\n",
      "Epoch 5785/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1397723310.3405 - val_loss: 4005346570.0822\n",
      "Epoch 5786/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1399450087.2016 - val_loss: 4006526909.3699\n",
      "Epoch 5787/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1398389488.2192 - val_loss: 4033158627.2146\n",
      "Epoch 5788/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1397391631.6556 - val_loss: 4016952259.5068\n",
      "Epoch 5789/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1397539256.3601 - val_loss: 4026375154.7032\n",
      "Epoch 5790/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1399281482.8963 - val_loss: 4031823979.3973\n",
      "Epoch 5791/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1396629028.3209 - val_loss: 4016031259.6164\n",
      "Epoch 5792/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1399047296.2505 - val_loss: 4010297674.5205\n",
      "Epoch 5793/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1400213988.3209 - val_loss: 4029202757.5525\n",
      "Epoch 5794/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1399480741.8239 - val_loss: 4009962435.2146\n",
      "Epoch 5795/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1397194643.7886 - val_loss: 4027094598.8676\n",
      "Epoch 5796/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1399561770.5832 - val_loss: 4021272831.2694\n",
      "Epoch 5797/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1399009134.7162 - val_loss: 4009626728.6210\n",
      "Epoch 5798/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1397494131.6008 - val_loss: 4010422646.6484\n",
      "Epoch 5799/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1396889812.9159 - val_loss: 4026059295.2694\n",
      "Epoch 5800/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1398218049.6282 - val_loss: 4021339441.8265\n",
      "Epoch 5801/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1397473255.4521 - val_loss: 4014766730.8128\n",
      "Epoch 5802/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1398590684.9315 - val_loss: 4034114095.4886\n",
      "Epoch 5803/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1397201222.0117 - val_loss: 4015040975.3425\n",
      "Epoch 5804/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1397022547.1624 - val_loss: 4014009227.1050\n",
      "Epoch 5805/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1397772791.4834 - val_loss: 4007246103.8174\n",
      "Epoch 5806/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1399270414.5284 - val_loss: 4038386183.5982\n",
      "Epoch 5807/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1397594161.3464 - val_loss: 4016288192.0000\n",
      "Epoch 5808/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1396990714.2387 - val_loss: 4023443133.0776\n",
      "Epoch 5809/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1396618935.8591 - val_loss: 4018245655.3790\n",
      "Epoch 5810/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1397591155.2250 - val_loss: 4022024878.1735\n",
      "Epoch 5811/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1397422418.9119 - val_loss: 4027843798.9406\n",
      "Epoch 5812/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1397246476.5245 - val_loss: 4005794461.3699\n",
      "Epoch 5813/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1398191548.8689 - val_loss: 4028320434.5571\n",
      "Epoch 5814/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1397264102.9511 - val_loss: 4012799286.5023\n",
      "Epoch 5815/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1397776087.2955 - val_loss: 4012674716.9315\n",
      "Epoch 5816/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1397022041.4247 - val_loss: 4022517705.3516\n",
      "Epoch 5817/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1396917921.6908 - val_loss: 4022873936.2192\n",
      "Epoch 5818/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1397080896.8767 - val_loss: 4010162557.6621\n",
      "Epoch 5819/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1398170048.3757 - val_loss: 4010944109.7352\n",
      "Epoch 5820/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1397888770.5049 - val_loss: 4030708402.5571\n",
      "Epoch 5821/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1397846428.8063 - val_loss: 4038052705.7534\n",
      "Epoch 5822/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1398637630.3718 - val_loss: 4009481741.5890\n",
      "Epoch 5823/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1399203623.2016 - val_loss: 4012887637.7717\n",
      "Epoch 5824/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1397604990.4971 - val_loss: 4022538322.9954\n",
      "Epoch 5825/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1397192568.8611 - val_loss: 4024978796.4201\n",
      "Epoch 5826/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1396326225.5342 - val_loss: 4021759030.5023\n",
      "Epoch 5827/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1396693849.6751 - val_loss: 4020284972.1279\n",
      "Epoch 5828/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1396729869.7769 - val_loss: 4023034234.3014\n",
      "Epoch 5829/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1397737949.8082 - val_loss: 4019058317.4429\n",
      "Epoch 5830/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1396477659.9295 - val_loss: 4022884495.6347\n",
      "Epoch 5831/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1396652785.7221 - val_loss: 4027047327.2694\n",
      "Epoch 5832/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1397073111.4207 - val_loss: 4022329688.2557\n",
      "Epoch 5833/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1398052392.4540 - val_loss: 4026483945.4977\n",
      "Epoch 5834/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1396292585.7065 - val_loss: 4013645833.6438\n",
      "Epoch 5835/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1397169670.2622 - val_loss: 4015014326.7945\n",
      "Epoch 5836/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1396571491.6947 - val_loss: 4020062282.6667\n",
      "Epoch 5837/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1396591663.3425 - val_loss: 4021005486.4658\n",
      "Epoch 5838/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1398497778.2231 - val_loss: 4038169282.4840\n",
      "Epoch 5839/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1396500254.0587 - val_loss: 4012911351.0868\n",
      "Epoch 5840/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 48us/step - loss: 1397096238.5910 - val_loss: 4026531886.9041\n",
      "Epoch 5841/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1398294498.4423 - val_loss: 4030229213.9543\n",
      "Epoch 5842/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1395882404.8219 - val_loss: 4015475950.9041\n",
      "Epoch 5843/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1396988321.3151 - val_loss: 4003421347.2146\n",
      "Epoch 5844/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1397608733.5577 - val_loss: 4017250373.1142\n",
      "Epoch 5845/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1396629081.6751 - val_loss: 4018248873.0594\n",
      "Epoch 5846/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1398296067.1311 - val_loss: 4014640119.8174\n",
      "Epoch 5847/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1396084050.4736 - val_loss: 4033865032.6210\n",
      "Epoch 5848/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1395895344.7202 - val_loss: 4032555464.7671\n",
      "Epoch 5849/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1396723275.8982 - val_loss: 4025191506.9954\n",
      "Epoch 5850/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1398205736.3288 - val_loss: 4007036464.0731\n",
      "Epoch 5851/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1396748289.5029 - val_loss: 4019339044.9680\n",
      "Epoch 5852/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1399696563.3503 - val_loss: 4045600534.0639\n",
      "Epoch 5853/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1398154722.9432 - val_loss: 4012778307.6530\n",
      "Epoch 5854/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1396765858.8180 - val_loss: 4028308204.1279\n",
      "Epoch 5855/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1396836576.8141 - val_loss: 4034100895.4155\n",
      "Epoch 5856/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1398300685.2759 - val_loss: 4011060533.9178\n",
      "Epoch 5857/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1396927662.3405 - val_loss: 4017662062.9041\n",
      "Epoch 5858/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1396117201.4090 - val_loss: 4022030397.8082\n",
      "Epoch 5859/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1396477797.9491 - val_loss: 4026950583.0868\n",
      "Epoch 5860/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1396510789.6360 - val_loss: 4018907846.7215\n",
      "Epoch 5861/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1396198663.8904 - val_loss: 4022784504.9863\n",
      "Epoch 5862/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1395811715.5068 - val_loss: 4027192929.1689\n",
      "Epoch 5863/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1396476151.9843 - val_loss: 4023678195.7260\n",
      "Epoch 5864/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1395692813.7769 - val_loss: 4019826985.3516\n",
      "Epoch 5865/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1396838093.0254 - val_loss: 4025415530.5205\n",
      "Epoch 5866/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1396024186.6145 - val_loss: 4029287939.2146\n",
      "Epoch 5867/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1395734680.2975 - val_loss: 4020475029.9178\n",
      "Epoch 5868/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1396310869.9178 - val_loss: 4016702513.8265\n",
      "Epoch 5869/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1396208120.7358 - val_loss: 4028476458.9589\n",
      "Epoch 5870/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1397365734.7006 - val_loss: 4034337506.9224\n",
      "Epoch 5871/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1397885252.1331 - val_loss: 4013860266.2283\n",
      "Epoch 5872/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1397827996.8063 - val_loss: 4038294664.7671\n",
      "Epoch 5873/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1395740666.4892 - val_loss: 4022495382.9406\n",
      "Epoch 5874/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1396171399.0137 - val_loss: 4023141531.6164\n",
      "Epoch 5875/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1396438211.1311 - val_loss: 4019308559.9269\n",
      "Epoch 5876/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1400487890.9119 - val_loss: 4012793890.6301\n",
      "Epoch 5877/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1396946039.4834 - val_loss: 4018974686.9772\n",
      "Epoch 5878/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1396775609.9883 - val_loss: 4026419671.9635\n",
      "Epoch 5879/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1396660186.8023 - val_loss: 4018080226.7763\n",
      "Epoch 5880/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1395915732.1644 - val_loss: 4028208173.5890\n",
      "Epoch 5881/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1397047450.9276 - val_loss: 4019041585.5342\n",
      "Epoch 5882/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1395114736.3444 - val_loss: 4026589080.8402\n",
      "Epoch 5883/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1398569468.2427 - val_loss: 4036562986.6667\n",
      "Epoch 5884/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1396872796.1800 - val_loss: 4022917086.6849\n",
      "Epoch 5885/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1395581454.5284 - val_loss: 4017175503.4886\n",
      "Epoch 5886/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1396279617.1272 - val_loss: 4025618783.4155\n",
      "Epoch 5887/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1396230218.2701 - val_loss: 4019617339.7626\n",
      "Epoch 5888/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1396944704.2505 - val_loss: 4020461834.8128\n",
      "Epoch 5889/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1396208896.5010 - val_loss: 4023932063.7078\n",
      "Epoch 5890/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1395458626.3796 - val_loss: 4023470747.0320\n",
      "Epoch 5891/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1397710606.5284 - val_loss: 4022761610.5205\n",
      "Epoch 5892/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1395495853.4012 - val_loss: 4024212626.5571\n",
      "Epoch 5893/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1396906564.1331 - val_loss: 4032063249.3881\n",
      "Epoch 5894/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1397014980.0078 - val_loss: 4028538884.5297\n",
      "Epoch 5895/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1397876966.9511 - val_loss: 4003302351.7808\n",
      "Epoch 5896/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1399801010.5988 - val_loss: 4025549333.7717\n",
      "Epoch 5897/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1395792961.1898 - val_loss: 4025042888.9132\n",
      "Epoch 5898/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1396673980.8689 - val_loss: 4018158549.7717\n",
      "Epoch 5899/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1395693399.1703 - val_loss: 4017095062.9406\n",
      "Epoch 5900/10000\n",
      "1022/1022 [==============================] - ETA: 0s - loss: 711821312.000 - 0s 46us/step - loss: 1396157957.0098 - val_loss: 4029223874.6301\n",
      "Epoch 5901/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1395774385.8474 - val_loss: 4027395641.1324\n",
      "Epoch 5902/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1396258884.3836 - val_loss: 4013999404.4201\n",
      "Epoch 5903/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1395941169.7221 - val_loss: 4025839076.6758\n",
      "Epoch 5904/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 48us/step - loss: 1395459282.9119 - val_loss: 4031838450.2648\n",
      "Epoch 5905/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1398978456.2975 - val_loss: 4025532013.8813\n",
      "Epoch 5906/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1395185264.4697 - val_loss: 4027810269.0776\n",
      "Epoch 5907/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1395872660.5401 - val_loss: 4019488348.0548\n",
      "Epoch 5908/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1397295927.9843 - val_loss: 4031219807.1233\n",
      "Epoch 5909/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1395564874.0196 - val_loss: 4026749676.8584\n",
      "Epoch 5910/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1396132875.3973 - val_loss: 4026624961.6073\n",
      "Epoch 5911/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1396728997.5734 - val_loss: 4025500588.7123\n",
      "Epoch 5912/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1397030828.5871 - val_loss: 4036922813.9543\n",
      "Epoch 5913/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1395869420.9628 - val_loss: 4016144838.4292\n",
      "Epoch 5914/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1395021513.0176 - val_loss: 4029898397.0776\n",
      "Epoch 5915/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1398014507.3346 - val_loss: 4015301411.3607\n",
      "Epoch 5916/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1396275563.2094 - val_loss: 4027480958.3927\n",
      "Epoch 5917/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1395364163.9452 - val_loss: 4026573611.8356\n",
      "Epoch 5918/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1396760079.7808 - val_loss: 4034624611.9452\n",
      "Epoch 5919/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1396883591.5147 - val_loss: 4016364566.9406\n",
      "Epoch 5920/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1397038861.0254 - val_loss: 4037856997.6986\n",
      "Epoch 5921/10000\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 1396047924.6654 - val_loss: 4028334808.5479\n",
      "Epoch 5922/10000\n",
      "1022/1022 [==============================] - 0s 63us/step - loss: 1397164523.9609 - val_loss: 4046805066.2283\n",
      "Epoch 5923/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1395870649.4873 - val_loss: 4016489998.6119\n",
      "Epoch 5924/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1395325879.8591 - val_loss: 4024107694.4658\n",
      "Epoch 5925/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1396014521.1115 - val_loss: 4020801861.5525\n",
      "Epoch 5926/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1395204267.7104 - val_loss: 4037473537.1689\n",
      "Epoch 5927/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1397088857.5499 - val_loss: 4031581327.4886\n",
      "Epoch 5928/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1396531825.4716 - val_loss: 4020475399.8904\n",
      "Epoch 5929/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1395521015.4834 - val_loss: 4023959887.6347\n",
      "Epoch 5930/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1394885760.3757 - val_loss: 4031408098.1918\n",
      "Epoch 5931/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1395344909.9022 - val_loss: 4023280311.8174\n",
      "Epoch 5932/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1395516105.8943 - val_loss: 4026674657.7534\n",
      "Epoch 5933/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1396397535.4364 - val_loss: 4016275796.7489\n",
      "Epoch 5934/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1394663084.0861 - val_loss: 4027241383.4521\n",
      "Epoch 5935/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1395990174.9354 - val_loss: 4037471897.4247\n",
      "Epoch 5936/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1395568746.3327 - val_loss: 4031838288.6575\n",
      "Epoch 5937/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1396836526.3405 - val_loss: 4047395520.2922\n",
      "Epoch 5938/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1397780859.9922 - val_loss: 4028674654.5388\n",
      "Epoch 5939/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1395260988.3679 - val_loss: 4021564700.7854\n",
      "Epoch 5940/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1395966220.2740 - val_loss: 4021897359.4886\n",
      "Epoch 5941/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1395664315.2407 - val_loss: 4029803643.0320\n",
      "Epoch 5942/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1397237670.3249 - val_loss: 4045444370.5571\n",
      "Epoch 5943/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1394159694.9041 - val_loss: 4025282282.6667\n",
      "Epoch 5944/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1397247877.1350 - val_loss: 4035326820.2374\n",
      "Epoch 5945/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1397958124.9628 - val_loss: 4015651352.9863\n",
      "Epoch 5946/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1395383509.1663 - val_loss: 4037325735.0137\n",
      "Epoch 5947/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1395790909.6204 - val_loss: 4033719629.5890\n",
      "Epoch 5948/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1396554864.3444 - val_loss: 4018178561.8995\n",
      "Epoch 5949/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1395274784.3131 - val_loss: 4021894184.1826\n",
      "Epoch 5950/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1395707258.6145 - val_loss: 4034337254.8676\n",
      "Epoch 5951/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1395718581.3542 - val_loss: 4024598739.8721\n",
      "Epoch 5952/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1395366102.4188 - val_loss: 4031137399.6712\n",
      "Epoch 5953/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1395290549.3542 - val_loss: 4033744195.7991\n",
      "Epoch 5954/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1394950266.8650 - val_loss: 4029860003.0685\n",
      "Epoch 5955/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1394537929.1429 - val_loss: 4034587878.1370\n",
      "Epoch 5956/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1396488342.7945 - val_loss: 4045584170.0822\n",
      "Epoch 5957/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1394806233.0489 - val_loss: 4021061224.1826\n",
      "Epoch 5958/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1394814558.4344 - val_loss: 4026432150.6484\n",
      "Epoch 5959/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1396153168.1566 - val_loss: 4039737791.8539\n",
      "Epoch 5960/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1395564370.6614 - val_loss: 4022067948.2740\n",
      "Epoch 5961/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1395823715.6947 - val_loss: 4035306680.2557\n",
      "Epoch 5962/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1395020913.4716 - val_loss: 4033986813.0776\n",
      "Epoch 5963/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1394399541.7299 - val_loss: 4022172139.2511\n",
      "Epoch 5964/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1394759264.4384 - val_loss: 4028396908.7123\n",
      "Epoch 5965/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1394883233.5656 - val_loss: 4041956448.5845\n",
      "Epoch 5966/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1399748310.1683 - val_loss: 4018247066.3014\n",
      "Epoch 5967/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1393860216.4853 - val_loss: 4037519019.6895\n",
      "Epoch 5968/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 45us/step - loss: 1395218232.7358 - val_loss: 4032814673.5342\n",
      "Epoch 5969/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1395708849.8474 - val_loss: 4042442821.4064\n",
      "Epoch 5970/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1394973753.1115 - val_loss: 4032866709.0411\n",
      "Epoch 5971/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1394793058.8180 - val_loss: 4026450243.9452\n",
      "Epoch 5972/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1395608061.9961 - val_loss: 4037397607.4521\n",
      "Epoch 5973/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1394184785.2838 - val_loss: 4029585243.9087\n",
      "Epoch 5974/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1395611863.7965 - val_loss: 4024563014.8676\n",
      "Epoch 5975/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1394730960.9080 - val_loss: 4038684492.7123\n",
      "Epoch 5976/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1396170673.8474 - val_loss: 4014925292.1279\n",
      "Epoch 5977/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1395416445.7456 - val_loss: 4023669397.1872\n",
      "Epoch 5978/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1394578747.8669 - val_loss: 4040786082.4840\n",
      "Epoch 5979/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1395124377.0489 - val_loss: 4038426604.5662\n",
      "Epoch 5980/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1395471260.3053 - val_loss: 4018867499.5434\n",
      "Epoch 5981/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1395191238.3875 - val_loss: 4022840971.3973\n",
      "Epoch 5982/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1395696119.4834 - val_loss: 4029858795.5434\n",
      "Epoch 5983/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1394129489.9100 - val_loss: 4041587080.0365\n",
      "Epoch 5984/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1394815962.9276 - val_loss: 4029624792.2557\n",
      "Epoch 5985/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1394852031.1233 - val_loss: 4031970181.5525\n",
      "Epoch 5986/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1395676068.0705 - val_loss: 4046090533.2603\n",
      "Epoch 5987/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1395343953.6595 - val_loss: 4035915498.5205\n",
      "Epoch 5988/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1395157112.5479 - val_loss: 4026015916.4201\n",
      "Epoch 5989/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1395364082.3483 - val_loss: 4036786085.2603\n",
      "Epoch 5990/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1396461126.8885 - val_loss: 4029687827.7260\n",
      "Epoch 5991/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1396317649.1585 - val_loss: 4024234614.0639\n",
      "Epoch 5992/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1394468944.4070 - val_loss: 4040158231.2329\n",
      "Epoch 5993/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1394366907.3659 - val_loss: 4037681029.6986\n",
      "Epoch 5994/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1395025965.3386 - val_loss: 4033525273.4247\n",
      "Epoch 5995/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1395551318.1683 - val_loss: 4044562595.3607\n",
      "Epoch 5996/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1395848282.4266 - val_loss: 4038117361.3881\n",
      "Epoch 5997/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1396981282.0665 - val_loss: 4018303837.0776\n",
      "Epoch 5998/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1394829234.2231 - val_loss: 4025545635.3607\n",
      "Epoch 5999/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1394100853.9804 - val_loss: 4036725027.0685\n",
      "Epoch 6000/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1395032702.2466 - val_loss: 4030081595.3242\n",
      "Epoch 6001/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1394982815.4364 - val_loss: 4043770770.8493\n",
      "Epoch 6002/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1397760102.1996 - val_loss: 4038419236.2374\n",
      "Epoch 6003/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1394968656.9080 - val_loss: 4034722785.1689\n",
      "Epoch 6004/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1395998978.7554 - val_loss: 4010668489.7900\n",
      "Epoch 6005/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1394101402.3014 - val_loss: 4032043199.1233\n",
      "Epoch 6006/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1396242509.1507 - val_loss: 4038095868.9315\n",
      "Epoch 6007/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1394783244.7750 - val_loss: 4037471224.5479\n",
      "Epoch 6008/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1398009869.4012 - val_loss: 4025369713.3881\n",
      "Epoch 6009/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1398018617.6125 - val_loss: 4062008927.5616\n",
      "Epoch 6010/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1394376071.7652 - val_loss: 4027911854.7580\n",
      "Epoch 6011/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1395992788.6654 - val_loss: 4035683252.3105\n",
      "Epoch 6012/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1395945855.2485 - val_loss: 4013929256.7671\n",
      "Epoch 6013/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1398037770.8963 - val_loss: 4022779297.8995\n",
      "Epoch 6014/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1397392860.6810 - val_loss: 4020931230.2466\n",
      "Epoch 6015/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1393924874.0196 - val_loss: 4052205781.6256\n",
      "Epoch 6016/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1396726720.3757 - val_loss: 4045384767.5616\n",
      "Epoch 6017/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1398089127.0763 - val_loss: 4028261940.4566\n",
      "Epoch 6018/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1394901900.3992 - val_loss: 4032112784.2192\n",
      "Epoch 6019/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1394061465.1742 - val_loss: 4039452628.3105\n",
      "Epoch 6020/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1394141235.0998 - val_loss: 4032624069.4064\n",
      "Epoch 6021/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1394445859.5695 - val_loss: 4027297936.9498\n",
      "Epoch 6022/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1394011796.7906 - val_loss: 4035179950.3196\n",
      "Epoch 6023/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1395052495.1546 - val_loss: 4031143753.9361\n",
      "Epoch 6024/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1394965324.9002 - val_loss: 4033554870.0639\n",
      "Epoch 6025/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1394393140.3523 - val_loss: 4038664683.1050\n",
      "Epoch 6026/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1396428761.0489 - val_loss: 4034900478.6849\n",
      "Epoch 6027/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1394281516.5871 - val_loss: 4041680052.8950\n",
      "Epoch 6028/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1396609539.0059 - val_loss: 4024719311.9269\n",
      "Epoch 6029/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1393405641.6438 - val_loss: 4040457133.1507\n",
      "Epoch 6030/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1396459051.7104 - val_loss: 4053323501.8813\n",
      "Epoch 6031/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1394586695.6399 - val_loss: 4022585247.4155\n",
      "Epoch 6032/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 42us/step - loss: 1394512232.2035 - val_loss: 4036411675.9087\n",
      "Epoch 6033/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1394336955.8669 - val_loss: 4024794153.3516\n",
      "Epoch 6034/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1396073700.3209 - val_loss: 4024592025.8630\n",
      "Epoch 6035/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1393912227.9452 - val_loss: 4034120551.4521\n",
      "Epoch 6036/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1394119583.5616 - val_loss: 4038030452.7489\n",
      "Epoch 6037/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1393666969.0489 - val_loss: 4044251661.1507\n",
      "Epoch 6038/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1394334152.1409 - val_loss: 4044930121.7900\n",
      "Epoch 6039/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1394575110.1370 - val_loss: 4046888137.7900\n",
      "Epoch 6040/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1395799880.6419 - val_loss: 4027658905.5708\n",
      "Epoch 6041/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1394443148.0235 - val_loss: 4044092939.5434\n",
      "Epoch 6042/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1393806595.5068 - val_loss: 4040684781.5890\n",
      "Epoch 6043/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1394074101.7299 - val_loss: 4029852009.7900\n",
      "Epoch 6044/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1393568172.8376 - val_loss: 4036042421.1872\n",
      "Epoch 6045/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1393342252.8376 - val_loss: 4036961805.4429\n",
      "Epoch 6046/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1397060986.7397 - val_loss: 4026692898.9224\n",
      "Epoch 6047/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1393731120.5949 - val_loss: 4034889422.4658\n",
      "Epoch 6048/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1394371872.8141 - val_loss: 4041767991.9635\n",
      "Epoch 6049/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1394476136.7045 - val_loss: 4038734117.5525\n",
      "Epoch 6050/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1395333325.4012 - val_loss: 4054873583.7808\n",
      "Epoch 6051/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1393994632.3914 - val_loss: 4020756880.6575\n",
      "Epoch 6052/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1396701027.4442 - val_loss: 4052096415.7078\n",
      "Epoch 6053/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1393584494.4658 - val_loss: 4025203159.3790\n",
      "Epoch 6054/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1393439930.7397 - val_loss: 4030556567.8174\n",
      "Epoch 6055/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1394689791.3738 - val_loss: 4036027538.5571\n",
      "Epoch 6056/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1395690920.8297 - val_loss: 4052097413.1142\n",
      "Epoch 6057/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1395998012.1174 - val_loss: 4026085349.5525\n",
      "Epoch 6058/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1394037368.2348 - val_loss: 4044825732.5297\n",
      "Epoch 6059/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1393737311.0607 - val_loss: 4034373370.5936\n",
      "Epoch 6060/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1395731941.1350 - val_loss: 4019103146.5205\n",
      "Epoch 6061/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1394287509.4168 - val_loss: 4036503154.9954\n",
      "Epoch 6062/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1394046528.1252 - val_loss: 4042745840.6575\n",
      "Epoch 6063/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1397232960.0000 - val_loss: 4061141038.3196\n",
      "Epoch 6064/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1394119624.5166 - val_loss: 4021936500.8950\n",
      "Epoch 6065/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1395088097.9413 - val_loss: 4026748755.1416\n",
      "Epoch 6066/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1395727905.4403 - val_loss: 4026584015.6347\n",
      "Epoch 6067/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1399414014.7476 - val_loss: 4035197423.1963\n",
      "Epoch 6068/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1394064947.6008 - val_loss: 4033090652.6393\n",
      "Epoch 6069/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1393468155.7417 - val_loss: 4033332395.5434\n",
      "Epoch 6070/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1397462960.8454 - val_loss: 4021997416.4749\n",
      "Epoch 6071/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1393807716.9472 - val_loss: 4043608418.6301\n",
      "Epoch 6072/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1394914389.1663 - val_loss: 4036604702.6849\n",
      "Epoch 6073/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1393906471.7025 - val_loss: 4046366426.1553\n",
      "Epoch 6074/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1393633577.8317 - val_loss: 4046095270.1370\n",
      "Epoch 6075/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1393561239.9217 - val_loss: 4040280316.6393\n",
      "Epoch 6076/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1393572764.1800 - val_loss: 4027506585.7169\n",
      "Epoch 6077/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1393668819.4129 - val_loss: 4031569635.5068\n",
      "Epoch 6078/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1393057403.3033 - val_loss: 4041587028.1644\n",
      "Epoch 6079/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1393595314.8493 - val_loss: 4048315152.3653\n",
      "Epoch 6080/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1393608151.1703 - val_loss: 4038182630.8676\n",
      "Epoch 6081/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1394435307.2094 - val_loss: 4030726100.1644\n",
      "Epoch 6082/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1394921912.3601 - val_loss: 4044002322.8493\n",
      "Epoch 6083/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1395867271.1389 - val_loss: 4027982712.4018\n",
      "Epoch 6084/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1395059535.0294 - val_loss: 4052197667.2146\n",
      "Epoch 6085/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1394914969.2994 - val_loss: 4034568566.5023\n",
      "Epoch 6086/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1392926961.4716 - val_loss: 4039036347.9087\n",
      "Epoch 6087/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1392975821.1507 - val_loss: 4044025140.7489\n",
      "Epoch 6088/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1394020491.7730 - val_loss: 4029934064.3653\n",
      "Epoch 6089/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1393507449.2368 - val_loss: 4031465033.9361\n",
      "Epoch 6090/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1395620509.3072 - val_loss: 4027046978.7763\n",
      "Epoch 6091/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1392874562.6301 - val_loss: 4042452038.7215\n",
      "Epoch 6092/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1395430691.8200 - val_loss: 4062001694.1005\n",
      "Epoch 6093/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1392305443.0059 - val_loss: 4037656629.0411\n",
      "Epoch 6094/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1392638347.5225 - val_loss: 4035386856.0365\n",
      "Epoch 6095/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1393806032.9080 - val_loss: 4046408517.9909\n",
      "Epoch 6096/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 43us/step - loss: 1393101559.7339 - val_loss: 4030054842.7397\n",
      "Epoch 6097/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1394342771.0372 - val_loss: 4024047905.3151\n",
      "Epoch 6098/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1394701661.5577 - val_loss: 4057279211.1050\n",
      "Epoch 6099/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1393791931.1155 - val_loss: 4043133928.0365\n",
      "Epoch 6100/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1394263336.3288 - val_loss: 4047937610.2283\n",
      "Epoch 6101/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1392813158.4501 - val_loss: 4026416249.2785\n",
      "Epoch 6102/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1393968176.9706 - val_loss: 4031507464.1826\n",
      "Epoch 6103/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1394981363.4755 - val_loss: 4034700793.8630\n",
      "Epoch 6104/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1393396554.8963 - val_loss: 4041595988.1644\n",
      "Epoch 6105/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1393260381.1820 - val_loss: 4044640083.4338\n",
      "Epoch 6106/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1396597754.4892 - val_loss: 4038105642.5205\n",
      "Epoch 6107/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1394147368.0783 - val_loss: 4028474581.1872\n",
      "Epoch 6108/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1395706033.3464 - val_loss: 4036355559.1598\n",
      "Epoch 6109/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1393579447.1076 - val_loss: 4045947568.2192\n",
      "Epoch 6110/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1393776346.1761 - val_loss: 4048724374.5023\n",
      "Epoch 6111/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1392985833.2055 - val_loss: 4042366499.0685\n",
      "Epoch 6112/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1394193711.3425 - val_loss: 4020539049.0594\n",
      "Epoch 6113/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1392360772.6341 - val_loss: 4041006489.8630\n",
      "Epoch 6114/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1392961445.1977 - val_loss: 4042217051.4703\n",
      "Epoch 6115/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1394323794.6614 - val_loss: 4045493005.8813\n",
      "Epoch 6116/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1392897131.4599 - val_loss: 4037636997.9909\n",
      "Epoch 6117/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1392571105.0646 - val_loss: 4041285306.1553\n",
      "Epoch 6118/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1393134070.4814 - val_loss: 4037679208.1826\n",
      "Epoch 6119/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1394529343.2485 - val_loss: 4033055621.6986\n",
      "Epoch 6120/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1392563820.2114 - val_loss: 4028742699.6895\n",
      "Epoch 6121/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1393500709.8239 - val_loss: 4038544815.1963\n",
      "Epoch 6122/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1393110338.2544 - val_loss: 4039803542.9406\n",
      "Epoch 6123/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1393498992.0939 - val_loss: 4031933298.9954\n",
      "Epoch 6124/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1393491617.5656 - val_loss: 4039401664.7306\n",
      "Epoch 6125/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1392874884.2583 - val_loss: 4048480943.3425\n",
      "Epoch 6126/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1392810056.6419 - val_loss: 4038947408.9498\n",
      "Epoch 6127/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1393190524.1174 - val_loss: 4028900827.0320\n",
      "Epoch 6128/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1394460774.9511 - val_loss: 4037691018.3744\n",
      "Epoch 6129/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1394171115.6477 - val_loss: 4044879798.3562\n",
      "Epoch 6130/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1393852645.0724 - val_loss: 4034668758.0639\n",
      "Epoch 6131/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1392721909.4168 - val_loss: 4029769954.1918\n",
      "Epoch 6132/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1393328546.9432 - val_loss: 4028349434.5936\n",
      "Epoch 6133/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1392284713.5812 - val_loss: 4042771088.0731\n",
      "Epoch 6134/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1392473847.4834 - val_loss: 4041293026.1918\n",
      "Epoch 6135/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1393750905.7378 - val_loss: 4038165079.5251\n",
      "Epoch 6136/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1393874527.1859 - val_loss: 4040801332.3105\n",
      "Epoch 6137/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1393352293.9491 - val_loss: 4039582183.7443\n",
      "Epoch 6138/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1392467985.5342 - val_loss: 4036252423.3059\n",
      "Epoch 6139/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1392691966.4971 - val_loss: 4039723259.7626\n",
      "Epoch 6140/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1393600919.2955 - val_loss: 4031441717.9178\n",
      "Epoch 6141/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1392567062.4188 - val_loss: 4039195073.8995\n",
      "Epoch 6142/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1394407670.9824 - val_loss: 4044620486.4292\n",
      "Epoch 6143/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1394255996.9941 - val_loss: 4020526384.6575\n",
      "Epoch 6144/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1396954267.8043 - val_loss: 4059013058.4840\n",
      "Epoch 6145/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1397595086.9041 - val_loss: 4029750203.6164\n",
      "Epoch 6146/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1393971915.1468 - val_loss: 4050071653.9909\n",
      "Epoch 6147/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1393173906.0352 - val_loss: 4043544145.8265\n",
      "Epoch 6148/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1394438172.8063 - val_loss: 4043731744.0000\n",
      "Epoch 6149/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1393971924.6654 - val_loss: 4027026708.0183\n",
      "Epoch 6150/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1392872016.6575 - val_loss: 4043370721.8995\n",
      "Epoch 6151/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1392374068.6027 - val_loss: 4046788786.4110\n",
      "Epoch 6152/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1394074481.9726 - val_loss: 4036585863.4521\n",
      "Epoch 6153/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1392114547.9765 - val_loss: 4040310347.8356\n",
      "Epoch 6154/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1392873907.8513 - val_loss: 4046466098.8493\n",
      "Epoch 6155/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1393454644.7280 - val_loss: 4049155084.4201\n",
      "Epoch 6156/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1393310879.0607 - val_loss: 4031968756.8950\n",
      "Epoch 6157/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1392409887.6869 - val_loss: 4039931109.6986\n",
      "Epoch 6158/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1395176187.2407 - val_loss: 4042823148.1279\n",
      "Epoch 6159/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1392803587.0059 - val_loss: 4042411782.4292\n",
      "Epoch 6160/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 43us/step - loss: 1393765681.3464 - val_loss: 4031725534.1005\n",
      "Epoch 6161/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1392542025.2681 - val_loss: 4035642955.9817\n",
      "Epoch 6162/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1394031969.1898 - val_loss: 4047599838.6849\n",
      "Epoch 6163/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1393500280.4853 - val_loss: 4046504900.0913\n",
      "Epoch 6164/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1394650660.8219 - val_loss: 4024306699.2511\n",
      "Epoch 6165/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1391978610.5988 - val_loss: 4045499714.1918\n",
      "Epoch 6166/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1394179964.7436 - val_loss: 4064425136.9498\n",
      "Epoch 6167/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1392116088.7358 - val_loss: 4035857531.0320\n",
      "Epoch 6168/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1393168749.7143 - val_loss: 4035163196.6393\n",
      "Epoch 6169/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1394812098.6928 - val_loss: 4030202990.9041\n",
      "Epoch 6170/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1392193490.4110 - val_loss: 4043005265.8265\n",
      "Epoch 6171/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1393946725.6986 - val_loss: 4032523033.1324\n",
      "Epoch 6172/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1394994431.7495 - val_loss: 4057056902.4292\n",
      "Epoch 6173/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1393262573.7143 - val_loss: 4030798491.7626\n",
      "Epoch 6174/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1394656574.3092 - val_loss: 4034693296.6575\n",
      "Epoch 6175/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1391808180.7280 - val_loss: 4046133092.6758\n",
      "Epoch 6176/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1392457696.1879 - val_loss: 4043205446.8676\n",
      "Epoch 6177/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1392643057.0959 - val_loss: 4046611519.8539\n",
      "Epoch 6178/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1392648318.7476 - val_loss: 4043925301.4795\n",
      "Epoch 6179/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1392521885.5577 - val_loss: 4041632146.1187\n",
      "Epoch 6180/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1393577683.9139 - val_loss: 4031209040.8037\n",
      "Epoch 6181/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1392020816.2818 - val_loss: 4034580321.3151\n",
      "Epoch 6182/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1392484617.7691 - val_loss: 4046380429.4429\n",
      "Epoch 6183/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1392406493.0568 - val_loss: 4041480765.5160\n",
      "Epoch 6184/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1391873064.9550 - val_loss: 4035945889.6073\n",
      "Epoch 6185/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1394047538.3483 - val_loss: 4050965795.5068\n",
      "Epoch 6186/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1392048577.8787 - val_loss: 4047814353.9726\n",
      "Epoch 6187/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1393252205.7143 - val_loss: 4036181827.5068\n",
      "Epoch 6188/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1392573596.8063 - val_loss: 4039942311.0137\n",
      "Epoch 6189/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1392519799.7339 - val_loss: 4045873356.4201\n",
      "Epoch 6190/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1392314748.4932 - val_loss: 4044029002.2283\n",
      "Epoch 6191/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1392823911.9530 - val_loss: 4026759106.4840\n",
      "Epoch 6192/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1392414949.3229 - val_loss: 4046021061.5525\n",
      "Epoch 6193/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1392143595.8356 - val_loss: 4045653213.6621\n",
      "Epoch 6194/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1392321736.5166 - val_loss: 4041852684.4201\n",
      "Epoch 6195/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1392589516.9002 - val_loss: 4030284560.3653\n",
      "Epoch 6196/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1392694425.1742 - val_loss: 4027516337.0959\n",
      "Epoch 6197/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1392414167.1703 - val_loss: 4046201581.0046\n",
      "Epoch 6198/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1394356556.9002 - val_loss: 4032973063.4521\n",
      "Epoch 6199/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1391586844.0548 - val_loss: 4039777400.6941\n",
      "Epoch 6200/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1391895787.0841 - val_loss: 4050370541.0046\n",
      "Epoch 6201/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1392899603.4129 - val_loss: 4043549280.0000\n",
      "Epoch 6202/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1392336105.2055 - val_loss: 4037784836.9680\n",
      "Epoch 6203/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1393214956.7123 - val_loss: 4036943312.2192\n",
      "Epoch 6204/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1392389774.4031 - val_loss: 4045306480.8037\n",
      "Epoch 6205/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1391652518.0744 - val_loss: 4050755400.6210\n",
      "Epoch 6206/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1391886906.3640 - val_loss: 4045265199.7808\n",
      "Epoch 6207/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1393138348.7123 - val_loss: 4051728655.9269\n",
      "Epoch 6208/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1392254868.0391 - val_loss: 4038329790.9772\n",
      "Epoch 6209/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1394085461.5421 - val_loss: 4030468110.1735\n",
      "Epoch 6210/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1392357701.3855 - val_loss: 4040691100.9315\n",
      "Epoch 6211/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1393310042.4266 - val_loss: 4051149873.9726\n",
      "Epoch 6212/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1392950054.8258 - val_loss: 4052978709.4795\n",
      "Epoch 6213/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1393720631.1076 - val_loss: 4030719828.3105\n",
      "Epoch 6214/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1393371097.5499 - val_loss: 4032187759.9269\n",
      "Epoch 6215/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1391866797.1194 - val_loss: 4052450878.2466\n",
      "Epoch 6216/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1391293746.4736 - val_loss: 4046862168.8402\n",
      "Epoch 6217/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1391980108.1487 - val_loss: 4035317916.2009\n",
      "Epoch 6218/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1391788440.5479 - val_loss: 4035901524.8950\n",
      "Epoch 6219/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1393550221.6517 - val_loss: 4045166499.7991\n",
      "Epoch 6220/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1393948175.7808 - val_loss: 4041198053.6986\n",
      "Epoch 6221/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1392142893.3386 - val_loss: 4058256683.8356\n",
      "Epoch 6222/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1393023928.3601 - val_loss: 4034002158.1735\n",
      "Epoch 6223/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1392710538.0196 - val_loss: 4055051969.4612\n",
      "Epoch 6224/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 52us/step - loss: 1392821376.2505 - val_loss: 4036113525.9178\n",
      "Epoch 6225/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1391733702.8885 - val_loss: 4036350162.7032\n",
      "Epoch 6226/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1395787120.9706 - val_loss: 4059482435.5068\n",
      "Epoch 6227/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1392656203.6477 - val_loss: 4031405921.0228\n",
      "Epoch 6228/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1392807128.1722 - val_loss: 4046685511.7443\n",
      "Epoch 6229/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1391993813.4168 - val_loss: 4032766296.8402\n",
      "Epoch 6230/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1391598360.0470 - val_loss: 4031126370.9224\n",
      "Epoch 6231/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1391597339.4286 - val_loss: 4047991045.5525\n",
      "Epoch 6232/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1391390234.6145 - val_loss: 4048722129.6804\n",
      "Epoch 6233/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1393356541.7456 - val_loss: 4035159958.2100\n",
      "Epoch 6234/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1392069274.0509 - val_loss: 4053857943.6712\n",
      "Epoch 6235/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1392277311.8748 - val_loss: 4042215559.7443\n",
      "Epoch 6236/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1393576737.6908 - val_loss: 4040263745.6073\n",
      "Epoch 6237/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1392364481.7534 - val_loss: 4051731469.7352\n",
      "Epoch 6238/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1392117684.4775 - val_loss: 4048596730.8858\n",
      "Epoch 6239/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1393418687.6243 - val_loss: 4034941059.3607\n",
      "Epoch 6240/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1391796131.5695 - val_loss: 4045976466.8493\n",
      "Epoch 6241/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1391328589.1507 - val_loss: 4043668473.7169\n",
      "Epoch 6242/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1392207869.9961 - val_loss: 4046457980.9315\n",
      "Epoch 6243/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1392593584.5949 - val_loss: 4055305843.1416\n",
      "Epoch 6244/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1391136478.8102 - val_loss: 4050769745.2420\n",
      "Epoch 6245/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1391492133.5734 - val_loss: 4042145740.2740\n",
      "Epoch 6246/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1395561130.8337 - val_loss: 4030343072.7306\n",
      "Epoch 6247/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1393514427.1155 - val_loss: 4039721180.0548\n",
      "Epoch 6248/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1392465333.6047 - val_loss: 4042551168.7306\n",
      "Epoch 6249/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1392763317.2290 - val_loss: 4056121467.0320\n",
      "Epoch 6250/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1391163049.5812 - val_loss: 4035610353.9726\n",
      "Epoch 6251/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1392334903.8591 - val_loss: 4042386731.8356\n",
      "Epoch 6252/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1393212190.0587 - val_loss: 4023034352.6575\n",
      "Epoch 6253/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1392057134.4658 - val_loss: 4042402680.9863\n",
      "Epoch 6254/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1391543486.7476 - val_loss: 4040149724.3470\n",
      "Epoch 6255/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1391274370.2544 - val_loss: 4036218794.0822\n",
      "Epoch 6256/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1391589515.6477 - val_loss: 4040904630.9406\n",
      "Epoch 6257/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1392326229.0411 - val_loss: 4048165940.0183\n",
      "Epoch 6258/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1391185788.2427 - val_loss: 4035703392.5845\n",
      "Epoch 6259/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1392245342.1840 - val_loss: 4050638464.4384\n",
      "Epoch 6260/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1391006110.8102 - val_loss: 4038283578.1553\n",
      "Epoch 6261/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1392654581.3542 - val_loss: 4042536552.0365\n",
      "Epoch 6262/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1392547891.9765 - val_loss: 4037978309.5525\n",
      "Epoch 6263/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1391525651.5382 - val_loss: 4058605942.7945\n",
      "Epoch 6264/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1392596116.5401 - val_loss: 4036055768.6941\n",
      "Epoch 6265/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1394408376.6106 - val_loss: 4044894929.3881\n",
      "Epoch 6266/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1391321648.9706 - val_loss: 4050466089.9361\n",
      "Epoch 6267/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1394077655.1703 - val_loss: 4057158295.8174\n",
      "Epoch 6268/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1391479325.3072 - val_loss: 4031906239.8539\n",
      "Epoch 6269/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1391609925.5108 - val_loss: 4034919237.5525\n",
      "Epoch 6270/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1391243782.0744 - val_loss: 4050144097.6073\n",
      "Epoch 6271/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1390983878.1996 - val_loss: 4043937006.3196\n",
      "Epoch 6272/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1392507485.5577 - val_loss: 4049640480.2922\n",
      "Epoch 6273/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1390556589.2759 - val_loss: 4030979964.6393\n",
      "Epoch 6274/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1391234478.8415 - val_loss: 4040079344.5114\n",
      "Epoch 6275/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1391577121.0646 - val_loss: 4028335491.0685\n",
      "Epoch 6276/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1392256275.2877 - val_loss: 4031319118.4658\n",
      "Epoch 6277/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1390379956.3523 - val_loss: 4051604573.6621\n",
      "Epoch 6278/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1395154588.3053 - val_loss: 4031750956.2740\n",
      "Epoch 6279/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1390995177.2055 - val_loss: 4050699348.4566\n",
      "Epoch 6280/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1392273420.7750 - val_loss: 4040920451.0685\n",
      "Epoch 6281/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1390958125.9022 - val_loss: 4055932063.7078\n",
      "Epoch 6282/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1391694814.4344 - val_loss: 4054277016.8402\n",
      "Epoch 6283/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1391547359.4364 - val_loss: 4035636423.4521\n",
      "Epoch 6284/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1391258963.9139 - val_loss: 4054949407.7078\n",
      "Epoch 6285/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1391195634.4736 - val_loss: 4044221855.7078\n",
      "Epoch 6286/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1390707753.8317 - val_loss: 4042311188.1644\n",
      "Epoch 6287/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1392451047.4521 - val_loss: 4026762756.2374\n",
      "Epoch 6288/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 49us/step - loss: 1391524932.8845 - val_loss: 4046864987.3242\n",
      "Epoch 6289/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1392982120.5793 - val_loss: 4034140891.1781\n",
      "Epoch 6290/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1391741952.2505 - val_loss: 4060174304.5845\n",
      "Epoch 6291/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1392761535.6243 - val_loss: 4055185287.5982\n",
      "Epoch 6292/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1392069311.1233 - val_loss: 4040487875.0685\n",
      "Epoch 6293/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1391184523.3973 - val_loss: 4042925170.1187\n",
      "Epoch 6294/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1391238787.0059 - val_loss: 4034136488.7671\n",
      "Epoch 6295/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1394174624.9393 - val_loss: 4066459429.5525\n",
      "Epoch 6296/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1391784386.3796 - val_loss: 4029457711.9269\n",
      "Epoch 6297/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1392001106.4110 - val_loss: 4041244370.8493\n",
      "Epoch 6298/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1393114932.8532 - val_loss: 4045514409.4977\n",
      "Epoch 6299/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1390805700.6341 - val_loss: 4051336679.4521\n",
      "Epoch 6300/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1391213384.1409 - val_loss: 4051539366.7215\n",
      "Epoch 6301/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1391214654.3718 - val_loss: 4045728967.7443\n",
      "Epoch 6302/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1390912088.1722 - val_loss: 4045367351.6712\n",
      "Epoch 6303/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1391963741.3072 - val_loss: 4044952923.9087\n",
      "Epoch 6304/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1390967947.2720 - val_loss: 4034522831.0502\n",
      "Epoch 6305/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1390967101.3699 - val_loss: 4045175617.6073\n",
      "Epoch 6306/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1392539076.3836 - val_loss: 4052265159.1598\n",
      "Epoch 6307/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1391869322.2701 - val_loss: 4035505592.6941\n",
      "Epoch 6308/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1391992197.0098 - val_loss: 4054300400.3653\n",
      "Epoch 6309/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1390155838.8728 - val_loss: 4037438872.1096\n",
      "Epoch 6310/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1390713966.9667 - val_loss: 4043771042.3379\n",
      "Epoch 6311/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1390820161.5029 - val_loss: 4047438360.8402\n",
      "Epoch 6312/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1396595453.7456 - val_loss: 4037130389.6256\n",
      "Epoch 6313/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1394281676.6497 - val_loss: 4055445193.9361\n",
      "Epoch 6314/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1390779773.9335 - val_loss: 4039643651.7991\n",
      "Epoch 6315/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1392431192.4227 - val_loss: 4028706908.2009\n",
      "Epoch 6316/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1391427995.3033 - val_loss: 4056190507.8356\n",
      "Epoch 6317/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1390809866.7710 - val_loss: 4036903444.8950\n",
      "Epoch 6318/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1392189576.0157 - val_loss: 4034053965.8813\n",
      "Epoch 6319/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1391200030.8102 - val_loss: 4039987167.8539\n",
      "Epoch 6320/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1392171041.8160 - val_loss: 4051608988.0548\n",
      "Epoch 6321/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1390676585.4560 - val_loss: 4043232440.2557\n",
      "Epoch 6322/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1390987416.5479 - val_loss: 4043783084.8584\n",
      "Epoch 6323/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1391122255.4051 - val_loss: 4038488221.2237\n",
      "Epoch 6324/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1390859932.6810 - val_loss: 4049284960.7306\n",
      "Epoch 6325/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1390522638.2779 - val_loss: 4043376387.7991\n",
      "Epoch 6326/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1390398850.1292 - val_loss: 4048260972.1279\n",
      "Epoch 6327/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1391712469.5421 - val_loss: 4045100881.8265\n",
      "Epoch 6328/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1390622076.8689 - val_loss: 4057064428.5662\n",
      "Epoch 6329/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1392096345.4247 - val_loss: 4043186010.8858\n",
      "Epoch 6330/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1391138024.2035 - val_loss: 4055107021.7352\n",
      "Epoch 6331/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1391630405.6360 - val_loss: 4041023890.4110\n",
      "Epoch 6332/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1391305685.4168 - val_loss: 4057760202.8128\n",
      "Epoch 6333/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1390330764.3992 - val_loss: 4049385838.1735\n",
      "Epoch 6334/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1393342213.5734 - val_loss: 4061887294.3927\n",
      "Epoch 6335/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1391016043.7104 - val_loss: 4043258510.9041\n",
      "Epoch 6336/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1391024408.7984 - val_loss: 4026854995.2877\n",
      "Epoch 6337/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1390914452.2896 - val_loss: 4034463087.6347\n",
      "Epoch 6338/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1390309022.7476 - val_loss: 4040381307.1781\n",
      "Epoch 6339/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1392504490.9589 - val_loss: 4038539330.0457\n",
      "Epoch 6340/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1393430275.8826 - val_loss: 4053687646.1005\n",
      "Epoch 6341/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1391442651.1781 - val_loss: 4050620768.5845\n",
      "Epoch 6342/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1390128337.9100 - val_loss: 4048581206.9406\n",
      "Epoch 6343/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1390529844.4775 - val_loss: 4042233628.4932\n",
      "Epoch 6344/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1390374854.1370 - val_loss: 4039371926.6484\n",
      "Epoch 6345/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1393082322.9119 - val_loss: 4046719989.9178\n",
      "Epoch 6346/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1390580713.9569 - val_loss: 4046222748.4932\n",
      "Epoch 6347/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1391448680.4540 - val_loss: 4051452810.6667\n",
      "Epoch 6348/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1390243868.3053 - val_loss: 4040358822.1370\n",
      "Epoch 6349/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1392065762.4423 - val_loss: 4031319661.7352\n",
      "Epoch 6350/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1390625883.0528 - val_loss: 4050827676.3470\n",
      "Epoch 6351/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1391817805.7769 - val_loss: 4034819367.7443\n",
      "Epoch 6352/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 56us/step - loss: 1390288159.5616 - val_loss: 4052753287.1598\n",
      "Epoch 6353/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1390307844.2583 - val_loss: 4056285511.4521\n",
      "Epoch 6354/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1391827213.5264 - val_loss: 4047088219.7626\n",
      "Epoch 6355/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1392319017.0802 - val_loss: 4055743179.5434\n",
      "Epoch 6356/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1390663100.8689 - val_loss: 4029093187.9452\n",
      "Epoch 6357/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1390080395.8982 - val_loss: 4045568641.3151\n",
      "Epoch 6358/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1392643829.2916 - val_loss: 4065218639.9269\n",
      "Epoch 6359/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1389978179.6321 - val_loss: 4039008559.1963\n",
      "Epoch 6360/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1390933047.6086 - val_loss: 4042193403.7626\n",
      "Epoch 6361/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1390936518.3875 - val_loss: 4038057422.7580\n",
      "Epoch 6362/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1390837327.1546 - val_loss: 4044730006.2100\n",
      "Epoch 6363/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1390522810.1135 - val_loss: 4037632567.0868\n",
      "Epoch 6364/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1390269156.3209 - val_loss: 4051210961.2420\n",
      "Epoch 6365/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1390318831.9687 - val_loss: 4045549208.9863\n",
      "Epoch 6366/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1390343784.4540 - val_loss: 4044401809.2420\n",
      "Epoch 6367/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1390796326.3249 - val_loss: 4044194384.3653\n",
      "Epoch 6368/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1390555091.1624 - val_loss: 4045257181.8082\n",
      "Epoch 6369/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1389854558.1840 - val_loss: 4056208867.2146\n",
      "Epoch 6370/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1391770595.5695 - val_loss: 4048325023.1233\n",
      "Epoch 6371/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1390475453.1194 - val_loss: 4053261172.1644\n",
      "Epoch 6372/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1390838834.8493 - val_loss: 4047225538.0457\n",
      "Epoch 6373/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1391659916.5245 - val_loss: 4038742494.6849\n",
      "Epoch 6374/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1390736378.7397 - val_loss: 4051920045.0046\n",
      "Epoch 6375/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1391436167.7652 - val_loss: 4050012470.2100\n",
      "Epoch 6376/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1390552753.9726 - val_loss: 4042953282.0457\n",
      "Epoch 6377/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1389959818.3953 - val_loss: 4050437892.5297\n",
      "Epoch 6378/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1390132818.4110 - val_loss: 4043041243.1781\n",
      "Epoch 6379/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1390855971.4442 - val_loss: 4040720810.8128\n",
      "Epoch 6380/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1390384779.2720 - val_loss: 4056031602.4110\n",
      "Epoch 6381/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1390779394.5049 - val_loss: 4058030803.1416\n",
      "Epoch 6382/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1390340428.6497 - val_loss: 4050110800.9498\n",
      "Epoch 6383/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1389810685.7456 - val_loss: 4043009109.0411\n",
      "Epoch 6384/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1389858507.3973 - val_loss: 4047289681.5342\n",
      "Epoch 6385/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1391522964.7906 - val_loss: 4055335575.8174\n",
      "Epoch 6386/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1391100548.5088 - val_loss: 4029962075.0320\n",
      "Epoch 6387/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1389734359.6712 - val_loss: 4044798610.7032\n",
      "Epoch 6388/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1393274153.4560 - val_loss: 4045918408.0365\n",
      "Epoch 6389/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1391406462.7476 - val_loss: 4050749884.3470\n",
      "Epoch 6390/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1390793104.5323 - val_loss: 4033573084.0548\n",
      "Epoch 6391/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1390054520.3601 - val_loss: 4047843931.4703\n",
      "Epoch 6392/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1390627850.7710 - val_loss: 4041318973.3699\n",
      "Epoch 6393/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1390046794.6458 - val_loss: 4047074037.9178\n",
      "Epoch 6394/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1392397740.5871 - val_loss: 4049224221.3699\n",
      "Epoch 6395/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1390667024.1566 - val_loss: 4040312627.2877\n",
      "Epoch 6396/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1390527568.6575 - val_loss: 4043135309.8813\n",
      "Epoch 6397/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1389959378.5362 - val_loss: 4062166832.5114\n",
      "Epoch 6398/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1390879947.7730 - val_loss: 4042659787.6895\n",
      "Epoch 6399/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1391730505.3933 - val_loss: 4065980037.6986\n",
      "Epoch 6400/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1389709256.6419 - val_loss: 4055131953.5342\n",
      "Epoch 6401/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1391136806.5753 - val_loss: 4028706375.0137\n",
      "Epoch 6402/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1389615432.8924 - val_loss: 4053471905.6073\n",
      "Epoch 6403/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1390522784.3131 - val_loss: 4042951145.6438\n",
      "Epoch 6404/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1389990080.1252 - val_loss: 4042498883.7991\n",
      "Epoch 6405/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1392729313.8160 - val_loss: 4067368062.5388\n",
      "Epoch 6406/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1390333309.9961 - val_loss: 4048934552.6941\n",
      "Epoch 6407/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1392272977.7847 - val_loss: 4030823095.9635\n",
      "Epoch 6408/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1390707952.8454 - val_loss: 4061134147.2146\n",
      "Epoch 6409/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1393384522.2701 - val_loss: 4048453313.0228\n",
      "Epoch 6410/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1389993981.1194 - val_loss: 4043971064.4018\n",
      "Epoch 6411/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1390081596.6184 - val_loss: 4054810207.1233\n",
      "Epoch 6412/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1391940807.0137 - val_loss: 4060519720.3288\n",
      "Epoch 6413/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1389633223.8904 - val_loss: 4040100558.3196\n",
      "Epoch 6414/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1390690077.4325 - val_loss: 4033908938.5205\n",
      "Epoch 6415/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1389215717.6986 - val_loss: 4052499061.6256\n",
      "Epoch 6416/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 42us/step - loss: 1389957675.3346 - val_loss: 4050392790.3562\n",
      "Epoch 6417/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1389732795.3659 - val_loss: 4055116546.0457\n",
      "Epoch 6418/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1389954583.2955 - val_loss: 4045321552.0731\n",
      "Epoch 6419/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1389606326.2309 - val_loss: 4045725860.5297\n",
      "Epoch 6420/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1392045163.2094 - val_loss: 4073339390.2466\n",
      "Epoch 6421/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1390539587.3816 - val_loss: 4052707759.1963\n",
      "Epoch 6422/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1391095222.8571 - val_loss: 4034971952.6575\n",
      "Epoch 6423/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1390280565.2290 - val_loss: 4057534860.5662\n",
      "Epoch 6424/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1390360264.1409 - val_loss: 4054688200.6210\n",
      "Epoch 6425/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1390724268.8376 - val_loss: 4029045924.6758\n",
      "Epoch 6426/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1389851843.3816 - val_loss: 4042423458.3379\n",
      "Epoch 6427/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1389602781.4325 - val_loss: 4051371483.1781\n",
      "Epoch 6428/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1390166081.6282 - val_loss: 4055988982.2100\n",
      "Epoch 6429/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1391323106.4423 - val_loss: 4046309372.3470\n",
      "Epoch 6430/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1389573216.8141 - val_loss: 4051913275.9087\n",
      "Epoch 6431/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1394222031.6556 - val_loss: 4076533074.1187\n",
      "Epoch 6432/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1388713986.0039 - val_loss: 4043751280.3653\n",
      "Epoch 6433/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1390273263.7182 - val_loss: 4040957951.5616\n",
      "Epoch 6434/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1389874858.3327 - val_loss: 4039194985.4977\n",
      "Epoch 6435/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1391635896.8611 - val_loss: 4067392645.9909\n",
      "Epoch 6436/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1392483705.2368 - val_loss: 4036929984.2922\n",
      "Epoch 6437/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1390097762.3170 - val_loss: 4045071370.5205\n",
      "Epoch 6438/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1389417963.9609 - val_loss: 4053401347.0685\n",
      "Epoch 6439/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1390574597.6360 - val_loss: 4052207225.1324\n",
      "Epoch 6440/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1389712125.9961 - val_loss: 4051856782.1735\n",
      "Epoch 6441/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1389570801.9726 - val_loss: 4051468928.2922\n",
      "Epoch 6442/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1394480865.9413 - val_loss: 4040952246.0639\n",
      "Epoch 6443/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1390488023.9217 - val_loss: 4052883652.3836\n",
      "Epoch 6444/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1391732136.8297 - val_loss: 4058837365.7717\n",
      "Epoch 6445/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1389750214.2622 - val_loss: 4042253278.5388\n",
      "Epoch 6446/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1390105836.8376 - val_loss: 4050902263.0868\n",
      "Epoch 6447/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1389195058.3483 - val_loss: 4042241010.1187\n",
      "Epoch 6448/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1389221607.4521 - val_loss: 4049880640.7306\n",
      "Epoch 6449/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1391452070.8258 - val_loss: 4049312965.6986\n",
      "Epoch 6450/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1391944172.2114 - val_loss: 4033087724.5662\n",
      "Epoch 6451/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1390224914.9119 - val_loss: 4063099017.4977\n",
      "Epoch 6452/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1389873855.6243 - val_loss: 4054399671.3790\n",
      "Epoch 6453/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1389592385.1272 - val_loss: 4049581130.0822\n",
      "Epoch 6454/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1389373003.6477 - val_loss: 4046812808.3288\n",
      "Epoch 6455/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1391601645.8395 - val_loss: 4046119537.6804\n",
      "Epoch 6456/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1390086075.1155 - val_loss: 4038047271.7443\n",
      "Epoch 6457/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1390003226.5519 - val_loss: 4048719811.9452\n",
      "Epoch 6458/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1390214570.3327 - val_loss: 4047265737.7900\n",
      "Epoch 6459/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1390122100.7280 - val_loss: 4054179008.0000\n",
      "Epoch 6460/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1390544932.8219 - val_loss: 4045631736.2557\n",
      "Epoch 6461/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1389981199.0294 - val_loss: 4058328646.5753\n",
      "Epoch 6462/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1389824998.4501 - val_loss: 4050800043.3973\n",
      "Epoch 6463/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1389619375.2172 - val_loss: 4051070312.7671\n",
      "Epoch 6464/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1389886185.4560 - val_loss: 4050196536.5479\n",
      "Epoch 6465/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1390556416.8767 - val_loss: 4055796277.9178\n",
      "Epoch 6466/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1392077151.6869 - val_loss: 4030426985.2055\n",
      "Epoch 6467/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1389148520.8297 - val_loss: 4045934831.0502\n",
      "Epoch 6468/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1389937328.0939 - val_loss: 4049277251.7991\n",
      "Epoch 6469/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1389193559.0450 - val_loss: 4046786610.8493\n",
      "Epoch 6470/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1390290913.6908 - val_loss: 4047294628.3836\n",
      "Epoch 6471/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1390968347.3033 - val_loss: 4059269465.7169\n",
      "Epoch 6472/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1389413312.3757 - val_loss: 4042231706.4475\n",
      "Epoch 6473/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1390657970.8493 - val_loss: 4059030013.9543\n",
      "Epoch 6474/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1390711259.6791 - val_loss: 4046450687.7078\n",
      "Epoch 6475/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1389930594.4423 - val_loss: 4047445958.8676\n",
      "Epoch 6476/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1390504040.8924 - val_loss: 4043735569.0959\n",
      "Epoch 6477/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1389113716.4775 - val_loss: 4046785430.2100\n",
      "Epoch 6478/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1389717259.8982 - val_loss: 4046840673.1689\n",
      "Epoch 6479/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1391759436.5245 - val_loss: 4073520225.4612\n",
      "Epoch 6480/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 49us/step - loss: 1390012623.1546 - val_loss: 4058500758.6484\n",
      "Epoch 6481/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1389018375.7652 - val_loss: 4054007455.4155\n",
      "Epoch 6482/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1390197212.9315 - val_loss: 4037012974.0274\n",
      "Epoch 6483/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1392588908.9628 - val_loss: 4064401481.9361\n",
      "Epoch 6484/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1388816667.4286 - val_loss: 4040519996.0548\n",
      "Epoch 6485/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1389695666.7241 - val_loss: 4044184142.3196\n",
      "Epoch 6486/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1390795117.4638 - val_loss: 4039071212.2740\n",
      "Epoch 6487/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1389430416.7828 - val_loss: 4051380659.5799\n",
      "Epoch 6488/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1390818335.5616 - val_loss: 4053221057.3151\n",
      "Epoch 6489/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1389929197.8395 - val_loss: 4043642566.1370\n",
      "Epoch 6490/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1389280939.3346 - val_loss: 4041442583.2329\n",
      "Epoch 6491/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1389488443.8669 - val_loss: 4046695647.2694\n",
      "Epoch 6492/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1389064343.0450 - val_loss: 4048304369.3881\n",
      "Epoch 6493/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1390454134.2309 - val_loss: 4047081607.8904\n",
      "Epoch 6494/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1392223279.4677 - val_loss: 4051577042.8493\n",
      "Epoch 6495/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1389538922.7084 - val_loss: 4042678466.9224\n",
      "Epoch 6496/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1389874029.2133 - val_loss: 4048119091.7260\n",
      "Epoch 6497/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1389797731.0059 - val_loss: 4057660354.4840\n",
      "Epoch 6498/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1391625586.2231 - val_loss: 4037589512.0365\n",
      "Epoch 6499/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1390169383.3268 - val_loss: 4059634496.0000\n",
      "Epoch 6500/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1392330749.8708 - val_loss: 4046608492.2740\n",
      "Epoch 6501/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1388707548.6810 - val_loss: 4057438936.1096\n",
      "Epoch 6502/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1390226836.7906 - val_loss: 4069843098.0091\n",
      "Epoch 6503/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1389633700.3209 - val_loss: 4035409062.8676\n",
      "Epoch 6504/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1388496706.2544 - val_loss: 4050520003.9452\n",
      "Epoch 6505/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1390569480.5166 - val_loss: 4063859960.6941\n",
      "Epoch 6506/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1389032562.5988 - val_loss: 4047509878.6484\n",
      "Epoch 6507/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1388885294.7162 - val_loss: 4044193969.3881\n",
      "Epoch 6508/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1389981428.9785 - val_loss: 4047899550.1005\n",
      "Epoch 6509/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1389823732.7280 - val_loss: 4055071249.3881\n",
      "Epoch 6510/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1390610047.3738 - val_loss: 4045968477.3699\n",
      "Epoch 6511/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1392521374.3092 - val_loss: 4041703863.8174\n",
      "Epoch 6512/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1389659980.1487 - val_loss: 4063365818.5936\n",
      "Epoch 6513/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1390524073.7065 - val_loss: 4062319795.4338\n",
      "Epoch 6514/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1389244518.0744 - val_loss: 4049691560.7671\n",
      "Epoch 6515/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1389069977.4247 - val_loss: 4050417403.9087\n",
      "Epoch 6516/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1389555578.9902 - val_loss: 4059073306.7397\n",
      "Epoch 6517/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1390053697.6282 - val_loss: 4058318304.5845\n",
      "Epoch 6518/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1389528627.6008 - val_loss: 4047087662.4658\n",
      "Epoch 6519/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1390178884.8845 - val_loss: 4049436619.2511\n",
      "Epoch 6520/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1389380942.6536 - val_loss: 4046546060.7123\n",
      "Epoch 6521/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1390605837.7769 - val_loss: 4034851415.3790\n",
      "Epoch 6522/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1389828524.3366 - val_loss: 4046558671.4886\n",
      "Epoch 6523/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1389113583.9687 - val_loss: 4060279882.3744\n",
      "Epoch 6524/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1391276686.2779 - val_loss: 4063235702.7945\n",
      "Epoch 6525/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1388884725.6047 - val_loss: 4038727529.4977\n",
      "Epoch 6526/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1388602940.8689 - val_loss: 4050015859.1416\n",
      "Epoch 6527/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1391579038.8102 - val_loss: 4072237175.9635\n",
      "Epoch 6528/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1389072245.7299 - val_loss: 4041722962.9954\n",
      "Epoch 6529/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1391976926.9354 - val_loss: 4039822954.6667\n",
      "Epoch 6530/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1389465551.4051 - val_loss: 4046087465.7900\n",
      "Epoch 6531/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1389851544.5479 - val_loss: 4059220891.9087\n",
      "Epoch 6532/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1389331789.1507 - val_loss: 4054006978.7763\n",
      "Epoch 6533/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1390105589.7299 - val_loss: 4040902729.4977\n",
      "Epoch 6534/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1389974445.2133 - val_loss: 4057002769.9726\n",
      "Epoch 6535/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1388970202.9276 - val_loss: 4051723461.8447\n",
      "Epoch 6536/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1388795442.8493 - val_loss: 4061424675.5068\n",
      "Epoch 6537/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1389940706.4423 - val_loss: 4038266562.3379\n",
      "Epoch 6538/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1389618155.2094 - val_loss: 4069816226.0457\n",
      "Epoch 6539/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1390018919.4521 - val_loss: 4055417661.0776\n",
      "Epoch 6540/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1390069803.0215 - val_loss: 4045501462.9406\n",
      "Epoch 6541/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1389331858.7867 - val_loss: 4066226238.2466\n",
      "Epoch 6542/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1389775682.7554 - val_loss: 4058091257.2785\n",
      "Epoch 6543/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1389867313.8474 - val_loss: 4033537418.3744\n",
      "Epoch 6544/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 40us/step - loss: 1388956400.9706 - val_loss: 4048898781.2237\n",
      "Epoch 6545/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1388346996.4775 - val_loss: 4054149303.0868\n",
      "Epoch 6546/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1389143486.8728 - val_loss: 4061829574.1370\n",
      "Epoch 6547/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1389281241.9256 - val_loss: 4056129651.7260\n",
      "Epoch 6548/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1389100979.3503 - val_loss: 4063105819.3242\n",
      "Epoch 6549/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1389823737.4873 - val_loss: 4041994648.6941\n",
      "Epoch 6550/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1389027899.1155 - val_loss: 4048351996.9315\n",
      "Epoch 6551/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1390592705.7534 - val_loss: 4061405211.4703\n",
      "Epoch 6552/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1389343414.6067 - val_loss: 4045286744.4018\n",
      "Epoch 6553/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1390262138.9902 - val_loss: 4051371348.6027\n",
      "Epoch 6554/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1388658003.6008 - val_loss: 4058952581.8447\n",
      "Epoch 6555/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1388660459.3346 - val_loss: 4049658976.2922\n",
      "Epoch 6556/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1390197818.2387 - val_loss: 4055923293.9543\n",
      "Epoch 6557/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1390951469.2133 - val_loss: 4038675399.5982\n",
      "Epoch 6558/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1389269303.8591 - val_loss: 4047728872.3288\n",
      "Epoch 6559/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1388899205.7613 - val_loss: 4061856090.7397\n",
      "Epoch 6560/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1389041865.0176 - val_loss: 4050051473.3881\n",
      "Epoch 6561/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1390496782.1526 - val_loss: 4045447084.5662\n",
      "Epoch 6562/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1388950861.6517 - val_loss: 4048896175.7808\n",
      "Epoch 6563/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1388601774.3405 - val_loss: 4054557775.7808\n",
      "Epoch 6564/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1388429914.0509 - val_loss: 4054382923.9817\n",
      "Epoch 6565/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1390061442.5049 - val_loss: 4069278199.3790\n",
      "Epoch 6566/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1389997668.1957 - val_loss: 4037224315.1781\n",
      "Epoch 6567/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1389444747.8982 - val_loss: 4060071333.4064\n",
      "Epoch 6568/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1388743929.2368 - val_loss: 4052479257.7169\n",
      "Epoch 6569/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1389131275.7730 - val_loss: 4045825377.8995\n",
      "Epoch 6570/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1389507651.8826 - val_loss: 4049801264.3653\n",
      "Epoch 6571/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1389315267.6321 - val_loss: 4067084624.8037\n",
      "Epoch 6572/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1389432068.5088 - val_loss: 4046480555.3973\n",
      "Epoch 6573/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1390033034.0196 - val_loss: 4065003606.9406\n",
      "Epoch 6574/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1389033408.8767 - val_loss: 4044833598.8311\n",
      "Epoch 6575/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1388827226.9902 - val_loss: 4055313660.6393\n",
      "Epoch 6576/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1389082730.8337 - val_loss: 4052437596.3470\n",
      "Epoch 6577/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1389485173.7299 - val_loss: 4041210949.8447\n",
      "Epoch 6578/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1389198080.0939 - val_loss: 4053975207.1598\n",
      "Epoch 6579/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1388894647.7339 - val_loss: 4068164817.5342\n",
      "Epoch 6580/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1389022724.5088 - val_loss: 4041883457.4612\n",
      "Epoch 6581/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1391277089.8160 - val_loss: 4058258727.8904\n",
      "Epoch 6582/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1389733497.7378 - val_loss: 4040236940.7123\n",
      "Epoch 6583/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1387919227.3659 - val_loss: 4056493679.3425\n",
      "Epoch 6584/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1390262701.8395 - val_loss: 4068239279.9269\n",
      "Epoch 6585/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1388797795.0685 - val_loss: 4047246399.7078\n",
      "Epoch 6586/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1387791702.9198 - val_loss: 4054900861.5160\n",
      "Epoch 6587/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1388297059.4442 - val_loss: 4052889928.7671\n",
      "Epoch 6588/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1388465833.0802 - val_loss: 4054135604.1644\n",
      "Epoch 6589/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1388840098.0665 - val_loss: 4050271744.7306\n",
      "Epoch 6590/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1389005065.7691 - val_loss: 4051349768.7671\n",
      "Epoch 6591/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1389378022.1996 - val_loss: 4061427408.9498\n",
      "Epoch 6592/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1388758818.3170 - val_loss: 4057828650.8128\n",
      "Epoch 6593/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1390965354.2074 - val_loss: 4041055342.7580\n",
      "Epoch 6594/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1388351657.3307 - val_loss: 4047286222.1735\n",
      "Epoch 6595/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1388684515.0685 - val_loss: 4048098551.8174\n",
      "Epoch 6596/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1388339341.7769 - val_loss: 4059308990.8311\n",
      "Epoch 6597/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1389651379.0998 - val_loss: 4046752492.7123\n",
      "Epoch 6598/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1390222824.7045 - val_loss: 4049486206.8311\n",
      "Epoch 6599/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1388325931.3346 - val_loss: 4051605765.9909\n",
      "Epoch 6600/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1390167555.0059 - val_loss: 4050896957.2237\n",
      "Epoch 6601/10000\n",
      "1022/1022 [==============================] - 0s 63us/step - loss: 1392331996.5558 - val_loss: 4074640229.6986\n",
      "Epoch 6602/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1387594383.7808 - val_loss: 4047338377.9361\n",
      "Epoch 6603/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1389132983.6086 - val_loss: 4049085873.2420\n",
      "Epoch 6604/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1388840475.9295 - val_loss: 4043809435.7626\n",
      "Epoch 6605/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1389664342.6693 - val_loss: 4061536363.6895\n",
      "Epoch 6606/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1388407372.5245 - val_loss: 4047296352.0000\n",
      "Epoch 6607/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1390537174.4188 - val_loss: 4037227887.4886\n",
      "Epoch 6608/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 51us/step - loss: 1387715696.0939 - val_loss: 4051815800.8402\n",
      "Epoch 6609/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1389403035.6791 - val_loss: 4066344869.9909\n",
      "Epoch 6610/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1388604997.6360 - val_loss: 4045752352.2922\n",
      "Epoch 6611/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1390751297.8787 - val_loss: 4061941639.7443\n",
      "Epoch 6612/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1388422819.6947 - val_loss: 4060063758.0274\n",
      "Epoch 6613/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1388726819.6947 - val_loss: 4047259634.2648\n",
      "Epoch 6614/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1388951758.9041 - val_loss: 4049512358.2831\n",
      "Epoch 6615/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1388721749.0411 - val_loss: 4054701856.1461\n",
      "Epoch 6616/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1387748669.3699 - val_loss: 4060548908.8584\n",
      "Epoch 6617/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1388659082.5205 - val_loss: 4054193405.8082\n",
      "Epoch 6618/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1388731077.8865 - val_loss: 4052155283.8721\n",
      "Epoch 6619/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1388448981.4168 - val_loss: 4056729912.8402\n",
      "Epoch 6620/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1388292836.3209 - val_loss: 4055489151.8539\n",
      "Epoch 6621/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1388296934.8258 - val_loss: 4051242477.8813\n",
      "Epoch 6622/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1389116957.5577 - val_loss: 4062948595.4338\n",
      "Epoch 6623/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1390214744.6732 - val_loss: 4044564156.3470\n",
      "Epoch 6624/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1388583864.2348 - val_loss: 4051253227.5434\n",
      "Epoch 6625/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1389519525.6986 - val_loss: 4052990953.4977\n",
      "Epoch 6626/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1388252653.3386 - val_loss: 4059707879.1598\n",
      "Epoch 6627/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1388554161.9726 - val_loss: 4054792117.3333\n",
      "Epoch 6628/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1388929244.5558 - val_loss: 4061579362.9224\n",
      "Epoch 6629/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1387872645.3855 - val_loss: 4049997222.1370\n",
      "Epoch 6630/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1389855402.2074 - val_loss: 4065369934.3196\n",
      "Epoch 6631/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1390114836.2896 - val_loss: 4049011946.0822\n",
      "Epoch 6632/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1392025259.5851 - val_loss: 4069309267.7260\n",
      "Epoch 6633/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1388500088.4853 - val_loss: 4048263116.5662\n",
      "Epoch 6634/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1389047184.5323 - val_loss: 4049141394.7032\n",
      "Epoch 6635/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1389469079.1703 - val_loss: 4057994514.8493\n",
      "Epoch 6636/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1388771500.7123 - val_loss: 4065374160.3653\n",
      "Epoch 6637/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1389210849.9413 - val_loss: 4048148543.7078\n",
      "Epoch 6638/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1388116423.1389 - val_loss: 4046744785.2420\n",
      "Epoch 6639/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1390807817.1429 - val_loss: 4069497029.4064\n",
      "Epoch 6640/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1388886780.5558 - val_loss: 4045808674.4840\n",
      "Epoch 6641/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1388007142.7006 - val_loss: 4054741776.3653\n",
      "Epoch 6642/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1389640983.6712 - val_loss: 4055937357.0046\n",
      "Epoch 6643/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1388976507.6164 - val_loss: 4043793884.2009\n",
      "Epoch 6644/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1389274515.4129 - val_loss: 4058876918.7945\n",
      "Epoch 6645/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1388666443.1468 - val_loss: 4063396647.1598\n",
      "Epoch 6646/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1388740503.4207 - val_loss: 4059288193.3151\n",
      "Epoch 6647/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1388047452.9315 - val_loss: 4057650878.5388\n",
      "Epoch 6648/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1388565679.0920 - val_loss: 4044085365.3333\n",
      "Epoch 6649/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1387733211.3033 - val_loss: 4057182304.8767\n",
      "Epoch 6650/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1388302699.5851 - val_loss: 4057080390.5753\n",
      "Epoch 6651/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1387580356.1331 - val_loss: 4058695104.4384\n",
      "Epoch 6652/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1389858622.9980 - val_loss: 4073949820.2009\n",
      "Epoch 6653/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1388231792.4697 - val_loss: 4054350131.5799\n",
      "Epoch 6654/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1389843941.4481 - val_loss: 4071278172.0548\n",
      "Epoch 6655/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1388469321.3933 - val_loss: 4040189820.2009\n",
      "Epoch 6656/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1387842504.1409 - val_loss: 4059229620.3105\n",
      "Epoch 6657/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1389326676.4149 - val_loss: 4061687650.6301\n",
      "Epoch 6658/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1388325083.6791 - val_loss: 4048235351.3790\n",
      "Epoch 6659/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1389506799.4677 - val_loss: 4047075123.1416\n",
      "Epoch 6660/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1389649602.8806 - val_loss: 4062384688.2192\n",
      "Epoch 6661/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1388723793.6595 - val_loss: 4053855958.0639\n",
      "Epoch 6662/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1387800965.7613 - val_loss: 4063986184.4749\n",
      "Epoch 6663/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1387739728.9080 - val_loss: 4061699715.6530\n",
      "Epoch 6664/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1388044575.5616 - val_loss: 4051085965.4429\n",
      "Epoch 6665/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1389135406.5910 - val_loss: 4049154720.0000\n",
      "Epoch 6666/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1387955655.6399 - val_loss: 4065610676.8950\n",
      "Epoch 6667/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1390130123.1468 - val_loss: 4060683048.0365\n",
      "Epoch 6668/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1388692299.6477 - val_loss: 4054603066.8858\n",
      "Epoch 6669/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1389774549.6673 - val_loss: 4053371624.6210\n",
      "Epoch 6670/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1388804608.7515 - val_loss: 4058096915.8721\n",
      "Epoch 6671/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1389531854.6536 - val_loss: 4068473235.8721\n",
      "Epoch 6672/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 40us/step - loss: 1388117967.5303 - val_loss: 4059168226.6301\n",
      "Epoch 6673/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1388694554.0509 - val_loss: 4051298952.1826\n",
      "Epoch 6674/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1387970135.8591 - val_loss: 4059102461.8082\n",
      "Epoch 6675/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1387523311.2172 - val_loss: 4060562474.5205\n",
      "Epoch 6676/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1388552896.5010 - val_loss: 4050276730.7397\n",
      "Epoch 6677/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1387220720.7202 - val_loss: 4061377273.5708\n",
      "Epoch 6678/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1389420931.7573 - val_loss: 4048135336.1826\n",
      "Epoch 6679/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1388220363.7730 - val_loss: 4052993763.9452\n",
      "Epoch 6680/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1392911787.3346 - val_loss: 4060237325.2968\n",
      "Epoch 6681/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1388129101.4012 - val_loss: 4046436642.4840\n",
      "Epoch 6682/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1387584293.3229 - val_loss: 4048628110.9041\n",
      "Epoch 6683/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1388817848.6106 - val_loss: 4056051768.2557\n",
      "Epoch 6684/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1389147390.8728 - val_loss: 4073094668.7123\n",
      "Epoch 6685/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1388411200.6262 - val_loss: 4062349492.6027\n",
      "Epoch 6686/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1387704782.9041 - val_loss: 4052914029.8813\n",
      "Epoch 6687/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1388056881.9726 - val_loss: 4059704229.6986\n",
      "Epoch 6688/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1388190753.5656 - val_loss: 4042447850.0822\n",
      "Epoch 6689/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1389727341.7143 - val_loss: 4069040647.7443\n",
      "Epoch 6690/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1390794296.3601 - val_loss: 4042367905.7534\n",
      "Epoch 6691/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1387199457.9413 - val_loss: 4062572229.9909\n",
      "Epoch 6692/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1388692183.1703 - val_loss: 4064774413.8813\n",
      "Epoch 6693/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1387596889.1742 - val_loss: 4058716436.0183\n",
      "Epoch 6694/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1389110630.7006 - val_loss: 4053642926.4658\n",
      "Epoch 6695/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1387429848.6732 - val_loss: 4063060507.1781\n",
      "Epoch 6696/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1389970557.3699 - val_loss: 4048039971.6530\n",
      "Epoch 6697/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1391952648.0157 - val_loss: 4075019442.4110\n",
      "Epoch 6698/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1387949916.8063 - val_loss: 4044643020.7123\n",
      "Epoch 6699/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1388017517.9648 - val_loss: 4054797372.4932\n",
      "Epoch 6700/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1387709262.6536 - val_loss: 4050445508.6758\n",
      "Epoch 6701/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1389841417.0176 - val_loss: 4074240985.8630\n",
      "Epoch 6702/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1386655125.4168 - val_loss: 4050829656.1096\n",
      "Epoch 6703/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1388232077.5264 - val_loss: 4055565675.8356\n",
      "Epoch 6704/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1388222703.4677 - val_loss: 4046218192.9498\n",
      "Epoch 6705/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1389224715.5225 - val_loss: 4072526646.9406\n",
      "Epoch 6706/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1387353907.2250 - val_loss: 4051543652.9680\n",
      "Epoch 6707/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1388082519.9217 - val_loss: 4041532082.2648\n",
      "Epoch 6708/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1387541429.2290 - val_loss: 4060705110.9406\n",
      "Epoch 6709/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1387588275.2250 - val_loss: 4063141778.8493\n",
      "Epoch 6710/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1387957369.2368 - val_loss: 4051493085.6621\n",
      "Epoch 6711/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1387420302.7789 - val_loss: 4056288959.2694\n",
      "Epoch 6712/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1391290268.5558 - val_loss: 4073428298.0822\n",
      "Epoch 6713/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1387487902.9354 - val_loss: 4052422356.3105\n",
      "Epoch 6714/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1389061223.4521 - val_loss: 4049790238.2466\n",
      "Epoch 6715/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1389200997.3229 - val_loss: 4050502305.4612\n",
      "Epoch 6716/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1388604001.0646 - val_loss: 4054800738.3379\n",
      "Epoch 6717/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1388209999.1546 - val_loss: 4056935070.2466\n",
      "Epoch 6718/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1388103393.6908 - val_loss: 4048780265.0594\n",
      "Epoch 6719/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1388017343.6869 - val_loss: 4068065118.1005\n",
      "Epoch 6720/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1387009046.2935 - val_loss: 4059505242.3014\n",
      "Epoch 6721/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1388362132.0391 - val_loss: 4050992238.6119\n",
      "Epoch 6722/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1387464957.3072 - val_loss: 4067599181.1507\n",
      "Epoch 6723/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1387523382.6067 - val_loss: 4063830823.4521\n",
      "Epoch 6724/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1387983858.7241 - val_loss: 4047705859.3607\n",
      "Epoch 6725/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1387770315.1468 - val_loss: 4065956223.8539\n",
      "Epoch 6726/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1387065169.5342 - val_loss: 4059919980.4201\n",
      "Epoch 6727/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1388434851.5695 - val_loss: 4071956859.3242\n",
      "Epoch 6728/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1387360114.0978 - val_loss: 4048241486.0274\n",
      "Epoch 6729/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1387715666.1605 - val_loss: 4057064521.4977\n",
      "Epoch 6730/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1388980239.2798 - val_loss: 4054094220.1279\n",
      "Epoch 6731/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1387654952.8297 - val_loss: 4045115480.2557\n",
      "Epoch 6732/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1387698935.9843 - val_loss: 4056899552.0000\n",
      "Epoch 6733/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1388695614.6223 - val_loss: 4066839205.2603\n",
      "Epoch 6734/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1389780376.7984 - val_loss: 4043398195.8721\n",
      "Epoch 6735/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1387094799.7808 - val_loss: 4058549281.7534\n",
      "Epoch 6736/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 48us/step - loss: 1387471065.4247 - val_loss: 4069507653.5525\n",
      "Epoch 6737/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1389095635.6634 - val_loss: 4066510838.6484\n",
      "Epoch 6738/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1386737065.5812 - val_loss: 4056826160.5114\n",
      "Epoch 6739/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1389105303.6712 - val_loss: 4067865537.3151\n",
      "Epoch 6740/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1387102108.3053 - val_loss: 4042155036.6393\n",
      "Epoch 6741/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1387788589.2133 - val_loss: 4055590143.8539\n",
      "Epoch 6742/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1387619565.9648 - val_loss: 4056762525.3699\n",
      "Epoch 6743/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1387780868.1331 - val_loss: 4062993460.3105\n",
      "Epoch 6744/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1387412911.8434 - val_loss: 4064367747.9452\n",
      "Epoch 6745/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1387189014.0431 - val_loss: 4064243131.9087\n",
      "Epoch 6746/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1388019197.4951 - val_loss: 4052666289.5342\n",
      "Epoch 6747/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1387622596.3836 - val_loss: 4060987886.4658\n",
      "Epoch 6748/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1387397932.3992 - val_loss: 4055516214.3562\n",
      "Epoch 6749/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1387405892.6341 - val_loss: 4066361863.0137\n",
      "Epoch 6750/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1387388930.3796 - val_loss: 4065580135.7443\n",
      "Epoch 6751/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1387505895.0763 - val_loss: 4043376641.6073\n",
      "Epoch 6752/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1387881824.0626 - val_loss: 4051292923.7626\n",
      "Epoch 6753/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1387863050.1448 - val_loss: 4059702781.9543\n",
      "Epoch 6754/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1387125163.0841 - val_loss: 4062975319.2329\n",
      "Epoch 6755/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1387354618.4892 - val_loss: 4057560449.0228\n",
      "Epoch 6756/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1387787734.2935 - val_loss: 4053307531.8356\n",
      "Epoch 6757/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1387353715.7260 - val_loss: 4065058241.6073\n",
      "Epoch 6758/10000\n",
      "1022/1022 [==============================] - 0s 77us/step - loss: 1388682994.9746 - val_loss: 4064126607.4886\n",
      "Epoch 6759/10000\n",
      "1022/1022 [==============================] - 0s 90us/step - loss: 1388077853.0568 - val_loss: 4068820482.6301\n",
      "Epoch 6760/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1389371850.7710 - val_loss: 4053526400.7306\n",
      "Epoch 6761/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1387596015.2172 - val_loss: 4050072801.0228\n",
      "Epoch 6762/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1387316322.6928 - val_loss: 4055381639.1598\n",
      "Epoch 6763/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1388652462.0900 - val_loss: 4074205966.0274\n",
      "Epoch 6764/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1387577907.0998 - val_loss: 4058204391.8904\n",
      "Epoch 6765/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1387277443.0059 - val_loss: 4059370878.9772\n",
      "Epoch 6766/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1387292481.9413 - val_loss: 4059003197.5160\n",
      "Epoch 6767/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1388003380.1018 - val_loss: 4071066150.5753\n",
      "Epoch 6768/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1386845050.4892 - val_loss: 4060543015.0137\n",
      "Epoch 6769/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1388477617.0959 - val_loss: 4071711614.3927\n",
      "Epoch 6770/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1390423094.3562 - val_loss: 4055240792.4018\n",
      "Epoch 6771/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1386847027.0998 - val_loss: 4054609081.5708\n",
      "Epoch 6772/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1387690309.1350 - val_loss: 4066126217.4977\n",
      "Epoch 6773/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1387033103.9061 - val_loss: 4057465323.5434\n",
      "Epoch 6774/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1386909833.7691 - val_loss: 4063872767.7078\n",
      "Epoch 6775/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1387506344.5793 - val_loss: 4057940636.9315\n",
      "Epoch 6776/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1387823337.7065 - val_loss: 4048595488.1461\n",
      "Epoch 6777/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1388868913.8474 - val_loss: 4072484918.2100\n",
      "Epoch 6778/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1386710974.1213 - val_loss: 4064740437.1872\n",
      "Epoch 6779/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1387386021.3229 - val_loss: 4043232512.1461\n",
      "Epoch 6780/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1387134561.9413 - val_loss: 4058732489.0594\n",
      "Epoch 6781/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1386612122.1761 - val_loss: 4057843422.5388\n",
      "Epoch 6782/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1387654925.5264 - val_loss: 4071133821.2237\n",
      "Epoch 6783/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1388030101.1037 - val_loss: 4059461741.4429\n",
      "Epoch 6784/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1388400427.9609 - val_loss: 4058007183.6347\n",
      "Epoch 6785/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1387716586.4579 - val_loss: 4070563863.0868\n",
      "Epoch 6786/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1391117602.3170 - val_loss: 4056377939.2877\n",
      "Epoch 6787/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1387893413.6986 - val_loss: 4056763678.8311\n",
      "Epoch 6788/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1390057233.5342 - val_loss: 4077748962.3379\n",
      "Epoch 6789/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1386388493.1507 - val_loss: 4049924681.4977\n",
      "Epoch 6790/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1387519794.8493 - val_loss: 4058421954.7763\n",
      "Epoch 6791/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1386693533.3072 - val_loss: 4054223045.9909\n",
      "Epoch 6792/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1389003510.8571 - val_loss: 4050573710.1735\n",
      "Epoch 6793/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1388564609.0020 - val_loss: 4063062110.8311\n",
      "Epoch 6794/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1387303524.1957 - val_loss: 4048170390.7945\n",
      "Epoch 6795/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1391149372.1174 - val_loss: 4068304757.1872\n",
      "Epoch 6796/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1387626601.0802 - val_loss: 4046801027.6530\n",
      "Epoch 6797/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1387950469.0098 - val_loss: 4049194794.2283\n",
      "Epoch 6798/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1386767599.3425 - val_loss: 4054838462.1005\n",
      "Epoch 6799/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1387747817.9569 - val_loss: 4074586954.2283\n",
      "Epoch 6800/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 47us/step - loss: 1387427300.1957 - val_loss: 4065265990.4292\n",
      "Epoch 6801/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1386389224.2035 - val_loss: 4057041574.4292\n",
      "Epoch 6802/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1386731048.9550 - val_loss: 4057940600.2557\n",
      "Epoch 6803/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1390195528.3914 - val_loss: 4033510653.8082\n",
      "Epoch 6804/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1390236545.8787 - val_loss: 4078883405.5890\n",
      "Epoch 6805/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1388182891.4599 - val_loss: 4046472751.4886\n",
      "Epoch 6806/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1387547779.0059 - val_loss: 4059126406.4292\n",
      "Epoch 6807/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1387261976.6732 - val_loss: 4064341261.2968\n",
      "Epoch 6808/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1387608593.7847 - val_loss: 4070733871.9269\n",
      "Epoch 6809/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1389178988.7123 - val_loss: 4065097788.2009\n",
      "Epoch 6810/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1390795642.2387 - val_loss: 4038139510.6484\n",
      "Epoch 6811/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1388326224.5323 - val_loss: 4058387750.7215\n",
      "Epoch 6812/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1386729019.6164 - val_loss: 4054837120.0000\n",
      "Epoch 6813/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1388334002.8493 - val_loss: 4064627792.5114\n",
      "Epoch 6814/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1386798033.4090 - val_loss: 4056629508.8219\n",
      "Epoch 6815/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1386954708.4149 - val_loss: 4052235543.8174\n",
      "Epoch 6816/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1387624499.8513 - val_loss: 4061294269.9543\n",
      "Epoch 6817/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1387922540.7123 - val_loss: 4047037684.6027\n",
      "Epoch 6818/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1387663228.9941 - val_loss: 4061766914.7763\n",
      "Epoch 6819/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1391661845.0411 - val_loss: 4047827183.9269\n",
      "Epoch 6820/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1386469587.1624 - val_loss: 4073550197.7717\n",
      "Epoch 6821/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1386706303.2485 - val_loss: 4067873061.2603\n",
      "Epoch 6822/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1387460364.3992 - val_loss: 4061166168.4018\n",
      "Epoch 6823/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1390673586.5988 - val_loss: 4046200189.8082\n",
      "Epoch 6824/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1389021072.2818 - val_loss: 4071711333.5525\n",
      "Epoch 6825/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1386880735.6869 - val_loss: 4059647022.3196\n",
      "Epoch 6826/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1386458930.0978 - val_loss: 4054788738.3379\n",
      "Epoch 6827/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1390815385.8004 - val_loss: 4080034580.4566\n",
      "Epoch 6828/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1387550192.2192 - val_loss: 4046730720.1461\n",
      "Epoch 6829/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1386626422.2309 - val_loss: 4056695786.0822\n",
      "Epoch 6830/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1386980159.8748 - val_loss: 4062063608.5479\n",
      "Epoch 6831/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1386977582.0900 - val_loss: 4050282854.8676\n",
      "Epoch 6832/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1386817381.6986 - val_loss: 4058878822.7215\n",
      "Epoch 6833/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1388814215.0137 - val_loss: 4059894349.4429\n",
      "Epoch 6834/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1387256198.1370 - val_loss: 4058840887.5251\n",
      "Epoch 6835/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1386441241.0489 - val_loss: 4057089647.6347\n",
      "Epoch 6836/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1387509745.4716 - val_loss: 4047654866.8493\n",
      "Epoch 6837/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1388399339.4599 - val_loss: 4076148416.7306\n",
      "Epoch 6838/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1389148046.1526 - val_loss: 4051149062.1370\n",
      "Epoch 6839/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1389003815.3268 - val_loss: 4061845900.2740\n",
      "Epoch 6840/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1387848102.5753 - val_loss: 4070439992.2557\n",
      "Epoch 6841/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1387816357.3229 - val_loss: 4061685704.1826\n",
      "Epoch 6842/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1387581020.6810 - val_loss: 4048923717.8447\n",
      "Epoch 6843/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1388231877.6360 - val_loss: 4055577224.7671\n",
      "Epoch 6844/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1386323036.6810 - val_loss: 4059481650.2648\n",
      "Epoch 6845/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1387912188.1174 - val_loss: 4074272481.6073\n",
      "Epoch 6846/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1389767649.1898 - val_loss: 4060131364.2374\n",
      "Epoch 6847/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1387628423.2642 - val_loss: 4056587081.4977\n",
      "Epoch 6848/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1386566249.3307 - val_loss: 4056982805.6256\n",
      "Epoch 6849/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1386978432.5010 - val_loss: 4059857522.8493\n",
      "Epoch 6850/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1387042518.1683 - val_loss: 4060164778.3744\n",
      "Epoch 6851/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1386852901.5734 - val_loss: 4069906622.2466\n",
      "Epoch 6852/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1387605247.3738 - val_loss: 4050862365.5160\n",
      "Epoch 6853/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1386898110.8728 - val_loss: 4063368934.4292\n",
      "Epoch 6854/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1386187971.5068 - val_loss: 4053448367.0502\n",
      "Epoch 6855/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1386740943.7808 - val_loss: 4053269393.0959\n",
      "Epoch 6856/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1387036271.9687 - val_loss: 4052928127.8539\n",
      "Epoch 6857/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1387349312.1252 - val_loss: 4073919685.5525\n",
      "Epoch 6858/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1388193488.9080 - val_loss: 4055611468.2740\n",
      "Epoch 6859/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1386492127.6869 - val_loss: 4065392259.3607\n",
      "Epoch 6860/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1387562133.5421 - val_loss: 4069934857.7900\n",
      "Epoch 6861/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1386631380.6654 - val_loss: 4046976598.7945\n",
      "Epoch 6862/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1386861583.0294 - val_loss: 4048759105.3151\n",
      "Epoch 6863/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1386331079.3894 - val_loss: 4064912483.5068\n",
      "Epoch 6864/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 46us/step - loss: 1387303579.3033 - val_loss: 4076018206.3927\n",
      "Epoch 6865/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1387200479.5616 - val_loss: 4052110158.1735\n",
      "Epoch 6866/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1386796869.1350 - val_loss: 4048180116.4566\n",
      "Epoch 6867/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1389770453.5421 - val_loss: 4055052175.6347\n",
      "Epoch 6868/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1389075075.2564 - val_loss: 4070567923.1416\n",
      "Epoch 6869/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1388274436.0078 - val_loss: 4040503683.9452\n",
      "Epoch 6870/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1387552981.7926 - val_loss: 4067381063.7443\n",
      "Epoch 6871/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1389072952.2348 - val_loss: 4057186206.1005\n",
      "Epoch 6872/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1387449207.7339 - val_loss: 4058977046.6484\n",
      "Epoch 6873/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1387625682.4110 - val_loss: 4060715116.5662\n",
      "Epoch 6874/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1388044117.4168 - val_loss: 4044105778.9954\n",
      "Epoch 6875/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1386412357.8865 - val_loss: 4059412186.3014\n",
      "Epoch 6876/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1386586037.8552 - val_loss: 4063257087.1233\n",
      "Epoch 6877/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1386295449.5499 - val_loss: 4064615348.0183\n",
      "Epoch 6878/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1386913952.3131 - val_loss: 4052260292.5297\n",
      "Epoch 6879/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1390048996.4462 - val_loss: 4078687557.4064\n",
      "Epoch 6880/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1385814986.3953 - val_loss: 4050399263.7078\n",
      "Epoch 6881/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1386646231.0450 - val_loss: 4055397556.4566\n",
      "Epoch 6882/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1388665637.5734 - val_loss: 4048632976.9498\n",
      "Epoch 6883/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1387511493.6360 - val_loss: 4081070225.3881\n",
      "Epoch 6884/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1385995715.8826 - val_loss: 4062096295.8904\n",
      "Epoch 6885/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1387535310.6536 - val_loss: 4048797251.2146\n",
      "Epoch 6886/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1386553123.0685 - val_loss: 4057301551.6347\n",
      "Epoch 6887/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1386335516.1800 - val_loss: 4054317403.6164\n",
      "Epoch 6888/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1390003306.9589 - val_loss: 4058475954.7032\n",
      "Epoch 6889/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1388211654.1370 - val_loss: 4038377440.7306\n",
      "Epoch 6890/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1385935871.7495 - val_loss: 4055761345.4612\n",
      "Epoch 6891/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1387035841.1272 - val_loss: 4060208031.4155\n",
      "Epoch 6892/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1386699814.7006 - val_loss: 4072858582.5023\n",
      "Epoch 6893/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1387068236.0235 - val_loss: 4053016791.8174\n",
      "Epoch 6894/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1388220394.9589 - val_loss: 4076601990.7215\n",
      "Epoch 6895/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1386798555.6791 - val_loss: 4057161501.8082\n",
      "Epoch 6896/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1385979748.9472 - val_loss: 4062565816.6941\n",
      "Epoch 6897/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1386949488.9706 - val_loss: 4056043931.7626\n",
      "Epoch 6898/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1386392230.0744 - val_loss: 4059233999.0502\n",
      "Epoch 6899/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1386456193.0020 - val_loss: 4057705012.6027\n",
      "Epoch 6900/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1386154446.9041 - val_loss: 4067240840.3288\n",
      "Epoch 6901/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1386530363.9295 - val_loss: 4061898780.7854\n",
      "Epoch 6902/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1387624089.0489 - val_loss: 4061089703.1598\n",
      "Epoch 6903/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1386722304.0000 - val_loss: 4063248654.1735\n",
      "Epoch 6904/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1386767563.8982 - val_loss: 4057355812.5297\n",
      "Epoch 6905/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1386806315.7104 - val_loss: 4059674569.4977\n",
      "Epoch 6906/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1386196466.2231 - val_loss: 4068881648.3653\n",
      "Epoch 6907/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1386513830.3249 - val_loss: 4067875920.2192\n",
      "Epoch 6908/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1387872397.2759 - val_loss: 4055620346.8858\n",
      "Epoch 6909/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1387612729.6125 - val_loss: 4058399978.2283\n",
      "Epoch 6910/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1387688044.9628 - val_loss: 4073731837.5160\n",
      "Epoch 6911/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1385464744.3288 - val_loss: 4060079407.9269\n",
      "Epoch 6912/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1386428596.3523 - val_loss: 4053632309.0411\n",
      "Epoch 6913/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1385919524.3209 - val_loss: 4054785318.4292\n",
      "Epoch 6914/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1386830181.1977 - val_loss: 4056698123.9817\n",
      "Epoch 6915/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1386583956.2896 - val_loss: 4051249307.7626\n",
      "Epoch 6916/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1386543122.5362 - val_loss: 4056014581.3333\n",
      "Epoch 6917/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1386011410.0352 - val_loss: 4060220636.7854\n",
      "Epoch 6918/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1386343539.7260 - val_loss: 4062476492.7123\n",
      "Epoch 6919/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1386864674.8180 - val_loss: 4062609318.2831\n",
      "Epoch 6920/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1388170587.6791 - val_loss: 4081385854.8311\n",
      "Epoch 6921/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1387099060.3523 - val_loss: 4063660265.9361\n",
      "Epoch 6922/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1385925865.7065 - val_loss: 4048432673.1689\n",
      "Epoch 6923/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1386400068.6341 - val_loss: 4065792258.6301\n",
      "Epoch 6924/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1386759360.1252 - val_loss: 4065407952.3653\n",
      "Epoch 6925/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1386815007.3112 - val_loss: 4055382448.0731\n",
      "Epoch 6926/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1386378224.5949 - val_loss: 4059959245.1507\n",
      "Epoch 6927/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1387696052.1018 - val_loss: 4075359310.7580\n",
      "Epoch 6928/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 53us/step - loss: 1386109002.8963 - val_loss: 4059670910.8311\n",
      "Epoch 6929/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1387501763.6321 - val_loss: 4061425089.1689\n",
      "Epoch 6930/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1387307194.3640 - val_loss: 4063273045.3333\n",
      "Epoch 6931/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1387095142.9511 - val_loss: 4045794542.3196\n",
      "Epoch 6932/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1388008863.8121 - val_loss: 4074763054.3196\n",
      "Epoch 6933/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1388576535.7965 - val_loss: 4047960915.7260\n",
      "Epoch 6934/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1387805235.9765 - val_loss: 4057804473.8630\n",
      "Epoch 6935/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1386346038.6067 - val_loss: 4060789269.6256\n",
      "Epoch 6936/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1386545344.6262 - val_loss: 4056869702.1370\n",
      "Epoch 6937/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1386707156.9159 - val_loss: 4057630155.1050\n",
      "Epoch 6938/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1387302944.3131 - val_loss: 4052007697.6804\n",
      "Epoch 6939/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1385804438.2935 - val_loss: 4057702719.2694\n",
      "Epoch 6940/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1388182478.9041 - val_loss: 4065896886.6484\n",
      "Epoch 6941/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1386439602.5988 - val_loss: 4061234761.6438\n",
      "Epoch 6942/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1386614595.3816 - val_loss: 4070831917.8813\n",
      "Epoch 6943/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1387984160.3131 - val_loss: 4078500988.7854\n",
      "Epoch 6944/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1385913102.2779 - val_loss: 4050485911.8174\n",
      "Epoch 6945/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1387007182.9041 - val_loss: 4055928393.6438\n",
      "Epoch 6946/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1386653460.0391 - val_loss: 4055780263.4521\n",
      "Epoch 6947/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1387018520.7984 - val_loss: 4058243959.6712\n",
      "Epoch 6948/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1386144290.8180 - val_loss: 4058234523.1781\n",
      "Epoch 6949/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1386589218.2544 - val_loss: 4059323704.5479\n",
      "Epoch 6950/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1386069888.8767 - val_loss: 4059060878.7580\n",
      "Epoch 6951/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1386138206.9354 - val_loss: 4062250455.5251\n",
      "Epoch 6952/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1386462443.0841 - val_loss: 4060269806.1735\n",
      "Epoch 6953/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1386647846.8258 - val_loss: 4051305492.4566\n",
      "Epoch 6954/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1386149757.9961 - val_loss: 4064619337.4977\n",
      "Epoch 6955/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1387300171.3973 - val_loss: 4059151609.1324\n",
      "Epoch 6956/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1387310660.8845 - val_loss: 4060464618.6667\n",
      "Epoch 6957/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1387337771.5851 - val_loss: 4044810998.5023\n",
      "Epoch 6958/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1386047978.2074 - val_loss: 4057650087.1598\n",
      "Epoch 6959/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1387207010.1918 - val_loss: 4064840352.8767\n",
      "Epoch 6960/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1387521654.6067 - val_loss: 4078052716.5662\n",
      "Epoch 6961/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1388126874.3014 - val_loss: 4056891088.0731\n",
      "Epoch 6962/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1386076864.8767 - val_loss: 4055525117.5160\n",
      "Epoch 6963/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1386425766.8258 - val_loss: 4075633963.5434\n",
      "Epoch 6964/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1387404495.9061 - val_loss: 4060033481.3516\n",
      "Epoch 6965/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1387215720.2035 - val_loss: 4067168141.8813\n",
      "Epoch 6966/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1389367408.3444 - val_loss: 4058159420.7854\n",
      "Epoch 6967/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1386879552.1252 - val_loss: 4072837283.2146\n",
      "Epoch 6968/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1390002294.4814 - val_loss: 4072147476.8950\n",
      "Epoch 6969/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1387615708.0548 - val_loss: 4062462337.1689\n",
      "Epoch 6970/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1388659911.6399 - val_loss: 4044591869.3699\n",
      "Epoch 6971/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1386283047.2642 - val_loss: 4063718531.5068\n",
      "Epoch 6972/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1385560334.6536 - val_loss: 4056421488.5114\n",
      "Epoch 6973/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1389519297.3777 - val_loss: 4049752701.8082\n",
      "Epoch 6974/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1386152074.3953 - val_loss: 4067857385.4977\n",
      "Epoch 6975/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1387929417.3933 - val_loss: 4067531641.7169\n",
      "Epoch 6976/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1386598927.2798 - val_loss: 4052663955.8721\n",
      "Epoch 6977/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1386816718.9041 - val_loss: 4049274133.7717\n",
      "Epoch 6978/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1388164342.7319 - val_loss: 4076608142.6119\n",
      "Epoch 6979/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1389162116.0078 - val_loss: 4052421703.3059\n",
      "Epoch 6980/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1388437669.5734 - val_loss: 4053713577.2055\n",
      "Epoch 6981/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1386093280.4384 - val_loss: 4073438484.4566\n",
      "Epoch 6982/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1388864726.9198 - val_loss: 4058931367.5982\n",
      "Epoch 6983/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1386638583.4834 - val_loss: 4067532867.2146\n",
      "Epoch 6984/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1387665666.1292 - val_loss: 4053431437.8813\n",
      "Epoch 6985/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1386674229.1037 - val_loss: 4059249003.5434\n",
      "Epoch 6986/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1387454258.7241 - val_loss: 4061129448.4749\n",
      "Epoch 6987/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1386537449.9569 - val_loss: 4066022955.5434\n",
      "Epoch 6988/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1386130219.0841 - val_loss: 4054072142.6119\n",
      "Epoch 6989/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1385410191.2798 - val_loss: 4058009386.8128\n",
      "Epoch 6990/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1385206151.2642 - val_loss: 4065828830.6849\n",
      "Epoch 6991/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1387048008.5166 - val_loss: 4057332779.1050\n",
      "Epoch 6992/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 53us/step - loss: 1386044422.7632 - val_loss: 4062608495.9269\n",
      "Epoch 6993/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1387669687.6086 - val_loss: 4063960464.6575\n",
      "Epoch 6994/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1387881920.1252 - val_loss: 4054839497.6438\n",
      "Epoch 6995/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1386166686.0587 - val_loss: 4051663326.5388\n",
      "Epoch 6996/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1386341606.7006 - val_loss: 4065974832.8037\n",
      "Epoch 6997/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1387333229.4638 - val_loss: 4058404974.7580\n",
      "Epoch 6998/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1385643757.7143 - val_loss: 4057136873.0594\n",
      "Epoch 6999/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1385442945.0646 - val_loss: 4062152471.6712\n",
      "Epoch 7000/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1386750090.2701 - val_loss: 4064425306.7397\n",
      "Epoch 7001/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1386383366.2622 - val_loss: 4066422423.8174\n",
      "Epoch 7002/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1386179021.1507 - val_loss: 4054913720.8402\n",
      "Epoch 7003/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1386523134.4971 - val_loss: 4057647275.5434\n",
      "Epoch 7004/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1387606748.9315 - val_loss: 4051345993.7900\n",
      "Epoch 7005/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1386127530.2074 - val_loss: 4062751590.5753\n",
      "Epoch 7006/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1386551578.3014 - val_loss: 4051275486.6849\n",
      "Epoch 7007/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1386954909.4325 - val_loss: 4071740104.1826\n",
      "Epoch 7008/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1385644148.9785 - val_loss: 4056343765.6256\n",
      "Epoch 7009/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1385296149.2916 - val_loss: 4056246881.6073\n",
      "Epoch 7010/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1385111518.6849 - val_loss: 4059580461.5890\n",
      "Epoch 7011/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1386601548.7750 - val_loss: 4063520509.0776\n",
      "Epoch 7012/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1385533572.0078 - val_loss: 4057654354.2648\n",
      "Epoch 7013/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1386651958.9824 - val_loss: 4053931069.3699\n",
      "Epoch 7014/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1385864924.8063 - val_loss: 4071926404.2374\n",
      "Epoch 7015/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1386915665.6595 - val_loss: 4079497421.8813\n",
      "Epoch 7016/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1385730651.4286 - val_loss: 4053530619.7626\n",
      "Epoch 7017/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1386719575.4207 - val_loss: 4063544091.9087\n",
      "Epoch 7018/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1386199430.5127 - val_loss: 4045474840.2557\n",
      "Epoch 7019/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1386074391.2955 - val_loss: 4056696781.5890\n",
      "Epoch 7020/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1385549591.6712 - val_loss: 4053014719.7078\n",
      "Epoch 7021/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1386670054.9511 - val_loss: 4062935462.7215\n",
      "Epoch 7022/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1386446243.8200 - val_loss: 4072490072.8402\n",
      "Epoch 7023/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1386434456.9237 - val_loss: 4047647534.3196\n",
      "Epoch 7024/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1390057531.3659 - val_loss: 4043225798.1370\n",
      "Epoch 7025/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1387197309.4951 - val_loss: 4070872312.4018\n",
      "Epoch 7026/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1388077400.1722 - val_loss: 4042443321.2785\n",
      "Epoch 7027/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1386671234.1292 - val_loss: 4063667911.4521\n",
      "Epoch 7028/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1385752750.5910 - val_loss: 4058109165.5890\n",
      "Epoch 7029/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1387100917.2290 - val_loss: 4048092791.8174\n",
      "Epoch 7030/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1386713972.4775 - val_loss: 4054851468.4201\n",
      "Epoch 7031/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1386298239.2485 - val_loss: 4059030604.5662\n",
      "Epoch 7032/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1385706343.0763 - val_loss: 4064772475.6164\n",
      "Epoch 7033/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1386419500.7750 - val_loss: 4064853347.7991\n",
      "Epoch 7034/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1386046630.5753 - val_loss: 4062810465.4612\n",
      "Epoch 7035/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1388606696.5793 - val_loss: 4063987228.7854\n",
      "Epoch 7036/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1385528007.3894 - val_loss: 4066352585.4977\n",
      "Epoch 7037/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1388496816.5949 - val_loss: 4062802119.1598\n",
      "Epoch 7038/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1385518520.4853 - val_loss: 4067097666.1918\n",
      "Epoch 7039/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1385580033.5029 - val_loss: 4054612488.3288\n",
      "Epoch 7040/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1387078311.5773 - val_loss: 4047978602.6667\n",
      "Epoch 7041/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1385873016.9863 - val_loss: 4054341921.0228\n",
      "Epoch 7042/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1387055029.8552 - val_loss: 4083717722.7397\n",
      "Epoch 7043/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1385376296.9550 - val_loss: 4056029875.1416\n",
      "Epoch 7044/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1385793767.3894 - val_loss: 4055852881.8265\n",
      "Epoch 7045/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1389308719.5930 - val_loss: 4084550664.0365\n",
      "Epoch 7046/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1388903210.2074 - val_loss: 4054567307.6895\n",
      "Epoch 7047/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1387073564.5558 - val_loss: 4056480128.5845\n",
      "Epoch 7048/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1385442488.6106 - val_loss: 4066562230.3562\n",
      "Epoch 7049/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1386917557.1037 - val_loss: 4056812334.3196\n",
      "Epoch 7050/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1387620872.5166 - val_loss: 4077303114.5205\n",
      "Epoch 7051/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1385687806.8728 - val_loss: 4064367056.2192\n",
      "Epoch 7052/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1386222019.8826 - val_loss: 4056620131.3607\n",
      "Epoch 7053/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1386581253.5108 - val_loss: 4063490556.0548\n",
      "Epoch 7054/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1385579212.1487 - val_loss: 4052023162.3014\n",
      "Epoch 7055/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1385967568.5949 - val_loss: 4064615998.1005\n",
      "Epoch 7056/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 44us/step - loss: 1385105748.6654 - val_loss: 4061621265.6804\n",
      "Epoch 7057/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1385562367.2485 - val_loss: 4061697720.1096\n",
      "Epoch 7058/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1386986681.6125 - val_loss: 4071495808.0000\n",
      "Epoch 7059/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1384822844.3679 - val_loss: 4055621798.8676\n",
      "Epoch 7060/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1385603749.3229 - val_loss: 4046866007.0868\n",
      "Epoch 7061/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1385819953.9100 - val_loss: 4047288384.0000\n",
      "Epoch 7062/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1385716146.4736 - val_loss: 4060745584.9498\n",
      "Epoch 7063/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1386099135.6243 - val_loss: 4066623099.3242\n",
      "Epoch 7064/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1385301489.9726 - val_loss: 4054719924.3105\n",
      "Epoch 7065/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1386265215.4990 - val_loss: 4068487819.1050\n",
      "Epoch 7066/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1385314811.0528 - val_loss: 4060138392.4018\n",
      "Epoch 7067/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1385531125.1037 - val_loss: 4051356920.4018\n",
      "Epoch 7068/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1384850757.7613 - val_loss: 4056410728.0365\n",
      "Epoch 7069/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1385890675.8513 - val_loss: 4065382404.3836\n",
      "Epoch 7070/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1386608663.7965 - val_loss: 4066506202.0091\n",
      "Epoch 7071/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1387126107.1781 - val_loss: 4062465035.1050\n",
      "Epoch 7072/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1385086837.6673 - val_loss: 4050455402.5205\n",
      "Epoch 7073/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1386580920.9863 - val_loss: 4064097096.3288\n",
      "Epoch 7074/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1387415515.4286 - val_loss: 4069055525.4064\n",
      "Epoch 7075/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1388792715.5225 - val_loss: 4040850614.2100\n",
      "Epoch 7076/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1385781558.8571 - val_loss: 4059189800.4749\n",
      "Epoch 7077/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1385997933.4638 - val_loss: 4058573490.4110\n",
      "Epoch 7078/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1385471643.8043 - val_loss: 4062284025.2785\n",
      "Epoch 7079/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1385378697.7691 - val_loss: 4048571724.4201\n",
      "Epoch 7080/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1386338048.6262 - val_loss: 4067855395.7991\n",
      "Epoch 7081/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1386179838.1213 - val_loss: 4067789214.6849\n",
      "Epoch 7082/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1384753526.9824 - val_loss: 4046967916.4201\n",
      "Epoch 7083/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1386531036.3679 - val_loss: 4051117964.1279\n",
      "Epoch 7084/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1387749941.8552 - val_loss: 4058089526.5023\n",
      "Epoch 7085/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1385817865.2681 - val_loss: 4059260953.1324\n",
      "Epoch 7086/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1385223706.0509 - val_loss: 4052714992.5114\n",
      "Epoch 7087/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1385531654.2622 - val_loss: 4054621174.3562\n",
      "Epoch 7088/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1386109121.3777 - val_loss: 4072970689.0228\n",
      "Epoch 7089/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1386452107.7730 - val_loss: 4044920410.5936\n",
      "Epoch 7090/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1385085103.2172 - val_loss: 4058556945.9726\n",
      "Epoch 7091/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1385745106.6614 - val_loss: 4058073639.8904\n",
      "Epoch 7092/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1385359822.1526 - val_loss: 4059140417.3151\n",
      "Epoch 7093/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1386358308.8219 - val_loss: 4052604456.0365\n",
      "Epoch 7094/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1386363493.1977 - val_loss: 4064495083.9817\n",
      "Epoch 7095/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1385476303.4051 - val_loss: 4050514174.1005\n",
      "Epoch 7096/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1386747542.4188 - val_loss: 4052536090.0091\n",
      "Epoch 7097/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1385319755.6477 - val_loss: 4068325627.1781\n",
      "Epoch 7098/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1385511860.0391 - val_loss: 4068772683.2511\n",
      "Epoch 7099/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1386353556.7906 - val_loss: 4076563009.0228\n",
      "Epoch 7100/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1385040963.3816 - val_loss: 4064265572.5297\n",
      "Epoch 7101/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1385485135.6556 - val_loss: 4063402013.6621\n",
      "Epoch 7102/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1387639701.5421 - val_loss: 4047400230.5753\n",
      "Epoch 7103/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1385720460.9002 - val_loss: 4063327074.0457\n",
      "Epoch 7104/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1385509090.6928 - val_loss: 4063624066.0457\n",
      "Epoch 7105/10000\n",
      "1022/1022 [==============================] - 0s 75us/step - loss: 1384817772.0861 - val_loss: 4053211207.3059\n",
      "Epoch 7106/10000\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 1385670314.3327 - val_loss: 4049642918.5753\n",
      "Epoch 7107/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1387838065.5969 - val_loss: 4056594921.4977\n",
      "Epoch 7108/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1386064991.9374 - val_loss: 4054399727.9269\n",
      "Epoch 7109/10000\n",
      "1022/1022 [==============================] - 0s 68us/step - loss: 1385037883.1155 - val_loss: 4056899316.6027\n",
      "Epoch 7110/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1388486774.9824 - val_loss: 4070369043.1416\n",
      "Epoch 7111/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1384418238.2466 - val_loss: 4052516558.9041\n",
      "Epoch 7112/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1385846322.5988 - val_loss: 4056636574.3927\n",
      "Epoch 7113/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1387009948.1174 - val_loss: 4042004815.9269\n",
      "Epoch 7114/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1386819905.1272 - val_loss: 4057118379.6895\n",
      "Epoch 7115/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1385759317.6673 - val_loss: 4063491266.6301\n",
      "Epoch 7116/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1386776583.8904 - val_loss: 4051490117.5525\n",
      "Epoch 7117/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1388560052.7280 - val_loss: 4066866410.8128\n",
      "Epoch 7118/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1386110708.4775 - val_loss: 4049865707.9817\n",
      "Epoch 7119/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1384547283.6634 - val_loss: 4065925569.4612\n",
      "Epoch 7120/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 46us/step - loss: 1385873531.8669 - val_loss: 4064779933.2237\n",
      "Epoch 7121/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1385188675.0059 - val_loss: 4060454069.9178\n",
      "Epoch 7122/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1388085683.6008 - val_loss: 4044522901.0411\n",
      "Epoch 7123/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1385922921.2055 - val_loss: 4073764977.3881\n",
      "Epoch 7124/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1385988672.1252 - val_loss: 4068524808.7671\n",
      "Epoch 7125/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1385781286.5753 - val_loss: 4052567270.7215\n",
      "Epoch 7126/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1384992537.0489 - val_loss: 4062352579.6530\n",
      "Epoch 7127/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1385215091.7260 - val_loss: 4060958829.4429\n",
      "Epoch 7128/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1385646863.4051 - val_loss: 4066285876.7489\n",
      "Epoch 7129/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1385387202.3796 - val_loss: 4060199658.2283\n",
      "Epoch 7130/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1385335333.3229 - val_loss: 4053667279.1963\n",
      "Epoch 7131/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1385478687.1859 - val_loss: 4061634296.6941\n",
      "Epoch 7132/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1385802682.9902 - val_loss: 4068259189.0411\n",
      "Epoch 7133/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1386205709.0254 - val_loss: 4071674766.7580\n",
      "Epoch 7134/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1387125147.3033 - val_loss: 4069587541.0411\n",
      "Epoch 7135/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1385029082.4266 - val_loss: 4057118341.2603\n",
      "Epoch 7136/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1385145221.2603 - val_loss: 4058495463.1598\n",
      "Epoch 7137/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1387120742.8258 - val_loss: 4069197374.6849\n",
      "Epoch 7138/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1385987998.4344 - val_loss: 4046643441.6804\n",
      "Epoch 7139/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1385104937.8317 - val_loss: 4052931804.7854\n",
      "Epoch 7140/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1385762496.1252 - val_loss: 4070301053.9543\n",
      "Epoch 7141/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1385750423.5460 - val_loss: 4061790600.0365\n",
      "Epoch 7142/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1385070119.5773 - val_loss: 4063757176.5479\n",
      "Epoch 7143/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1386099293.8082 - val_loss: 4061285950.9772\n",
      "Epoch 7144/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1385765884.8689 - val_loss: 4056225723.1781\n",
      "Epoch 7145/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1385507021.1507 - val_loss: 4049573029.4064\n",
      "Epoch 7146/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1384780479.3738 - val_loss: 4066227382.7945\n",
      "Epoch 7147/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1385681387.3346 - val_loss: 4064831861.0411\n",
      "Epoch 7148/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1387556224.7515 - val_loss: 4066497199.7808\n",
      "Epoch 7149/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1385224141.0254 - val_loss: 4071497982.3927\n",
      "Epoch 7150/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1386199720.5793 - val_loss: 4062824518.4292\n",
      "Epoch 7151/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1385791226.4892 - val_loss: 4061275345.8265\n",
      "Epoch 7152/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1384635932.3053 - val_loss: 4065799529.3516\n",
      "Epoch 7153/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1385569296.7828 - val_loss: 4058990359.0868\n",
      "Epoch 7154/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1386452288.1252 - val_loss: 4050765465.1324\n",
      "Epoch 7155/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1384614913.0020 - val_loss: 4062129124.2374\n",
      "Epoch 7156/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1385816164.9472 - val_loss: 4060137764.8219\n",
      "Epoch 7157/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1386142611.5382 - val_loss: 4086990211.7991\n",
      "Epoch 7158/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1385083159.0450 - val_loss: 4063683685.4064\n",
      "Epoch 7159/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1385595754.3327 - val_loss: 4056001199.0502\n",
      "Epoch 7160/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1385452635.6791 - val_loss: 4061407275.9817\n",
      "Epoch 7161/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1386459429.5734 - val_loss: 4047034803.7260\n",
      "Epoch 7162/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1385953384.4540 - val_loss: 4058177623.5251\n",
      "Epoch 7163/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1389589770.5205 - val_loss: 4099932878.9041\n",
      "Epoch 7164/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1387206542.5284 - val_loss: 4055261461.6256\n",
      "Epoch 7165/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1386767673.1115 - val_loss: 4066222179.3607\n",
      "Epoch 7166/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1384720000.6262 - val_loss: 4056268350.6849\n",
      "Epoch 7167/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1385265409.7534 - val_loss: 4071048854.3562\n",
      "Epoch 7168/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1387158500.5714 - val_loss: 4045687311.4886\n",
      "Epoch 7169/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1387893543.8278 - val_loss: 4073107105.7534\n",
      "Epoch 7170/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1384575208.8924 - val_loss: 4063735678.1005\n",
      "Epoch 7171/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1386041340.4932 - val_loss: 4048179708.4932\n",
      "Epoch 7172/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1384746197.4168 - val_loss: 4062354646.0639\n",
      "Epoch 7173/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1384860982.3562 - val_loss: 4059893877.9178\n",
      "Epoch 7174/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1385495517.4325 - val_loss: 4065706039.2329\n",
      "Epoch 7175/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1385024975.1546 - val_loss: 4069684669.6621\n",
      "Epoch 7176/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1384986862.4658 - val_loss: 4066225081.2785\n",
      "Epoch 7177/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1389683901.3699 - val_loss: 4045476580.5297\n",
      "Epoch 7178/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1384671525.9491 - val_loss: 4069478765.8813\n",
      "Epoch 7179/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1385338495.4990 - val_loss: 4055400472.9863\n",
      "Epoch 7180/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1385159201.5656 - val_loss: 4070332498.7032\n",
      "Epoch 7181/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1385023357.2446 - val_loss: 4054859302.7215\n",
      "Epoch 7182/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1386922960.4070 - val_loss: 4065825232.5114\n",
      "Epoch 7183/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1384454955.0841 - val_loss: 4058473102.7580\n",
      "Epoch 7184/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 44us/step - loss: 1384440442.9902 - val_loss: 4058960029.6621\n",
      "Epoch 7185/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1387397680.3444 - val_loss: 4064958823.4521\n",
      "Epoch 7186/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1386137541.3855 - val_loss: 4068866453.3333\n",
      "Epoch 7187/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1384783704.6732 - val_loss: 4061489284.3836\n",
      "Epoch 7188/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1386729713.2211 - val_loss: 4053320161.1689\n",
      "Epoch 7189/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1384078083.8826 - val_loss: 4064802072.2557\n",
      "Epoch 7190/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1385769104.5323 - val_loss: 4070323110.7215\n",
      "Epoch 7191/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1384965045.8552 - val_loss: 4059459248.2192\n",
      "Epoch 7192/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1385033639.3268 - val_loss: 4064743701.4795\n",
      "Epoch 7193/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1387976344.2975 - val_loss: 4043326535.3059\n",
      "Epoch 7194/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1385168450.5049 - val_loss: 4061276199.1598\n",
      "Epoch 7195/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1385884829.3072 - val_loss: 4062201731.3607\n",
      "Epoch 7196/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1385178334.0587 - val_loss: 4058585089.8995\n",
      "Epoch 7197/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1386872208.5323 - val_loss: 4062879516.0548\n",
      "Epoch 7198/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1387260890.4266 - val_loss: 4064313958.4292\n",
      "Epoch 7199/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1385764673.1272 - val_loss: 4059300790.2100\n",
      "Epoch 7200/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1387090970.3014 - val_loss: 4064307175.0137\n",
      "Epoch 7201/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1386206502.0744 - val_loss: 4056317268.1644\n",
      "Epoch 7202/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1385714331.5538 - val_loss: 4061318441.6438\n",
      "Epoch 7203/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1384911287.1076 - val_loss: 4064718784.0000\n",
      "Epoch 7204/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1384896449.8787 - val_loss: 4063017802.9589\n",
      "Epoch 7205/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1384610504.7671 - val_loss: 4058774643.4338\n",
      "Epoch 7206/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1387129795.6321 - val_loss: 4055046546.5571\n",
      "Epoch 7207/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1385078253.5890 - val_loss: 4065160430.6119\n",
      "Epoch 7208/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1385034050.8806 - val_loss: 4054756427.3973\n",
      "Epoch 7209/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1385122665.7065 - val_loss: 4062777185.1689\n",
      "Epoch 7210/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1385778755.6321 - val_loss: 4058467876.6758\n",
      "Epoch 7211/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1384902423.4207 - val_loss: 4066818255.3425\n",
      "Epoch 7212/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1385166980.0078 - val_loss: 4056420863.2694\n",
      "Epoch 7213/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1384634488.8611 - val_loss: 4069505978.1553\n",
      "Epoch 7214/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1386724712.2035 - val_loss: 4070114107.7626\n",
      "Epoch 7215/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1386642607.3425 - val_loss: 4071475706.1553\n",
      "Epoch 7216/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1384452807.1389 - val_loss: 4063654865.2420\n",
      "Epoch 7217/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1384522865.5969 - val_loss: 4054817241.5708\n",
      "Epoch 7218/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1385168744.4540 - val_loss: 4046143306.0822\n",
      "Epoch 7219/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1384536851.7886 - val_loss: 4064294397.0776\n",
      "Epoch 7220/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1385597759.4364 - val_loss: 4073630009.7169\n",
      "Epoch 7221/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1384930239.1233 - val_loss: 4053031305.2055\n",
      "Epoch 7222/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1385729347.6321 - val_loss: 4053120545.7534\n",
      "Epoch 7223/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1384296545.9413 - val_loss: 4065574336.0000\n",
      "Epoch 7224/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1385042330.4892 - val_loss: 4062685165.5890\n",
      "Epoch 7225/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1384897843.6008 - val_loss: 4057705032.0365\n",
      "Epoch 7226/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1385113441.4403 - val_loss: 4059109244.7854\n",
      "Epoch 7227/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1385067734.4188 - val_loss: 4058507726.9041\n",
      "Epoch 7228/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1384907196.3679 - val_loss: 4053638267.0320\n",
      "Epoch 7229/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1385811250.3483 - val_loss: 4062835665.5342\n",
      "Epoch 7230/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1386108765.1820 - val_loss: 4072470368.0000\n",
      "Epoch 7231/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1385555116.0861 - val_loss: 4058371394.7763\n",
      "Epoch 7232/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1384562373.8865 - val_loss: 4047139214.9041\n",
      "Epoch 7233/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1390684808.2661 - val_loss: 4089981420.8584\n",
      "Epoch 7234/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1385924609.5029 - val_loss: 4047180591.4886\n",
      "Epoch 7235/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1385424766.2466 - val_loss: 4059323248.9498\n",
      "Epoch 7236/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1384855611.0528 - val_loss: 4058181887.4155\n",
      "Epoch 7237/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1384794964.1644 - val_loss: 4054515332.8219\n",
      "Epoch 7238/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1384892492.2740 - val_loss: 4058248994.6301\n",
      "Epoch 7239/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1384837406.3092 - val_loss: 4049556875.5434\n",
      "Epoch 7240/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1384976028.3053 - val_loss: 4062131681.8995\n",
      "Epoch 7241/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1384703900.3053 - val_loss: 4052491875.0685\n",
      "Epoch 7242/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1386227407.2798 - val_loss: 4057124902.4292\n",
      "Epoch 7243/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1384894728.0157 - val_loss: 4074253224.7671\n",
      "Epoch 7244/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1385271080.8297 - val_loss: 4061687808.4384\n",
      "Epoch 7245/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1385728423.5773 - val_loss: 4063805661.3699\n",
      "Epoch 7246/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1385199951.6556 - val_loss: 4054342760.1826\n",
      "Epoch 7247/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1384601356.1487 - val_loss: 4060346878.9772\n",
      "Epoch 7248/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 39us/step - loss: 1385814906.7397 - val_loss: 4067184620.8584\n",
      "Epoch 7249/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1384558407.1389 - val_loss: 4049902358.5023\n",
      "Epoch 7250/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1384608199.8904 - val_loss: 4060042153.9361\n",
      "Epoch 7251/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1384675076.7593 - val_loss: 4061385731.2146\n",
      "Epoch 7252/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1385653214.4344 - val_loss: 4052583953.2420\n",
      "Epoch 7253/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1384637549.3386 - val_loss: 4063027817.7900\n",
      "Epoch 7254/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1385701002.0196 - val_loss: 4062989871.1963\n",
      "Epoch 7255/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1386030468.2583 - val_loss: 4055069948.2009\n",
      "Epoch 7256/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1384764254.1840 - val_loss: 4068679917.0046\n",
      "Epoch 7257/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1384239011.8200 - val_loss: 4064926247.4521\n",
      "Epoch 7258/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1384088845.5264 - val_loss: 4056119016.3288\n",
      "Epoch 7259/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1384971205.1350 - val_loss: 4060130489.8630\n",
      "Epoch 7260/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1386835051.7104 - val_loss: 4050086576.0731\n",
      "Epoch 7261/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1385373538.0665 - val_loss: 4061562233.4247\n",
      "Epoch 7262/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1384835254.1057 - val_loss: 4065758145.4612\n",
      "Epoch 7263/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1384581063.7025 - val_loss: 4053768225.7534\n",
      "Epoch 7264/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1384664076.7123 - val_loss: 4063437630.9772\n",
      "Epoch 7265/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1384899889.0959 - val_loss: 4059079223.2329\n",
      "Epoch 7266/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1384240676.3209 - val_loss: 4059512590.7580\n",
      "Epoch 7267/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1384669929.8317 - val_loss: 4062694075.4703\n",
      "Epoch 7268/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1384773808.8454 - val_loss: 4058721445.2603\n",
      "Epoch 7269/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1385593689.6751 - val_loss: 4054861401.8630\n",
      "Epoch 7270/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1388726817.8160 - val_loss: 4071316259.7991\n",
      "Epoch 7271/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1384207605.6047 - val_loss: 4055573711.3425\n",
      "Epoch 7272/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1384478387.7260 - val_loss: 4058531589.2603\n",
      "Epoch 7273/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1385284788.6027 - val_loss: 4061930730.0822\n",
      "Epoch 7274/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1384790252.0861 - val_loss: 4062372718.1735\n",
      "Epoch 7275/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1385963221.4168 - val_loss: 4046205780.6027\n",
      "Epoch 7276/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1386111946.3953 - val_loss: 4062443900.6393\n",
      "Epoch 7277/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1384693592.9237 - val_loss: 4057490071.5251\n",
      "Epoch 7278/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1384961822.3092 - val_loss: 4056234372.9680\n",
      "Epoch 7279/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1384579289.2368 - val_loss: 4066934433.8995\n",
      "Epoch 7280/10000\n",
      "1022/1022 [==============================] - 0s 66us/step - loss: 1385245779.9139 - val_loss: 4066910092.5662\n",
      "Epoch 7281/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1384575147.3346 - val_loss: 4070282651.4703\n",
      "Epoch 7282/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1384465604.8845 - val_loss: 4048775637.1872\n",
      "Epoch 7283/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1384796205.3386 - val_loss: 4067644583.3059\n",
      "Epoch 7284/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1388573873.5969 - val_loss: 4053343236.8219\n",
      "Epoch 7285/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1384153739.5225 - val_loss: 4060590941.6621\n",
      "Epoch 7286/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1385102978.2544 - val_loss: 4066132295.4521\n",
      "Epoch 7287/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1385299885.3386 - val_loss: 4062498049.4612\n",
      "Epoch 7288/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1385592592.5323 - val_loss: 4082954416.3653\n",
      "Epoch 7289/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1385968171.5851 - val_loss: 4049319785.2055\n",
      "Epoch 7290/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1384521562.1761 - val_loss: 4070645054.2466\n",
      "Epoch 7291/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1384189728.1879 - val_loss: 4062789997.7352\n",
      "Epoch 7292/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1386478661.8865 - val_loss: 4048511002.1553\n",
      "Epoch 7293/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1384769228.3992 - val_loss: 4070053864.1826\n",
      "Epoch 7294/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1386398209.7534 - val_loss: 4058489837.0046\n",
      "Epoch 7295/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1385113476.7593 - val_loss: 4068356537.2785\n",
      "Epoch 7296/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1385056230.9511 - val_loss: 4052730152.3288\n",
      "Epoch 7297/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1386391119.2798 - val_loss: 4075784570.5936\n",
      "Epoch 7298/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1388905308.9315 - val_loss: 4055279898.3014\n",
      "Epoch 7299/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1385235715.7573 - val_loss: 4066003062.7945\n",
      "Epoch 7300/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1384188355.5068 - val_loss: 4058897146.0091\n",
      "Epoch 7301/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1384410702.6536 - val_loss: 4057445795.0685\n",
      "Epoch 7302/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1385472342.6693 - val_loss: 4053347825.0959\n",
      "Epoch 7303/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1385271011.4442 - val_loss: 4069048838.1370\n",
      "Epoch 7304/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1384845164.6497 - val_loss: 4055278160.5114\n",
      "Epoch 7305/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1385276781.4638 - val_loss: 4078388335.0502\n",
      "Epoch 7306/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1385765880.3601 - val_loss: 4055584795.0320\n",
      "Epoch 7307/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1383654342.4501 - val_loss: 4063349947.0320\n",
      "Epoch 7308/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1385653458.4110 - val_loss: 4083184092.4932\n",
      "Epoch 7309/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1385001948.6810 - val_loss: 4047272110.4658\n",
      "Epoch 7310/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1385887499.0215 - val_loss: 4058532482.0457\n",
      "Epoch 7311/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1385108729.9883 - val_loss: 4066296650.5205\n",
      "Epoch 7312/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 38us/step - loss: 1385653935.3425 - val_loss: 4060644239.4886\n",
      "Epoch 7313/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1386501225.9569 - val_loss: 4074482361.7169\n",
      "Epoch 7314/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1383895006.8102 - val_loss: 4052817843.4338\n",
      "Epoch 7315/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1385121068.1487 - val_loss: 4062733416.3288\n",
      "Epoch 7316/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1385455663.2172 - val_loss: 4061500032.0000\n",
      "Epoch 7317/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1384411638.4814 - val_loss: 4067685530.1553\n",
      "Epoch 7318/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1385037867.0841 - val_loss: 4060284715.9817\n",
      "Epoch 7319/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1385604414.6223 - val_loss: 4061407531.2511\n",
      "Epoch 7320/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1384892212.1018 - val_loss: 4061130645.1872\n",
      "Epoch 7321/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1386181628.2427 - val_loss: 4050496775.7443\n",
      "Epoch 7322/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1384934002.5988 - val_loss: 4062720855.8174\n",
      "Epoch 7323/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1387363505.0959 - val_loss: 4056924466.8493\n",
      "Epoch 7324/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1383969096.2035 - val_loss: 4063023332.6758\n",
      "Epoch 7325/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1384571859.9139 - val_loss: 4072213182.2466\n",
      "Epoch 7326/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1384304256.2505 - val_loss: 4070106419.5799\n",
      "Epoch 7327/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1385355935.0607 - val_loss: 4060518000.6575\n",
      "Epoch 7328/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1385830511.5930 - val_loss: 4074139626.2283\n",
      "Epoch 7329/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1384435904.8767 - val_loss: 4052917463.5251\n",
      "Epoch 7330/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1389528373.6047 - val_loss: 4078204362.6667\n",
      "Epoch 7331/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1385650941.3699 - val_loss: 4043432407.5251\n",
      "Epoch 7332/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1385094067.8513 - val_loss: 4065215534.4658\n",
      "Epoch 7333/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1384371069.4951 - val_loss: 4050292421.2603\n",
      "Epoch 7334/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1386494368.0626 - val_loss: 4070458116.6758\n",
      "Epoch 7335/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1386011515.2407 - val_loss: 4051733091.3607\n",
      "Epoch 7336/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1386216112.3444 - val_loss: 4056135882.6667\n",
      "Epoch 7337/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1384565138.2857 - val_loss: 4055723473.6804\n",
      "Epoch 7338/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1385102008.8611 - val_loss: 4061868037.9909\n",
      "Epoch 7339/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1386169653.6047 - val_loss: 4049091614.8311\n",
      "Epoch 7340/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1384420114.8493 - val_loss: 4053456270.0274\n",
      "Epoch 7341/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1383889320.5793 - val_loss: 4065670171.1781\n",
      "Epoch 7342/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1385080498.5988 - val_loss: 4077393116.6393\n",
      "Epoch 7343/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1384885624.8611 - val_loss: 4060539873.1689\n",
      "Epoch 7344/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1384503005.9335 - val_loss: 4066698375.4521\n",
      "Epoch 7345/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1383972478.1213 - val_loss: 4055961765.2603\n",
      "Epoch 7346/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1384209624.9237 - val_loss: 4053585435.3242\n",
      "Epoch 7347/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1384996005.0724 - val_loss: 4063323673.4247\n",
      "Epoch 7348/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1384290945.7534 - val_loss: 4050802544.0731\n",
      "Epoch 7349/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1384342326.3562 - val_loss: 4068342902.7945\n",
      "Epoch 7350/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1384555444.9785 - val_loss: 4066631761.3881\n",
      "Epoch 7351/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1385374036.0391 - val_loss: 4061003545.7169\n",
      "Epoch 7352/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1385027609.0489 - val_loss: 4057268155.3242\n",
      "Epoch 7353/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1384682376.2661 - val_loss: 4056475875.7991\n",
      "Epoch 7354/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383735487.8748 - val_loss: 4054263172.0913\n",
      "Epoch 7355/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1386819871.3112 - val_loss: 4052131474.5571\n",
      "Epoch 7356/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1383487115.7730 - val_loss: 4073261807.4886\n",
      "Epoch 7357/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1384105112.4227 - val_loss: 4067624615.5982\n",
      "Epoch 7358/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1383881971.7260 - val_loss: 4064640630.2100\n",
      "Epoch 7359/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1384606930.9119 - val_loss: 4052185621.9178\n",
      "Epoch 7360/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1384147240.5793 - val_loss: 4056168147.2877\n",
      "Epoch 7361/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1384464441.6751 - val_loss: 4058432585.2055\n",
      "Epoch 7362/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1384163036.4305 - val_loss: 4063861181.8082\n",
      "Epoch 7363/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1384275226.1761 - val_loss: 4057939789.5890\n",
      "Epoch 7364/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1385704551.9530 - val_loss: 4059720391.3059\n",
      "Epoch 7365/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1386579496.0783 - val_loss: 4059517202.9954\n",
      "Epoch 7366/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1385258011.8043 - val_loss: 4053312907.5434\n",
      "Epoch 7367/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1385076288.0000 - val_loss: 4067208459.2511\n",
      "Epoch 7368/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1383624830.1213 - val_loss: 4055386468.8219\n",
      "Epoch 7369/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1385934362.0509 - val_loss: 4060402856.6210\n",
      "Epoch 7370/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1384160977.9100 - val_loss: 4065131231.4155\n",
      "Epoch 7371/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1384093694.4971 - val_loss: 4070745173.6256\n",
      "Epoch 7372/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1384380026.4892 - val_loss: 4057097338.5936\n",
      "Epoch 7373/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1384342854.7632 - val_loss: 4052075300.0913\n",
      "Epoch 7374/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1384505777.8474 - val_loss: 4072842346.0822\n",
      "Epoch 7375/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1384165849.9256 - val_loss: 4052792010.8128\n",
      "Epoch 7376/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 49us/step - loss: 1384445115.4912 - val_loss: 4054183066.5936\n",
      "Epoch 7377/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1384740929.1272 - val_loss: 4075744672.0000\n",
      "Epoch 7378/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1385462991.6556 - val_loss: 4059442444.2740\n",
      "Epoch 7379/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1387121159.2642 - val_loss: 4051944229.2603\n",
      "Epoch 7380/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1383855061.1663 - val_loss: 4058002265.4247\n",
      "Epoch 7381/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1384360431.4677 - val_loss: 4059346525.9543\n",
      "Epoch 7382/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1387112842.5205 - val_loss: 4068421724.9315\n",
      "Epoch 7383/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1383993814.7945 - val_loss: 4055452881.6804\n",
      "Epoch 7384/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1384544965.6360 - val_loss: 4055497678.0274\n",
      "Epoch 7385/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1384899890.3483 - val_loss: 4047455148.7123\n",
      "Epoch 7386/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1384549708.6497 - val_loss: 4064764209.3881\n",
      "Epoch 7387/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1384588169.2681 - val_loss: 4060423980.4201\n",
      "Epoch 7388/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1384840060.1174 - val_loss: 4058046261.3333\n",
      "Epoch 7389/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1386621922.6928 - val_loss: 4060916084.1644\n",
      "Epoch 7390/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1384831671.1076 - val_loss: 4060259005.0776\n",
      "Epoch 7391/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1386282786.4423 - val_loss: 4057801292.2740\n",
      "Epoch 7392/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1384515845.2603 - val_loss: 4064926377.7900\n",
      "Epoch 7393/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1384065428.2896 - val_loss: 4070504284.3470\n",
      "Epoch 7394/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1383749345.9413 - val_loss: 4066630862.9041\n",
      "Epoch 7395/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1384348190.3092 - val_loss: 4065189206.7945\n",
      "Epoch 7396/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1384808089.3620 - val_loss: 4070366442.8128\n",
      "Epoch 7397/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1384134091.3973 - val_loss: 4055228367.9269\n",
      "Epoch 7398/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1383919340.9628 - val_loss: 4059021743.9269\n",
      "Epoch 7399/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1384318090.2701 - val_loss: 4054407562.6667\n",
      "Epoch 7400/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1384801109.6673 - val_loss: 4074149648.6575\n",
      "Epoch 7401/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1385852102.2622 - val_loss: 4052642523.1781\n",
      "Epoch 7402/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1385877020.8063 - val_loss: 4065013658.1553\n",
      "Epoch 7403/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1386113408.3757 - val_loss: 4053416832.5845\n",
      "Epoch 7404/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1385534125.9648 - val_loss: 4063571397.1142\n",
      "Epoch 7405/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1383841208.7358 - val_loss: 4062717764.2374\n",
      "Epoch 7406/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1385422084.0078 - val_loss: 4057927030.7945\n",
      "Epoch 7407/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1384558389.6047 - val_loss: 4056173433.2785\n",
      "Epoch 7408/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1383626296.6106 - val_loss: 4065846282.2283\n",
      "Epoch 7409/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1383669491.1624 - val_loss: 4070851043.2146\n",
      "Epoch 7410/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1384119820.5245 - val_loss: 4058010863.7808\n",
      "Epoch 7411/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1386032362.2074 - val_loss: 4058505805.5890\n",
      "Epoch 7412/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1384320259.1311 - val_loss: 4060664340.4566\n",
      "Epoch 7413/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1383702518.8571 - val_loss: 4053874864.3653\n",
      "Epoch 7414/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1385977581.2133 - val_loss: 4071216704.8767\n",
      "Epoch 7415/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1384865246.1840 - val_loss: 4057793615.9269\n",
      "Epoch 7416/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1384554620.9941 - val_loss: 4046715896.4018\n",
      "Epoch 7417/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1384100569.4247 - val_loss: 4058498831.7808\n",
      "Epoch 7418/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1384628543.2485 - val_loss: 4051777270.6484\n",
      "Epoch 7419/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1385011374.8415 - val_loss: 4071657648.8037\n",
      "Epoch 7420/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1387471435.6477 - val_loss: 4071006431.8539\n",
      "Epoch 7421/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1385459903.1233 - val_loss: 4046901581.0046\n",
      "Epoch 7422/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1385664842.1448 - val_loss: 4051487369.2055\n",
      "Epoch 7423/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1383938000.1566 - val_loss: 4067318502.4292\n",
      "Epoch 7424/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1384352314.6145 - val_loss: 4063196383.7078\n",
      "Epoch 7425/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1385017572.4462 - val_loss: 4059176662.0639\n",
      "Epoch 7426/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1384080495.0920 - val_loss: 4068481275.9087\n",
      "Epoch 7427/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1383873528.9863 - val_loss: 4062941187.3607\n",
      "Epoch 7428/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1384474891.5225 - val_loss: 4066520426.8128\n",
      "Epoch 7429/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1386345904.8454 - val_loss: 4072018937.7169\n",
      "Epoch 7430/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1384010137.2994 - val_loss: 4049555534.7580\n",
      "Epoch 7431/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1385819015.0137 - val_loss: 4051746844.6393\n",
      "Epoch 7432/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1383591866.2387 - val_loss: 4062068337.3881\n",
      "Epoch 7433/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1383863968.3131 - val_loss: 4062712667.9087\n",
      "Epoch 7434/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1384306066.7867 - val_loss: 4061284809.9361\n",
      "Epoch 7435/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1386472346.4266 - val_loss: 4055410655.2694\n",
      "Epoch 7436/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1387456512.0000 - val_loss: 4081620976.0731\n",
      "Epoch 7437/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1384379891.2250 - val_loss: 4043976021.1872\n",
      "Epoch 7438/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1383467124.4775 - val_loss: 4057261755.9087\n",
      "Epoch 7439/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1385412896.9393 - val_loss: 4073816852.7489\n",
      "Epoch 7440/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 50us/step - loss: 1384511257.0489 - val_loss: 4057897482.2283\n",
      "Epoch 7441/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1383805985.0646 - val_loss: 4063187920.6575\n",
      "Epoch 7442/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1384628997.8865 - val_loss: 4055074948.2374\n",
      "Epoch 7443/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1385309321.7691 - val_loss: 4066552130.0457\n",
      "Epoch 7444/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1385416995.0685 - val_loss: 4061619096.2557\n",
      "Epoch 7445/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1384531912.1409 - val_loss: 4064014789.9909\n",
      "Epoch 7446/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1384391596.3366 - val_loss: 4058901645.4429\n",
      "Epoch 7447/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1383873948.6810 - val_loss: 4064791392.0000\n",
      "Epoch 7448/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1383680116.2270 - val_loss: 4056600315.0320\n",
      "Epoch 7449/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1384592965.3855 - val_loss: 4048343820.8584\n",
      "Epoch 7450/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1385010196.5401 - val_loss: 4069494120.1826\n",
      "Epoch 7451/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1383755080.8924 - val_loss: 4064453364.1644\n",
      "Epoch 7452/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1385514446.9041 - val_loss: 4051756619.2511\n",
      "Epoch 7453/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1386829279.9374 - val_loss: 4081014945.7534\n",
      "Epoch 7454/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1384820099.7573 - val_loss: 4061384087.9635\n",
      "Epoch 7455/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1384955715.1311 - val_loss: 4069129276.6393\n",
      "Epoch 7456/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1384438573.3386 - val_loss: 4057412946.1187\n",
      "Epoch 7457/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1386690951.2642 - val_loss: 4075358103.5251\n",
      "Epoch 7458/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1385375228.3053 - val_loss: 4055814478.9041\n",
      "Epoch 7459/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1384922168.6106 - val_loss: 4066280468.3105\n",
      "Epoch 7460/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1385117050.9902 - val_loss: 4054743555.5068\n",
      "Epoch 7461/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1383980209.8474 - val_loss: 4063232240.0731\n",
      "Epoch 7462/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1383900555.5225 - val_loss: 4059248190.9772\n",
      "Epoch 7463/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1383831194.3014 - val_loss: 4051225876.6027\n",
      "Epoch 7464/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1384855711.5616 - val_loss: 4059665827.3607\n",
      "Epoch 7465/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1385354988.2114 - val_loss: 4067064977.8265\n",
      "Epoch 7466/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1384740508.3053 - val_loss: 4060262142.8311\n",
      "Epoch 7467/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1383576639.1233 - val_loss: 4072978413.1507\n",
      "Epoch 7468/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1386433774.9667 - val_loss: 4083917331.4338\n",
      "Epoch 7469/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1382979445.9804 - val_loss: 4053885920.2922\n",
      "Epoch 7470/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1384379638.1057 - val_loss: 4059519844.3836\n",
      "Epoch 7471/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1385085578.2701 - val_loss: 4052793246.1005\n",
      "Epoch 7472/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1385509816.6106 - val_loss: 4056644274.4110\n",
      "Epoch 7473/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1383991710.0587 - val_loss: 4074247701.6256\n",
      "Epoch 7474/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1383994836.5401 - val_loss: 4061016397.8813\n",
      "Epoch 7475/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1385391848.0783 - val_loss: 4066840341.7717\n",
      "Epoch 7476/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1383783726.5910 - val_loss: 4077192701.8082\n",
      "Epoch 7477/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1383802522.1761 - val_loss: 4061183440.8037\n",
      "Epoch 7478/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1385770878.4971 - val_loss: 4063917602.7763\n",
      "Epoch 7479/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383859834.2387 - val_loss: 4075423468.8584\n",
      "Epoch 7480/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1384124036.5088 - val_loss: 4056280519.1598\n",
      "Epoch 7481/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1384601861.5108 - val_loss: 4055283079.8904\n",
      "Epoch 7482/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1384240700.2427 - val_loss: 4066275458.0457\n",
      "Epoch 7483/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1384612364.7750 - val_loss: 4064428393.9361\n",
      "Epoch 7484/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1385507754.3327 - val_loss: 4073838915.6530\n",
      "Epoch 7485/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383875474.7867 - val_loss: 4055544054.3562\n",
      "Epoch 7486/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1384205834.2701 - val_loss: 4054464250.7397\n",
      "Epoch 7487/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1384098625.7534 - val_loss: 4063247485.8082\n",
      "Epoch 7488/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1385654006.3562 - val_loss: 4061742985.3516\n",
      "Epoch 7489/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1383360567.6086 - val_loss: 4057656829.0776\n",
      "Epoch 7490/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1387369437.4325 - val_loss: 4054869867.1050\n",
      "Epoch 7491/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1383726929.7847 - val_loss: 4059321438.1005\n",
      "Epoch 7492/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1383812517.6986 - val_loss: 4058817892.0913\n",
      "Epoch 7493/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1385067475.5382 - val_loss: 4056002730.2283\n",
      "Epoch 7494/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1383317780.5401 - val_loss: 4062031364.2374\n",
      "Epoch 7495/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1384129847.8591 - val_loss: 4065852514.4840\n",
      "Epoch 7496/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1383889699.9452 - val_loss: 4057157224.3288\n",
      "Epoch 7497/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1383832909.6517 - val_loss: 4051269508.5297\n",
      "Epoch 7498/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1384435294.4344 - val_loss: 4061233424.5114\n",
      "Epoch 7499/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1383590977.1272 - val_loss: 4061203340.4201\n",
      "Epoch 7500/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1384580533.3542 - val_loss: 4055283865.5708\n",
      "Epoch 7501/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383966045.4325 - val_loss: 4060846944.8767\n",
      "Epoch 7502/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1386336557.5890 - val_loss: 4068560472.2557\n",
      "Epoch 7503/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1385127537.9726 - val_loss: 4058047179.3973\n",
      "Epoch 7504/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 48us/step - loss: 1384937210.4892 - val_loss: 4056817418.9589\n",
      "Epoch 7505/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383827664.5323 - val_loss: 4063315810.6301\n",
      "Epoch 7506/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383749890.2544 - val_loss: 4062679493.4064\n",
      "Epoch 7507/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1384709288.0783 - val_loss: 4063092943.1963\n",
      "Epoch 7508/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1383778560.5010 - val_loss: 4068642392.1096\n",
      "Epoch 7509/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383609530.6145 - val_loss: 4056623912.9132\n",
      "Epoch 7510/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1383596337.5342 - val_loss: 4057389340.3470\n",
      "Epoch 7511/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1383653787.4286 - val_loss: 4066921137.2420\n",
      "Epoch 7512/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1384858123.3973 - val_loss: 4058531400.3288\n",
      "Epoch 7513/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1383709776.4070 - val_loss: 4071397097.0594\n",
      "Epoch 7514/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1383547262.2466 - val_loss: 4064160685.7352\n",
      "Epoch 7515/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1383431359.8748 - val_loss: 4064818060.5662\n",
      "Epoch 7516/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1383594617.7378 - val_loss: 4066411478.6484\n",
      "Epoch 7517/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383327051.1468 - val_loss: 4058268937.9361\n",
      "Epoch 7518/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1383792421.1977 - val_loss: 4061532824.2557\n",
      "Epoch 7519/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1383968451.1311 - val_loss: 4068696765.3699\n",
      "Epoch 7520/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383618643.5382 - val_loss: 4050687093.0411\n",
      "Epoch 7521/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1383336093.6830 - val_loss: 4057516559.0502\n",
      "Epoch 7522/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1384932508.8063 - val_loss: 4063532980.7489\n",
      "Epoch 7523/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1383720134.3875 - val_loss: 4062932644.6758\n",
      "Epoch 7524/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1385835355.3033 - val_loss: 4053408371.8721\n",
      "Epoch 7525/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1384218536.3288 - val_loss: 4060411443.8721\n",
      "Epoch 7526/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1383439029.8552 - val_loss: 4068135867.6164\n",
      "Epoch 7527/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383081642.8337 - val_loss: 4060416653.4429\n",
      "Epoch 7528/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1383750849.1272 - val_loss: 4066710755.5068\n",
      "Epoch 7529/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1385898796.0861 - val_loss: 4055759292.7854\n",
      "Epoch 7530/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1384069910.2935 - val_loss: 4057073221.6986\n",
      "Epoch 7531/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1383199359.8748 - val_loss: 4057459073.0228\n",
      "Epoch 7532/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1386625384.7671 - val_loss: 4054619087.9269\n",
      "Epoch 7533/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1385400216.2975 - val_loss: 4074022113.6073\n",
      "Epoch 7534/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383553744.0313 - val_loss: 4051158297.7169\n",
      "Epoch 7535/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1383876703.4364 - val_loss: 4062614042.8858\n",
      "Epoch 7536/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383774349.6517 - val_loss: 4057485212.6393\n",
      "Epoch 7537/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1385428433.1585 - val_loss: 4054351566.9041\n",
      "Epoch 7538/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1383306546.2231 - val_loss: 4061830615.9635\n",
      "Epoch 7539/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1383329205.8552 - val_loss: 4058624210.8493\n",
      "Epoch 7540/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1383075030.7319 - val_loss: 4064591819.2511\n",
      "Epoch 7541/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1384812863.4990 - val_loss: 4070118017.6073\n",
      "Epoch 7542/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1383322305.3777 - val_loss: 4072459716.2374\n",
      "Epoch 7543/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1383809815.7965 - val_loss: 4071528343.6712\n",
      "Epoch 7544/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1385676419.0059 - val_loss: 4055085615.9269\n",
      "Epoch 7545/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1384081210.6145 - val_loss: 4057187483.1781\n",
      "Epoch 7546/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1383913170.1605 - val_loss: 4062163869.0776\n",
      "Epoch 7547/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1383255718.1996 - val_loss: 4061758124.1279\n",
      "Epoch 7548/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1384775631.9061 - val_loss: 4066651430.1370\n",
      "Epoch 7549/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1384860956.3679 - val_loss: 4051141315.0685\n",
      "Epoch 7550/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1383320004.7593 - val_loss: 4066061308.0548\n",
      "Epoch 7551/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1384896485.9491 - val_loss: 4067898958.9041\n",
      "Epoch 7552/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1384919121.7847 - val_loss: 4057286888.4749\n",
      "Epoch 7553/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1383797357.4638 - val_loss: 4066634269.9543\n",
      "Epoch 7554/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1383411890.3483 - val_loss: 4064896715.2511\n",
      "Epoch 7555/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1384086316.4618 - val_loss: 4060584095.8539\n",
      "Epoch 7556/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1386451325.2446 - val_loss: 4081805018.5936\n",
      "Epoch 7557/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1386510977.2524 - val_loss: 4087098200.5479\n",
      "Epoch 7558/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383255325.0568 - val_loss: 4040232264.1826\n",
      "Epoch 7559/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1384012168.7671 - val_loss: 4051622868.6027\n",
      "Epoch 7560/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1382922178.6301 - val_loss: 4053169227.5434\n",
      "Epoch 7561/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1385076617.3933 - val_loss: 4062708126.8311\n",
      "Epoch 7562/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1383592108.7123 - val_loss: 4059318051.2146\n",
      "Epoch 7563/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1383282628.6341 - val_loss: 4052240074.8128\n",
      "Epoch 7564/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1383213971.7886 - val_loss: 4071405138.9954\n",
      "Epoch 7565/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1383949830.2622 - val_loss: 4059871177.2055\n",
      "Epoch 7566/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1383091141.4481 - val_loss: 4062067174.1370\n",
      "Epoch 7567/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1383038656.8767 - val_loss: 4062454647.2329\n",
      "Epoch 7568/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 54us/step - loss: 1384564424.3914 - val_loss: 4063526448.9498\n",
      "Epoch 7569/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1383925925.5734 - val_loss: 4048430532.6758\n",
      "Epoch 7570/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1385541544.7045 - val_loss: 4063463626.0822\n",
      "Epoch 7571/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1382906468.6967 - val_loss: 4062620050.2648\n",
      "Epoch 7572/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1383583129.5499 - val_loss: 4054058291.1416\n",
      "Epoch 7573/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1383961218.7554 - val_loss: 4055533882.1553\n",
      "Epoch 7574/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1383226872.9863 - val_loss: 4054834177.8995\n",
      "Epoch 7575/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1383209365.6673 - val_loss: 4066119015.5982\n",
      "Epoch 7576/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1383539323.2407 - val_loss: 4052561596.7854\n",
      "Epoch 7577/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1383422400.4384 - val_loss: 4060801336.8402\n",
      "Epoch 7578/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1383373620.1018 - val_loss: 4064329247.7078\n",
      "Epoch 7579/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1384115852.5245 - val_loss: 4059874879.4155\n",
      "Epoch 7580/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1384017041.9100 - val_loss: 4058804401.0959\n",
      "Epoch 7581/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1383409088.3757 - val_loss: 4062694067.2877\n",
      "Epoch 7582/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1384208958.7476 - val_loss: 4062238871.2329\n",
      "Epoch 7583/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1382866070.7945 - val_loss: 4056638043.3242\n",
      "Epoch 7584/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1383916178.1605 - val_loss: 4060254890.8128\n",
      "Epoch 7585/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1385951283.2250 - val_loss: 4063387721.0594\n",
      "Epoch 7586/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1386769129.5812 - val_loss: 4063760837.4064\n",
      "Epoch 7587/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1383042464.0000 - val_loss: 4061380707.6530\n",
      "Epoch 7588/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1384774525.7456 - val_loss: 4071696445.6621\n",
      "Epoch 7589/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1383784320.6262 - val_loss: 4055382680.6941\n",
      "Epoch 7590/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1383986949.2603 - val_loss: 4060587696.9498\n",
      "Epoch 7591/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1383183356.2427 - val_loss: 4061375039.4155\n",
      "Epoch 7592/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1386041449.7065 - val_loss: 4063788789.1872\n",
      "Epoch 7593/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1385517546.2074 - val_loss: 4069360394.9589\n",
      "Epoch 7594/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1383372184.5479 - val_loss: 4074336390.2831\n",
      "Epoch 7595/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1384284532.4775 - val_loss: 4055407757.7352\n",
      "Epoch 7596/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1383443502.8415 - val_loss: 4068111528.3288\n",
      "Epoch 7597/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1383132154.6145 - val_loss: 4062966624.2922\n",
      "Epoch 7598/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1382746747.7417 - val_loss: 4054410875.3242\n",
      "Epoch 7599/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1384180784.7828 - val_loss: 4057027793.6804\n",
      "Epoch 7600/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1384461160.9550 - val_loss: 4058017941.1872\n",
      "Epoch 7601/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1382826656.0626 - val_loss: 4070057215.5616\n",
      "Epoch 7602/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1385157946.4892 - val_loss: 4065600648.7671\n",
      "Epoch 7603/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1383533287.4521 - val_loss: 4059862137.8630\n",
      "Epoch 7604/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1383370641.0333 - val_loss: 4058578217.9361\n",
      "Epoch 7605/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383500436.1644 - val_loss: 4069441675.1050\n",
      "Epoch 7606/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1384899367.0763 - val_loss: 4062541935.0502\n",
      "Epoch 7607/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1386122937.9883 - val_loss: 4065921042.4110\n",
      "Epoch 7608/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1383499065.9883 - val_loss: 4075520959.2694\n",
      "Epoch 7609/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1384946486.6067 - val_loss: 4076661751.9635\n",
      "Epoch 7610/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1383591178.5205 - val_loss: 4065742409.3516\n",
      "Epoch 7611/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1384210909.9335 - val_loss: 4055011749.1142\n",
      "Epoch 7612/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1383952891.7417 - val_loss: 4048827671.5251\n",
      "Epoch 7613/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1383716516.4462 - val_loss: 4054861788.2009\n",
      "Epoch 7614/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1383869666.9432 - val_loss: 4066627364.5297\n",
      "Epoch 7615/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1383981868.0861 - val_loss: 4072322983.7443\n",
      "Epoch 7616/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1383793629.8082 - val_loss: 4069974475.3973\n",
      "Epoch 7617/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1383290995.9765 - val_loss: 4067757425.5342\n",
      "Epoch 7618/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1382902346.7710 - val_loss: 4056086275.3607\n",
      "Epoch 7619/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1384346612.7280 - val_loss: 4067601434.7397\n",
      "Epoch 7620/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1383422512.2192 - val_loss: 4064914019.7991\n",
      "Epoch 7621/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1383450400.5636 - val_loss: 4051391389.5160\n",
      "Epoch 7622/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1383843477.7299 - val_loss: 4043286037.6256\n",
      "Epoch 7623/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1385568620.7123 - val_loss: 4085192016.6575\n",
      "Epoch 7624/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1384632796.4305 - val_loss: 4052996602.4475\n",
      "Epoch 7625/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1383345110.6693 - val_loss: 4055609340.0548\n",
      "Epoch 7626/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1383687155.4755 - val_loss: 4066675895.0868\n",
      "Epoch 7627/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1383318971.2407 - val_loss: 4066176972.4201\n",
      "Epoch 7628/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383296190.3718 - val_loss: 4078849008.5114\n",
      "Epoch 7629/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1386656884.9785 - val_loss: 4051428023.3790\n",
      "Epoch 7630/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1382381207.2955 - val_loss: 4063804120.1096\n",
      "Epoch 7631/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1383266703.9061 - val_loss: 4069065016.9863\n",
      "Epoch 7632/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 42us/step - loss: 1385631238.0117 - val_loss: 4052682984.1826\n",
      "Epoch 7633/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1383838961.4716 - val_loss: 4079879416.6941\n",
      "Epoch 7634/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1385163736.4227 - val_loss: 4068231331.5068\n",
      "Epoch 7635/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1384075213.1507 - val_loss: 4071101055.7078\n",
      "Epoch 7636/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1384948773.5734 - val_loss: 4076189142.6484\n",
      "Epoch 7637/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383535877.1350 - val_loss: 4047029561.4247\n",
      "Epoch 7638/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1384144192.5010 - val_loss: 4065768229.8447\n",
      "Epoch 7639/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1384039551.4990 - val_loss: 4051581588.7489\n",
      "Epoch 7640/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1383270422.2309 - val_loss: 4062462643.8721\n",
      "Epoch 7641/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1384143848.9550 - val_loss: 4060449338.7397\n",
      "Epoch 7642/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1385064691.7260 - val_loss: 4063187991.6712\n",
      "Epoch 7643/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1384037237.7299 - val_loss: 4064444235.1050\n",
      "Epoch 7644/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1383327210.2074 - val_loss: 4065608462.1735\n",
      "Epoch 7645/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1385319637.2916 - val_loss: 4046786421.1872\n",
      "Epoch 7646/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1383777298.1605 - val_loss: 4058604088.6941\n",
      "Epoch 7647/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1382745031.8904 - val_loss: 4072313404.3470\n",
      "Epoch 7648/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1383977745.7847 - val_loss: 4061541048.5479\n",
      "Epoch 7649/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1384207358.4971 - val_loss: 4059343904.1461\n",
      "Epoch 7650/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383813083.3033 - val_loss: 4069526495.4155\n",
      "Epoch 7651/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1382637816.2348 - val_loss: 4056051524.5297\n",
      "Epoch 7652/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1383997426.2231 - val_loss: 4060273092.8219\n",
      "Epoch 7653/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1384453336.2348 - val_loss: 4074560896.0000\n",
      "Epoch 7654/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1383273130.0822 - val_loss: 4052985843.5799\n",
      "Epoch 7655/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1382964793.3620 - val_loss: 4061069263.7808\n",
      "Epoch 7656/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1382997109.7299 - val_loss: 4061692104.0365\n",
      "Epoch 7657/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1386355835.2407 - val_loss: 4049335896.4018\n",
      "Epoch 7658/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1382084101.5108 - val_loss: 4064952912.8037\n",
      "Epoch 7659/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383451475.6634 - val_loss: 4075978433.1689\n",
      "Epoch 7660/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383988283.1155 - val_loss: 4067227622.7215\n",
      "Epoch 7661/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1383374589.9961 - val_loss: 4070207047.7443\n",
      "Epoch 7662/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1383651219.2877 - val_loss: 4061477910.3562\n",
      "Epoch 7663/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1382544472.5479 - val_loss: 4062009441.8995\n",
      "Epoch 7664/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1383119744.0626 - val_loss: 4061526175.7078\n",
      "Epoch 7665/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1383679864.2348 - val_loss: 4062496421.2603\n",
      "Epoch 7666/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1383656211.8513 - val_loss: 4070341524.4566\n",
      "Epoch 7667/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383038685.1194 - val_loss: 4067370492.9315\n",
      "Epoch 7668/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1383941893.3855 - val_loss: 4064008092.4932\n",
      "Epoch 7669/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1383655520.5010 - val_loss: 4056945433.2785\n",
      "Epoch 7670/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1386506332.1800 - val_loss: 4063272229.5525\n",
      "Epoch 7671/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1384047965.1820 - val_loss: 4074500618.6667\n",
      "Epoch 7672/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1386202452.7906 - val_loss: 4041921175.2329\n",
      "Epoch 7673/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1384702667.5225 - val_loss: 4065876327.8904\n",
      "Epoch 7674/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1384383625.2681 - val_loss: 4062772038.8676\n",
      "Epoch 7675/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1382874998.7319 - val_loss: 4065918087.0137\n",
      "Epoch 7676/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1383972782.8415 - val_loss: 4052163533.8813\n",
      "Epoch 7677/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1384388392.3288 - val_loss: 4063969797.6986\n",
      "Epoch 7678/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1384267104.6888 - val_loss: 4065431922.5571\n",
      "Epoch 7679/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1384970782.0587 - val_loss: 4049347411.5799\n",
      "Epoch 7680/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1384666259.4129 - val_loss: 4069299603.1416\n",
      "Epoch 7681/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1382504655.9061 - val_loss: 4064942010.5936\n",
      "Epoch 7682/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1383283383.1076 - val_loss: 4069469194.2283\n",
      "Epoch 7683/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1382732917.8552 - val_loss: 4058419190.3562\n",
      "Epoch 7684/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1383570570.5205 - val_loss: 4066014226.9954\n",
      "Epoch 7685/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1383377885.9335 - val_loss: 4049182400.7306\n",
      "Epoch 7686/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1383644990.6223 - val_loss: 4059734789.2603\n",
      "Epoch 7687/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1384405889.5029 - val_loss: 4074534858.8128\n",
      "Epoch 7688/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1382568434.7241 - val_loss: 4063712284.9315\n",
      "Epoch 7689/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1385349184.3757 - val_loss: 4048152175.0502\n",
      "Epoch 7690/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1383185005.8395 - val_loss: 4072520620.8584\n",
      "Epoch 7691/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1382623318.9198 - val_loss: 4062443995.0320\n",
      "Epoch 7692/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1383880395.3973 - val_loss: 4057226575.9269\n",
      "Epoch 7693/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1383378876.9941 - val_loss: 4069783836.4932\n",
      "Epoch 7694/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1386403691.2094 - val_loss: 4092635927.8174\n",
      "Epoch 7695/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1381922019.1937 - val_loss: 4049224246.0639\n",
      "Epoch 7696/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 54us/step - loss: 1385711626.1448 - val_loss: 4071291883.8356\n",
      "Epoch 7697/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1384335220.9785 - val_loss: 4061204036.0913\n",
      "Epoch 7698/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1383836170.2701 - val_loss: 4056980587.1050\n",
      "Epoch 7699/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1383616726.9198 - val_loss: 4049858753.6073\n",
      "Epoch 7700/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1385936348.1800 - val_loss: 4053853474.7763\n",
      "Epoch 7701/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1382279417.3620 - val_loss: 4065235138.9224\n",
      "Epoch 7702/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1382545356.9002 - val_loss: 4062535734.6484\n",
      "Epoch 7703/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1383300947.4755 - val_loss: 4063256420.0913\n",
      "Epoch 7704/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1383416971.7730 - val_loss: 4069191240.6210\n",
      "Epoch 7705/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1382559007.9374 - val_loss: 4060612782.3196\n",
      "Epoch 7706/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1384498555.2407 - val_loss: 4047667249.5342\n",
      "Epoch 7707/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1382472329.2681 - val_loss: 4062637219.2146\n",
      "Epoch 7708/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1383991711.9374 - val_loss: 4073563563.3973\n",
      "Epoch 7709/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1387213702.3875 - val_loss: 4058086152.4749\n",
      "Epoch 7710/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1382796333.8395 - val_loss: 4068250416.3653\n",
      "Epoch 7711/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1383203551.8121 - val_loss: 4073035461.9909\n",
      "Epoch 7712/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1382879706.4266 - val_loss: 4063099577.8630\n",
      "Epoch 7713/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1382918690.0665 - val_loss: 4069457059.9452\n",
      "Epoch 7714/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1384029032.7045 - val_loss: 4052483384.6941\n",
      "Epoch 7715/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1383739908.2583 - val_loss: 4072983330.4840\n",
      "Epoch 7716/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1383177088.2505 - val_loss: 4054796938.0822\n",
      "Epoch 7717/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1383313548.0235 - val_loss: 4059590966.5023\n",
      "Epoch 7718/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1382880383.6243 - val_loss: 4066214818.0457\n",
      "Epoch 7719/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1382824101.8239 - val_loss: 4067132127.1233\n",
      "Epoch 7720/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1382566265.6125 - val_loss: 4057960914.9954\n",
      "Epoch 7721/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1383769412.1331 - val_loss: 4055031567.7808\n",
      "Epoch 7722/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1383016775.1389 - val_loss: 4058888368.9498\n",
      "Epoch 7723/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1383506262.1683 - val_loss: 4061588637.5160\n",
      "Epoch 7724/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1383227737.6751 - val_loss: 4085078169.2785\n",
      "Epoch 7725/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1383702087.8904 - val_loss: 4079161984.7306\n",
      "Epoch 7726/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1386409756.5558 - val_loss: 4055737345.1689\n",
      "Epoch 7727/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1381925321.0176 - val_loss: 4067436174.6119\n",
      "Epoch 7728/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1383478558.8102 - val_loss: 4059982619.1781\n",
      "Epoch 7729/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1385616399.1546 - val_loss: 4090305662.6849\n",
      "Epoch 7730/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1383915778.0039 - val_loss: 4056802791.3059\n",
      "Epoch 7731/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1382697530.6145 - val_loss: 4064403649.4612\n",
      "Epoch 7732/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383866250.2701 - val_loss: 4058339840.8767\n",
      "Epoch 7733/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1382865817.8004 - val_loss: 4065319127.5251\n",
      "Epoch 7734/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1382793750.5440 - val_loss: 4064266834.4110\n",
      "Epoch 7735/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1383712425.3307 - val_loss: 4057544606.2466\n",
      "Epoch 7736/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1383263858.2231 - val_loss: 4082389467.0320\n",
      "Epoch 7737/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1382475214.1526 - val_loss: 4061114381.8813\n",
      "Epoch 7738/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1383059582.4971 - val_loss: 4060335931.3242\n",
      "Epoch 7739/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1383564610.3796 - val_loss: 4059438344.7671\n",
      "Epoch 7740/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383239717.0724 - val_loss: 4066332437.3333\n",
      "Epoch 7741/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1384346305.1272 - val_loss: 4073095588.8219\n",
      "Epoch 7742/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1382007407.4677 - val_loss: 4051235620.3836\n",
      "Epoch 7743/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1384031715.6947 - val_loss: 4060066721.4612\n",
      "Epoch 7744/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1383488854.4188 - val_loss: 4063846671.7808\n",
      "Epoch 7745/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1384816827.6164 - val_loss: 4074553695.8539\n",
      "Epoch 7746/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1381835642.2387 - val_loss: 4055165926.7215\n",
      "Epoch 7747/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1384085859.6321 - val_loss: 4066019795.8721\n",
      "Epoch 7748/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1384982960.0939 - val_loss: 4046990309.8447\n",
      "Epoch 7749/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1384732987.8669 - val_loss: 4060548670.8311\n",
      "Epoch 7750/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1383305402.1135 - val_loss: 4069846117.1142\n",
      "Epoch 7751/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1385276346.4892 - val_loss: 4079669551.0502\n",
      "Epoch 7752/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1384606511.6556 - val_loss: 4057008456.9132\n",
      "Epoch 7753/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1382997386.3327 - val_loss: 4064232840.0365\n",
      "Epoch 7754/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1384619700.3523 - val_loss: 4081645473.1689\n",
      "Epoch 7755/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383868498.1605 - val_loss: 4079978286.0274\n",
      "Epoch 7756/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1382964623.0294 - val_loss: 4051195603.5799\n",
      "Epoch 7757/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1382469516.5245 - val_loss: 4055517423.4886\n",
      "Epoch 7758/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1385066995.4129 - val_loss: 4054865416.9132\n",
      "Epoch 7759/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1383969834.7084 - val_loss: 4077815776.0000\n",
      "Epoch 7760/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 47us/step - loss: 1383271634.6614 - val_loss: 4056579586.6301\n",
      "Epoch 7761/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1382965065.6438 - val_loss: 4062125046.0639\n",
      "Epoch 7762/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1384771820.2114 - val_loss: 4053198495.5616\n",
      "Epoch 7763/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1382421183.2485 - val_loss: 4068313285.9909\n",
      "Epoch 7764/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383622497.1898 - val_loss: 4068926703.6347\n",
      "Epoch 7765/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1382326621.4325 - val_loss: 4065147347.7260\n",
      "Epoch 7766/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1382927691.6477 - val_loss: 4066766344.1826\n",
      "Epoch 7767/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1382386107.4286 - val_loss: 4055117551.1963\n",
      "Epoch 7768/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1383441992.6419 - val_loss: 4055485124.9680\n",
      "Epoch 7769/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1384161229.1507 - val_loss: 4063970705.0959\n",
      "Epoch 7770/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1383748170.6458 - val_loss: 4053247504.3653\n",
      "Epoch 7771/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1383365730.1918 - val_loss: 4063093820.6393\n",
      "Epoch 7772/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383228247.0450 - val_loss: 4067659751.1598\n",
      "Epoch 7773/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1382743909.1977 - val_loss: 4062729792.1461\n",
      "Epoch 7774/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1383021409.8160 - val_loss: 4057649173.4795\n",
      "Epoch 7775/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1382301891.5068 - val_loss: 4072143595.3973\n",
      "Epoch 7776/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1383166732.9002 - val_loss: 4069950901.6256\n",
      "Epoch 7777/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1382649398.6067 - val_loss: 4064503932.9315\n",
      "Epoch 7778/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1384375894.5440 - val_loss: 4056427234.7763\n",
      "Epoch 7779/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1382750904.2348 - val_loss: 4068284478.5388\n",
      "Epoch 7780/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383237147.0528 - val_loss: 4077275450.7397\n",
      "Epoch 7781/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1383009262.4658 - val_loss: 4073679824.9498\n",
      "Epoch 7782/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1384287598.2153 - val_loss: 4048398920.1826\n",
      "Epoch 7783/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1381402442.5205 - val_loss: 4067111010.4840\n",
      "Epoch 7784/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1383440247.2329 - val_loss: 4063780625.0959\n",
      "Epoch 7785/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1383681542.2622 - val_loss: 4070784412.9315\n",
      "Epoch 7786/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383343154.9746 - val_loss: 4064936236.5662\n",
      "Epoch 7787/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1383245596.9315 - val_loss: 4053716661.1872\n",
      "Epoch 7788/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1386116108.0861 - val_loss: 4080452511.2694\n",
      "Epoch 7789/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1383679389.0568 - val_loss: 4053839779.7991\n",
      "Epoch 7790/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1382435701.5421 - val_loss: 4065154299.6164\n",
      "Epoch 7791/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1383168498.7241 - val_loss: 4053204855.9635\n",
      "Epoch 7792/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1383179220.4149 - val_loss: 4063796319.1233\n",
      "Epoch 7793/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1382109835.2720 - val_loss: 4066032657.3881\n",
      "Epoch 7794/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1382737596.3679 - val_loss: 4060214347.3973\n",
      "Epoch 7795/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1385820940.7750 - val_loss: 4082322708.7489\n",
      "Epoch 7796/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1382389284.0705 - val_loss: 4056043649.8995\n",
      "Epoch 7797/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1382281212.4305 - val_loss: 4062697984.4384\n",
      "Epoch 7798/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1383415749.3855 - val_loss: 4065866748.7854\n",
      "Epoch 7799/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1382183409.7221 - val_loss: 4069829074.9954\n",
      "Epoch 7800/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1384141459.9139 - val_loss: 4054346069.0411\n",
      "Epoch 7801/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1382344641.8787 - val_loss: 4080819081.2055\n",
      "Epoch 7802/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1383643234.9432 - val_loss: 4061731426.7763\n",
      "Epoch 7803/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1384852282.6145 - val_loss: 4062384218.3014\n",
      "Epoch 7804/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1384556608.3757 - val_loss: 4057740259.7991\n",
      "Epoch 7805/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1382542107.8043 - val_loss: 4059370925.4429\n",
      "Epoch 7806/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1382787758.8415 - val_loss: 4064697457.3881\n",
      "Epoch 7807/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1383437046.4814 - val_loss: 4089559791.3425\n",
      "Epoch 7808/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1381887719.4521 - val_loss: 4071472904.9132\n",
      "Epoch 7809/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1383577192.7045 - val_loss: 4076098302.6849\n",
      "Epoch 7810/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1383132182.5440 - val_loss: 4049101380.3836\n",
      "Epoch 7811/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1383127552.3757 - val_loss: 4072117628.0548\n",
      "Epoch 7812/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1382279859.8513 - val_loss: 4069751732.4566\n",
      "Epoch 7813/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1382833618.2857 - val_loss: 4063333376.7306\n",
      "Epoch 7814/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1382879594.2074 - val_loss: 4066243666.7032\n",
      "Epoch 7815/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1382058056.1409 - val_loss: 4061222170.0091\n",
      "Epoch 7816/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1382195310.7162 - val_loss: 4059551490.3379\n",
      "Epoch 7817/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1383489501.3072 - val_loss: 4061037412.5297\n",
      "Epoch 7818/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1381973277.3072 - val_loss: 4071867070.8311\n",
      "Epoch 7819/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1382612671.1233 - val_loss: 4078834226.9954\n",
      "Epoch 7820/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1382383826.7867 - val_loss: 4061448444.7854\n",
      "Epoch 7821/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1382148610.5049 - val_loss: 4065088368.5114\n",
      "Epoch 7822/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1382440435.4755 - val_loss: 4071864956.9315\n",
      "Epoch 7823/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1384169388.0861 - val_loss: 4075167216.5114\n",
      "Epoch 7824/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383633334.1057 - val_loss: 4048253747.2877\n",
      "Epoch 7825/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1382698015.5616 - val_loss: 4077913115.6164\n",
      "Epoch 7826/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1382634920.5166 - val_loss: 4069781166.6119\n",
      "Epoch 7827/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1383622641.9726 - val_loss: 4054176908.8584\n",
      "Epoch 7828/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1382382792.8924 - val_loss: 4066671960.5479\n",
      "Epoch 7829/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1384718285.1507 - val_loss: 4083610248.1826\n",
      "Epoch 7830/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1386268280.2348 - val_loss: 4054802167.2329\n",
      "Epoch 7831/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1384215592.5793 - val_loss: 4070794034.4110\n",
      "Epoch 7832/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1390614536.7671 - val_loss: 4053886447.4886\n",
      "Epoch 7833/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383532415.1233 - val_loss: 4071583852.1279\n",
      "Epoch 7834/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383692440.1722 - val_loss: 4070095761.0959\n",
      "Epoch 7835/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1383243391.7495 - val_loss: 4059676785.8265\n",
      "Epoch 7836/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1383589729.9413 - val_loss: 4066106420.7489\n",
      "Epoch 7837/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1382216731.0528 - val_loss: 4069570711.3790\n",
      "Epoch 7838/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1384901382.7632 - val_loss: 4078423820.5662\n",
      "Epoch 7839/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1382801945.5499 - val_loss: 4059784218.4475\n",
      "Epoch 7840/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1382277439.8748 - val_loss: 4054970860.1279\n",
      "Epoch 7841/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1384728407.1703 - val_loss: 4063226218.8128\n",
      "Epoch 7842/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383266964.5401 - val_loss: 4061664511.4155\n",
      "Epoch 7843/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1382054410.1448 - val_loss: 4067543681.7534\n",
      "Epoch 7844/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1382339712.0000 - val_loss: 4065828792.4018\n",
      "Epoch 7845/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383390273.0020 - val_loss: 4063334450.5571\n",
      "Epoch 7846/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1382341777.5342 - val_loss: 4070965457.5342\n",
      "Epoch 7847/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383970595.8200 - val_loss: 4057362409.9361\n",
      "Epoch 7848/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1383371734.4188 - val_loss: 4081875748.8219\n",
      "Epoch 7849/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1383793825.8160 - val_loss: 4052007767.3790\n",
      "Epoch 7850/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1382460315.8043 - val_loss: 4072290157.2968\n",
      "Epoch 7851/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1382651031.6712 - val_loss: 4068934187.5434\n",
      "Epoch 7852/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1381726884.4462 - val_loss: 4067315301.5525\n",
      "Epoch 7853/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1383353917.1194 - val_loss: 4054880785.5342\n",
      "Epoch 7854/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1382486266.4892 - val_loss: 4067490552.4018\n",
      "Epoch 7855/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383912904.3914 - val_loss: 4075192823.8174\n",
      "Epoch 7856/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1381730015.6869 - val_loss: 4062131154.9954\n",
      "Epoch 7857/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1381849129.8317 - val_loss: 4058852471.9635\n",
      "Epoch 7858/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1384383993.6125 - val_loss: 4065606194.2648\n",
      "Epoch 7859/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1383418933.3542 - val_loss: 4055413131.9817\n",
      "Epoch 7860/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1382339749.9491 - val_loss: 4073905440.0000\n",
      "Epoch 7861/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1382327973.9491 - val_loss: 4067581775.6347\n",
      "Epoch 7862/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1382345427.9139 - val_loss: 4070148108.4201\n",
      "Epoch 7863/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1382356687.0294 - val_loss: 4074037400.4018\n",
      "Epoch 7864/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1383736497.7221 - val_loss: 4066427328.0000\n",
      "Epoch 7865/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1382244500.2896 - val_loss: 4060531271.1598\n",
      "Epoch 7866/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1383644350.3092 - val_loss: 4068490744.9863\n",
      "Epoch 7867/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1383478948.4462 - val_loss: 4065791063.3790\n",
      "Epoch 7868/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1382851842.2544 - val_loss: 4070754697.4977\n",
      "Epoch 7869/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1382460012.7123 - val_loss: 4066170125.5890\n",
      "Epoch 7870/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1381793081.8630 - val_loss: 4069767452.6393\n",
      "Epoch 7871/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1382667801.6751 - val_loss: 4058636968.9132\n",
      "Epoch 7872/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1382987645.9961 - val_loss: 4065737194.2283\n",
      "Epoch 7873/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1382456239.0920 - val_loss: 4063358227.8721\n",
      "Epoch 7874/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1385485656.0470 - val_loss: 4058472331.5434\n",
      "Epoch 7875/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1382847089.2211 - val_loss: 4057589847.6712\n",
      "Epoch 7876/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1382855915.2094 - val_loss: 4074268710.7215\n",
      "Epoch 7877/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1383272180.4775 - val_loss: 4061988705.3151\n",
      "Epoch 7878/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1383028647.0763 - val_loss: 4075852463.1963\n",
      "Epoch 7879/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1383265014.9824 - val_loss: 4063033207.0868\n",
      "Epoch 7880/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1381568563.0372 - val_loss: 4063593094.2831\n",
      "Epoch 7881/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1384426230.2309 - val_loss: 4062701603.7991\n",
      "Epoch 7882/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1383022272.3757 - val_loss: 4064184436.4566\n",
      "Epoch 7883/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1381971476.5401 - val_loss: 4072212841.9361\n",
      "Epoch 7884/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383090554.8650 - val_loss: 4065863876.6758\n",
      "Epoch 7885/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1383569769.0176 - val_loss: 4071758818.7763\n",
      "Epoch 7886/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1382159046.2622 - val_loss: 4072527982.3196\n",
      "Epoch 7887/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1385960975.1546 - val_loss: 4075036431.9269\n",
      "Epoch 7888/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 50us/step - loss: 1386566127.4677 - val_loss: 4052110585.5708\n",
      "Epoch 7889/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1384926987.0215 - val_loss: 4071683718.5753\n",
      "Epoch 7890/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1383063754.1448 - val_loss: 4055073248.0000\n",
      "Epoch 7891/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1382474074.1761 - val_loss: 4059252388.0913\n",
      "Epoch 7892/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1383111554.0039 - val_loss: 4058746454.5023\n",
      "Epoch 7893/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1385970784.3131 - val_loss: 4077942483.2877\n",
      "Epoch 7894/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1381950573.0881 - val_loss: 4075332938.3744\n",
      "Epoch 7895/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1383223427.0059 - val_loss: 4055474892.8584\n",
      "Epoch 7896/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1383742087.2642 - val_loss: 4069000697.7169\n",
      "Epoch 7897/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1382190313.9569 - val_loss: 4057052220.9315\n",
      "Epoch 7898/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1382020579.6947 - val_loss: 4059240028.7854\n",
      "Epoch 7899/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1382324874.0196 - val_loss: 4075643465.4977\n",
      "Epoch 7900/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1382656231.7652 - val_loss: 4061830927.7808\n",
      "Epoch 7901/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1382733407.4364 - val_loss: 4057433883.1781\n",
      "Epoch 7902/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1382811254.4814 - val_loss: 4078400426.5205\n",
      "Epoch 7903/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1381737811.2877 - val_loss: 4071683038.8311\n",
      "Epoch 7904/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1382304041.0802 - val_loss: 4057234455.2329\n",
      "Epoch 7905/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1382882816.2505 - val_loss: 4061159564.2740\n",
      "Epoch 7906/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1385502906.1135 - val_loss: 4065008974.7580\n",
      "Epoch 7907/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1382165362.0978 - val_loss: 4062090683.0320\n",
      "Epoch 7908/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1382616069.2603 - val_loss: 4055989715.5799\n",
      "Epoch 7909/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1385485089.5656 - val_loss: 4076975691.6895\n",
      "Epoch 7910/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1381408985.4247 - val_loss: 4058846587.9087\n",
      "Epoch 7911/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1382368113.3464 - val_loss: 4067094378.3744\n",
      "Epoch 7912/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1382139336.8924 - val_loss: 4059485420.7123\n",
      "Epoch 7913/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1382545560.0470 - val_loss: 4073083834.5936\n",
      "Epoch 7914/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383785367.7965 - val_loss: 4077371566.0274\n",
      "Epoch 7915/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1383078959.0920 - val_loss: 4057585728.8767\n",
      "Epoch 7916/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1381630551.6712 - val_loss: 4067214407.7443\n",
      "Epoch 7917/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1382445594.3014 - val_loss: 4060989523.2877\n",
      "Epoch 7918/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1382027201.1272 - val_loss: 4072188115.2877\n",
      "Epoch 7919/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1382758967.8591 - val_loss: 4058100188.4932\n",
      "Epoch 7920/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1382629008.8454 - val_loss: 4074596616.6210\n",
      "Epoch 7921/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1383553615.2798 - val_loss: 4062863306.6667\n",
      "Epoch 7922/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1382835833.2368 - val_loss: 4065215371.6895\n",
      "Epoch 7923/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1381698550.9824 - val_loss: 4060991455.4155\n",
      "Epoch 7924/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1381988546.0039 - val_loss: 4059099454.2466\n",
      "Epoch 7925/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1381972797.1194 - val_loss: 4061850272.8767\n",
      "Epoch 7926/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1382365654.6693 - val_loss: 4060823069.0776\n",
      "Epoch 7927/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1382661695.1233 - val_loss: 4059763131.6164\n",
      "Epoch 7928/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383260525.2133 - val_loss: 4080331175.8904\n",
      "Epoch 7929/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1384160945.4716 - val_loss: 4063250486.2100\n",
      "Epoch 7930/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1384591746.7554 - val_loss: 4092113728.4384\n",
      "Epoch 7931/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1381107119.4677 - val_loss: 4065957288.4749\n",
      "Epoch 7932/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1382654485.0411 - val_loss: 4070668455.5982\n",
      "Epoch 7933/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1384472632.6106 - val_loss: 4054462753.6073\n",
      "Epoch 7934/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1387124105.8943 - val_loss: 4070284465.9726\n",
      "Epoch 7935/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1383815392.0626 - val_loss: 4044817630.9772\n",
      "Epoch 7936/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1382040124.6184 - val_loss: 4070774346.3744\n",
      "Epoch 7937/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1382687575.9217 - val_loss: 4061943481.1324\n",
      "Epoch 7938/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1382929148.9941 - val_loss: 4062651832.6941\n",
      "Epoch 7939/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1382120202.5205 - val_loss: 4076106869.3333\n",
      "Epoch 7940/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1382326467.3816 - val_loss: 4074593616.2192\n",
      "Epoch 7941/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1382685842.7867 - val_loss: 4056119595.1050\n",
      "Epoch 7942/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383583389.8082 - val_loss: 4052966382.3196\n",
      "Epoch 7943/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1382805313.1272 - val_loss: 4066218072.4018\n",
      "Epoch 7944/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1384559942.5127 - val_loss: 4072048663.0868\n",
      "Epoch 7945/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1381465216.5010 - val_loss: 4074608288.1461\n",
      "Epoch 7946/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1382060314.8023 - val_loss: 4077421285.6986\n",
      "Epoch 7947/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1382187523.3190 - val_loss: 4073473123.6530\n",
      "Epoch 7948/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1382854935.6712 - val_loss: 4054082645.0411\n",
      "Epoch 7949/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1383036866.0039 - val_loss: 4070295982.1735\n",
      "Epoch 7950/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1383584502.9824 - val_loss: 4067945174.6484\n",
      "Epoch 7951/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1383287159.2329 - val_loss: 4082413945.7169\n",
      "Epoch 7952/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 47us/step - loss: 1381758195.8513 - val_loss: 4064659998.6849\n",
      "Epoch 7953/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1383054990.7789 - val_loss: 4073440682.6667\n",
      "Epoch 7954/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1381125018.3014 - val_loss: 4063352431.7808\n",
      "Epoch 7955/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1382491832.8611 - val_loss: 4060519927.0868\n",
      "Epoch 7956/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1381333803.8356 - val_loss: 4066923843.9452\n",
      "Epoch 7957/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1382189606.5753 - val_loss: 4080376419.7991\n",
      "Epoch 7958/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1382167265.8160 - val_loss: 4059073172.1644\n",
      "Epoch 7959/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1382531622.8258 - val_loss: 4057334807.5251\n",
      "Epoch 7960/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1384080416.3131 - val_loss: 4061383115.6895\n",
      "Epoch 7961/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1381688516.8845 - val_loss: 4076014114.3379\n",
      "Epoch 7962/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1382071940.5088 - val_loss: 4067306445.7352\n",
      "Epoch 7963/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1383226690.1292 - val_loss: 4065034678.9406\n",
      "Epoch 7964/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1382828890.1761 - val_loss: 4072847844.8219\n",
      "Epoch 7965/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1382393821.9335 - val_loss: 4073528288.1461\n",
      "Epoch 7966/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1384751092.4775 - val_loss: 4079629119.2694\n",
      "Epoch 7967/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1381345897.0802 - val_loss: 4068880150.3562\n",
      "Epoch 7968/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1385442782.6849 - val_loss: 4090103339.1050\n",
      "Epoch 7969/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1388332328.3288 - val_loss: 4049157503.5616\n",
      "Epoch 7970/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1383540469.2290 - val_loss: 4076206429.9543\n",
      "Epoch 7971/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1382853889.5029 - val_loss: 4079677048.2557\n",
      "Epoch 7972/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1380963860.0391 - val_loss: 4066165810.4110\n",
      "Epoch 7973/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1381604877.2759 - val_loss: 4062793339.3242\n",
      "Epoch 7974/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1381826623.1233 - val_loss: 4058193023.5616\n",
      "Epoch 7975/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1381608036.0705 - val_loss: 4062400484.8219\n",
      "Epoch 7976/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1382403950.9667 - val_loss: 4074695317.0411\n",
      "Epoch 7977/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1383066328.1722 - val_loss: 4069904357.8447\n",
      "Epoch 7978/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1382588989.4951 - val_loss: 4065942264.8402\n",
      "Epoch 7979/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1384036795.7417 - val_loss: 4061200400.9498\n",
      "Epoch 7980/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1381497147.5538 - val_loss: 4067810479.9269\n",
      "Epoch 7981/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1383472456.8924 - val_loss: 4062142776.5479\n",
      "Epoch 7982/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1381464031.0607 - val_loss: 4071820135.3059\n",
      "Epoch 7983/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1381974362.1761 - val_loss: 4066132111.1963\n",
      "Epoch 7984/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1381736301.2133 - val_loss: 4078690588.0548\n",
      "Epoch 7985/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1381425262.3405 - val_loss: 4068117826.7763\n",
      "Epoch 7986/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1381851020.7750 - val_loss: 4076735161.5708\n",
      "Epoch 7987/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1382243764.8532 - val_loss: 4055994171.4703\n",
      "Epoch 7988/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1381828023.4834 - val_loss: 4062585630.2466\n",
      "Epoch 7989/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1381437866.3327 - val_loss: 4071289167.1963\n",
      "Epoch 7990/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1383744657.5342 - val_loss: 4067487148.5662\n",
      "Epoch 7991/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1381500206.4658 - val_loss: 4068968750.3196\n",
      "Epoch 7992/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1382431366.5127 - val_loss: 4063590658.0457\n",
      "Epoch 7993/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1381475218.9119 - val_loss: 4067955861.1872\n",
      "Epoch 7994/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1381626668.9002 - val_loss: 4066450792.0365\n",
      "Epoch 7995/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1381513580.4618 - val_loss: 4073317293.4429\n",
      "Epoch 7996/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1381836928.7515 - val_loss: 4061330085.5525\n",
      "Epoch 7997/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1382098925.9648 - val_loss: 4077731097.8630\n",
      "Epoch 7998/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1381268413.8708 - val_loss: 4070366968.6941\n",
      "Epoch 7999/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1382187176.6419 - val_loss: 4071201777.3881\n",
      "Epoch 8000/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1381847777.9413 - val_loss: 4059553405.0776\n",
      "Epoch 8001/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1382224916.0391 - val_loss: 4081823608.6941\n",
      "Epoch 8002/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1381931161.2994 - val_loss: 4068224581.2603\n",
      "Epoch 8003/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1382612956.4305 - val_loss: 4062119471.7808\n",
      "Epoch 8004/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1383913793.8787 - val_loss: 4061655714.3379\n",
      "Epoch 8005/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1381843507.3503 - val_loss: 4060053367.0868\n",
      "Epoch 8006/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1384906436.3836 - val_loss: 4076373941.4795\n",
      "Epoch 8007/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1381484533.2290 - val_loss: 4061164619.3973\n",
      "Epoch 8008/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1387826390.0431 - val_loss: 4088374872.4018\n",
      "Epoch 8009/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1381185850.8650 - val_loss: 4056736296.9132\n",
      "Epoch 8010/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1381765098.7084 - val_loss: 4066429018.4475\n",
      "Epoch 8011/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1382847896.5479 - val_loss: 4060170970.5936\n",
      "Epoch 8012/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1382782730.5205 - val_loss: 4081705068.1279\n",
      "Epoch 8013/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1381934997.6673 - val_loss: 4065843893.4795\n",
      "Epoch 8014/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1381709998.0900 - val_loss: 4066040185.5708\n",
      "Epoch 8015/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1381325610.0822 - val_loss: 4072200191.2694\n",
      "Epoch 8016/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 39us/step - loss: 1381598800.7828 - val_loss: 4073411716.6758\n",
      "Epoch 8017/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1382642626.6301 - val_loss: 4055268725.9178\n",
      "Epoch 8018/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1386677746.2231 - val_loss: 4071139052.8584\n",
      "Epoch 8019/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1381091112.5793 - val_loss: 4062933622.3562\n",
      "Epoch 8020/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1381729579.0841 - val_loss: 4068783493.1142\n",
      "Epoch 8021/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1382792895.8748 - val_loss: 4069679883.6895\n",
      "Epoch 8022/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1384351706.0509 - val_loss: 4069597638.7215\n",
      "Epoch 8023/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1381703730.3483 - val_loss: 4057219487.7078\n",
      "Epoch 8024/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1381929412.0078 - val_loss: 4066385918.2466\n",
      "Epoch 8025/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1382153876.0391 - val_loss: 4056010664.7671\n",
      "Epoch 8026/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1381287733.6047 - val_loss: 4073421323.6895\n",
      "Epoch 8027/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1384273548.1487 - val_loss: 4074852954.0091\n",
      "Epoch 8028/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1381466887.5147 - val_loss: 4050781702.7215\n",
      "Epoch 8029/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1382469831.8904 - val_loss: 4058233277.6621\n",
      "Epoch 8030/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1384663008.6888 - val_loss: 4080520177.0959\n",
      "Epoch 8031/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1381328202.0196 - val_loss: 4060485822.6849\n",
      "Epoch 8032/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1381282149.9491 - val_loss: 4062378085.5525\n",
      "Epoch 8033/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1384068854.1057 - val_loss: 4080463504.2192\n",
      "Epoch 8034/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1381424570.4892 - val_loss: 4073991165.2237\n",
      "Epoch 8035/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1385389895.1389 - val_loss: 4068224585.2055\n",
      "Epoch 8036/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1382505627.1781 - val_loss: 4076775386.4475\n",
      "Epoch 8037/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1381866850.1918 - val_loss: 4064343833.7169\n",
      "Epoch 8038/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1382743440.9080 - val_loss: 4055835408.5114\n",
      "Epoch 8039/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1382655102.4971 - val_loss: 4072169006.0274\n",
      "Epoch 8040/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1382704527.9687 - val_loss: 4058484054.0639\n",
      "Epoch 8041/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1383159631.6556 - val_loss: 4087860329.9361\n",
      "Epoch 8042/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1381229363.8513 - val_loss: 4070403510.0639\n",
      "Epoch 8043/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1383852675.2564 - val_loss: 4066583290.0091\n",
      "Epoch 8044/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1381919977.0802 - val_loss: 4064792860.0548\n",
      "Epoch 8045/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1383073158.0117 - val_loss: 4078896651.5434\n",
      "Epoch 8046/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1381420099.8826 - val_loss: 4074168517.6986\n",
      "Epoch 8047/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1380884124.0548 - val_loss: 4066386406.7215\n",
      "Epoch 8048/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1382305134.7162 - val_loss: 4057696596.8950\n",
      "Epoch 8049/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1380926845.7456 - val_loss: 4062299528.7671\n",
      "Epoch 8050/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1381288677.9491 - val_loss: 4073839234.3379\n",
      "Epoch 8051/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1382431016.9550 - val_loss: 4079080559.7808\n",
      "Epoch 8052/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1381793621.9178 - val_loss: 4062055762.4110\n",
      "Epoch 8053/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1384561020.4932 - val_loss: 4073429687.6712\n",
      "Epoch 8054/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1381461142.2935 - val_loss: 4059400700.7854\n",
      "Epoch 8055/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1381258203.5538 - val_loss: 4073008398.9041\n",
      "Epoch 8056/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1381396916.3523 - val_loss: 4066560906.6667\n",
      "Epoch 8057/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1381119699.9139 - val_loss: 4062284704.8767\n",
      "Epoch 8058/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1381503517.9335 - val_loss: 4073579878.7215\n",
      "Epoch 8059/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1381521043.9139 - val_loss: 4080096400.9498\n",
      "Epoch 8060/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1381561546.6458 - val_loss: 4069618982.1370\n",
      "Epoch 8061/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1381529336.2348 - val_loss: 4068022826.8128\n",
      "Epoch 8062/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1382109361.2211 - val_loss: 4063746248.4749\n",
      "Epoch 8063/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1383989156.0705 - val_loss: 4081581423.4886\n",
      "Epoch 8064/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1381941028.5714 - val_loss: 4075200816.8037\n",
      "Epoch 8065/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1381838079.2485 - val_loss: 4067296303.7808\n",
      "Epoch 8066/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1381060363.5225 - val_loss: 4064178779.7626\n",
      "Epoch 8067/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1383916426.7710 - val_loss: 4073967785.6438\n",
      "Epoch 8068/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1382188953.5499 - val_loss: 4060816842.2283\n",
      "Epoch 8069/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1381719869.3699 - val_loss: 4069687484.0548\n",
      "Epoch 8070/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1382533787.0528 - val_loss: 4065439854.9041\n",
      "Epoch 8071/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1382685941.4795 - val_loss: 4079146097.2420\n",
      "Epoch 8072/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1382037981.0568 - val_loss: 4056958966.0639\n",
      "Epoch 8073/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1382861932.4618 - val_loss: 4084091189.6256\n",
      "Epoch 8074/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1381479740.4932 - val_loss: 4057669915.6164\n",
      "Epoch 8075/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1382296376.8611 - val_loss: 4071564576.5845\n",
      "Epoch 8076/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1381548548.0078 - val_loss: 4061964775.5982\n",
      "Epoch 8077/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1380940239.4051 - val_loss: 4066649147.4703\n",
      "Epoch 8078/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1382243039.9374 - val_loss: 4084721369.5708\n",
      "Epoch 8079/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1380270424.4227 - val_loss: 4058214955.5434\n",
      "Epoch 8080/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 49us/step - loss: 1381536624.4697 - val_loss: 4065990526.2466\n",
      "Epoch 8081/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1381444950.2935 - val_loss: 4061764119.9635\n",
      "Epoch 8082/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1380963952.8454 - val_loss: 4062375426.0457\n",
      "Epoch 8083/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1385523779.0059 - val_loss: 4083015236.9680\n",
      "Epoch 8084/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1381845111.4834 - val_loss: 4062539081.2055\n",
      "Epoch 8085/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1381671527.7025 - val_loss: 4064748431.6347\n",
      "Epoch 8086/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1383540866.3796 - val_loss: 4049979499.5434\n",
      "Epoch 8087/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1380851045.5108 - val_loss: 4064640597.0411\n",
      "Epoch 8088/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1381185320.5793 - val_loss: 4065499269.8447\n",
      "Epoch 8089/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1380868342.4814 - val_loss: 4075624768.8767\n",
      "Epoch 8090/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1382034416.0939 - val_loss: 4072550928.0731\n",
      "Epoch 8091/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1380566385.2211 - val_loss: 4072295461.9909\n",
      "Epoch 8092/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1382140021.6047 - val_loss: 4064408787.1416\n",
      "Epoch 8093/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1383237157.8239 - val_loss: 4060923226.1553\n",
      "Epoch 8094/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1382119430.3875 - val_loss: 4070698588.9315\n",
      "Epoch 8095/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1381802616.7358 - val_loss: 4086692262.7215\n",
      "Epoch 8096/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1383581197.0254 - val_loss: 4046933449.9361\n",
      "Epoch 8097/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1382563492.3209 - val_loss: 4084188605.2237\n",
      "Epoch 8098/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1381888024.2975 - val_loss: 4069260337.6804\n",
      "Epoch 8099/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1381380898.8180 - val_loss: 4067552954.3014\n",
      "Epoch 8100/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1380730392.9237 - val_loss: 4070179575.2329\n",
      "Epoch 8101/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1381600133.5108 - val_loss: 4064985690.4475\n",
      "Epoch 8102/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1381128294.1996 - val_loss: 4082704862.3927\n",
      "Epoch 8103/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1380596794.6145 - val_loss: 4064854514.8493\n",
      "Epoch 8104/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1382370265.4247 - val_loss: 4057431892.3105\n",
      "Epoch 8105/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1384171722.1448 - val_loss: 4076999632.9498\n",
      "Epoch 8106/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1383320890.1135 - val_loss: 4055332661.4795\n",
      "Epoch 8107/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1383015200.6888 - val_loss: 4073319032.1096\n",
      "Epoch 8108/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1381460347.2407 - val_loss: 4059687709.6621\n",
      "Epoch 8109/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1381126721.2524 - val_loss: 4066592258.6301\n",
      "Epoch 8110/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1381702473.7691 - val_loss: 4061216179.1416\n",
      "Epoch 8111/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1381602179.2564 - val_loss: 4064678921.6438\n",
      "Epoch 8112/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1383641612.1487 - val_loss: 4066424600.9863\n",
      "Epoch 8113/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1381573618.4736 - val_loss: 4069327209.9361\n",
      "Epoch 8114/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1381349723.6791 - val_loss: 4071181207.3790\n",
      "Epoch 8115/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1381379979.7730 - val_loss: 4064407385.5708\n",
      "Epoch 8116/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1380936416.9393 - val_loss: 4071948536.2557\n",
      "Epoch 8117/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383288275.6634 - val_loss: 4057412181.4795\n",
      "Epoch 8118/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1381179702.1057 - val_loss: 4076333989.6986\n",
      "Epoch 8119/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1382436233.0176 - val_loss: 4050274733.8813\n",
      "Epoch 8120/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1382380083.3503 - val_loss: 4059229182.3927\n",
      "Epoch 8121/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1381628895.2485 - val_loss: 4073190507.1050\n",
      "Epoch 8122/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1381048603.0528 - val_loss: 4073506110.2466\n",
      "Epoch 8123/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1384008407.1703 - val_loss: 4052648243.7260\n",
      "Epoch 8124/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1380505214.9980 - val_loss: 4076273531.6164\n",
      "Epoch 8125/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1381540639.0607 - val_loss: 4073320096.2922\n",
      "Epoch 8126/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1380696512.2505 - val_loss: 4074953941.9178\n",
      "Epoch 8127/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1380883721.0176 - val_loss: 4058238713.2785\n",
      "Epoch 8128/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1383012298.6458 - val_loss: 4076060189.3699\n",
      "Epoch 8129/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1381617389.2133 - val_loss: 4062800744.4749\n",
      "Epoch 8130/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1381502315.4599 - val_loss: 4057354626.3379\n",
      "Epoch 8131/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1381106639.4051 - val_loss: 4068111064.4018\n",
      "Epoch 8132/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1382145490.9119 - val_loss: 4060411605.3333\n",
      "Epoch 8133/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1381427504.5949 - val_loss: 4067199289.5708\n",
      "Epoch 8134/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1381198053.1977 - val_loss: 4068421936.9498\n",
      "Epoch 8135/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1381341975.7965 - val_loss: 4074089218.9224\n",
      "Epoch 8136/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1383344630.7319 - val_loss: 4062886955.8356\n",
      "Epoch 8137/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1383534533.8865 - val_loss: 4089506153.6438\n",
      "Epoch 8138/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1381023815.8904 - val_loss: 4063800691.2877\n",
      "Epoch 8139/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1380910448.8454 - val_loss: 4067544642.7763\n",
      "Epoch 8140/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1380952662.0431 - val_loss: 4070694375.7443\n",
      "Epoch 8141/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1381120269.2759 - val_loss: 4067299294.5388\n",
      "Epoch 8142/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1381765379.7573 - val_loss: 4057089127.1598\n",
      "Epoch 8143/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1380783844.8219 - val_loss: 4066575250.8493\n",
      "Epoch 8144/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 43us/step - loss: 1381608820.4775 - val_loss: 4069609466.3014\n",
      "Epoch 8145/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1382575354.4892 - val_loss: 4059658703.4886\n",
      "Epoch 8146/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1380585812.4149 - val_loss: 4067530867.2877\n",
      "Epoch 8147/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1381467803.3033 - val_loss: 4078340077.4429\n",
      "Epoch 8148/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1380764746.1448 - val_loss: 4069349735.5982\n",
      "Epoch 8149/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1383226635.8982 - val_loss: 4051158815.2694\n",
      "Epoch 8150/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1381425230.4031 - val_loss: 4072623193.5708\n",
      "Epoch 8151/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1380636957.3072 - val_loss: 4066335121.5342\n",
      "Epoch 8152/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1383146287.5930 - val_loss: 4078420565.3333\n",
      "Epoch 8153/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1381595182.8415 - val_loss: 4076169936.0731\n",
      "Epoch 8154/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1382343228.1174 - val_loss: 4066311683.7991\n",
      "Epoch 8155/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1381754469.0724 - val_loss: 4058933859.9452\n",
      "Epoch 8156/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1381947981.6517 - val_loss: 4063946666.3744\n",
      "Epoch 8157/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1381404275.4755 - val_loss: 4080383040.0000\n",
      "Epoch 8158/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1380562893.4012 - val_loss: 4073307273.4977\n",
      "Epoch 8159/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1380940566.0431 - val_loss: 4076434768.0731\n",
      "Epoch 8160/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1384774354.4110 - val_loss: 4060228279.8174\n",
      "Epoch 8161/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1381374116.9472 - val_loss: 4070561351.0137\n",
      "Epoch 8162/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1381276837.4481 - val_loss: 4073618357.6256\n",
      "Epoch 8163/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1381227810.6928 - val_loss: 4076070845.0776\n",
      "Epoch 8164/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1381956534.6067 - val_loss: 4068690987.5434\n",
      "Epoch 8165/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1382094524.9941 - val_loss: 4087169885.9543\n",
      "Epoch 8166/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1380579993.5499 - val_loss: 4062585883.1781\n",
      "Epoch 8167/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1382140667.3659 - val_loss: 4067078285.2968\n",
      "Epoch 8168/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1380620378.6771 - val_loss: 4061660160.5845\n",
      "Epoch 8169/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1381714581.1663 - val_loss: 4063496555.1050\n",
      "Epoch 8170/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1381809706.3953 - val_loss: 4065419984.9498\n",
      "Epoch 8171/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1381732896.3131 - val_loss: 4053204561.2420\n",
      "Epoch 8172/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1380840639.4990 - val_loss: 4065876357.9909\n",
      "Epoch 8173/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1382755178.9589 - val_loss: 4087541254.5753\n",
      "Epoch 8174/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1381264046.0900 - val_loss: 4072748005.5525\n",
      "Epoch 8175/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1383302307.0685 - val_loss: 4058087030.2100\n",
      "Epoch 8176/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1380836236.2740 - val_loss: 4071556361.7900\n",
      "Epoch 8177/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1382136850.7867 - val_loss: 4073681711.0502\n",
      "Epoch 8178/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1380423483.9922 - val_loss: 4058863624.3288\n",
      "Epoch 8179/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1381679424.7515 - val_loss: 4067922172.0548\n",
      "Epoch 8180/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1380465693.5577 - val_loss: 4058129627.4703\n",
      "Epoch 8181/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1382473535.8748 - val_loss: 4059654886.5753\n",
      "Epoch 8182/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1380874999.9217 - val_loss: 4065962460.0548\n",
      "Epoch 8183/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1381066389.7926 - val_loss: 4072533123.7991\n",
      "Epoch 8184/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1381424739.2564 - val_loss: 4060902191.0502\n",
      "Epoch 8185/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1383538142.9354 - val_loss: 4077439997.0776\n",
      "Epoch 8186/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1383639897.6751 - val_loss: 4056828896.5845\n",
      "Epoch 8187/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1382854938.3014 - val_loss: 4076995552.8767\n",
      "Epoch 8188/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1383352091.5538 - val_loss: 4055872278.7945\n",
      "Epoch 8189/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1382862168.1722 - val_loss: 4063463869.8082\n",
      "Epoch 8190/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1380482529.1898 - val_loss: 4070477964.8584\n",
      "Epoch 8191/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1384685794.4423 - val_loss: 4049325610.5205\n",
      "Epoch 8192/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1381105724.4305 - val_loss: 4069647672.1096\n",
      "Epoch 8193/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1381733514.0196 - val_loss: 4073550378.5205\n",
      "Epoch 8194/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1381205200.1566 - val_loss: 4069677031.4521\n",
      "Epoch 8195/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1382249762.0665 - val_loss: 4071563806.3927\n",
      "Epoch 8196/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1381011194.2387 - val_loss: 4056435851.9817\n",
      "Epoch 8197/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1381849843.4755 - val_loss: 4063850486.6484\n",
      "Epoch 8198/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1380913211.3659 - val_loss: 4063197567.5616\n",
      "Epoch 8199/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1380695913.4560 - val_loss: 4074997423.7808\n",
      "Epoch 8200/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1382014454.2309 - val_loss: 4088050476.2740\n",
      "Epoch 8201/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1384259526.6380 - val_loss: 4053025103.6347\n",
      "Epoch 8202/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1382827238.4501 - val_loss: 4075012405.6256\n",
      "Epoch 8203/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1383468547.2564 - val_loss: 4054087373.0046\n",
      "Epoch 8204/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1380511140.8219 - val_loss: 4055947856.5114\n",
      "Epoch 8205/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1380262506.4579 - val_loss: 4074047184.9498\n",
      "Epoch 8206/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1380840931.4442 - val_loss: 4064622753.7534\n",
      "Epoch 8207/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1381584242.3483 - val_loss: 4081660126.5388\n",
      "Epoch 8208/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 50us/step - loss: 1380718187.7104 - val_loss: 4072822597.8447\n",
      "Epoch 8209/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1382715599.7808 - val_loss: 4078447692.4201\n",
      "Epoch 8210/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1380752023.2955 - val_loss: 4059668014.1735\n",
      "Epoch 8211/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1385569099.3973 - val_loss: 4080335077.6986\n",
      "Epoch 8212/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1381450025.3307 - val_loss: 4073156284.9315\n",
      "Epoch 8213/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1381121762.1292 - val_loss: 4053649787.4703\n",
      "Epoch 8214/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1383680512.2505 - val_loss: 4078540047.7808\n",
      "Epoch 8215/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1384488146.4110 - val_loss: 4054957559.8174\n",
      "Epoch 8216/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1381168791.1703 - val_loss: 4070360799.4155\n",
      "Epoch 8217/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1380954095.8434 - val_loss: 4057592573.2237\n",
      "Epoch 8218/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1380730575.4051 - val_loss: 4071499777.4612\n",
      "Epoch 8219/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1382679926.6067 - val_loss: 4068861025.8995\n",
      "Epoch 8220/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1381594281.4560 - val_loss: 4065412731.0320\n",
      "Epoch 8221/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1380338209.0646 - val_loss: 4072805990.2831\n",
      "Epoch 8222/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1381549738.7084 - val_loss: 4062680452.2374\n",
      "Epoch 8223/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1382102307.9452 - val_loss: 4067087944.7671\n",
      "Epoch 8224/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1382592949.7299 - val_loss: 4082616038.2831\n",
      "Epoch 8225/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1380956190.9354 - val_loss: 4071324162.4840\n",
      "Epoch 8226/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1382377491.2877 - val_loss: 4058707718.4292\n",
      "Epoch 8227/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1382399811.1311 - val_loss: 4069337551.6347\n",
      "Epoch 8228/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1381740959.5616 - val_loss: 4085495914.5205\n",
      "Epoch 8229/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1380615046.8885 - val_loss: 4064659766.5023\n",
      "Epoch 8230/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1380182117.4481 - val_loss: 4058125724.7854\n",
      "Epoch 8231/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1380393548.6497 - val_loss: 4064394902.0639\n",
      "Epoch 8232/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1382442498.0039 - val_loss: 4057120964.9680\n",
      "Epoch 8233/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1381302264.7984 - val_loss: 4058670688.7306\n",
      "Epoch 8234/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1380313355.0215 - val_loss: 4081220800.1461\n",
      "Epoch 8235/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1381776038.8258 - val_loss: 4069512404.1644\n",
      "Epoch 8236/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1382214576.2192 - val_loss: 4067295940.8219\n",
      "Epoch 8237/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1382663161.4873 - val_loss: 4096793138.5571\n",
      "Epoch 8238/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1386526267.7417 - val_loss: 4054784777.9361\n",
      "Epoch 8239/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1381710503.2016 - val_loss: 4072264400.5114\n",
      "Epoch 8240/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1380785181.5577 - val_loss: 4078016389.5525\n",
      "Epoch 8241/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1381198646.1057 - val_loss: 4066746583.0868\n",
      "Epoch 8242/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1380880983.1703 - val_loss: 4078072548.2374\n",
      "Epoch 8243/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1380642441.1429 - val_loss: 4069076783.0502\n",
      "Epoch 8244/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1380525166.4658 - val_loss: 4058146581.9178\n",
      "Epoch 8245/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1381531073.8787 - val_loss: 4076304214.6484\n",
      "Epoch 8246/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1380644619.7730 - val_loss: 4078774771.7260\n",
      "Epoch 8247/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1380529191.3268 - val_loss: 4065641730.4840\n",
      "Epoch 8248/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1382967976.8297 - val_loss: 4058218865.2420\n",
      "Epoch 8249/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1383307854.2779 - val_loss: 4076224591.6347\n",
      "Epoch 8250/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1380363765.8552 - val_loss: 4066496036.9680\n",
      "Epoch 8251/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1382742751.0607 - val_loss: 4068655717.8447\n",
      "Epoch 8252/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1381289336.2348 - val_loss: 4071824611.9452\n",
      "Epoch 8253/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1382041591.2329 - val_loss: 4077469234.8493\n",
      "Epoch 8254/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1381488606.3092 - val_loss: 4058443349.4795\n",
      "Epoch 8255/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1381390501.8239 - val_loss: 4069236040.4749\n",
      "Epoch 8256/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1380594079.8121 - val_loss: 4074039007.8539\n",
      "Epoch 8257/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1380868769.1898 - val_loss: 4056770756.0913\n",
      "Epoch 8258/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1380893577.0176 - val_loss: 4064525843.8721\n",
      "Epoch 8259/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1380508695.7965 - val_loss: 4066036997.1142\n",
      "Epoch 8260/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1380679661.9648 - val_loss: 4068018064.8037\n",
      "Epoch 8261/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1380319142.0744 - val_loss: 4070465362.2648\n",
      "Epoch 8262/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1382667910.6380 - val_loss: 4073054063.9269\n",
      "Epoch 8263/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1382084745.2681 - val_loss: 4064834919.4521\n",
      "Epoch 8264/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1380874180.0705 - val_loss: 4063016435.8721\n",
      "Epoch 8265/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1381187460.7593 - val_loss: 4075282264.6941\n",
      "Epoch 8266/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1381957257.1429 - val_loss: 4074774094.1735\n",
      "Epoch 8267/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1381373812.8532 - val_loss: 4052085274.0091\n",
      "Epoch 8268/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1380281099.0215 - val_loss: 4066521784.6941\n",
      "Epoch 8269/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1381015277.0881 - val_loss: 4057127874.3379\n",
      "Epoch 8270/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1381467689.2055 - val_loss: 4076360577.3151\n",
      "Epoch 8271/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1380367663.5930 - val_loss: 4063649710.6119\n",
      "Epoch 8272/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 45us/step - loss: 1381240802.1918 - val_loss: 4066546053.5525\n",
      "Epoch 8273/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1381884888.2348 - val_loss: 4071036666.5936\n",
      "Epoch 8274/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1381883335.6399 - val_loss: 4055016562.1187\n",
      "Epoch 8275/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1381040626.2231 - val_loss: 4079645630.5388\n",
      "Epoch 8276/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1382813578.2701 - val_loss: 4056856485.2603\n",
      "Epoch 8277/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1380520768.3757 - val_loss: 4066771434.5205\n",
      "Epoch 8278/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1381575991.6086 - val_loss: 4084915396.5297\n",
      "Epoch 8279/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1383755177.0802 - val_loss: 4057142005.6256\n",
      "Epoch 8280/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1384246555.4286 - val_loss: 4082545309.6621\n",
      "Epoch 8281/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1380105399.9843 - val_loss: 4061380287.1233\n",
      "Epoch 8282/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1381313979.1155 - val_loss: 4071978564.9680\n",
      "Epoch 8283/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1380837989.4481 - val_loss: 4058367218.4110\n",
      "Epoch 8284/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1379757690.1135 - val_loss: 4066341572.9680\n",
      "Epoch 8285/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1382319265.2524 - val_loss: 4062948130.6301\n",
      "Epoch 8286/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1382380163.2564 - val_loss: 4055604549.9909\n",
      "Epoch 8287/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1380301530.1761 - val_loss: 4078339395.0685\n",
      "Epoch 8288/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1380701676.4618 - val_loss: 4072645710.6119\n",
      "Epoch 8289/10000\n",
      "1022/1022 [==============================] - 0s 63us/step - loss: 1381323516.9941 - val_loss: 4077946981.9909\n",
      "Epoch 8290/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1380186805.6047 - val_loss: 4062463363.2146\n",
      "Epoch 8291/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1380818621.1194 - val_loss: 4059441281.4612\n",
      "Epoch 8292/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1382855315.1624 - val_loss: 4059944781.7352\n",
      "Epoch 8293/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1380567827.0372 - val_loss: 4071098128.6575\n",
      "Epoch 8294/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1381075832.2348 - val_loss: 4079951619.3607\n",
      "Epoch 8295/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1381648192.8767 - val_loss: 4056723146.5205\n",
      "Epoch 8296/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1380128950.6067 - val_loss: 4067801690.0091\n",
      "Epoch 8297/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1380193268.6027 - val_loss: 4064365823.4155\n",
      "Epoch 8298/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1381032795.1781 - val_loss: 4075101064.1826\n",
      "Epoch 8299/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1381603663.4051 - val_loss: 4066316338.8493\n",
      "Epoch 8300/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1380171750.4501 - val_loss: 4074658850.1918\n",
      "Epoch 8301/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1380899961.7378 - val_loss: 4061038875.9087\n",
      "Epoch 8302/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1383583483.4912 - val_loss: 4093355899.4703\n",
      "Epoch 8303/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1386268183.0450 - val_loss: 4044321048.4018\n",
      "Epoch 8304/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1381016839.5147 - val_loss: 4058842369.0228\n",
      "Epoch 8305/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1380514750.8728 - val_loss: 4074026480.2192\n",
      "Epoch 8306/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1381484552.5166 - val_loss: 4057304197.9909\n",
      "Epoch 8307/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1381519302.3875 - val_loss: 4073092872.3288\n",
      "Epoch 8308/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1381200401.9100 - val_loss: 4058900666.0091\n",
      "Epoch 8309/10000\n",
      "1022/1022 [==============================] - 0s 68us/step - loss: 1379643912.7671 - val_loss: 4070754403.5068\n",
      "Epoch 8310/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1380583243.7730 - val_loss: 4071984725.4795\n",
      "Epoch 8311/10000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1383950245.1977 - val_loss: 4090873298.9954\n",
      "Epoch 8312/10000\n",
      "1022/1022 [==============================] - 0s 34us/step - loss: 1381033785.1115 - val_loss: 4070413184.5845\n",
      "Epoch 8313/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1380390582.6067 - val_loss: 4058374102.6484\n",
      "Epoch 8314/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1381519056.1566 - val_loss: 4049210395.7626\n",
      "Epoch 8315/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1380082463.0607 - val_loss: 4072325669.9909\n",
      "Epoch 8316/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1380401408.1252 - val_loss: 4067626314.9589\n",
      "Epoch 8317/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1380532158.8728 - val_loss: 4073558330.7397\n",
      "Epoch 8318/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1380575209.2055 - val_loss: 4062930912.2922\n",
      "Epoch 8319/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1382456569.9883 - val_loss: 4070446076.3470\n",
      "Epoch 8320/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1381261647.1546 - val_loss: 4058508011.2511\n",
      "Epoch 8321/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1380277272.7984 - val_loss: 4063607737.4247\n",
      "Epoch 8322/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1382661526.1057 - val_loss: 4081829121.1689\n",
      "Epoch 8323/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1383168407.0450 - val_loss: 4054864147.1416\n",
      "Epoch 8324/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1380981558.8571 - val_loss: 4063780560.3653\n",
      "Epoch 8325/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1379811838.9980 - val_loss: 4068171659.1050\n",
      "Epoch 8326/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1380554523.5538 - val_loss: 4067046856.4749\n",
      "Epoch 8327/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1380766892.2114 - val_loss: 4073423921.5342\n",
      "Epoch 8328/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1380673949.8082 - val_loss: 4076538945.7534\n",
      "Epoch 8329/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1381814147.0059 - val_loss: 4056897728.5845\n",
      "Epoch 8330/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1380377161.6438 - val_loss: 4072926632.9132\n",
      "Epoch 8331/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1381552148.5401 - val_loss: 4053523564.4201\n",
      "Epoch 8332/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1380124701.6830 - val_loss: 4063326276.6758\n",
      "Epoch 8333/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1380129731.6321 - val_loss: 4072965792.5845\n",
      "Epoch 8334/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1380984667.8043 - val_loss: 4072620369.8265\n",
      "Epoch 8335/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1380450622.1213 - val_loss: 4066568827.6164\n",
      "Epoch 8336/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 53us/step - loss: 1379980159.4990 - val_loss: 4070082359.5251\n",
      "Epoch 8337/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1381426565.5108 - val_loss: 4069574240.8767\n",
      "Epoch 8338/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1382361844.2270 - val_loss: 4065730583.8174\n",
      "Epoch 8339/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1380038297.4247 - val_loss: 4076339002.3014\n",
      "Epoch 8340/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1381210633.2681 - val_loss: 4063093637.9909\n",
      "Epoch 8341/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1384410599.9530 - val_loss: 4085034428.6393\n",
      "Epoch 8342/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1379713818.9276 - val_loss: 4054487697.3881\n",
      "Epoch 8343/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1382605574.2622 - val_loss: 4046244360.6210\n",
      "Epoch 8344/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1379812769.0646 - val_loss: 4064235295.1233\n",
      "Epoch 8345/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1380694824.0783 - val_loss: 4080628067.0685\n",
      "Epoch 8346/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1379572980.8532 - val_loss: 4073561227.3973\n",
      "Epoch 8347/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1382295421.4951 - val_loss: 4064502739.1416\n",
      "Epoch 8348/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1382451170.0665 - val_loss: 4086649622.6484\n",
      "Epoch 8349/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1380617473.0020 - val_loss: 4079427699.2877\n",
      "Epoch 8350/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1381949640.3914 - val_loss: 4070039497.7900\n",
      "Epoch 8351/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1381811141.3855 - val_loss: 4052090509.5890\n",
      "Epoch 8352/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1380916926.1213 - val_loss: 4062655352.5479\n",
      "Epoch 8353/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1380154931.3503 - val_loss: 4072259255.0868\n",
      "Epoch 8354/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1381160897.2524 - val_loss: 4056710350.1735\n",
      "Epoch 8355/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1385988187.5538 - val_loss: 4084445768.6210\n",
      "Epoch 8356/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1379521016.4853 - val_loss: 4053684125.5160\n",
      "Epoch 8357/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1380492131.1937 - val_loss: 4067183452.7854\n",
      "Epoch 8358/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1379957135.7808 - val_loss: 4068981990.8676\n",
      "Epoch 8359/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1380944027.0528 - val_loss: 4061345274.1553\n",
      "Epoch 8360/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1380415200.4384 - val_loss: 4067960528.6575\n",
      "Epoch 8361/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1380621275.4286 - val_loss: 4065744359.0137\n",
      "Epoch 8362/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1380151165.4951 - val_loss: 4068885850.8858\n",
      "Epoch 8363/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1380515198.9980 - val_loss: 4069722386.7032\n",
      "Epoch 8364/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1380072209.7847 - val_loss: 4061984965.9909\n",
      "Epoch 8365/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1380309950.6223 - val_loss: 4064058340.3836\n",
      "Epoch 8366/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1383079560.7671 - val_loss: 4066678444.1279\n",
      "Epoch 8367/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1379870860.2740 - val_loss: 4071855818.3744\n",
      "Epoch 8368/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1381005792.8767 - val_loss: 4052665859.5068\n",
      "Epoch 8369/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1379432738.5675 - val_loss: 4061821995.1050\n",
      "Epoch 8370/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1381770087.4521 - val_loss: 4085989164.7123\n",
      "Epoch 8371/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1379874153.7065 - val_loss: 4059759625.4977\n",
      "Epoch 8372/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1380623026.8493 - val_loss: 4061885995.1050\n",
      "Epoch 8373/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1380166970.7397 - val_loss: 4063195481.5708\n",
      "Epoch 8374/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1380104255.6243 - val_loss: 4073112465.0959\n",
      "Epoch 8375/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1380686849.7534 - val_loss: 4063045771.8356\n",
      "Epoch 8376/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1380819056.5323 - val_loss: 4057541560.4018\n",
      "Epoch 8377/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1380133448.3914 - val_loss: 4064163902.3927\n",
      "Epoch 8378/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1380470159.5303 - val_loss: 4067953558.0639\n",
      "Epoch 8379/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1380672559.0920 - val_loss: 4084083412.3105\n",
      "Epoch 8380/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1380939308.3366 - val_loss: 4052802679.6712\n",
      "Epoch 8381/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1382461327.0294 - val_loss: 4070923606.0639\n",
      "Epoch 8382/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1379938160.8454 - val_loss: 4064788798.3927\n",
      "Epoch 8383/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1380537496.0470 - val_loss: 4060254749.8082\n",
      "Epoch 8384/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1380487027.6008 - val_loss: 4060784970.5205\n",
      "Epoch 8385/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1379683944.2035 - val_loss: 4068890737.3881\n",
      "Epoch 8386/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1380468016.3444 - val_loss: 4070380207.1963\n",
      "Epoch 8387/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1380506377.7691 - val_loss: 4057177095.4521\n",
      "Epoch 8388/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1380304364.4618 - val_loss: 4071792343.9635\n",
      "Epoch 8389/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1380721720.1096 - val_loss: 4068619707.3242\n",
      "Epoch 8390/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1381586394.9276 - val_loss: 4057698442.9589\n",
      "Epoch 8391/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1382041224.0157 - val_loss: 4073413721.4247\n",
      "Epoch 8392/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1381803802.5519 - val_loss: 4075177922.9224\n",
      "Epoch 8393/10000\n",
      "1022/1022 [==============================] - 0s 72us/step - loss: 1380316655.8434 - val_loss: 4065165619.2877\n",
      "Epoch 8394/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1381160335.4677 - val_loss: 4074629594.1553\n",
      "Epoch 8395/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1381247567.4051 - val_loss: 4057944007.0137\n",
      "Epoch 8396/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1379653654.2935 - val_loss: 4071160678.8676\n",
      "Epoch 8397/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1381068692.7906 - val_loss: 4057290304.4384\n",
      "Epoch 8398/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1381200375.4834 - val_loss: 4060099867.4703\n",
      "Epoch 8399/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1381483540.2896 - val_loss: 4082412966.2831\n",
      "Epoch 8400/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 47us/step - loss: 1380268568.5479 - val_loss: 4060740501.0411\n",
      "Epoch 8401/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1381440696.6106 - val_loss: 4063849129.7900\n",
      "Epoch 8402/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1380394880.7515 - val_loss: 4062072502.9406\n",
      "Epoch 8403/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1381333305.6125 - val_loss: 4062978476.2740\n",
      "Epoch 8404/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1380970233.2368 - val_loss: 4079032949.7717\n",
      "Epoch 8405/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1380343306.8963 - val_loss: 4060430687.1233\n",
      "Epoch 8406/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1381382415.5303 - val_loss: 4073848204.7123\n",
      "Epoch 8407/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1380661268.2896 - val_loss: 4055863884.2740\n",
      "Epoch 8408/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1379430344.0157 - val_loss: 4065150223.1963\n",
      "Epoch 8409/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1382752230.9511 - val_loss: 4083807284.8950\n",
      "Epoch 8410/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1379904404.5401 - val_loss: 4063052349.2237\n",
      "Epoch 8411/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1380658505.1429 - val_loss: 4058463530.0822\n",
      "Epoch 8412/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1382853349.0724 - val_loss: 4080506416.6575\n",
      "Epoch 8413/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1380541634.5049 - val_loss: 4049146663.8904\n",
      "Epoch 8414/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1380059962.8650 - val_loss: 4053965303.8174\n",
      "Epoch 8415/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1380641446.1996 - val_loss: 4061803713.6073\n",
      "Epoch 8416/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1380169725.7456 - val_loss: 4064746062.7580\n",
      "Epoch 8417/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1380059198.8728 - val_loss: 4071397266.8493\n",
      "Epoch 8418/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1382705124.9472 - val_loss: 4055519529.3516\n",
      "Epoch 8419/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1379406175.6869 - val_loss: 4081743857.3881\n",
      "Epoch 8420/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1382934743.2955 - val_loss: 4069603373.0046\n",
      "Epoch 8421/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1382387008.1252 - val_loss: 4092870757.4064\n",
      "Epoch 8422/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1382583518.5597 - val_loss: 4058274226.1187\n",
      "Epoch 8423/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1379798387.0998 - val_loss: 4064417377.1689\n",
      "Epoch 8424/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1379861367.7339 - val_loss: 4073124995.2146\n",
      "Epoch 8425/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1380175638.7945 - val_loss: 4068631718.7215\n",
      "Epoch 8426/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1379753921.6282 - val_loss: 4065557260.2740\n",
      "Epoch 8427/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1380209338.3640 - val_loss: 4075479986.4110\n",
      "Epoch 8428/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1379891997.0568 - val_loss: 4060772213.4795\n",
      "Epoch 8429/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1379968489.5812 - val_loss: 4070086936.4018\n",
      "Epoch 8430/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1383595634.9746 - val_loss: 4085852722.8493\n",
      "Epoch 8431/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1380894257.0959 - val_loss: 4068385890.4840\n",
      "Epoch 8432/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1382470423.5460 - val_loss: 4075844725.9178\n",
      "Epoch 8433/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1381702858.5205 - val_loss: 4062697260.7123\n",
      "Epoch 8434/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1382693564.3679 - val_loss: 4075079560.3288\n",
      "Epoch 8435/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1380247900.8063 - val_loss: 4070619109.2603\n",
      "Epoch 8436/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1380778009.0489 - val_loss: 4057472739.3607\n",
      "Epoch 8437/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1381003018.5205 - val_loss: 4066395792.2192\n",
      "Epoch 8438/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1380258744.6106 - val_loss: 4074083873.3151\n",
      "Epoch 8439/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1379524163.3816 - val_loss: 4066016243.2877\n",
      "Epoch 8440/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1383229995.0841 - val_loss: 4083331481.7169\n",
      "Epoch 8441/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1381208145.4090 - val_loss: 4073509850.8858\n",
      "Epoch 8442/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1383053352.8297 - val_loss: 4045476327.3059\n",
      "Epoch 8443/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1379916240.6575 - val_loss: 4066509225.6438\n",
      "Epoch 8444/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1381170260.1644 - val_loss: 4072416226.1918\n",
      "Epoch 8445/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1380114298.2387 - val_loss: 4064019583.2694\n",
      "Epoch 8446/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1380662261.2290 - val_loss: 4061818622.1005\n",
      "Epoch 8447/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1380721501.6830 - val_loss: 4072068195.5068\n",
      "Epoch 8448/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1380374761.9569 - val_loss: 4064379881.0594\n",
      "Epoch 8449/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1381553231.5303 - val_loss: 4078655966.3927\n",
      "Epoch 8450/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1380078279.1389 - val_loss: 4056120414.8311\n",
      "Epoch 8451/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1380295894.9198 - val_loss: 4067537293.7352\n",
      "Epoch 8452/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1379862565.5734 - val_loss: 4060051943.4521\n",
      "Epoch 8453/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1379919001.0489 - val_loss: 4068697879.9635\n",
      "Epoch 8454/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1379903617.1272 - val_loss: 4057613786.1553\n",
      "Epoch 8455/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1379991023.7182 - val_loss: 4068029476.9680\n",
      "Epoch 8456/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1381978515.2877 - val_loss: 4076070000.6575\n",
      "Epoch 8457/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1380803191.3581 - val_loss: 4075068899.5068\n",
      "Epoch 8458/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1380274242.8806 - val_loss: 4077635418.7397\n",
      "Epoch 8459/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1380359159.6086 - val_loss: 4060543639.5251\n",
      "Epoch 8460/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1379572412.1174 - val_loss: 4069632387.3607\n",
      "Epoch 8461/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1380165449.1429 - val_loss: 4076798490.7397\n",
      "Epoch 8462/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1379802651.5538 - val_loss: 4065909836.4201\n",
      "Epoch 8463/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1380217436.9315 - val_loss: 4063699630.1735\n",
      "Epoch 8464/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 41us/step - loss: 1381176463.4051 - val_loss: 4062814043.0320\n",
      "Epoch 8465/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1380470292.0391 - val_loss: 4082010289.6804\n",
      "Epoch 8466/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1380252287.4990 - val_loss: 4058963972.8219\n",
      "Epoch 8467/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1380198030.0900 - val_loss: 4069754558.6849\n",
      "Epoch 8468/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1379553822.5597 - val_loss: 4059767138.1918\n",
      "Epoch 8469/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1380375866.3640 - val_loss: 4067359179.3973\n",
      "Epoch 8470/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1381594644.5401 - val_loss: 4080310945.4612\n",
      "Epoch 8471/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1379376655.0294 - val_loss: 4061950964.7489\n",
      "Epoch 8472/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1381872080.9080 - val_loss: 4083546762.6667\n",
      "Epoch 8473/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1381665513.8317 - val_loss: 4057929147.3242\n",
      "Epoch 8474/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1380345275.1155 - val_loss: 4071281359.1963\n",
      "Epoch 8475/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1379747695.8434 - val_loss: 4062146609.8265\n",
      "Epoch 8476/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1380797915.4286 - val_loss: 4063494005.0411\n",
      "Epoch 8477/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1381520429.6517 - val_loss: 4077042684.7854\n",
      "Epoch 8478/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1381701407.3112 - val_loss: 4076665536.2922\n",
      "Epoch 8479/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1379640182.6067 - val_loss: 4057870187.2511\n",
      "Epoch 8480/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1381435172.5714 - val_loss: 4056618634.2283\n",
      "Epoch 8481/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1380340361.6438 - val_loss: 4071891844.5297\n",
      "Epoch 8482/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1380553014.4814 - val_loss: 4063515694.4658\n",
      "Epoch 8483/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1382517076.0391 - val_loss: 4065712432.6575\n",
      "Epoch 8484/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1380321560.4227 - val_loss: 4063640977.2420\n",
      "Epoch 8485/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1381009446.5753 - val_loss: 4066185322.6667\n",
      "Epoch 8486/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1381121217.8787 - val_loss: 4058561554.2648\n",
      "Epoch 8487/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1381298346.0822 - val_loss: 4053309567.1233\n",
      "Epoch 8488/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1379442409.4560 - val_loss: 4072906419.5799\n",
      "Epoch 8489/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1379800686.7162 - val_loss: 4068874127.9269\n",
      "Epoch 8490/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1379468805.2603 - val_loss: 4077395539.1416\n",
      "Epoch 8491/10000\n",
      "1022/1022 [==============================] - 0s 77us/step - loss: 1379459370.0822 - val_loss: 4060745170.8493\n",
      "Epoch 8492/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1382339899.8669 - val_loss: 4059615194.8858\n",
      "Epoch 8493/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1381591657.7065 - val_loss: 4087960155.1781\n",
      "Epoch 8494/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1382259025.2838 - val_loss: 4066955010.6301\n",
      "Epoch 8495/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1380442005.2916 - val_loss: 4063828289.7534\n",
      "Epoch 8496/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1380332064.4384 - val_loss: 4057419612.0548\n",
      "Epoch 8497/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1379912699.3659 - val_loss: 4074728928.4384\n",
      "Epoch 8498/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1379474057.8943 - val_loss: 4066220879.6347\n",
      "Epoch 8499/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1379810435.0059 - val_loss: 4064641303.6712\n",
      "Epoch 8500/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1380588193.8160 - val_loss: 4079226612.4566\n",
      "Epoch 8501/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1380027616.4384 - val_loss: 4073354520.5479\n",
      "Epoch 8502/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1379500663.2329 - val_loss: 4059924725.0411\n",
      "Epoch 8503/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1379547644.9941 - val_loss: 4076469380.5297\n",
      "Epoch 8504/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1381223386.6145 - val_loss: 4061695405.4429\n",
      "Epoch 8505/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1379824473.1742 - val_loss: 4061966752.5845\n",
      "Epoch 8506/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1379558656.6262 - val_loss: 4064915623.7443\n",
      "Epoch 8507/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1379880607.3112 - val_loss: 4061010222.3196\n",
      "Epoch 8508/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1380747847.6399 - val_loss: 4062458475.1050\n",
      "Epoch 8509/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1379594333.1820 - val_loss: 4081292997.8447\n",
      "Epoch 8510/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1381075229.0568 - val_loss: 4058042076.2009\n",
      "Epoch 8511/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1382162319.4051 - val_loss: 4075547634.5571\n",
      "Epoch 8512/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1379808554.2074 - val_loss: 4067733835.1050\n",
      "Epoch 8513/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1379874961.2838 - val_loss: 4066323026.5571\n",
      "Epoch 8514/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1379405366.3562 - val_loss: 4068130868.0183\n",
      "Epoch 8515/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1380968853.8552 - val_loss: 4068161390.3196\n",
      "Epoch 8516/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1379378277.9491 - val_loss: 4060693980.7854\n",
      "Epoch 8517/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1380962497.8787 - val_loss: 4067580840.1826\n",
      "Epoch 8518/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1381259856.2818 - val_loss: 4050432645.5525\n",
      "Epoch 8519/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1379573979.9295 - val_loss: 4069756317.0776\n",
      "Epoch 8520/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1380186238.7476 - val_loss: 4068359858.7032\n",
      "Epoch 8521/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1379903257.5499 - val_loss: 4074520899.7991\n",
      "Epoch 8522/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1381019523.6321 - val_loss: 4066770444.2740\n",
      "Epoch 8523/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1380025042.1605 - val_loss: 4056044608.5845\n",
      "Epoch 8524/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1379424381.9961 - val_loss: 4073353722.8858\n",
      "Epoch 8525/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1381207193.8004 - val_loss: 4057910515.8721\n",
      "Epoch 8526/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1379049391.0920 - val_loss: 4076148380.9315\n",
      "Epoch 8527/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1380025812.4149 - val_loss: 4077250998.5023\n",
      "Epoch 8528/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 41us/step - loss: 1380025892.8845 - val_loss: 4068051627.3973\n",
      "Epoch 8529/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1379987585.5029 - val_loss: 4069342115.6530\n",
      "Epoch 8530/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1379419024.7828 - val_loss: 4061434530.7763\n",
      "Epoch 8531/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1379489113.8004 - val_loss: 4060535234.4840\n",
      "Epoch 8532/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1381617064.3288 - val_loss: 4079510138.8858\n",
      "Epoch 8533/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1380611763.0998 - val_loss: 4058476663.8174\n",
      "Epoch 8534/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1380263425.0020 - val_loss: 4078496935.0137\n",
      "Epoch 8535/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1382899401.3933 - val_loss: 4069346864.9498\n",
      "Epoch 8536/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1380167216.5949 - val_loss: 4073686886.1370\n",
      "Epoch 8537/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1379875910.6380 - val_loss: 4057180822.9406\n",
      "Epoch 8538/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1379395229.5577 - val_loss: 4060023084.4201\n",
      "Epoch 8539/10000\n",
      "1022/1022 [==============================] - 0s 36us/step - loss: 1379903785.0802 - val_loss: 4071621053.5160\n",
      "Epoch 8540/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1379823900.3053 - val_loss: 4070618889.3516\n",
      "Epoch 8541/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1379541451.8982 - val_loss: 4069876162.7763\n",
      "Epoch 8542/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1381329528.2348 - val_loss: 4052639429.8447\n",
      "Epoch 8543/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1379228263.5773 - val_loss: 4069301660.7854\n",
      "Epoch 8544/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1380937247.8121 - val_loss: 4076531651.3607\n",
      "Epoch 8545/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1380949270.2935 - val_loss: 4053451406.9041\n",
      "Epoch 8546/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1381512397.4012 - val_loss: 4065759751.4521\n",
      "Epoch 8547/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1379245908.1644 - val_loss: 4065865816.2557\n",
      "Epoch 8548/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1379786504.5166 - val_loss: 4069891546.0091\n",
      "Epoch 8549/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1379360199.2642 - val_loss: 4061082813.9543\n",
      "Epoch 8550/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1381480669.4325 - val_loss: 4088690043.1781\n",
      "Epoch 8551/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1379982570.0822 - val_loss: 4063733703.8904\n",
      "Epoch 8552/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1379441950.3092 - val_loss: 4068292288.5845\n",
      "Epoch 8553/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1379739726.7789 - val_loss: 4071081876.4566\n",
      "Epoch 8554/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1379477160.2035 - val_loss: 4062109853.3699\n",
      "Epoch 8555/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1379467831.1076 - val_loss: 4064987706.3014\n",
      "Epoch 8556/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1379877877.3542 - val_loss: 4057537203.5799\n",
      "Epoch 8557/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1379419913.0176 - val_loss: 4067324807.8904\n",
      "Epoch 8558/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1380597861.6986 - val_loss: 4062854455.9635\n",
      "Epoch 8559/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1379775657.8317 - val_loss: 4076178385.5342\n",
      "Epoch 8560/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1380073901.6517 - val_loss: 4067662665.3516\n",
      "Epoch 8561/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1380601410.1292 - val_loss: 4085049941.3333\n",
      "Epoch 8562/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1381062090.6458 - val_loss: 4053481098.8128\n",
      "Epoch 8563/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1380923039.3112 - val_loss: 4063126721.4612\n",
      "Epoch 8564/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1379486117.5734 - val_loss: 4062247765.7717\n",
      "Epoch 8565/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1379245601.8160 - val_loss: 4064820538.7397\n",
      "Epoch 8566/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1380461574.7006 - val_loss: 4078493134.0274\n",
      "Epoch 8567/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1380141605.5734 - val_loss: 4063584157.5160\n",
      "Epoch 8568/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1379684822.4188 - val_loss: 4067473838.0274\n",
      "Epoch 8569/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1379061194.1448 - val_loss: 4064178062.9041\n",
      "Epoch 8570/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1379105301.7926 - val_loss: 4066203050.6667\n",
      "Epoch 8571/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1380756824.9237 - val_loss: 4073631978.9589\n",
      "Epoch 8572/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1379477587.5382 - val_loss: 4068704996.6758\n",
      "Epoch 8573/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1379927038.4971 - val_loss: 4067949077.7717\n",
      "Epoch 8574/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1384622625.0646 - val_loss: 4063572696.2557\n",
      "Epoch 8575/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1379937729.1272 - val_loss: 4069875945.6438\n",
      "Epoch 8576/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1379169761.1898 - val_loss: 4071204610.0457\n",
      "Epoch 8577/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1379213160.0783 - val_loss: 4058664285.2237\n",
      "Epoch 8578/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1379308072.0783 - val_loss: 4069034464.1461\n",
      "Epoch 8579/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1379627924.0391 - val_loss: 4071058199.0868\n",
      "Epoch 8580/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1379665110.7945 - val_loss: 4059153435.1781\n",
      "Epoch 8581/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1379207800.9863 - val_loss: 4066669337.4247\n",
      "Epoch 8582/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1379490835.9139 - val_loss: 4067056580.3836\n",
      "Epoch 8583/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1380591343.4677 - val_loss: 4062452509.9543\n",
      "Epoch 8584/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1380579348.9159 - val_loss: 4079706833.0959\n",
      "Epoch 8585/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1379876472.7358 - val_loss: 4053663722.2283\n",
      "Epoch 8586/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1379146903.5460 - val_loss: 4064760978.4110\n",
      "Epoch 8587/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1381034345.2055 - val_loss: 4058697141.9178\n",
      "Epoch 8588/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1380536661.1663 - val_loss: 4057238879.7078\n",
      "Epoch 8589/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1379563592.6419 - val_loss: 4069486381.2968\n",
      "Epoch 8590/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1380069719.1703 - val_loss: 4082307075.5068\n",
      "Epoch 8591/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1379332072.4540 - val_loss: 4076889986.7763\n",
      "Epoch 8592/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 41us/step - loss: 1381985726.2466 - val_loss: 4054514205.8082\n",
      "Epoch 8593/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1381273573.4481 - val_loss: 4076687163.7626\n",
      "Epoch 8594/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1379436743.6399 - val_loss: 4067208047.3425\n",
      "Epoch 8595/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1380210958.7789 - val_loss: 4055272257.0228\n",
      "Epoch 8596/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1381863204.4462 - val_loss: 4064154332.7854\n",
      "Epoch 8597/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1379686346.0196 - val_loss: 4063392923.3242\n",
      "Epoch 8598/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1379247769.2994 - val_loss: 4071254068.1644\n",
      "Epoch 8599/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1379117317.3855 - val_loss: 4075407847.3059\n",
      "Epoch 8600/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1379505604.0078 - val_loss: 4063633919.1233\n",
      "Epoch 8601/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1380441060.4462 - val_loss: 4073445349.8447\n",
      "Epoch 8602/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1381535165.2446 - val_loss: 4073009964.7123\n",
      "Epoch 8603/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1379864036.4462 - val_loss: 4074692417.1689\n",
      "Epoch 8604/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1379078421.0411 - val_loss: 4067049312.5845\n",
      "Epoch 8605/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1379271068.3053 - val_loss: 4067894098.1187\n",
      "Epoch 8606/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1378988229.5108 - val_loss: 4072713331.2877\n",
      "Epoch 8607/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1379817908.7280 - val_loss: 4062077775.1963\n",
      "Epoch 8608/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1385390406.2622 - val_loss: 4069851092.0183\n",
      "Epoch 8609/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1379889514.2074 - val_loss: 4057309013.7717\n",
      "Epoch 8610/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1382833406.7476 - val_loss: 4059642347.3973\n",
      "Epoch 8611/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1382107995.6791 - val_loss: 4069990785.3151\n",
      "Epoch 8612/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1379490682.9902 - val_loss: 4060045645.2968\n",
      "Epoch 8613/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1379416749.3386 - val_loss: 4058484031.8539\n",
      "Epoch 8614/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1381719867.1155 - val_loss: 4083580048.8037\n",
      "Epoch 8615/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1379090242.6301 - val_loss: 4060505226.6667\n",
      "Epoch 8616/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1379001456.2192 - val_loss: 4062968240.9498\n",
      "Epoch 8617/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1380206190.4658 - val_loss: 4060991287.8174\n",
      "Epoch 8618/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1381831795.7260 - val_loss: 4071871893.6256\n",
      "Epoch 8619/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1379786729.1429 - val_loss: 4062592234.3744\n",
      "Epoch 8620/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1381405010.5362 - val_loss: 4090137980.6393\n",
      "Epoch 8621/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1378811700.3523 - val_loss: 4072534353.3881\n",
      "Epoch 8622/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1380758208.5010 - val_loss: 4052162562.7763\n",
      "Epoch 8623/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1380095979.0841 - val_loss: 4061380289.7534\n",
      "Epoch 8624/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1380315106.3170 - val_loss: 4070929510.4292\n",
      "Epoch 8625/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1379593567.1859 - val_loss: 4068790501.4064\n",
      "Epoch 8626/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1381323188.8532 - val_loss: 4060687250.8493\n",
      "Epoch 8627/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1380541615.2172 - val_loss: 4060676400.2192\n",
      "Epoch 8628/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1379597161.4560 - val_loss: 4084426360.9863\n",
      "Epoch 8629/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1379299707.2407 - val_loss: 4068067785.2055\n",
      "Epoch 8630/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1379418997.3542 - val_loss: 4063892477.2237\n",
      "Epoch 8631/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1379454558.1840 - val_loss: 4078279056.8037\n",
      "Epoch 8632/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1381395611.0528 - val_loss: 4070235225.1324\n",
      "Epoch 8633/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1378771284.0391 - val_loss: 4066901521.5342\n",
      "Epoch 8634/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1379303704.9237 - val_loss: 4060807636.4566\n",
      "Epoch 8635/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1380649853.7456 - val_loss: 4070364458.0822\n",
      "Epoch 8636/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1381293527.9217 - val_loss: 4046379256.6941\n",
      "Epoch 8637/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1385576687.4677 - val_loss: 4090382229.7717\n",
      "Epoch 8638/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1380402208.0626 - val_loss: 4071154585.4247\n",
      "Epoch 8639/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1379968490.4579 - val_loss: 4062028554.9589\n",
      "Epoch 8640/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1379366531.2564 - val_loss: 4061705800.0365\n",
      "Epoch 8641/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1379276536.9863 - val_loss: 4072884692.4566\n",
      "Epoch 8642/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1379131261.7456 - val_loss: 4073615793.8265\n",
      "Epoch 8643/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1379032716.0235 - val_loss: 4069381985.1689\n",
      "Epoch 8644/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1378878198.7319 - val_loss: 4062518354.9954\n",
      "Epoch 8645/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1381057013.4795 - val_loss: 4056368264.7671\n",
      "Epoch 8646/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1380348067.8200 - val_loss: 4082077868.8584\n",
      "Epoch 8647/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1381008479.9374 - val_loss: 4075301153.8995\n",
      "Epoch 8648/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1379774618.0509 - val_loss: 4060998437.6986\n",
      "Epoch 8649/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1379523221.0411 - val_loss: 4067142201.7169\n",
      "Epoch 8650/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1378786631.1389 - val_loss: 4068110666.0822\n",
      "Epoch 8651/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1379280333.9022 - val_loss: 4071373231.9269\n",
      "Epoch 8652/10000\n",
      "1022/1022 [==============================] - 0s 98us/step - loss: 1381149738.2701 - val_loss: 4071064694.7945\n",
      "Epoch 8653/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1379961938.0352 - val_loss: 4066572025.8630\n",
      "Epoch 8654/10000\n",
      "1022/1022 [==============================] - 0s 73us/step - loss: 1379618967.2955 - val_loss: 4061895473.0959\n",
      "Epoch 8655/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1379472821.1037 - val_loss: 4062220564.6027\n",
      "Epoch 8656/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 46us/step - loss: 1379356728.8611 - val_loss: 4066908417.1689\n",
      "Epoch 8657/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1381075816.5793 - val_loss: 4060913325.7352\n",
      "Epoch 8658/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1381275494.4501 - val_loss: 4081324073.6438\n",
      "Epoch 8659/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1382337849.2368 - val_loss: 4065039341.1507\n",
      "Epoch 8660/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1381967370.7710 - val_loss: 4066991468.8584\n",
      "Epoch 8661/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1378911116.2740 - val_loss: 4064080929.3151\n",
      "Epoch 8662/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1381225475.6321 - val_loss: 4061080568.5479\n",
      "Epoch 8663/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1378775838.4344 - val_loss: 4068256169.0594\n",
      "Epoch 8664/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1378578726.0744 - val_loss: 4072126446.0274\n",
      "Epoch 8665/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1379134059.7104 - val_loss: 4066169368.2557\n",
      "Epoch 8666/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1379258980.4462 - val_loss: 4062615869.2237\n",
      "Epoch 8667/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1379808850.6614 - val_loss: 4068119515.7626\n",
      "Epoch 8668/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1379622151.8904 - val_loss: 4056083807.7078\n",
      "Epoch 8669/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1378509437.9961 - val_loss: 4068422686.8311\n",
      "Epoch 8670/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1380790896.7202 - val_loss: 4079520281.2785\n",
      "Epoch 8671/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1379179118.4658 - val_loss: 4056090727.1598\n",
      "Epoch 8672/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1379413198.9041 - val_loss: 4067982028.5662\n",
      "Epoch 8673/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1378866914.6928 - val_loss: 4064284488.1826\n",
      "Epoch 8674/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1378363538.7867 - val_loss: 4068467807.1233\n",
      "Epoch 8675/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1379564650.5832 - val_loss: 4057192800.2922\n",
      "Epoch 8676/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1379178345.7065 - val_loss: 4068856827.7626\n",
      "Epoch 8677/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1381164400.9706 - val_loss: 4052761451.6895\n",
      "Epoch 8678/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1381026724.6967 - val_loss: 4080793388.5662\n",
      "Epoch 8679/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1381157493.7299 - val_loss: 4049172670.8311\n",
      "Epoch 8680/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1379954242.8806 - val_loss: 4056775832.5479\n",
      "Epoch 8681/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1387581218.5675 - val_loss: 4087981172.3105\n",
      "Epoch 8682/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1381181631.1859 - val_loss: 4059612227.2146\n",
      "Epoch 8683/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1382085261.5264 - val_loss: 4076615003.1781\n",
      "Epoch 8684/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1379609098.2701 - val_loss: 4061872402.8493\n",
      "Epoch 8685/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1379687112.5166 - val_loss: 4059816093.3699\n",
      "Epoch 8686/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1379333901.1507 - val_loss: 4065298582.2100\n",
      "Epoch 8687/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1378932382.3092 - val_loss: 4065365461.4795\n",
      "Epoch 8688/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1380246609.9100 - val_loss: 4056905323.9817\n",
      "Epoch 8689/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1381167029.8552 - val_loss: 4088299357.8082\n",
      "Epoch 8690/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1378008371.3503 - val_loss: 4063572861.6621\n",
      "Epoch 8691/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1380924241.0333 - val_loss: 4061817809.5342\n",
      "Epoch 8692/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1381125269.9178 - val_loss: 4067700776.6210\n",
      "Epoch 8693/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1381277390.1526 - val_loss: 4059334288.2192\n",
      "Epoch 8694/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1379903715.1937 - val_loss: 4061716058.4475\n",
      "Epoch 8695/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1379151315.9139 - val_loss: 4077974551.3790\n",
      "Epoch 8696/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1379626427.3659 - val_loss: 4069629330.1187\n",
      "Epoch 8697/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1379461995.7104 - val_loss: 4077295058.5571\n",
      "Epoch 8698/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1379997283.1937 - val_loss: 4068605398.6484\n",
      "Epoch 8699/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1381596128.8141 - val_loss: 4049063356.6393\n",
      "Epoch 8700/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1378922260.5401 - val_loss: 4061084320.4384\n",
      "Epoch 8701/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1379411870.1840 - val_loss: 4075307102.8311\n",
      "Epoch 8702/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1379060321.8160 - val_loss: 4069422767.9269\n",
      "Epoch 8703/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1379284853.2290 - val_loss: 4074199793.0959\n",
      "Epoch 8704/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1380472929.9413 - val_loss: 4063163278.1735\n",
      "Epoch 8705/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1378858009.5499 - val_loss: 4069912018.7032\n",
      "Epoch 8706/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1378933608.8297 - val_loss: 4069541470.8311\n",
      "Epoch 8707/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1379909088.4384 - val_loss: 4075318896.9498\n",
      "Epoch 8708/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1381342596.5088 - val_loss: 4082500576.2922\n",
      "Epoch 8709/10000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1378582426.5519 - val_loss: 4064058165.7717\n",
      "Epoch 8710/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1379035404.6497 - val_loss: 4059614484.8950\n",
      "Epoch 8711/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1379263723.8356 - val_loss: 4062647334.1370\n",
      "Epoch 8712/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1380146884.2583 - val_loss: 4065235060.8950\n",
      "Epoch 8713/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1379578239.4990 - val_loss: 4071277263.3425\n",
      "Epoch 8714/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1378749236.3523 - val_loss: 4058512697.1324\n",
      "Epoch 8715/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1380609274.2387 - val_loss: 4061709308.6393\n",
      "Epoch 8716/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1379516819.0372 - val_loss: 4054564107.9817\n",
      "Epoch 8717/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1382095496.0157 - val_loss: 4077909454.1735\n",
      "Epoch 8718/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1378544265.3933 - val_loss: 4064012532.0183\n",
      "Epoch 8719/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1380970915.0685 - val_loss: 4061744515.2146\n",
      "Epoch 8720/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 63us/step - loss: 1378644433.7847 - val_loss: 4062639668.0183\n",
      "Epoch 8721/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1379552722.6614 - val_loss: 4056320253.9543\n",
      "Epoch 8722/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1378130444.2740 - val_loss: 4072230882.9224\n",
      "Epoch 8723/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1378510042.6771 - val_loss: 4072183845.6986\n",
      "Epoch 8724/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1378205464.5479 - val_loss: 4066566822.1370\n",
      "Epoch 8725/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1379466410.9589 - val_loss: 4061753900.2740\n",
      "Epoch 8726/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1378685769.1429 - val_loss: 4071860132.0913\n",
      "Epoch 8727/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1380314844.1800 - val_loss: 4055856009.2055\n",
      "Epoch 8728/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1378892304.4070 - val_loss: 4080133830.2831\n",
      "Epoch 8729/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1379660625.1585 - val_loss: 4079800931.2146\n",
      "Epoch 8730/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1380834538.2074 - val_loss: 4078416961.6073\n",
      "Epoch 8731/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1380177459.0998 - val_loss: 4077292997.6986\n",
      "Epoch 8732/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1378651869.5577 - val_loss: 4052045711.0502\n",
      "Epoch 8733/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1381781080.6732 - val_loss: 4048153745.3881\n",
      "Epoch 8734/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1378923021.1507 - val_loss: 4080514474.9589\n",
      "Epoch 8735/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1380071647.0607 - val_loss: 4067789515.8356\n",
      "Epoch 8736/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1378424441.6125 - val_loss: 4065199982.6119\n",
      "Epoch 8737/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1378970473.3307 - val_loss: 4074166234.8858\n",
      "Epoch 8738/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1379321164.9002 - val_loss: 4057107390.5388\n",
      "Epoch 8739/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1379598074.8650 - val_loss: 4069081387.2511\n",
      "Epoch 8740/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1380146001.9100 - val_loss: 4071343744.7306\n",
      "Epoch 8741/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1379295965.4325 - val_loss: 4061545091.3607\n",
      "Epoch 8742/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1379961610.7710 - val_loss: 4059833637.8447\n",
      "Epoch 8743/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1379353338.4892 - val_loss: 4068771512.1096\n",
      "Epoch 8744/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1379814343.3894 - val_loss: 4055648080.0731\n",
      "Epoch 8745/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1381397641.0176 - val_loss: 4076174384.5114\n",
      "Epoch 8746/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1378707485.3072 - val_loss: 4060317152.7306\n",
      "Epoch 8747/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1380187851.5225 - val_loss: 4068683525.4064\n",
      "Epoch 8748/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1381169390.9667 - val_loss: 4055719384.2557\n",
      "Epoch 8749/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1379573528.9863 - val_loss: 4064340016.0731\n",
      "Epoch 8750/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1378567152.7202 - val_loss: 4080394386.4110\n",
      "Epoch 8751/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1378787408.6575 - val_loss: 4073332828.9315\n",
      "Epoch 8752/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1379991793.4716 - val_loss: 4058356363.6895\n",
      "Epoch 8753/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1381118488.1722 - val_loss: 4071369887.7078\n",
      "Epoch 8754/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1380775469.2133 - val_loss: 4060089066.5205\n",
      "Epoch 8755/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1378122903.0450 - val_loss: 4073933715.5799\n",
      "Epoch 8756/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1378774398.1213 - val_loss: 4069847917.1507\n",
      "Epoch 8757/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1379195883.7104 - val_loss: 4058326639.4886\n",
      "Epoch 8758/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1380020935.1389 - val_loss: 4075792277.6256\n",
      "Epoch 8759/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1379583113.0176 - val_loss: 4065013347.7991\n",
      "Epoch 8760/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1379368607.5616 - val_loss: 4062574685.0776\n",
      "Epoch 8761/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1379075527.3894 - val_loss: 4070066761.0594\n",
      "Epoch 8762/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1379387232.1879 - val_loss: 4062477376.8767\n",
      "Epoch 8763/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1382613151.9374 - val_loss: 4072511919.0502\n",
      "Epoch 8764/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1379804992.7515 - val_loss: 4060641315.5068\n",
      "Epoch 8765/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1379241498.3014 - val_loss: 4078963297.1689\n",
      "Epoch 8766/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1379357404.1800 - val_loss: 4077935715.5068\n",
      "Epoch 8767/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1378669480.7045 - val_loss: 4068628485.1142\n",
      "Epoch 8768/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1378987268.2583 - val_loss: 4068113772.2740\n",
      "Epoch 8769/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1378542911.1233 - val_loss: 4055359550.6849\n",
      "Epoch 8770/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1379751076.0705 - val_loss: 4059473565.6621\n",
      "Epoch 8771/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1379514886.7632 - val_loss: 4080048531.4338\n",
      "Epoch 8772/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1378986877.1194 - val_loss: 4066458043.9087\n",
      "Epoch 8773/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1380860867.3816 - val_loss: 4067649245.9543\n",
      "Epoch 8774/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1378597814.1057 - val_loss: 4071249814.2100\n",
      "Epoch 8775/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1379519649.0646 - val_loss: 4061834804.0183\n",
      "Epoch 8776/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1378857400.8611 - val_loss: 4077946491.6164\n",
      "Epoch 8777/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1379269602.1918 - val_loss: 4060620625.8265\n",
      "Epoch 8778/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1380227182.7162 - val_loss: 4058846805.0411\n",
      "Epoch 8779/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1378291125.3542 - val_loss: 4063461005.4429\n",
      "Epoch 8780/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1379182095.0294 - val_loss: 4065726411.8356\n",
      "Epoch 8781/10000\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 1378441703.4521 - val_loss: 4074615423.2694\n",
      "Epoch 8782/10000\n",
      "1022/1022 [==============================] - 0s 70us/step - loss: 1379315419.4286 - val_loss: 4078610629.5525\n",
      "Epoch 8783/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1381512782.9041 - val_loss: 4057183705.1324\n",
      "Epoch 8784/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 43us/step - loss: 1378457536.6262 - val_loss: 4069894120.0365\n",
      "Epoch 8785/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1380801210.8650 - val_loss: 4081303768.8402\n",
      "Epoch 8786/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1377789850.4266 - val_loss: 4060228254.2466\n",
      "Epoch 8787/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1378856933.4481 - val_loss: 4060549529.8630\n",
      "Epoch 8788/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1378577270.2309 - val_loss: 4063991432.4749\n",
      "Epoch 8789/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1379437944.7358 - val_loss: 4063193179.9087\n",
      "Epoch 8790/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1380997216.6888 - val_loss: 4062116866.9224\n",
      "Epoch 8791/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1380393494.1683 - val_loss: 4070382686.3927\n",
      "Epoch 8792/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1378720060.7436 - val_loss: 4075266575.0502\n",
      "Epoch 8793/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1379952355.4442 - val_loss: 4081991627.5434\n",
      "Epoch 8794/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1379501104.9706 - val_loss: 4055907652.2374\n",
      "Epoch 8795/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1378964628.2896 - val_loss: 4071209071.4886\n",
      "Epoch 8796/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1378550765.7769 - val_loss: 4058504104.6210\n",
      "Epoch 8797/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1380053311.8748 - val_loss: 4068661593.1324\n",
      "Epoch 8798/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1380749942.3562 - val_loss: 4065842338.1918\n",
      "Epoch 8799/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1378661518.7789 - val_loss: 4056809019.3242\n",
      "Epoch 8800/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1378462740.4149 - val_loss: 4069320569.4247\n",
      "Epoch 8801/10000\n",
      "1022/1022 [==============================] - 0s 66us/step - loss: 1379007424.8767 - val_loss: 4065525665.0228\n",
      "Epoch 8802/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1378064607.1859 - val_loss: 4064939942.8676\n",
      "Epoch 8803/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1380917517.5264 - val_loss: 4083760577.7534\n",
      "Epoch 8804/10000\n",
      "1022/1022 [==============================] - 0s 63us/step - loss: 1385430759.8278 - val_loss: 4049707710.1005\n",
      "Epoch 8805/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1380591531.4599 - val_loss: 4083992778.9589\n",
      "Epoch 8806/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1377814996.6654 - val_loss: 4068520872.0365\n",
      "Epoch 8807/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1378287122.2857 - val_loss: 4060918624.8767\n",
      "Epoch 8808/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1378967339.3346 - val_loss: 4056355687.3059\n",
      "Epoch 8809/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1379150776.7358 - val_loss: 4061430230.5023\n",
      "Epoch 8810/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1378875397.8239 - val_loss: 4075635509.6256\n",
      "Epoch 8811/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1378626426.4892 - val_loss: 4057105014.5023\n",
      "Epoch 8812/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1380629959.2642 - val_loss: 4050540183.6712\n",
      "Epoch 8813/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1378732156.4932 - val_loss: 4063464891.6164\n",
      "Epoch 8814/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1382590440.2035 - val_loss: 4069872089.1324\n",
      "Epoch 8815/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1380479646.4344 - val_loss: 4082935702.2100\n",
      "Epoch 8816/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1378373110.2309 - val_loss: 4064988940.2740\n",
      "Epoch 8817/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1378894928.1566 - val_loss: 4060925873.3881\n",
      "Epoch 8818/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1378366389.4795 - val_loss: 4065332007.4521\n",
      "Epoch 8819/10000\n",
      "1022/1022 [==============================] - 0s 71us/step - loss: 1379831662.4658 - val_loss: 4076128943.4886\n",
      "Epoch 8820/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1380411252.2270 - val_loss: 4051418443.1050\n",
      "Epoch 8821/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1378513726.8728 - val_loss: 4061588082.2648\n",
      "Epoch 8822/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1379189333.6673 - val_loss: 4055062856.1826\n",
      "Epoch 8823/10000\n",
      "1022/1022 [==============================] - 0s 63us/step - loss: 1382953177.0489 - val_loss: 4075339587.7991\n",
      "Epoch 8824/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1378684736.5010 - val_loss: 4069715672.6941\n",
      "Epoch 8825/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1378083922.4110 - val_loss: 4069661370.3014\n",
      "Epoch 8826/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1380248402.1605 - val_loss: 4053298919.5982\n",
      "Epoch 8827/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1380161410.5049 - val_loss: 4081662029.8813\n",
      "Epoch 8828/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1381961992.5166 - val_loss: 4058246161.0959\n",
      "Epoch 8829/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1378360177.7221 - val_loss: 4072813380.9680\n",
      "Epoch 8830/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1379190002.4736 - val_loss: 4061507814.2831\n",
      "Epoch 8831/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1379829065.0176 - val_loss: 4059909817.7169\n",
      "Epoch 8832/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1379319220.3523 - val_loss: 4068560009.2055\n",
      "Epoch 8833/10000\n",
      "1022/1022 [==============================] - 0s 74us/step - loss: 1379841051.6791 - val_loss: 4068042568.9132\n",
      "Epoch 8834/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1379598210.0039 - val_loss: 4059316154.1553\n",
      "Epoch 8835/10000\n",
      "1022/1022 [==============================] - 0s 66us/step - loss: 1378769010.8493 - val_loss: 4078284770.7763\n",
      "Epoch 8836/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1378759070.5597 - val_loss: 4062675901.5160\n",
      "Epoch 8837/10000\n",
      "1022/1022 [==============================] - 0s 72us/step - loss: 1379135460.6967 - val_loss: 4069167632.2192\n",
      "Epoch 8838/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1378615033.3620 - val_loss: 4076940026.0091\n",
      "Epoch 8839/10000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1378138938.7397 - val_loss: 4065308869.1142\n",
      "Epoch 8840/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1378376010.6458 - val_loss: 4072740084.6027\n",
      "Epoch 8841/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1380632922.8023 - val_loss: 4066541801.3516\n",
      "Epoch 8842/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1379333220.6967 - val_loss: 4060613743.9269\n",
      "Epoch 8843/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1378491898.7397 - val_loss: 4076436684.5662\n",
      "Epoch 8844/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1378795283.4129 - val_loss: 4074144935.5982\n",
      "Epoch 8845/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1378500175.1546 - val_loss: 4064320113.0959\n",
      "Epoch 8846/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1379067375.2172 - val_loss: 4073684730.4475\n",
      "Epoch 8847/10000\n",
      "1022/1022 [==============================] - 0s 78us/step - loss: 1378823955.5382 - val_loss: 4057899504.0731\n",
      "Epoch 8848/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 42us/step - loss: 1380558741.7926 - val_loss: 4083476553.3516\n",
      "Epoch 8849/10000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1384749690.7397 - val_loss: 4053117525.0411\n",
      "Epoch 8850/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1379209258.5832 - val_loss: 4066419412.8950\n",
      "Epoch 8851/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1379894869.6673 - val_loss: 4069378010.4475\n",
      "Epoch 8852/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1380451703.8591 - val_loss: 4064636724.1644\n",
      "Epoch 8853/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1379594867.9765 - val_loss: 4079375040.4384\n",
      "Epoch 8854/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1378870289.2838 - val_loss: 4064798120.0365\n",
      "Epoch 8855/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1378838467.1311 - val_loss: 4066722292.4566\n",
      "Epoch 8856/10000\n",
      "1022/1022 [==============================] - 0s 73us/step - loss: 1379093171.6008 - val_loss: 4058568774.8676\n",
      "Epoch 8857/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1378442846.6849 - val_loss: 4072593007.3425\n",
      "Epoch 8858/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1379434078.1840 - val_loss: 4080802942.9772\n",
      "Epoch 8859/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1378521142.3562 - val_loss: 4069919630.3196\n",
      "Epoch 8860/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1379034268.8063 - val_loss: 4057102897.9726\n",
      "Epoch 8861/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1379217205.6047 - val_loss: 4063147284.7489\n",
      "Epoch 8862/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1379085705.5186 - val_loss: 4059879970.7763\n",
      "Epoch 8863/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1378288224.4384 - val_loss: 4069650682.7397\n",
      "Epoch 8864/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1378898745.6125 - val_loss: 4077820240.6575\n",
      "Epoch 8865/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1379166087.5147 - val_loss: 4062438677.7717\n",
      "Epoch 8866/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1378346440.7671 - val_loss: 4067039971.7991\n",
      "Epoch 8867/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1378273098.1448 - val_loss: 4054832814.0274\n",
      "Epoch 8868/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1378938729.4560 - val_loss: 4071369624.4018\n",
      "Epoch 8869/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1379507451.7417 - val_loss: 4058200539.4703\n",
      "Epoch 8870/10000\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 1378540381.9335 - val_loss: 4077539100.7854\n",
      "Epoch 8871/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1378122421.4795 - val_loss: 4061566544.6575\n",
      "Epoch 8872/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1378529052.5558 - val_loss: 4064350464.4384\n",
      "Epoch 8873/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1378947945.0802 - val_loss: 4058684115.1416\n",
      "Epoch 8874/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1378999382.4188 - val_loss: 4056965843.1416\n",
      "Epoch 8875/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1378598393.7378 - val_loss: 4068976175.7808\n",
      "Epoch 8876/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1379148428.1487 - val_loss: 4065881433.1324\n",
      "Epoch 8877/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1378514506.7710 - val_loss: 4074727506.8493\n",
      "Epoch 8878/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1378920451.3190 - val_loss: 4065071484.0548\n",
      "Epoch 8879/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1378664821.9804 - val_loss: 4054623040.4384\n",
      "Epoch 8880/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1378764618.8963 - val_loss: 4059775002.4475\n",
      "Epoch 8881/10000\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 1378097406.8728 - val_loss: 4063475256.9863\n",
      "Epoch 8882/10000\n",
      "1022/1022 [==============================] - 0s 68us/step - loss: 1378272201.1429 - val_loss: 4066084815.4886\n",
      "Epoch 8883/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1378389427.6008 - val_loss: 4070567779.9452\n",
      "Epoch 8884/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1378224755.9765 - val_loss: 4076647129.7169\n",
      "Epoch 8885/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1379803356.1800 - val_loss: 4071443188.3105\n",
      "Epoch 8886/10000\n",
      "1022/1022 [==============================] - 0s 68us/step - loss: 1378600033.6908 - val_loss: 4059232698.4475\n",
      "Epoch 8887/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1378460519.8278 - val_loss: 4055312709.4064\n",
      "Epoch 8888/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1378469208.2975 - val_loss: 4060390695.7443\n",
      "Epoch 8889/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1378567712.8141 - val_loss: 4073826096.9498\n",
      "Epoch 8890/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1379093904.5323 - val_loss: 4062058508.8584\n",
      "Epoch 8891/10000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1380466001.9100 - val_loss: 4083277411.2146\n",
      "Epoch 8892/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1378157467.0528 - val_loss: 4067681383.8904\n",
      "Epoch 8893/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1379107344.8454 - val_loss: 4064442236.9315\n",
      "Epoch 8894/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1378256704.0000 - val_loss: 4058215621.8447\n",
      "Epoch 8895/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1378666506.0196 - val_loss: 4065111353.1324\n",
      "Epoch 8896/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1378170472.7045 - val_loss: 4063950610.5571\n",
      "Epoch 8897/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1378986086.1996 - val_loss: 4082057053.9543\n",
      "Epoch 8898/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1378415506.5362 - val_loss: 4063201482.5205\n",
      "Epoch 8899/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1378899568.2192 - val_loss: 4058593475.7991\n",
      "Epoch 8900/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1378862427.1781 - val_loss: 4064994884.5297\n",
      "Epoch 8901/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1379391107.6321 - val_loss: 4054988274.4110\n",
      "Epoch 8902/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1379939960.1096 - val_loss: 4057777518.3196\n",
      "Epoch 8903/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1377625330.7241 - val_loss: 4071850218.5205\n",
      "Epoch 8904/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1379685060.1331 - val_loss: 4058274588.6393\n",
      "Epoch 8905/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1378569043.0372 - val_loss: 4073247006.9772\n",
      "Epoch 8906/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1379749747.8513 - val_loss: 4054615401.6438\n",
      "Epoch 8907/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1378381194.4579 - val_loss: 4078538128.5114\n",
      "Epoch 8908/10000\n",
      "1022/1022 [==============================] - 0s 63us/step - loss: 1378627243.9609 - val_loss: 4058707850.0822\n",
      "Epoch 8909/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1379036164.2583 - val_loss: 4062783633.2420\n",
      "Epoch 8910/10000\n",
      "1022/1022 [==============================] - 0s 65us/step - loss: 1380073347.5068 - val_loss: 4070951028.3105\n",
      "Epoch 8911/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1377990267.3659 - val_loss: 4064786834.4110\n",
      "Epoch 8912/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 46us/step - loss: 1378700487.3894 - val_loss: 4056536265.9361\n",
      "Epoch 8913/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1378901178.3640 - val_loss: 4071347321.7169\n",
      "Epoch 8914/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1378432732.4305 - val_loss: 4070403581.5160\n",
      "Epoch 8915/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1381262162.1605 - val_loss: 4073944910.6119\n",
      "Epoch 8916/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1380447423.8748 - val_loss: 4072423857.2420\n",
      "Epoch 8917/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1379046417.5342 - val_loss: 4054757389.1507\n",
      "Epoch 8918/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1379038056.7045 - val_loss: 4059991356.2009\n",
      "Epoch 8919/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1381376031.3112 - val_loss: 4054462689.7534\n",
      "Epoch 8920/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1379437565.2446 - val_loss: 4069458689.6073\n",
      "Epoch 8921/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1378704630.9824 - val_loss: 4077464043.8356\n",
      "Epoch 8922/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1379152640.5010 - val_loss: 4054234810.0091\n",
      "Epoch 8923/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1378929205.3542 - val_loss: 4062307314.4110\n",
      "Epoch 8924/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1380517328.4070 - val_loss: 4062765005.7352\n",
      "Epoch 8925/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1378505185.6908 - val_loss: 4074086101.1872\n",
      "Epoch 8926/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1379129228.5245 - val_loss: 4071433138.2648\n",
      "Epoch 8927/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1378171550.5597 - val_loss: 4058900148.4566\n",
      "Epoch 8928/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1378507959.2329 - val_loss: 4056758211.6530\n",
      "Epoch 8929/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1380078340.0078 - val_loss: 4073772150.7945\n",
      "Epoch 8930/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1377895548.9941 - val_loss: 4058849456.5114\n",
      "Epoch 8931/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1380092476.4932 - val_loss: 4052517157.5525\n",
      "Epoch 8932/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1381880840.3914 - val_loss: 4067685840.0731\n",
      "Epoch 8933/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1378409679.4051 - val_loss: 4057566243.5068\n",
      "Epoch 8934/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1378173610.2074 - val_loss: 4063675362.7763\n",
      "Epoch 8935/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1378219597.6517 - val_loss: 4071396861.5160\n",
      "Epoch 8936/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1379128553.8317 - val_loss: 4052002973.9543\n",
      "Epoch 8937/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1378977303.5460 - val_loss: 4068061701.8447\n",
      "Epoch 8938/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1377798713.7378 - val_loss: 4068914107.7626\n",
      "Epoch 8939/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1378599339.5851 - val_loss: 4071094640.9498\n",
      "Epoch 8940/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1379678080.5010 - val_loss: 4055505343.8539\n",
      "Epoch 8941/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1378175023.5930 - val_loss: 4068056600.1096\n",
      "Epoch 8942/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1378533821.1194 - val_loss: 4074287875.3607\n",
      "Epoch 8943/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1378273106.1605 - val_loss: 4060049693.3699\n",
      "Epoch 8944/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1378437021.9335 - val_loss: 4056189840.6575\n",
      "Epoch 8945/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1378384282.5519 - val_loss: 4067743784.6210\n",
      "Epoch 8946/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1379197572.8219 - val_loss: 4070552725.0411\n",
      "Epoch 8947/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1378601297.1585 - val_loss: 4074076506.1553\n",
      "Epoch 8948/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1379666945.0020 - val_loss: 4055154416.8037\n",
      "Epoch 8949/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1377659702.8571 - val_loss: 4068356872.1826\n",
      "Epoch 8950/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1378447988.7280 - val_loss: 4069336793.2785\n",
      "Epoch 8951/10000\n",
      "1022/1022 [==============================] - 0s 73us/step - loss: 1377742828.2114 - val_loss: 4070572093.3699\n",
      "Epoch 8952/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1378801102.4031 - val_loss: 4065313072.2192\n",
      "Epoch 8953/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1379563603.6634 - val_loss: 4073602042.3014\n",
      "Epoch 8954/10000\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 1378368423.5773 - val_loss: 4056682432.0000\n",
      "Epoch 8955/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1378323319.8591 - val_loss: 4063923820.4201\n",
      "Epoch 8956/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1378611323.4912 - val_loss: 4055237578.9589\n",
      "Epoch 8957/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1379619084.2740 - val_loss: 4058113467.6164\n",
      "Epoch 8958/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1378770171.4912 - val_loss: 4074595960.5479\n",
      "Epoch 8959/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1379221687.8591 - val_loss: 4059114113.8995\n",
      "Epoch 8960/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1377935742.9980 - val_loss: 4073154241.7534\n",
      "Epoch 8961/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1379309941.9804 - val_loss: 4060904260.9680\n",
      "Epoch 8962/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1378628168.2661 - val_loss: 4073874816.5845\n",
      "Epoch 8963/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1378049970.8493 - val_loss: 4076517478.1370\n",
      "Epoch 8964/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1378415598.9041 - val_loss: 4057539770.4475\n",
      "Epoch 8965/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1378212177.6595 - val_loss: 4069359602.8493\n",
      "Epoch 8966/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1379614457.9883 - val_loss: 4054502787.5068\n",
      "Epoch 8967/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1379811732.9159 - val_loss: 4066723220.0183\n",
      "Epoch 8968/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1380396140.2114 - val_loss: 4060109972.4566\n",
      "Epoch 8969/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1378875216.6575 - val_loss: 4068574976.7306\n",
      "Epoch 8970/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1378867818.2074 - val_loss: 4082398881.8995\n",
      "Epoch 8971/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1378123113.4560 - val_loss: 4059666774.9406\n",
      "Epoch 8972/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1379035075.3816 - val_loss: 4058494348.8584\n",
      "Epoch 8973/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1377833446.1996 - val_loss: 4058663426.3379\n",
      "Epoch 8974/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1378095693.4012 - val_loss: 4074851961.1324\n",
      "Epoch 8975/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1381036934.3875 - val_loss: 4083283192.4018\n",
      "Epoch 8976/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 54us/step - loss: 1381296729.5499 - val_loss: 4063460893.2237\n",
      "Epoch 8977/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1377840621.2133 - val_loss: 4067733914.7397\n",
      "Epoch 8978/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1379799983.8434 - val_loss: 4055461512.3288\n",
      "Epoch 8979/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1377807924.1018 - val_loss: 4070435353.2785\n",
      "Epoch 8980/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1379063665.0959 - val_loss: 4064292798.2466\n",
      "Epoch 8981/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1378178549.2290 - val_loss: 4060017120.2922\n",
      "Epoch 8982/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1378336155.0528 - val_loss: 4064506624.0000\n",
      "Epoch 8983/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1377955679.5616 - val_loss: 4068464926.3927\n",
      "Epoch 8984/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1377752057.7378 - val_loss: 4063664370.5571\n",
      "Epoch 8985/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1377916624.1566 - val_loss: 4074113044.6027\n",
      "Epoch 8986/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1377988000.4384 - val_loss: 4059721922.6301\n",
      "Epoch 8987/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1378821728.3131 - val_loss: 4056986147.7991\n",
      "Epoch 8988/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1377926078.6223 - val_loss: 4069210262.5023\n",
      "Epoch 8989/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1378817661.4951 - val_loss: 4056554618.3014\n",
      "Epoch 8990/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1379216945.8474 - val_loss: 4063219179.1050\n",
      "Epoch 8991/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1379133696.5010 - val_loss: 4081172137.4977\n",
      "Epoch 8992/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1379324576.8141 - val_loss: 4059539855.0502\n",
      "Epoch 8993/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1378632969.5186 - val_loss: 4057920891.4703\n",
      "Epoch 8994/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1378314247.6399 - val_loss: 4073672648.3288\n",
      "Epoch 8995/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1378821128.8924 - val_loss: 4073394511.1963\n",
      "Epoch 8996/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1378247226.1135 - val_loss: 4077989308.4932\n",
      "Epoch 8997/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1379042898.6614 - val_loss: 4062165098.9589\n",
      "Epoch 8998/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1378859059.6008 - val_loss: 4070100291.7991\n",
      "Epoch 8999/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1379709218.5675 - val_loss: 4057740003.0685\n",
      "Epoch 9000/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1379422043.9295 - val_loss: 4068396117.3333\n",
      "Epoch 9001/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1378160159.5616 - val_loss: 4066855054.0274\n",
      "Epoch 9002/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1378848362.2074 - val_loss: 4081920473.2785\n",
      "Epoch 9003/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1379428686.8415 - val_loss: 4057042132.1644\n",
      "Epoch 9004/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1379236884.7906 - val_loss: 4059742278.4292\n",
      "Epoch 9005/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1377562687.6243 - val_loss: 4063745835.9817\n",
      "Epoch 9006/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1378301376.3757 - val_loss: 4072791719.1598\n",
      "Epoch 9007/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1380549920.0626 - val_loss: 4052920749.7352\n",
      "Epoch 9008/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1378616690.2231 - val_loss: 4075383465.9361\n",
      "Epoch 9009/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1378850965.5421 - val_loss: 4056918843.0320\n",
      "Epoch 9010/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1378486261.7299 - val_loss: 4071817444.3836\n",
      "Epoch 9011/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1378708164.6341 - val_loss: 4064669885.9543\n",
      "Epoch 9012/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1379037928.2035 - val_loss: 4063205249.1689\n",
      "Epoch 9013/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1377542133.7299 - val_loss: 4069200004.3836\n",
      "Epoch 9014/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1378291377.2211 - val_loss: 4066843416.1096\n",
      "Epoch 9015/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1378672039.4521 - val_loss: 4058556097.0228\n",
      "Epoch 9016/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1378179529.3933 - val_loss: 4080486450.7032\n",
      "Epoch 9017/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1378557705.7691 - val_loss: 4063694795.2511\n",
      "Epoch 9018/10000\n",
      "1022/1022 [==============================] - 0s 70us/step - loss: 1378487964.1800 - val_loss: 4079311334.4292\n",
      "Epoch 9019/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1378301131.6477 - val_loss: 4052898181.5525\n",
      "Epoch 9020/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1377799516.1800 - val_loss: 4068873917.9543\n",
      "Epoch 9021/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1378036199.3894 - val_loss: 4070398553.7169\n",
      "Epoch 9022/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1379299319.1076 - val_loss: 4058843101.6621\n",
      "Epoch 9023/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1378011307.0841 - val_loss: 4061352754.1187\n",
      "Epoch 9024/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1378777487.7808 - val_loss: 4061561209.1324\n",
      "Epoch 9025/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1378708739.7573 - val_loss: 4064484666.4475\n",
      "Epoch 9026/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1379055065.4247 - val_loss: 4075098880.4384\n",
      "Epoch 9027/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1377533655.4207 - val_loss: 4062260959.5616\n",
      "Epoch 9028/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1378636206.4658 - val_loss: 4057522279.7443\n",
      "Epoch 9029/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1377999359.4990 - val_loss: 4063458617.8630\n",
      "Epoch 9030/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1377755896.6106 - val_loss: 4068453465.7169\n",
      "Epoch 9031/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1380760551.8278 - val_loss: 4061750577.3881\n",
      "Epoch 9032/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1378852754.2857 - val_loss: 4066943630.4658\n",
      "Epoch 9033/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1378355192.2348 - val_loss: 4067139267.7991\n",
      "Epoch 9034/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1377736622.3405 - val_loss: 4071152653.4429\n",
      "Epoch 9035/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1378852739.3816 - val_loss: 4055337046.9406\n",
      "Epoch 9036/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1379298891.1468 - val_loss: 4061172825.5708\n",
      "Epoch 9037/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1377824415.8121 - val_loss: 4064107669.7717\n",
      "Epoch 9038/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1378289395.6008 - val_loss: 4076214945.3151\n",
      "Epoch 9039/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1378550750.1840 - val_loss: 4057327861.0411\n",
      "Epoch 9040/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 58us/step - loss: 1379664996.9472 - val_loss: 4066650772.6027\n",
      "Epoch 9041/10000\n",
      "1022/1022 [==============================] - 0s 106us/step - loss: 1379325241.3620 - val_loss: 4081695500.7123\n",
      "Epoch 9042/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1379552352.6888 - val_loss: 4067598484.3105\n",
      "Epoch 9043/10000\n",
      "1022/1022 [==============================] - 0s 87us/step - loss: 1379307827.0998 - val_loss: 4050119990.5023\n",
      "Epoch 9044/10000\n",
      "1022/1022 [==============================] - 0s 63us/step - loss: 1378306593.5656 - val_loss: 4066968699.0320\n",
      "Epoch 9045/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1377534014.3718 - val_loss: 4064881996.2740\n",
      "Epoch 9046/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1377537546.2701 - val_loss: 4067902509.7352\n",
      "Epoch 9047/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1381279468.7123 - val_loss: 4059425318.7215\n",
      "Epoch 9048/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1377623238.6380 - val_loss: 4072588316.2009\n",
      "Epoch 9049/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1378211916.3992 - val_loss: 4061510128.9498\n",
      "Epoch 9050/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1377840266.5205 - val_loss: 4069654858.2283\n",
      "Epoch 9051/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1378485928.0783 - val_loss: 4060031948.8584\n",
      "Epoch 9052/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1378551654.2622 - val_loss: 4065219305.3516\n",
      "Epoch 9053/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1378242252.9002 - val_loss: 4071899321.7169\n",
      "Epoch 9054/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1377437788.1800 - val_loss: 4065456106.5205\n",
      "Epoch 9055/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1378785905.7221 - val_loss: 4052244847.4886\n",
      "Epoch 9056/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1379901139.5382 - val_loss: 4074935117.5890\n",
      "Epoch 9057/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1377813752.7358 - val_loss: 4060054799.0502\n",
      "Epoch 9058/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1379310103.5460 - val_loss: 4057148227.5068\n",
      "Epoch 9059/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1378662318.5910 - val_loss: 4065695416.2557\n",
      "Epoch 9060/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1380236698.8023 - val_loss: 4081094949.5525\n",
      "Epoch 9061/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1378072480.5636 - val_loss: 4058226168.1096\n",
      "Epoch 9062/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1378202266.3014 - val_loss: 4063256363.6895\n",
      "Epoch 9063/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1379322378.0196 - val_loss: 4058024660.7489\n",
      "Epoch 9064/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1378399643.0528 - val_loss: 4073882681.4247\n",
      "Epoch 9065/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1378104767.6243 - val_loss: 4061422638.9041\n",
      "Epoch 9066/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1378748112.1566 - val_loss: 4059752772.0913\n",
      "Epoch 9067/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1380111420.8063 - val_loss: 4072013150.1005\n",
      "Epoch 9068/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1378486395.4912 - val_loss: 4068536144.0731\n",
      "Epoch 9069/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1378170632.7671 - val_loss: 4050326800.0731\n",
      "Epoch 9070/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1377591354.7397 - val_loss: 4064266202.5936\n",
      "Epoch 9071/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1378771947.7104 - val_loss: 4054295681.0228\n",
      "Epoch 9072/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1380670057.9569 - val_loss: 4081220682.0822\n",
      "Epoch 9073/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1379928417.1898 - val_loss: 4055375053.7352\n",
      "Epoch 9074/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1377556386.5675 - val_loss: 4073437730.0457\n",
      "Epoch 9075/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1378057990.8885 - val_loss: 4054039312.8037\n",
      "Epoch 9076/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1377435423.6869 - val_loss: 4065378214.4292\n",
      "Epoch 9077/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1379491988.7906 - val_loss: 4073708342.3562\n",
      "Epoch 9078/10000\n",
      "1022/1022 [==============================] - 0s 69us/step - loss: 1378176309.6047 - val_loss: 4079729102.1735\n",
      "Epoch 9079/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1377196249.1742 - val_loss: 4068764993.4612\n",
      "Epoch 9080/10000\n",
      "1022/1022 [==============================] - 0s 72us/step - loss: 1377756009.7065 - val_loss: 4064512392.9132\n",
      "Epoch 9081/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1379734923.7730 - val_loss: 4047544837.2603\n",
      "Epoch 9082/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1377954436.3836 - val_loss: 4062835988.1644\n",
      "Epoch 9083/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1377534807.9217 - val_loss: 4057594608.8037\n",
      "Epoch 9084/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1382438209.1272 - val_loss: 4084754767.9269\n",
      "Epoch 9085/10000\n",
      "1022/1022 [==============================] - 0s 63us/step - loss: 1378231111.1389 - val_loss: 4047371590.5753\n",
      "Epoch 9086/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1378194797.9648 - val_loss: 4071311618.4840\n",
      "Epoch 9087/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1378316688.4070 - val_loss: 4054948836.5297\n",
      "Epoch 9088/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1378270167.6712 - val_loss: 4051295480.5479\n",
      "Epoch 9089/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1377573388.6497 - val_loss: 4073337995.1050\n",
      "Epoch 9090/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1378946689.7534 - val_loss: 4067398087.1598\n",
      "Epoch 9091/10000\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 1378421679.5930 - val_loss: 4067211050.0822\n",
      "Epoch 9092/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1378039142.5753 - val_loss: 4057955766.6484\n",
      "Epoch 9093/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1378306222.0274 - val_loss: 4067377351.3059\n",
      "Epoch 9094/10000\n",
      "1022/1022 [==============================] - 0s 68us/step - loss: 1377799781.0724 - val_loss: 4068407746.6301\n",
      "Epoch 9095/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1377312737.0646 - val_loss: 4064094305.3151\n",
      "Epoch 9096/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1378065346.8806 - val_loss: 4058946376.3288\n",
      "Epoch 9097/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1379118837.7299 - val_loss: 4059261203.1416\n",
      "Epoch 9098/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1380178441.1429 - val_loss: 4048209264.3653\n",
      "Epoch 9099/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1377757846.7945 - val_loss: 4064952585.0594\n",
      "Epoch 9100/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1381874303.4990 - val_loss: 4094018966.7945\n",
      "Epoch 9101/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1378218522.6771 - val_loss: 4059208778.9589\n",
      "Epoch 9102/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1382627210.3953 - val_loss: 4046637107.4338\n",
      "Epoch 9103/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1376759013.1977 - val_loss: 4071203501.5890\n",
      "Epoch 9104/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 47us/step - loss: 1377578550.1057 - val_loss: 4068654159.9269\n",
      "Epoch 9105/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1379927871.7495 - val_loss: 4069963534.0274\n",
      "Epoch 9106/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1378099693.8395 - val_loss: 4062613592.9863\n",
      "Epoch 9107/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1377025794.0665 - val_loss: 4064328279.9635\n",
      "Epoch 9108/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1378477921.9413 - val_loss: 4065292694.6484\n",
      "Epoch 9109/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1378763333.7613 - val_loss: 4075622072.5479\n",
      "Epoch 9110/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1377231504.0313 - val_loss: 4060906762.8128\n",
      "Epoch 9111/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1377914044.8689 - val_loss: 4065770548.1644\n",
      "Epoch 9112/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1379886264.2348 - val_loss: 4051596882.4110\n",
      "Epoch 9113/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1377339400.5166 - val_loss: 4058894231.2329\n",
      "Epoch 9114/10000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1378122757.2603 - val_loss: 4066128996.9680\n",
      "Epoch 9115/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1378989078.6693 - val_loss: 4058386974.8311\n",
      "Epoch 9116/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1377835425.8160 - val_loss: 4061582617.7169\n",
      "Epoch 9117/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1378338876.8689 - val_loss: 4068556547.2146\n",
      "Epoch 9118/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1377598100.2896 - val_loss: 4060216503.3790\n",
      "Epoch 9119/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1378076058.5519 - val_loss: 4061171590.2831\n",
      "Epoch 9120/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1377428337.7221 - val_loss: 4065118943.8539\n",
      "Epoch 9121/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1378415575.2955 - val_loss: 4053351338.8128\n",
      "Epoch 9122/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1377337469.2446 - val_loss: 4070306506.5205\n",
      "Epoch 9123/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1377809819.0528 - val_loss: 4066923819.1050\n",
      "Epoch 9124/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1379930509.6517 - val_loss: 4054615301.6986\n",
      "Epoch 9125/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1377713483.1468 - val_loss: 4073052501.4795\n",
      "Epoch 9126/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1376967003.4286 - val_loss: 4067511996.3470\n",
      "Epoch 9127/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1379070632.3288 - val_loss: 4052246178.0457\n",
      "Epoch 9128/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1377159908.4462 - val_loss: 4060555269.4064\n",
      "Epoch 9129/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1378481219.1311 - val_loss: 4080275713.4612\n",
      "Epoch 9130/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1377571722.7710 - val_loss: 4076932071.3059\n",
      "Epoch 9131/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1377794354.7241 - val_loss: 4055369773.7352\n",
      "Epoch 9132/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1378281020.8689 - val_loss: 4061272331.1050\n",
      "Epoch 9133/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1380649089.0020 - val_loss: 4059633477.4064\n",
      "Epoch 9134/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1377825915.4912 - val_loss: 4063097052.4932\n",
      "Epoch 9135/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1377907100.8063 - val_loss: 4067331446.7945\n",
      "Epoch 9136/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1377071383.7965 - val_loss: 4065056329.3516\n",
      "Epoch 9137/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1377573037.4638 - val_loss: 4074302256.6575\n",
      "Epoch 9138/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1379009381.1977 - val_loss: 4080406155.8356\n",
      "Epoch 9139/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1377849289.3933 - val_loss: 4059690780.4932\n",
      "Epoch 9140/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1378384118.3562 - val_loss: 4065681596.6393\n",
      "Epoch 9141/10000\n",
      "1022/1022 [==============================] - 0s 63us/step - loss: 1377843767.0450 - val_loss: 4062377782.2100\n",
      "Epoch 9142/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1378239762.7867 - val_loss: 4055143619.5068\n",
      "Epoch 9143/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1377736374.1057 - val_loss: 4078157327.6347\n",
      "Epoch 9144/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1378556816.2818 - val_loss: 4056116456.7671\n",
      "Epoch 9145/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1378288501.7299 - val_loss: 4069359869.2237\n",
      "Epoch 9146/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1377839745.8787 - val_loss: 4072121881.2785\n",
      "Epoch 9147/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1378307603.7886 - val_loss: 4056964713.6438\n",
      "Epoch 9148/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1380401482.3953 - val_loss: 4076915453.3699\n",
      "Epoch 9149/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1380795755.0841 - val_loss: 4055413780.0183\n",
      "Epoch 9150/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1377006121.9569 - val_loss: 4074362806.2100\n",
      "Epoch 9151/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1378270535.3268 - val_loss: 4059378569.4977\n",
      "Epoch 9152/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1377758854.2622 - val_loss: 4074294577.8265\n",
      "Epoch 9153/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1377339989.9178 - val_loss: 4060369433.5708\n",
      "Epoch 9154/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1377089378.9432 - val_loss: 4065883132.4932\n",
      "Epoch 9155/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1379173849.2994 - val_loss: 4061265730.1918\n",
      "Epoch 9156/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1377509124.0078 - val_loss: 4063056764.0548\n",
      "Epoch 9157/10000\n",
      "1022/1022 [==============================] - 0s 63us/step - loss: 1378412168.6419 - val_loss: 4066352477.6621\n",
      "Epoch 9158/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1378245574.8885 - val_loss: 4081801250.6301\n",
      "Epoch 9159/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1379050832.6575 - val_loss: 4079559242.3744\n",
      "Epoch 9160/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1381018861.3386 - val_loss: 4048688217.4247\n",
      "Epoch 9161/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1379437770.6458 - val_loss: 4079561413.8447\n",
      "Epoch 9162/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1378184121.3620 - val_loss: 4054912919.9635\n",
      "Epoch 9163/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1376672637.7456 - val_loss: 4064672435.5799\n",
      "Epoch 9164/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1377651068.9941 - val_loss: 4070656758.9406\n",
      "Epoch 9165/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1377410690.0039 - val_loss: 4067279108.5297\n",
      "Epoch 9166/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1377869756.6184 - val_loss: 4056094958.7580\n",
      "Epoch 9167/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1377240476.5558 - val_loss: 4060449018.7397\n",
      "Epoch 9168/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 43us/step - loss: 1379536852.7906 - val_loss: 4057654319.4886\n",
      "Epoch 9169/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1376641085.2446 - val_loss: 4074467749.2603\n",
      "Epoch 9170/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1379182256.4697 - val_loss: 4060003667.4338\n",
      "Epoch 9171/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1377110460.1174 - val_loss: 4076947214.1735\n",
      "Epoch 9172/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1377168812.8376 - val_loss: 4061799853.2968\n",
      "Epoch 9173/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1377889883.9295 - val_loss: 4065878179.7991\n",
      "Epoch 9174/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1378060453.3229 - val_loss: 4063657137.5342\n",
      "Epoch 9175/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1378209091.3816 - val_loss: 4053393771.2511\n",
      "Epoch 9176/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1377090906.3014 - val_loss: 4064972959.7078\n",
      "Epoch 9177/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1378452801.7534 - val_loss: 4070378929.0959\n",
      "Epoch 9178/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1377244644.6967 - val_loss: 4061422478.0274\n",
      "Epoch 9179/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1377546136.0470 - val_loss: 4060170242.7763\n",
      "Epoch 9180/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1377454241.0646 - val_loss: 4076044411.3242\n",
      "Epoch 9181/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1377358270.4971 - val_loss: 4073547111.1598\n",
      "Epoch 9182/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1377658518.0431 - val_loss: 4057831983.4886\n",
      "Epoch 9183/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1377384956.7436 - val_loss: 4056300032.7306\n",
      "Epoch 9184/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1376995512.8611 - val_loss: 4065267735.3790\n",
      "Epoch 9185/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1380697304.0470 - val_loss: 4087756075.1050\n",
      "Epoch 9186/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1376273054.3092 - val_loss: 4061844120.1096\n",
      "Epoch 9187/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1378738401.6908 - val_loss: 4051912573.3699\n",
      "Epoch 9188/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1378501284.3209 - val_loss: 4076884316.9315\n",
      "Epoch 9189/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1378273468.9941 - val_loss: 4056090020.6758\n",
      "Epoch 9190/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1377734114.9432 - val_loss: 4081151362.6301\n",
      "Epoch 9191/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1377314360.6106 - val_loss: 4060882126.9041\n",
      "Epoch 9192/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1376872909.1507 - val_loss: 4062559170.0457\n",
      "Epoch 9193/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1377287789.2133 - val_loss: 4066267310.9041\n",
      "Epoch 9194/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1377953263.2172 - val_loss: 4070539684.0913\n",
      "Epoch 9195/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1377889660.7436 - val_loss: 4071365090.7763\n",
      "Epoch 9196/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1381430148.5088 - val_loss: 4061885187.7991\n",
      "Epoch 9197/10000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1377275845.8865 - val_loss: 4072439738.0091\n",
      "Epoch 9198/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1378329674.2701 - val_loss: 4061287227.3242\n",
      "Epoch 9199/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1379355573.6047 - val_loss: 4056354976.4384\n",
      "Epoch 9200/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1377828196.6967 - val_loss: 4080724148.4566\n",
      "Epoch 9201/10000\n",
      "1022/1022 [==============================] - 0s 67us/step - loss: 1381052600.3601 - val_loss: 4045128426.8128\n",
      "Epoch 9202/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1381272655.9061 - val_loss: 4079403691.8356\n",
      "Epoch 9203/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1377285907.7886 - val_loss: 4055106524.0548\n",
      "Epoch 9204/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1377494466.3796 - val_loss: 4065305133.2968\n",
      "Epoch 9205/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1378893430.4814 - val_loss: 4062508097.4612\n",
      "Epoch 9206/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1376992108.2114 - val_loss: 4056081202.1187\n",
      "Epoch 9207/10000\n",
      "1022/1022 [==============================] - 0s 76us/step - loss: 1377256850.7867 - val_loss: 4065346305.8995\n",
      "Epoch 9208/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1378409751.0450 - val_loss: 4071625983.4155\n",
      "Epoch 9209/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1377464168.9550 - val_loss: 4059974663.4521\n",
      "Epoch 9210/10000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1377993206.4814 - val_loss: 4065553559.2329\n",
      "Epoch 9211/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1378058429.6204 - val_loss: 4079363931.0320\n",
      "Epoch 9212/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1378300869.5108 - val_loss: 4053908714.2283\n",
      "Epoch 9213/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1379892465.5969 - val_loss: 4072245665.1689\n",
      "Epoch 9214/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1377807226.4892 - val_loss: 4056743289.2785\n",
      "Epoch 9215/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1379152402.9119 - val_loss: 4056690764.1279\n",
      "Epoch 9216/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1377269287.4521 - val_loss: 4069881992.1826\n",
      "Epoch 9217/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1377935508.7906 - val_loss: 4069176101.4064\n",
      "Epoch 9218/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1377641588.8532 - val_loss: 4059026884.2374\n",
      "Epoch 9219/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1376997088.0626 - val_loss: 4073591081.4977\n",
      "Epoch 9220/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1378028040.0157 - val_loss: 4073152651.5434\n",
      "Epoch 9221/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1377053560.4853 - val_loss: 4056781507.5068\n",
      "Epoch 9222/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1377138825.6438 - val_loss: 4067043359.2694\n",
      "Epoch 9223/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1378247689.2681 - val_loss: 4063767111.7443\n",
      "Epoch 9224/10000\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 1377197526.7945 - val_loss: 4058467892.6027\n",
      "Epoch 9225/10000\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 1383861908.6027 - val_loss: 4057241968.0731\n",
      "Epoch 9226/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1376500477.4951 - val_loss: 4070665013.4795\n",
      "Epoch 9227/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1377455024.2192 - val_loss: 4073032887.3790\n",
      "Epoch 9228/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1377421128.6419 - val_loss: 4060291035.3242\n",
      "Epoch 9229/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1380234432.1252 - val_loss: 4052727072.8767\n",
      "Epoch 9230/10000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1376605299.7886 - val_loss: 4065741529.8630\n",
      "Epoch 9231/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1378275205.1977 - val_loss: 4073682724.2374\n",
      "Epoch 9232/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 49us/step - loss: 1377276059.0528 - val_loss: 4057349935.3425\n",
      "Epoch 9233/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1378394349.4638 - val_loss: 4074573453.4429\n",
      "Epoch 9234/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1376898516.9159 - val_loss: 4060205140.7489\n",
      "Epoch 9235/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1378401681.0333 - val_loss: 4049444601.8630\n",
      "Epoch 9236/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1378443363.1937 - val_loss: 4059927377.3881\n",
      "Epoch 9237/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1378579709.9961 - val_loss: 4069824712.4749\n",
      "Epoch 9238/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1377239753.3933 - val_loss: 4061740073.0594\n",
      "Epoch 9239/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1376544530.5362 - val_loss: 4060267516.0548\n",
      "Epoch 9240/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1377042021.3229 - val_loss: 4069253319.4521\n",
      "Epoch 9241/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1377415553.7534 - val_loss: 4066174540.7123\n",
      "Epoch 9242/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1378104306.8493 - val_loss: 4059269705.2055\n",
      "Epoch 9243/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1377002209.1272 - val_loss: 4060783790.1735\n",
      "Epoch 9244/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1377005955.2564 - val_loss: 4068813921.6073\n",
      "Epoch 9245/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1376558311.9530 - val_loss: 4061313972.1644\n",
      "Epoch 9246/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1376988223.1233 - val_loss: 4070589256.4749\n",
      "Epoch 9247/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1377081573.1977 - val_loss: 4054079730.7032\n",
      "Epoch 9248/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1379325273.6751 - val_loss: 4086990739.8721\n",
      "Epoch 9249/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1376311707.8043 - val_loss: 4055848244.4566\n",
      "Epoch 9250/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1378904522.8963 - val_loss: 4060258536.1826\n",
      "Epoch 9251/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1377398153.1429 - val_loss: 4063889238.7945\n",
      "Epoch 9252/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1379414659.2564 - val_loss: 4040565467.0320\n",
      "Epoch 9253/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1377293572.3836 - val_loss: 4078853100.7123\n",
      "Epoch 9254/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1376909849.0489 - val_loss: 4079477944.2557\n",
      "Epoch 9255/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1376968208.9080 - val_loss: 4053396420.5297\n",
      "Epoch 9256/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1377355018.2701 - val_loss: 4056073355.8356\n",
      "Epoch 9257/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1378891205.0098 - val_loss: 4060537606.7215\n",
      "Epoch 9258/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1376495893.7926 - val_loss: 4061681592.4018\n",
      "Epoch 9259/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1377139886.5910 - val_loss: 4056273880.8402\n",
      "Epoch 9260/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1377195287.9217 - val_loss: 4077710311.5982\n",
      "Epoch 9261/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1378427468.9002 - val_loss: 4062258425.7169\n",
      "Epoch 9262/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1379793627.4286 - val_loss: 4061165829.1142\n",
      "Epoch 9263/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1377944248.6106 - val_loss: 4073576239.0502\n",
      "Epoch 9264/10000\n",
      "1022/1022 [==============================] - 0s 71us/step - loss: 1377288090.5519 - val_loss: 4065736854.2100\n",
      "Epoch 9265/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1376737961.0176 - val_loss: 4071564044.4201\n",
      "Epoch 9266/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1377954057.7691 - val_loss: 4053992350.9772\n",
      "Epoch 9267/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1376730463.1859 - val_loss: 4053682250.8128\n",
      "Epoch 9268/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1376963080.0157 - val_loss: 4063948932.6758\n",
      "Epoch 9269/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1379500889.0489 - val_loss: 4081771414.2100\n",
      "Epoch 9270/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1378318611.0372 - val_loss: 4082769720.5479\n",
      "Epoch 9271/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1380198311.8278 - val_loss: 4071210996.8950\n",
      "Epoch 9272/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1379069038.3405 - val_loss: 4041941468.4932\n",
      "Epoch 9273/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1377147010.1292 - val_loss: 4059118248.9132\n",
      "Epoch 9274/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1378264457.2681 - val_loss: 4065155140.3836\n",
      "Epoch 9275/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1377976884.7280 - val_loss: 4059529233.9726\n",
      "Epoch 9276/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1377754604.7123 - val_loss: 4059083438.7580\n",
      "Epoch 9277/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1377088662.0431 - val_loss: 4065642085.6986\n",
      "Epoch 9278/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1376976159.3112 - val_loss: 4064245172.7489\n",
      "Epoch 9279/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1379364489.2681 - val_loss: 4067605682.5571\n",
      "Epoch 9280/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1377809729.5029 - val_loss: 4069738557.3699\n",
      "Epoch 9281/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1378483935.9374 - val_loss: 4063911028.4566\n",
      "Epoch 9282/10000\n",
      "1022/1022 [==============================] - 0s 66us/step - loss: 1378881582.8415 - val_loss: 4064159557.4064\n",
      "Epoch 9283/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1377621867.8356 - val_loss: 4063702144.0000\n",
      "Epoch 9284/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1377087253.7926 - val_loss: 4068016475.0320\n",
      "Epoch 9285/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1378414353.0333 - val_loss: 4054845141.3333\n",
      "Epoch 9286/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1380505147.1155 - val_loss: 4098828743.1598\n",
      "Epoch 9287/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1375977959.5773 - val_loss: 4064032061.0776\n",
      "Epoch 9288/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1376953244.0548 - val_loss: 4054628936.9132\n",
      "Epoch 9289/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1377537318.4501 - val_loss: 4065391096.1096\n",
      "Epoch 9290/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1377200360.5793 - val_loss: 4060910459.3242\n",
      "Epoch 9291/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1377603738.8023 - val_loss: 4068753147.4703\n",
      "Epoch 9292/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1378745847.3581 - val_loss: 4062138862.6119\n",
      "Epoch 9293/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1377571636.3523 - val_loss: 4072800195.9452\n",
      "Epoch 9294/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1377569408.7515 - val_loss: 4060034800.3653\n",
      "Epoch 9295/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1379078286.2779 - val_loss: 4060440918.9406\n",
      "Epoch 9296/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 66us/step - loss: 1378094885.0724 - val_loss: 4069610637.0046\n",
      "Epoch 9297/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1377566798.2779 - val_loss: 4068724827.9087\n",
      "Epoch 9298/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1377165738.9589 - val_loss: 4074107068.0548\n",
      "Epoch 9299/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1377261922.6928 - val_loss: 4051177755.6164\n",
      "Epoch 9300/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1377373464.7984 - val_loss: 4064249248.2922\n",
      "Epoch 9301/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1378959007.8121 - val_loss: 4048747359.7078\n",
      "Epoch 9302/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1376470747.4286 - val_loss: 4059810530.0457\n",
      "Epoch 9303/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1376968039.4521 - val_loss: 4066284478.2466\n",
      "Epoch 9304/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1377116632.6732 - val_loss: 4059961550.0274\n",
      "Epoch 9305/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1376619903.6243 - val_loss: 4072665809.8265\n",
      "Epoch 9306/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1377499357.9335 - val_loss: 4055065322.6667\n",
      "Epoch 9307/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1376946208.1879 - val_loss: 4070596987.6164\n",
      "Epoch 9308/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1377280689.0959 - val_loss: 4064406093.2968\n",
      "Epoch 9309/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1376719871.6243 - val_loss: 4066501052.4932\n",
      "Epoch 9310/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1378528574.8728 - val_loss: 4060165120.7306\n",
      "Epoch 9311/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1377414082.3796 - val_loss: 4054325963.3973\n",
      "Epoch 9312/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1376265972.2270 - val_loss: 4064611439.7808\n",
      "Epoch 9313/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1377163864.9237 - val_loss: 4061363107.0685\n",
      "Epoch 9314/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1377414774.9824 - val_loss: 4076487541.3333\n",
      "Epoch 9315/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1377724926.3718 - val_loss: 4074432417.6073\n",
      "Epoch 9316/10000\n",
      "1022/1022 [==============================] - 0s 63us/step - loss: 1376218094.7162 - val_loss: 4067793896.6210\n",
      "Epoch 9317/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1377381433.7378 - val_loss: 4066716406.2100\n",
      "Epoch 9318/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1376419578.9902 - val_loss: 4058861194.5205\n",
      "Epoch 9319/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1377230237.6830 - val_loss: 4059665082.4475\n",
      "Epoch 9320/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1377181961.0176 - val_loss: 4058058237.8082\n",
      "Epoch 9321/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1379473240.1722 - val_loss: 4043306754.0457\n",
      "Epoch 9322/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1376733653.4168 - val_loss: 4055927812.3836\n",
      "Epoch 9323/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1377271309.0254 - val_loss: 4074764553.0594\n",
      "Epoch 9324/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1378256656.1566 - val_loss: 4063764236.4201\n",
      "Epoch 9325/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1377277139.9139 - val_loss: 4080818750.9772\n",
      "Epoch 9326/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1376275775.3738 - val_loss: 4060315558.4292\n",
      "Epoch 9327/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1378795687.5773 - val_loss: 4078176239.1963\n",
      "Epoch 9328/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1376168174.9667 - val_loss: 4057891349.1872\n",
      "Epoch 9329/10000\n",
      "1022/1022 [==============================] - 0s 76us/step - loss: 1377129163.8982 - val_loss: 4050965282.6301\n",
      "Epoch 9330/10000\n",
      "1022/1022 [==============================] - 0s 79us/step - loss: 1378882729.2055 - val_loss: 4075302836.8950\n",
      "Epoch 9331/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1377620016.5949 - val_loss: 4060351548.2009\n",
      "Epoch 9332/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1378836268.9628 - val_loss: 4065438682.8858\n",
      "Epoch 9333/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1377309653.4168 - val_loss: 4062252687.1963\n",
      "Epoch 9334/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1376388049.9100 - val_loss: 4067843738.7397\n",
      "Epoch 9335/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1376831149.7143 - val_loss: 4062999704.4018\n",
      "Epoch 9336/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1376674124.9002 - val_loss: 4062747044.8219\n",
      "Epoch 9337/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1378229611.7104 - val_loss: 4067577810.1187\n",
      "Epoch 9338/10000\n",
      "1022/1022 [==============================] - 0s 76us/step - loss: 1376439520.0626 - val_loss: 4068158455.9635\n",
      "Epoch 9339/10000\n",
      "1022/1022 [==============================] - 0s 72us/step - loss: 1379251339.5225 - val_loss: 4044973794.9224\n",
      "Epoch 9340/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1376848140.0235 - val_loss: 4061425204.3105\n",
      "Epoch 9341/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1377217329.5969 - val_loss: 4073587533.1507\n",
      "Epoch 9342/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1376376366.5910 - val_loss: 4055493918.2466\n",
      "Epoch 9343/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1378010095.9687 - val_loss: 4069481956.5297\n",
      "Epoch 9344/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1376666851.4442 - val_loss: 4055678745.4247\n",
      "Epoch 9345/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1379084887.9217 - val_loss: 4073927321.4247\n",
      "Epoch 9346/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1376385615.9061 - val_loss: 4058990035.2877\n",
      "Epoch 9347/10000\n",
      "1022/1022 [==============================] - 0s 68us/step - loss: 1377325860.4462 - val_loss: 4057751552.5845\n",
      "Epoch 9348/10000\n",
      "1022/1022 [==============================] - 0s 72us/step - loss: 1376589216.9393 - val_loss: 4063240258.6301\n",
      "Epoch 9349/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1376156691.7886 - val_loss: 4062192677.9909\n",
      "Epoch 9350/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1376754527.6869 - val_loss: 4068707310.4658\n",
      "Epoch 9351/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1377894915.0059 - val_loss: 4054404707.5068\n",
      "Epoch 9352/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1378416175.5930 - val_loss: 4079111607.9635\n",
      "Epoch 9353/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1382154186.8963 - val_loss: 4049412444.9315\n",
      "Epoch 9354/10000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1378533589.6673 - val_loss: 4076633994.6667\n",
      "Epoch 9355/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1376892699.3033 - val_loss: 4069930705.8265\n",
      "Epoch 9356/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1376581242.4892 - val_loss: 4057794116.3836\n",
      "Epoch 9357/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1377932151.2329 - val_loss: 4063563734.3562\n",
      "Epoch 9358/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1378184595.5382 - val_loss: 4059311981.2968\n",
      "Epoch 9359/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1377583613.6204 - val_loss: 4074800082.2648\n",
      "Epoch 9360/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 49us/step - loss: 1376810534.5753 - val_loss: 4058664884.7489\n",
      "Epoch 9361/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1377258900.5401 - val_loss: 4055404846.7580\n",
      "Epoch 9362/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1380727808.0000 - val_loss: 4082206073.4247\n",
      "Epoch 9363/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1376306307.5068 - val_loss: 4064457560.4018\n",
      "Epoch 9364/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1375732534.1057 - val_loss: 4052967182.1735\n",
      "Epoch 9365/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1376813374.8728 - val_loss: 4053118198.2100\n",
      "Epoch 9366/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1376956107.1468 - val_loss: 4056077592.6941\n",
      "Epoch 9367/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1376659175.8278 - val_loss: 4061271808.4384\n",
      "Epoch 9368/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1376822307.8200 - val_loss: 4055204134.4292\n",
      "Epoch 9369/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1376855529.9569 - val_loss: 4052230657.7534\n",
      "Epoch 9370/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1382315016.7671 - val_loss: 4069920927.8539\n",
      "Epoch 9371/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1376615608.3601 - val_loss: 4060367099.3242\n",
      "Epoch 9372/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1377268010.5832 - val_loss: 4054589296.5114\n",
      "Epoch 9373/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1376474352.8454 - val_loss: 4064535668.0183\n",
      "Epoch 9374/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1376678989.6517 - val_loss: 4060843475.8721\n",
      "Epoch 9375/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1376358168.7984 - val_loss: 4059673455.9269\n",
      "Epoch 9376/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1378139942.0744 - val_loss: 4079758281.7900\n",
      "Epoch 9377/10000\n",
      "1022/1022 [==============================] - 0s 79us/step - loss: 1376637719.5460 - val_loss: 4065206726.8676\n",
      "Epoch 9378/10000\n",
      "1022/1022 [==============================] - 0s 86us/step - loss: 1377053240.6106 - val_loss: 4054146546.9954\n",
      "Epoch 9379/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1378307325.4951 - val_loss: 4076274770.9954\n",
      "Epoch 9380/10000\n",
      "1022/1022 [==============================] - 0s 69us/step - loss: 1377556748.5245 - val_loss: 4054855021.0046\n",
      "Epoch 9381/10000\n",
      "1022/1022 [==============================] - 0s 246us/step - loss: 1376419782.5127 - val_loss: 4059045823.2694\n",
      "Epoch 9382/10000\n",
      "1022/1022 [==============================] - 0s 70us/step - loss: 1376323243.2094 - val_loss: 4059907759.1963\n",
      "Epoch 9383/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1376764695.5460 - val_loss: 4055358889.4977\n",
      "Epoch 9384/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1376629754.4892 - val_loss: 4072053148.2009\n",
      "Epoch 9385/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1376994480.8454 - val_loss: 4064062413.8813\n",
      "Epoch 9386/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1376357403.9295 - val_loss: 4061789324.7123\n",
      "Epoch 9387/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1376586376.1409 - val_loss: 4064775963.7626\n",
      "Epoch 9388/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1377110426.0509 - val_loss: 4063722396.4932\n",
      "Epoch 9389/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1376316899.9452 - val_loss: 4070224222.9772\n",
      "Epoch 9390/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1381070891.8356 - val_loss: 4075968443.7626\n",
      "Epoch 9391/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1376354474.5832 - val_loss: 4049674375.4521\n",
      "Epoch 9392/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1378388679.2642 - val_loss: 4046595918.6119\n",
      "Epoch 9393/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1378010014.3092 - val_loss: 4057183953.6804\n",
      "Epoch 9394/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1378148469.8552 - val_loss: 4077239025.2420\n",
      "Epoch 9395/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1376079276.5871 - val_loss: 4058611970.0457\n",
      "Epoch 9396/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1377750721.8787 - val_loss: 4057786214.2831\n",
      "Epoch 9397/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1377096747.8356 - val_loss: 4073490999.6712\n",
      "Epoch 9398/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1376788837.6986 - val_loss: 4066889773.4429\n",
      "Epoch 9399/10000\n",
      "1022/1022 [==============================] - 0s 75us/step - loss: 1377262119.0763 - val_loss: 4058952474.5936\n",
      "Epoch 9400/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1376138216.8297 - val_loss: 4059355604.0183\n",
      "Epoch 9401/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1376755453.3699 - val_loss: 4068202382.9041\n",
      "Epoch 9402/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1376791081.0802 - val_loss: 4058841610.8128\n",
      "Epoch 9403/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1379989056.1252 - val_loss: 4092858637.5890\n",
      "Epoch 9404/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1377369471.1233 - val_loss: 4051416882.5571\n",
      "Epoch 9405/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1377404932.7593 - val_loss: 4065125205.7717\n",
      "Epoch 9406/10000\n",
      "1022/1022 [==============================] - 0s 76us/step - loss: 1376162434.2544 - val_loss: 4056810048.7306\n",
      "Epoch 9407/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1376089903.2798 - val_loss: 4060488380.0548\n",
      "Epoch 9408/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1376580343.9217 - val_loss: 4069612240.0731\n",
      "Epoch 9409/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1376629933.5890 - val_loss: 4057629743.0502\n",
      "Epoch 9410/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1377242260.4149 - val_loss: 4059338598.2831\n",
      "Epoch 9411/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1377200162.8180 - val_loss: 4070687435.8356\n",
      "Epoch 9412/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1376078444.7123 - val_loss: 4055271355.6164\n",
      "Epoch 9413/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1376323091.2877 - val_loss: 4063028157.8082\n",
      "Epoch 9414/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1376270065.5342 - val_loss: 4064494144.0000\n",
      "Epoch 9415/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1376126832.2192 - val_loss: 4062055408.0731\n",
      "Epoch 9416/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1376607161.1115 - val_loss: 4064883874.1918\n",
      "Epoch 9417/10000\n",
      "1022/1022 [==============================] - 0s 70us/step - loss: 1376617710.9667 - val_loss: 4057352060.9315\n",
      "Epoch 9418/10000\n",
      "1022/1022 [==============================] - 0s 78us/step - loss: 1376710321.8474 - val_loss: 4061990156.4201\n",
      "Epoch 9419/10000\n",
      "1022/1022 [==============================] - 0s 70us/step - loss: 1377241368.2975 - val_loss: 4057502033.2420\n",
      "Epoch 9420/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1377630512.7202 - val_loss: 4067045619.7260\n",
      "Epoch 9421/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1377483926.5440 - val_loss: 4073228479.1233\n",
      "Epoch 9422/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1375812673.3777 - val_loss: 4060153055.4155\n",
      "Epoch 9423/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1376922150.5753 - val_loss: 4055709863.8904\n",
      "Epoch 9424/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 45us/step - loss: 1376674915.9452 - val_loss: 4059002515.4338\n",
      "Epoch 9425/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1376124099.7573 - val_loss: 4068489713.5342\n",
      "Epoch 9426/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1376237125.0098 - val_loss: 4058157249.6073\n",
      "Epoch 9427/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1376343378.6614 - val_loss: 4058002532.0913\n",
      "Epoch 9428/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1375829698.5049 - val_loss: 4073440709.1142\n",
      "Epoch 9429/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1376679109.4481 - val_loss: 4066494583.8174\n",
      "Epoch 9430/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1377485324.7750 - val_loss: 4067017586.9954\n",
      "Epoch 9431/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1375943493.2603 - val_loss: 4058857354.9589\n",
      "Epoch 9432/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1378283937.5656 - val_loss: 4066145298.7032\n",
      "Epoch 9433/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1378383463.8278 - val_loss: 4050580199.7443\n",
      "Epoch 9434/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1377313713.0959 - val_loss: 4072473721.7169\n",
      "Epoch 9435/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1376510689.4403 - val_loss: 4054364139.9817\n",
      "Epoch 9436/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1376942495.8121 - val_loss: 4067535181.5890\n",
      "Epoch 9437/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1381246072.2348 - val_loss: 4043595834.0091\n",
      "Epoch 9438/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1376082234.4892 - val_loss: 4078112710.7215\n",
      "Epoch 9439/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1376512941.5890 - val_loss: 4071840721.9726\n",
      "Epoch 9440/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1376332541.4951 - val_loss: 4064191572.4566\n",
      "Epoch 9441/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1375952627.8513 - val_loss: 4061905025.4612\n",
      "Epoch 9442/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1377925266.7867 - val_loss: 4067226571.9817\n",
      "Epoch 9443/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1377677927.2016 - val_loss: 4052212380.9315\n",
      "Epoch 9444/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1376664479.3112 - val_loss: 4058826273.3151\n",
      "Epoch 9445/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1376676187.1781 - val_loss: 4061896494.9041\n",
      "Epoch 9446/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1376555806.1213 - val_loss: 4068211006.6849\n",
      "Epoch 9447/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1376456317.3699 - val_loss: 4064622647.2329\n",
      "Epoch 9448/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1376496627.4755 - val_loss: 4052299593.3516\n",
      "Epoch 9449/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1376994927.4677 - val_loss: 4074938806.7945\n",
      "Epoch 9450/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1380026979.5695 - val_loss: 4055092241.5342\n",
      "Epoch 9451/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1376416271.2798 - val_loss: 4073834994.8493\n",
      "Epoch 9452/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1377588473.2368 - val_loss: 4077594232.4018\n",
      "Epoch 9453/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1377493932.3366 - val_loss: 4055464478.2466\n",
      "Epoch 9454/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1377349744.4697 - val_loss: 4067902002.8493\n",
      "Epoch 9455/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1378246296.1722 - val_loss: 4048904214.2100\n",
      "Epoch 9456/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1376825515.0841 - val_loss: 4058701485.8813\n",
      "Epoch 9457/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1377771029.5421 - val_loss: 4071675146.3744\n",
      "Epoch 9458/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1376779931.6164 - val_loss: 4076972391.8904\n",
      "Epoch 9459/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1376110286.9041 - val_loss: 4069819061.7717\n",
      "Epoch 9460/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1378033109.1663 - val_loss: 4066208052.8950\n",
      "Epoch 9461/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1377689229.7769 - val_loss: 4064218298.4475\n",
      "Epoch 9462/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1378299259.7417 - val_loss: 4040194393.1324\n",
      "Epoch 9463/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1376545858.8180 - val_loss: 4063993854.2466\n",
      "Epoch 9464/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1376398142.6223 - val_loss: 4060288271.1963\n",
      "Epoch 9465/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1376755597.7769 - val_loss: 4060000706.7763\n",
      "Epoch 9466/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1376426541.8395 - val_loss: 4072174601.3516\n",
      "Epoch 9467/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1377338122.6458 - val_loss: 4071300389.1142\n",
      "Epoch 9468/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1377183060.4149 - val_loss: 4052385912.9863\n",
      "Epoch 9469/10000\n",
      "1022/1022 [==============================] - 0s 61us/step - loss: 1377269969.6595 - val_loss: 4065316246.7945\n",
      "Epoch 9470/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1378248466.5362 - val_loss: 4069927345.0959\n",
      "Epoch 9471/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1377066401.4403 - val_loss: 4068217074.2648\n",
      "Epoch 9472/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1376622399.8748 - val_loss: 4052895936.5845\n",
      "Epoch 9473/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1376235959.9843 - val_loss: 4065143856.0731\n",
      "Epoch 9474/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1377914064.1566 - val_loss: 4052265812.1644\n",
      "Epoch 9475/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1376959523.3190 - val_loss: 4055918521.8630\n",
      "Epoch 9476/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1376518622.6849 - val_loss: 4067013893.6986\n",
      "Epoch 9477/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1378794574.6536 - val_loss: 4043586516.4566\n",
      "Epoch 9478/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1376320680.9550 - val_loss: 4054835871.8539\n",
      "Epoch 9479/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1376812706.0665 - val_loss: 4080951072.0000\n",
      "Epoch 9480/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1377363936.5636 - val_loss: 4051309404.2009\n",
      "Epoch 9481/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1380796239.1546 - val_loss: 4063648809.0594\n",
      "Epoch 9482/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1376387042.8180 - val_loss: 4056450627.6530\n",
      "Epoch 9483/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1376849496.5479 - val_loss: 4064791547.3242\n",
      "Epoch 9484/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1376069468.6810 - val_loss: 4067015758.1735\n",
      "Epoch 9485/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1376465944.6732 - val_loss: 4055792228.9680\n",
      "Epoch 9486/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1377004275.7260 - val_loss: 4063509715.1416\n",
      "Epoch 9487/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1378526686.4344 - val_loss: 4077089805.8813\n",
      "Epoch 9488/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 42us/step - loss: 1376620579.0685 - val_loss: 4065613638.1370\n",
      "Epoch 9489/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1377071743.7495 - val_loss: 4045173773.2968\n",
      "Epoch 9490/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1376830653.2446 - val_loss: 4052165631.5616\n",
      "Epoch 9491/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1377073731.1311 - val_loss: 4077854492.2009\n",
      "Epoch 9492/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1376872566.1057 - val_loss: 4059214880.1461\n",
      "Epoch 9493/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1376959013.9491 - val_loss: 4069119119.0502\n",
      "Epoch 9494/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1375870357.5421 - val_loss: 4050512967.7443\n",
      "Epoch 9495/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1378582754.9432 - val_loss: 4077473840.5114\n",
      "Epoch 9496/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1375317169.8474 - val_loss: 4052312662.0639\n",
      "Epoch 9497/10000\n",
      "1022/1022 [==============================] - 0s 75us/step - loss: 1377162395.9295 - val_loss: 4043503888.0731\n",
      "Epoch 9498/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1375962009.2994 - val_loss: 4068105139.5799\n",
      "Epoch 9499/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1377423362.2544 - val_loss: 4053858533.8447\n",
      "Epoch 9500/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1376365050.8023 - val_loss: 4076603615.2694\n",
      "Epoch 9501/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1376702134.8571 - val_loss: 4063754103.5251\n",
      "Epoch 9502/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1382037316.3836 - val_loss: 4077274879.5616\n",
      "Epoch 9503/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1375980128.0626 - val_loss: 4057684131.0685\n",
      "Epoch 9504/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1378680245.1037 - val_loss: 4042547914.8128\n",
      "Epoch 9505/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1377531427.3190 - val_loss: 4053554993.0959\n",
      "Epoch 9506/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1377784076.9002 - val_loss: 4069307781.6986\n",
      "Epoch 9507/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1376616466.6614 - val_loss: 4058925012.1644\n",
      "Epoch 9508/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1377312161.0646 - val_loss: 4051681940.8950\n",
      "Epoch 9509/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1377424111.3425 - val_loss: 4079387511.3790\n",
      "Epoch 9510/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1377196523.2094 - val_loss: 4052694622.8311\n",
      "Epoch 9511/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1376861258.8963 - val_loss: 4073279173.4064\n",
      "Epoch 9512/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1375969460.4775 - val_loss: 4052482422.3562\n",
      "Epoch 9513/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1375461906.5362 - val_loss: 4061333921.0228\n",
      "Epoch 9514/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1378514942.9980 - val_loss: 4041424062.1005\n",
      "Epoch 9515/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1374856166.5127 - val_loss: 4071885626.0091\n",
      "Epoch 9516/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1376877369.9883 - val_loss: 4054753340.9315\n",
      "Epoch 9517/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1376686001.7221 - val_loss: 4069570493.8082\n",
      "Epoch 9518/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1377869436.6184 - val_loss: 4054726174.1005\n",
      "Epoch 9519/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1376699824.7202 - val_loss: 4055310848.4384\n",
      "Epoch 9520/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1375671255.4207 - val_loss: 4056326813.6621\n",
      "Epoch 9521/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1376485061.8865 - val_loss: 4054565013.7717\n",
      "Epoch 9522/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1379133967.7808 - val_loss: 4080483495.5982\n",
      "Epoch 9523/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1375294793.8943 - val_loss: 4057152862.5388\n",
      "Epoch 9524/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1376801581.8395 - val_loss: 4056223477.0411\n",
      "Epoch 9525/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1375934489.8004 - val_loss: 4059175678.5388\n",
      "Epoch 9526/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1377603903.3738 - val_loss: 4065824483.3607\n",
      "Epoch 9527/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1376249397.4795 - val_loss: 4052592685.7352\n",
      "Epoch 9528/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1375888776.2661 - val_loss: 4064434298.8858\n",
      "Epoch 9529/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1379314707.6634 - val_loss: 4051872255.2694\n",
      "Epoch 9530/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1378082441.7691 - val_loss: 4065461882.4475\n",
      "Epoch 9531/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1375378058.0196 - val_loss: 4059655658.2283\n",
      "Epoch 9532/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1376827792.0313 - val_loss: 4050898036.1644\n",
      "Epoch 9533/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1379391707.3659 - val_loss: 4074421954.4840\n",
      "Epoch 9534/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1378270548.4149 - val_loss: 4048105187.6530\n",
      "Epoch 9535/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1377141316.8845 - val_loss: 4058834608.5114\n",
      "Epoch 9536/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1375780356.7593 - val_loss: 4057059724.5662\n",
      "Epoch 9537/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1376939890.8493 - val_loss: 4063741713.3881\n",
      "Epoch 9538/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1377262487.2955 - val_loss: 4065076129.8995\n",
      "Epoch 9539/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1376233105.7847 - val_loss: 4067888180.0183\n",
      "Epoch 9540/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1377821113.2368 - val_loss: 4046599473.0959\n",
      "Epoch 9541/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1376607085.7143 - val_loss: 4058761126.4292\n",
      "Epoch 9542/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1376538757.0098 - val_loss: 4061972841.6438\n",
      "Epoch 9543/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1376812090.3640 - val_loss: 4061763655.7443\n",
      "Epoch 9544/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1377264348.9315 - val_loss: 4078271770.1553\n",
      "Epoch 9545/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1378155360.6888 - val_loss: 4054123462.4292\n",
      "Epoch 9546/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1376216138.1448 - val_loss: 4052390392.9863\n",
      "Epoch 9547/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1376656612.9472 - val_loss: 4056175988.1644\n",
      "Epoch 9548/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1376236581.4481 - val_loss: 4066067085.1507\n",
      "Epoch 9549/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1375983231.1233 - val_loss: 4057682823.3059\n",
      "Epoch 9550/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1375392593.4090 - val_loss: 4059887527.1598\n",
      "Epoch 9551/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1377532886.1683 - val_loss: 4059861597.0776\n",
      "Epoch 9552/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 57us/step - loss: 1376058063.5303 - val_loss: 4062131360.2922\n",
      "Epoch 9553/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1375491453.8708 - val_loss: 4064467533.4429\n",
      "Epoch 9554/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1376464572.2427 - val_loss: 4073423078.7215\n",
      "Epoch 9555/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1375842672.7202 - val_loss: 4068232720.6575\n",
      "Epoch 9556/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1376167162.8650 - val_loss: 4056736406.3562\n",
      "Epoch 9557/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1376575296.0000 - val_loss: 4057125800.4749\n",
      "Epoch 9558/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1375580882.9119 - val_loss: 4063108894.9772\n",
      "Epoch 9559/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1376001978.1135 - val_loss: 4071652704.4384\n",
      "Epoch 9560/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1379061540.3209 - val_loss: 4056073921.4612\n",
      "Epoch 9561/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1375949143.6712 - val_loss: 4064178740.4566\n",
      "Epoch 9562/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1377469040.2192 - val_loss: 4068655271.5982\n",
      "Epoch 9563/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1376540643.6321 - val_loss: 4061482422.3562\n",
      "Epoch 9564/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1375894268.7436 - val_loss: 4065902909.2237\n",
      "Epoch 9565/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1376220185.0489 - val_loss: 4053136738.4840\n",
      "Epoch 9566/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1376582818.6928 - val_loss: 4050988911.4886\n",
      "Epoch 9567/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1375119564.1487 - val_loss: 4063022795.9817\n",
      "Epoch 9568/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1375998461.1194 - val_loss: 4066329049.1324\n",
      "Epoch 9569/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1376788386.3170 - val_loss: 4065554856.0365\n",
      "Epoch 9570/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1377373268.9159 - val_loss: 4063017970.5571\n",
      "Epoch 9571/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1377983213.9648 - val_loss: 4052183336.4749\n",
      "Epoch 9572/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1376052040.6419 - val_loss: 4076138085.9909\n",
      "Epoch 9573/10000\n",
      "1022/1022 [==============================] - 0s 73us/step - loss: 1375194851.4442 - val_loss: 4064625135.7808\n",
      "Epoch 9574/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1379987532.6497 - val_loss: 4033125634.6301\n",
      "Epoch 9575/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1375021510.1370 - val_loss: 4060627393.4612\n",
      "Epoch 9576/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1376088394.2701 - val_loss: 4076209519.6347\n",
      "Epoch 9577/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1375523726.0274 - val_loss: 4061530161.5342\n",
      "Epoch 9578/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1376211617.0646 - val_loss: 4065670926.7580\n",
      "Epoch 9579/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1376961376.3131 - val_loss: 4066159822.3196\n",
      "Epoch 9580/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1378045920.1879 - val_loss: 4073293175.2329\n",
      "Epoch 9581/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1381695123.4755 - val_loss: 4051493621.7717\n",
      "Epoch 9582/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1376766066.9746 - val_loss: 4058053160.1826\n",
      "Epoch 9583/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1376845272.1722 - val_loss: 4073269324.2740\n",
      "Epoch 9584/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1375510878.6849 - val_loss: 4051813292.5662\n",
      "Epoch 9585/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1375509179.7417 - val_loss: 4061028820.3105\n",
      "Epoch 9586/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1375594583.8591 - val_loss: 4063961153.3151\n",
      "Epoch 9587/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1377389986.1918 - val_loss: 4054883738.0091\n",
      "Epoch 9588/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1377043507.8513 - val_loss: 4063967470.0274\n",
      "Epoch 9589/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1376526436.4462 - val_loss: 4048569324.7123\n",
      "Epoch 9590/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1376172303.9687 - val_loss: 4068048005.6986\n",
      "Epoch 9591/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1376015158.1057 - val_loss: 4063542594.0457\n",
      "Epoch 9592/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1376726014.7476 - val_loss: 4072992562.4110\n",
      "Epoch 9593/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1375404653.7143 - val_loss: 4051797385.3516\n",
      "Epoch 9594/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1378772930.6301 - val_loss: 4045664405.7717\n",
      "Epoch 9595/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1375188124.8063 - val_loss: 4064388518.5753\n",
      "Epoch 9596/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1376779389.7456 - val_loss: 4080237148.0548\n",
      "Epoch 9597/10000\n",
      "1022/1022 [==============================] - 0s 74us/step - loss: 1376283636.4775 - val_loss: 4056758684.3470\n",
      "Epoch 9598/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1379049154.2544 - val_loss: 4074893488.0731\n",
      "Epoch 9599/10000\n",
      "1022/1022 [==============================] - 0s 78us/step - loss: 1374534991.1546 - val_loss: 4055009442.3379\n",
      "Epoch 9600/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1375838649.2368 - val_loss: 4053386802.8493\n",
      "Epoch 9601/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1375949595.0528 - val_loss: 4051972936.1826\n",
      "Epoch 9602/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1377126718.2466 - val_loss: 4050074560.1461\n",
      "Epoch 9603/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1376076048.2818 - val_loss: 4057811218.5571\n",
      "Epoch 9604/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1376016764.8689 - val_loss: 4058070571.9817\n",
      "Epoch 9605/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1376895567.9061 - val_loss: 4045183136.7306\n",
      "Epoch 9606/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1377008366.9667 - val_loss: 4054175932.3470\n",
      "Epoch 9607/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1376861198.9041 - val_loss: 4062775879.8904\n",
      "Epoch 9608/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1376597501.9961 - val_loss: 4066326070.5023\n",
      "Epoch 9609/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1375611567.5930 - val_loss: 4062649049.4247\n",
      "Epoch 9610/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1376800474.1761 - val_loss: 4060431901.2237\n",
      "Epoch 9611/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1378234760.2661 - val_loss: 4071781260.7123\n",
      "Epoch 9612/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1375588647.0763 - val_loss: 4051870973.2237\n",
      "Epoch 9613/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1376383610.3640 - val_loss: 4056378643.7260\n",
      "Epoch 9614/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1376357003.8982 - val_loss: 4060865200.2192\n",
      "Epoch 9615/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1376459759.7182 - val_loss: 4053275767.8174\n",
      "Epoch 9616/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 48us/step - loss: 1376629006.5284 - val_loss: 4061661807.3425\n",
      "Epoch 9617/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1376028950.0431 - val_loss: 4064332365.8813\n",
      "Epoch 9618/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1375115381.9804 - val_loss: 4059751178.0822\n",
      "Epoch 9619/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1376741532.8063 - val_loss: 4056977312.7306\n",
      "Epoch 9620/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1376483950.4658 - val_loss: 4053111925.7717\n",
      "Epoch 9621/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1375209011.6008 - val_loss: 4063947677.0776\n",
      "Epoch 9622/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1376434086.5753 - val_loss: 4056458722.3379\n",
      "Epoch 9623/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1376920504.7984 - val_loss: 4081605949.5160\n",
      "Epoch 9624/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1376117045.3542 - val_loss: 4061696893.9543\n",
      "Epoch 9625/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1377117337.1742 - val_loss: 4066951499.3973\n",
      "Epoch 9626/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1376627663.4051 - val_loss: 4042235025.3881\n",
      "Epoch 9627/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1375340386.9432 - val_loss: 4054139589.9909\n",
      "Epoch 9628/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1378406122.5832 - val_loss: 4073672350.5388\n",
      "Epoch 9629/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1376638837.7299 - val_loss: 4076797951.4155\n",
      "Epoch 9630/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1377507626.8337 - val_loss: 4032054855.7443\n",
      "Epoch 9631/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1375707966.8728 - val_loss: 4059268927.4155\n",
      "Epoch 9632/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1376634223.9687 - val_loss: 4044114246.8676\n",
      "Epoch 9633/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1374595803.9295 - val_loss: 4062222990.0274\n",
      "Epoch 9634/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1375925168.0939 - val_loss: 4070042596.0913\n",
      "Epoch 9635/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1375839202.3170 - val_loss: 4055529223.8904\n",
      "Epoch 9636/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1378329197.7143 - val_loss: 4062864105.0594\n",
      "Epoch 9637/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1375111177.5186 - val_loss: 4064968212.7489\n",
      "Epoch 9638/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1376572847.7182 - val_loss: 4068887018.8128\n",
      "Epoch 9639/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1377475017.0176 - val_loss: 4047784725.0411\n",
      "Epoch 9640/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1375891859.0372 - val_loss: 4068367524.5297\n",
      "Epoch 9641/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1375182109.9335 - val_loss: 4062055822.6119\n",
      "Epoch 9642/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1375268556.3992 - val_loss: 4060524335.1963\n",
      "Epoch 9643/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1376002135.6712 - val_loss: 4050414783.8539\n",
      "Epoch 9644/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1376066056.2661 - val_loss: 4052106963.5799\n",
      "Epoch 9645/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1376259381.6673 - val_loss: 4059922770.5571\n",
      "Epoch 9646/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1375807843.0685 - val_loss: 4054845321.9361\n",
      "Epoch 9647/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1376611418.4266 - val_loss: 4054441791.1233\n",
      "Epoch 9648/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1378060578.5675 - val_loss: 4089052514.3379\n",
      "Epoch 9649/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1375904617.4560 - val_loss: 4049835896.4018\n",
      "Epoch 9650/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1378337791.0607 - val_loss: 4059579223.5251\n",
      "Epoch 9651/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1376557989.1977 - val_loss: 4042591571.4338\n",
      "Epoch 9652/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1375138895.1546 - val_loss: 4058106196.3105\n",
      "Epoch 9653/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1375779905.6282 - val_loss: 4057140200.6210\n",
      "Epoch 9654/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1375369001.8317 - val_loss: 4058135172.9680\n",
      "Epoch 9655/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1375950614.0431 - val_loss: 4071100152.9863\n",
      "Epoch 9656/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1378203709.1820 - val_loss: 4049662593.4612\n",
      "Epoch 9657/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1375408146.4736 - val_loss: 4057671347.7260\n",
      "Epoch 9658/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1375944318.4971 - val_loss: 4055191127.2329\n",
      "Epoch 9659/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1375594091.9609 - val_loss: 4064430974.9772\n",
      "Epoch 9660/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1378526142.6223 - val_loss: 4071811215.0502\n",
      "Epoch 9661/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1376517849.9256 - val_loss: 4047373361.9726\n",
      "Epoch 9662/10000\n",
      "1022/1022 [==============================] - 0s 63us/step - loss: 1376111297.8787 - val_loss: 4062606949.9909\n",
      "Epoch 9663/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1375582223.0294 - val_loss: 4051504543.2694\n",
      "Epoch 9664/10000\n",
      "1022/1022 [==============================] - 0s 57us/step - loss: 1375669814.8571 - val_loss: 4060274025.3516\n",
      "Epoch 9665/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1377051336.1409 - val_loss: 4071602903.9635\n",
      "Epoch 9666/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1377254594.0039 - val_loss: 4050993581.2968\n",
      "Epoch 9667/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1376103257.6751 - val_loss: 4045189960.6210\n",
      "Epoch 9668/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1377238816.3131 - val_loss: 4049156786.4110\n",
      "Epoch 9669/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1376955645.9961 - val_loss: 4047500872.6210\n",
      "Epoch 9670/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1374887445.0411 - val_loss: 4062559548.6393\n",
      "Epoch 9671/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1375990461.1194 - val_loss: 4066286162.1187\n",
      "Epoch 9672/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1375287483.3659 - val_loss: 4060865831.1598\n",
      "Epoch 9673/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1376209306.5519 - val_loss: 4056316823.8174\n",
      "Epoch 9674/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1375732796.2427 - val_loss: 4055767758.3196\n",
      "Epoch 9675/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1375534025.6438 - val_loss: 4062371620.9680\n",
      "Epoch 9676/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1375783860.3523 - val_loss: 4048527217.8265\n",
      "Epoch 9677/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1375679464.0783 - val_loss: 4053399962.3014\n",
      "Epoch 9678/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1376016762.4892 - val_loss: 4059779469.4429\n",
      "Epoch 9679/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1375556633.2994 - val_loss: 4059840955.4703\n",
      "Epoch 9680/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 51us/step - loss: 1375713412.7593 - val_loss: 4062665893.4064\n",
      "Epoch 9681/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1376329751.5460 - val_loss: 4061011672.8402\n",
      "Epoch 9682/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1375870228.4149 - val_loss: 4055513723.3242\n",
      "Epoch 9683/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1375588931.3816 - val_loss: 4064862594.1918\n",
      "Epoch 9684/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1376713768.8297 - val_loss: 4063414649.1324\n",
      "Epoch 9685/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1375180072.0783 - val_loss: 4047808661.3333\n",
      "Epoch 9686/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1377129170.9119 - val_loss: 4041100616.6210\n",
      "Epoch 9687/10000\n",
      "1022/1022 [==============================] - 0s 62us/step - loss: 1374783664.0939 - val_loss: 4054740701.3699\n",
      "Epoch 9688/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1376003971.5068 - val_loss: 4065144662.5023\n",
      "Epoch 9689/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1375191351.9843 - val_loss: 4058125937.3881\n",
      "Epoch 9690/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1376725705.8943 - val_loss: 4055627770.5936\n",
      "Epoch 9691/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1375615041.3777 - val_loss: 4060306968.1096\n",
      "Epoch 9692/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1376572901.8239 - val_loss: 4071793312.7306\n",
      "Epoch 9693/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1375350604.6497 - val_loss: 4051395979.6895\n",
      "Epoch 9694/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1374854153.0176 - val_loss: 4055146571.6895\n",
      "Epoch 9695/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1376658947.3816 - val_loss: 4050273080.5479\n",
      "Epoch 9696/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1375387192.8611 - val_loss: 4068883643.1781\n",
      "Epoch 9697/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1376867902.1213 - val_loss: 4048609966.3196\n",
      "Epoch 9698/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1375302878.6849 - val_loss: 4067368986.4475\n",
      "Epoch 9699/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1378088103.4521 - val_loss: 4052959326.2466\n",
      "Epoch 9700/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1375006639.5930 - val_loss: 4071787815.8904\n",
      "Epoch 9701/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1377399411.4755 - val_loss: 4055475198.1005\n",
      "Epoch 9702/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1375709648.9080 - val_loss: 4057891597.8813\n",
      "Epoch 9703/10000\n",
      "1022/1022 [==============================] - 0s 77us/step - loss: 1376213186.8806 - val_loss: 4052659843.7991\n",
      "Epoch 9704/10000\n",
      "1022/1022 [==============================] - 0s 84us/step - loss: 1377623446.0431 - val_loss: 4073696985.1324\n",
      "Epoch 9705/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1374933199.1546 - val_loss: 4048202127.3425\n",
      "Epoch 9706/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1377117176.7358 - val_loss: 4052657577.0594\n",
      "Epoch 9707/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1376016938.8337 - val_loss: 4064263884.4201\n",
      "Epoch 9708/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1378994907.9295 - val_loss: 4046336513.1689\n",
      "Epoch 9709/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1375366471.6399 - val_loss: 4063256894.8311\n",
      "Epoch 9710/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1375910493.4325 - val_loss: 4061533007.6347\n",
      "Epoch 9711/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1375741733.9491 - val_loss: 4068241388.7123\n",
      "Epoch 9712/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1375499578.9902 - val_loss: 4057166605.2968\n",
      "Epoch 9713/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1377375703.2955 - val_loss: 4048252304.2192\n",
      "Epoch 9714/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1376210992.5949 - val_loss: 4052275902.1005\n",
      "Epoch 9715/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1376029304.4853 - val_loss: 4062358253.1507\n",
      "Epoch 9716/10000\n",
      "1022/1022 [==============================] - 0s 67us/step - loss: 1376388246.6693 - val_loss: 4058372237.0046\n",
      "Epoch 9717/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1376781087.8121 - val_loss: 4078437695.1233\n",
      "Epoch 9718/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1374551665.0333 - val_loss: 4051371893.3333\n",
      "Epoch 9719/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1375167373.4638 - val_loss: 4060666661.4064\n",
      "Epoch 9720/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1375977552.9080 - val_loss: 4056670721.7534\n",
      "Epoch 9721/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1375431740.6184 - val_loss: 4056696590.0274\n",
      "Epoch 9722/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1375698392.9237 - val_loss: 4047166404.6758\n",
      "Epoch 9723/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1375411683.9452 - val_loss: 4048708384.5845\n",
      "Epoch 9724/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1375253789.5577 - val_loss: 4063184816.0731\n",
      "Epoch 9725/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1374993964.9628 - val_loss: 4055838113.4612\n",
      "Epoch 9726/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1376761699.8200 - val_loss: 4074308854.5023\n",
      "Epoch 9727/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1375977821.1820 - val_loss: 4061313191.7443\n",
      "Epoch 9728/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1376235025.1585 - val_loss: 4060935326.6849\n",
      "Epoch 9729/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1376021957.0098 - val_loss: 4052989611.1050\n",
      "Epoch 9730/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1375891192.4853 - val_loss: 4057678151.0137\n",
      "Epoch 9731/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1374916458.2074 - val_loss: 4061071772.6393\n",
      "Epoch 9732/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1376256847.9061 - val_loss: 4059865923.6530\n",
      "Epoch 9733/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1377303018.0822 - val_loss: 4078331800.9863\n",
      "Epoch 9734/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1375042532.4462 - val_loss: 4054651065.5708\n",
      "Epoch 9735/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1375253181.8708 - val_loss: 4058804040.3288\n",
      "Epoch 9736/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1377892543.4990 - val_loss: 4069622583.9635\n",
      "Epoch 9737/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1374771383.3581 - val_loss: 4050723476.4566\n",
      "Epoch 9738/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1380575631.1546 - val_loss: 4047889775.7808\n",
      "Epoch 9739/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1375137102.2779 - val_loss: 4068957767.0137\n",
      "Epoch 9740/10000\n",
      "1022/1022 [==============================] - 0s 63us/step - loss: 1375183641.0489 - val_loss: 4062550003.2877\n",
      "Epoch 9741/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1375547087.1546 - val_loss: 4062435032.5479\n",
      "Epoch 9742/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1376067524.2583 - val_loss: 4062023258.7397\n",
      "Epoch 9743/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1375306002.7867 - val_loss: 4051512730.4475\n",
      "Epoch 9744/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 47us/step - loss: 1377702187.8356 - val_loss: 4057858394.8858\n",
      "Epoch 9745/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1376672009.6438 - val_loss: 4059054181.4064\n",
      "Epoch 9746/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1376389428.1018 - val_loss: 4047021799.3059\n",
      "Epoch 9747/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1374818475.5851 - val_loss: 4075467473.6804\n",
      "Epoch 9748/10000\n",
      "1022/1022 [==============================] - 0s 130us/step - loss: 1377664542.6849 - val_loss: 4055137648.3653\n",
      "Epoch 9749/10000\n",
      "1022/1022 [==============================] - 0s 103us/step - loss: 1375102297.4247 - val_loss: 4069434878.2466\n",
      "Epoch 9750/10000\n",
      "1022/1022 [==============================] - 0s 108us/step - loss: 1374620925.8708 - val_loss: 4062061688.6941\n",
      "Epoch 9751/10000\n",
      "1022/1022 [==============================] - 0s 110us/step - loss: 1377120116.6027 - val_loss: 4054407146.5205\n",
      "Epoch 9752/10000\n",
      "1022/1022 [==============================] - 0s 69us/step - loss: 1375269333.4168 - val_loss: 4064555881.2055\n",
      "Epoch 9753/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1375645635.6321 - val_loss: 4062184388.3836\n",
      "Epoch 9754/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1375718777.0489 - val_loss: 4055538143.7078\n",
      "Epoch 9755/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1376078831.8434 - val_loss: 4057581714.1187\n",
      "Epoch 9756/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1375328796.5558 - val_loss: 4059075706.0091\n",
      "Epoch 9757/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1377599783.2016 - val_loss: 4051400768.0000\n",
      "Epoch 9758/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1376111036.6184 - val_loss: 4051157356.1279\n",
      "Epoch 9759/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1376204201.0802 - val_loss: 4051980519.0137\n",
      "Epoch 9760/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1375978964.6654 - val_loss: 4058332456.4749\n",
      "Epoch 9761/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1374933435.1155 - val_loss: 4057144128.1461\n",
      "Epoch 9762/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1376068031.3738 - val_loss: 4060588322.0457\n",
      "Epoch 9763/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1374942789.7613 - val_loss: 4054900970.5205\n",
      "Epoch 9764/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1377285624.2348 - val_loss: 4055507424.4384\n",
      "Epoch 9765/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1375356455.5773 - val_loss: 4063907352.1096\n",
      "Epoch 9766/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1375028430.0274 - val_loss: 4057186739.2877\n",
      "Epoch 9767/10000\n",
      "1022/1022 [==============================] - 0s 66us/step - loss: 1376141909.9178 - val_loss: 4062931897.4247\n",
      "Epoch 9768/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1375556100.0078 - val_loss: 4051122773.3333\n",
      "Epoch 9769/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1375574405.5108 - val_loss: 4066189817.5708\n",
      "Epoch 9770/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1374599966.9354 - val_loss: 4059652825.1324\n",
      "Epoch 9771/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1376526795.6477 - val_loss: 4063737010.9954\n",
      "Epoch 9772/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1376895047.5773 - val_loss: 4058047330.6301\n",
      "Epoch 9773/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1377883836.6184 - val_loss: 4037152607.5616\n",
      "Epoch 9774/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1375384779.3973 - val_loss: 4058292981.1872\n",
      "Epoch 9775/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1376975509.7926 - val_loss: 4070263915.9817\n",
      "Epoch 9776/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1375626711.9217 - val_loss: 4043907932.3470\n",
      "Epoch 9777/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1375274850.8180 - val_loss: 4049787091.2877\n",
      "Epoch 9778/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1376094885.8239 - val_loss: 4052740491.6895\n",
      "Epoch 9779/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1376594378.5205 - val_loss: 4066249956.0913\n",
      "Epoch 9780/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1376182330.6145 - val_loss: 4044994943.8539\n",
      "Epoch 9781/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1374833859.8826 - val_loss: 4068174422.3562\n",
      "Epoch 9782/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1375760815.7808 - val_loss: 4065141193.6438\n",
      "Epoch 9783/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1376134430.3092 - val_loss: 4047633762.1918\n",
      "Epoch 9784/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1375070769.3464 - val_loss: 4062315515.3242\n",
      "Epoch 9785/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1375829466.5519 - val_loss: 4052451511.2329\n",
      "Epoch 9786/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1376415058.6614 - val_loss: 4047161775.7808\n",
      "Epoch 9787/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1374800860.3053 - val_loss: 4058466971.6164\n",
      "Epoch 9788/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1379824458.0196 - val_loss: 4093114097.3881\n",
      "Epoch 9789/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1375350645.4795 - val_loss: 4045321744.3653\n",
      "Epoch 9790/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1375586035.9765 - val_loss: 4055465848.6941\n",
      "Epoch 9791/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1375627495.2016 - val_loss: 4073691913.0594\n",
      "Epoch 9792/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1375150819.0685 - val_loss: 4047700560.8037\n",
      "Epoch 9793/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1375223305.0176 - val_loss: 4052008634.4475\n",
      "Epoch 9794/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1374916153.8630 - val_loss: 4065889327.3425\n",
      "Epoch 9795/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1375347154.2857 - val_loss: 4049423359.8539\n",
      "Epoch 9796/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1375231351.1076 - val_loss: 4065100164.3836\n",
      "Epoch 9797/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1374894998.9198 - val_loss: 4056466203.7626\n",
      "Epoch 9798/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1374646023.0137 - val_loss: 4058918875.3242\n",
      "Epoch 9799/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1377553345.6282 - val_loss: 4047430120.0365\n",
      "Epoch 9800/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1374986491.7417 - val_loss: 4061815326.8311\n",
      "Epoch 9801/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1374687833.1742 - val_loss: 4060744800.2922\n",
      "Epoch 9802/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1375048416.4384 - val_loss: 4060955715.3607\n",
      "Epoch 9803/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1375183362.5049 - val_loss: 4058842200.4018\n",
      "Epoch 9804/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1375365199.6556 - val_loss: 4042245299.1416\n",
      "Epoch 9805/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1376079289.8630 - val_loss: 4061133837.4429\n",
      "Epoch 9806/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1375161303.6712 - val_loss: 4056989418.8128\n",
      "Epoch 9807/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1375137798.7632 - val_loss: 4051763129.7169\n",
      "Epoch 9808/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 45us/step - loss: 1377395350.0431 - val_loss: 4071127279.1963\n",
      "Epoch 9809/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1376259959.2329 - val_loss: 4045726834.9954\n",
      "Epoch 9810/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1374897260.9628 - val_loss: 4053894234.7397\n",
      "Epoch 9811/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1375184831.6869 - val_loss: 4056587072.1461\n",
      "Epoch 9812/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1376354091.8356 - val_loss: 4065779888.9498\n",
      "Epoch 9813/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1374684539.7417 - val_loss: 4050054723.3607\n",
      "Epoch 9814/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1376074319.2798 - val_loss: 4052162198.3562\n",
      "Epoch 9815/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1374720535.7965 - val_loss: 4061409711.9269\n",
      "Epoch 9816/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1376085024.5636 - val_loss: 4052605645.0046\n",
      "Epoch 9817/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1377416446.2466 - val_loss: 4054606114.9224\n",
      "Epoch 9818/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1376110684.6810 - val_loss: 4068100957.3699\n",
      "Epoch 9819/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1374430971.6164 - val_loss: 4052417911.8174\n",
      "Epoch 9820/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1374877839.5303 - val_loss: 4052543185.5342\n",
      "Epoch 9821/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1375860614.8885 - val_loss: 4044224240.8037\n",
      "Epoch 9822/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1375487411.3503 - val_loss: 4054176362.5205\n",
      "Epoch 9823/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1375282185.5186 - val_loss: 4062851497.2055\n",
      "Epoch 9824/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1376835548.4305 - val_loss: 4066045913.2785\n",
      "Epoch 9825/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1375058751.8748 - val_loss: 4058025554.7032\n",
      "Epoch 9826/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1376169260.3366 - val_loss: 4040924451.7991\n",
      "Epoch 9827/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1374977678.0274 - val_loss: 4057386786.3379\n",
      "Epoch 9828/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1376051006.8728 - val_loss: 4046079178.0822\n",
      "Epoch 9829/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1376690077.3699 - val_loss: 4072868042.3744\n",
      "Epoch 9830/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1375100948.0391 - val_loss: 4053106221.5890\n",
      "Epoch 9831/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1376346566.3875 - val_loss: 4047305424.8037\n",
      "Epoch 9832/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1376623466.4579 - val_loss: 4063292705.6073\n",
      "Epoch 9833/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1375586615.3581 - val_loss: 4057493559.6712\n",
      "Epoch 9834/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1374310426.5519 - val_loss: 4063927438.1735\n",
      "Epoch 9835/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1375679460.4462 - val_loss: 4069132974.6119\n",
      "Epoch 9836/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1375333515.7730 - val_loss: 4053047468.8584\n",
      "Epoch 9837/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1374591577.6751 - val_loss: 4058471084.5662\n",
      "Epoch 9838/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1375193254.5753 - val_loss: 4061511248.9498\n",
      "Epoch 9839/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1374928347.9295 - val_loss: 4057542376.6210\n",
      "Epoch 9840/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1375145206.7319 - val_loss: 4066716362.8128\n",
      "Epoch 9841/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1375696189.6204 - val_loss: 4056762209.3151\n",
      "Epoch 9842/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1375614094.2779 - val_loss: 4064115353.5708\n",
      "Epoch 9843/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1375068098.3796 - val_loss: 4051123383.6712\n",
      "Epoch 9844/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1374712180.2270 - val_loss: 4059877422.0274\n",
      "Epoch 9845/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1374539563.4599 - val_loss: 4054780119.5251\n",
      "Epoch 9846/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1376367787.5851 - val_loss: 4059936100.9680\n",
      "Epoch 9847/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1375493854.6849 - val_loss: 4056317441.4612\n",
      "Epoch 9848/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1375679572.5401 - val_loss: 4058415310.9041\n",
      "Epoch 9849/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1374695462.8258 - val_loss: 4054683933.2237\n",
      "Epoch 9850/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1376123088.4070 - val_loss: 4050431017.9361\n",
      "Epoch 9851/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1374681882.8023 - val_loss: 4054891708.9315\n",
      "Epoch 9852/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1375786024.5793 - val_loss: 4050219488.5845\n",
      "Epoch 9853/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1374758489.2994 - val_loss: 4061019978.9589\n",
      "Epoch 9854/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1376451551.5616 - val_loss: 4048389771.8356\n",
      "Epoch 9855/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1375581238.6067 - val_loss: 4073311448.4018\n",
      "Epoch 9856/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1374200016.0313 - val_loss: 4054148531.2877\n",
      "Epoch 9857/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1374910880.8141 - val_loss: 4053430598.5753\n",
      "Epoch 9858/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1376716514.8180 - val_loss: 4056581161.4977\n",
      "Epoch 9859/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1375659485.6830 - val_loss: 4060759281.9726\n",
      "Epoch 9860/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1376089020.3679 - val_loss: 4057975598.1735\n",
      "Epoch 9861/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1375044933.5108 - val_loss: 4063954346.8128\n",
      "Epoch 9862/10000\n",
      "1022/1022 [==============================] - 0s 58us/step - loss: 1375058634.6458 - val_loss: 4063782482.2648\n",
      "Epoch 9863/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1375073221.1350 - val_loss: 4048491838.2466\n",
      "Epoch 9864/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1374373087.6869 - val_loss: 4058570101.3333\n",
      "Epoch 9865/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1375428258.3170 - val_loss: 4060065978.3014\n",
      "Epoch 9866/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1377709095.3268 - val_loss: 4055636328.6210\n",
      "Epoch 9867/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1375574279.5773 - val_loss: 4063207208.0365\n",
      "Epoch 9868/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1374774034.7867 - val_loss: 4060044639.7078\n",
      "Epoch 9869/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1375351070.3092 - val_loss: 4043853262.9041\n",
      "Epoch 9870/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1377189541.8239 - val_loss: 4063184057.5708\n",
      "Epoch 9871/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1374923312.8454 - val_loss: 4061692013.0046\n",
      "Epoch 9872/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 55us/step - loss: 1374852039.8904 - val_loss: 4047948487.8904\n",
      "Epoch 9873/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1375461135.0920 - val_loss: 4053620001.7534\n",
      "Epoch 9874/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1378038558.3092 - val_loss: 4067854035.1416\n",
      "Epoch 9875/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1374690436.1331 - val_loss: 4050063849.0594\n",
      "Epoch 9876/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1375979356.6810 - val_loss: 4066754483.2877\n",
      "Epoch 9877/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1379696678.5753 - val_loss: 4035010368.4384\n",
      "Epoch 9878/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1374314711.4207 - val_loss: 4065975669.0411\n",
      "Epoch 9879/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1375656179.7260 - val_loss: 4054821056.8767\n",
      "Epoch 9880/10000\n",
      "1022/1022 [==============================] - 0s 37us/step - loss: 1376069328.4070 - val_loss: 4067873852.3470\n",
      "Epoch 9881/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1375113523.0998 - val_loss: 4046802601.9361\n",
      "Epoch 9882/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1375434507.1468 - val_loss: 4066228436.0183\n",
      "Epoch 9883/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1375156968.4540 - val_loss: 4067023898.7397\n",
      "Epoch 9884/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1374522600.1409 - val_loss: 4055116945.3881\n",
      "Epoch 9885/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1378811855.4051 - val_loss: 4062652465.8265\n",
      "Epoch 9886/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1375181837.0254 - val_loss: 4043218037.4795\n",
      "Epoch 9887/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1377779328.2505 - val_loss: 4070930632.0365\n",
      "Epoch 9888/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1374637883.6164 - val_loss: 4051031418.8858\n",
      "Epoch 9889/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1375130003.0372 - val_loss: 4053022030.9041\n",
      "Epoch 9890/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1375167385.4247 - val_loss: 4057332824.8402\n",
      "Epoch 9891/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1376596300.1487 - val_loss: 4063401974.3562\n",
      "Epoch 9892/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1376130786.5675 - val_loss: 4055741236.1644\n",
      "Epoch 9893/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1375523435.7104 - val_loss: 4043433498.8858\n",
      "Epoch 9894/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1375022680.1722 - val_loss: 4048403434.2283\n",
      "Epoch 9895/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1373966301.4325 - val_loss: 4057630520.1096\n",
      "Epoch 9896/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1375900000.1879 - val_loss: 4061447507.7260\n",
      "Epoch 9897/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1375989531.3033 - val_loss: 4050909352.4749\n",
      "Epoch 9898/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1374955803.3033 - val_loss: 4069050074.1553\n",
      "Epoch 9899/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1376329593.7378 - val_loss: 4046187229.0776\n",
      "Epoch 9900/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1375449246.0587 - val_loss: 4049286764.2740\n",
      "Epoch 9901/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1375014771.9765 - val_loss: 4061881980.9315\n",
      "Epoch 9902/10000\n",
      "1022/1022 [==============================] - 0s 60us/step - loss: 1375490935.2329 - val_loss: 4069114752.8767\n",
      "Epoch 9903/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1375571773.3699 - val_loss: 4045393137.5342\n",
      "Epoch 9904/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1374370905.5499 - val_loss: 4052005822.6849\n",
      "Epoch 9905/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1374650406.1996 - val_loss: 4060058606.6119\n",
      "Epoch 9906/10000\n",
      "1022/1022 [==============================] - 0s 55us/step - loss: 1374534103.5460 - val_loss: 4071554321.9726\n",
      "Epoch 9907/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1377393205.1037 - val_loss: 4057315689.2055\n",
      "Epoch 9908/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1374363750.0117 - val_loss: 4053505845.0411\n",
      "Epoch 9909/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1376593047.2955 - val_loss: 4068583123.2877\n",
      "Epoch 9910/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1373768158.6849 - val_loss: 4047503160.5479\n",
      "Epoch 9911/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1374724621.0254 - val_loss: 4057779194.0091\n",
      "Epoch 9912/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1375431250.0352 - val_loss: 4054130107.1781\n",
      "Epoch 9913/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1374720544.8141 - val_loss: 4063584242.8493\n",
      "Epoch 9914/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1375135126.9198 - val_loss: 4057503020.4201\n",
      "Epoch 9915/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1374308221.4951 - val_loss: 4048788971.1050\n",
      "Epoch 9916/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1374401021.4951 - val_loss: 4049587672.1096\n",
      "Epoch 9917/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1376605908.4149 - val_loss: 4080003886.1735\n",
      "Epoch 9918/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1380066528.9393 - val_loss: 4032364203.6895\n",
      "Epoch 9919/10000\n",
      "1022/1022 [==============================] - 0s 53us/step - loss: 1376462856.2035 - val_loss: 4054474797.7352\n",
      "Epoch 9920/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1375646944.9393 - val_loss: 4070292822.2100\n",
      "Epoch 9921/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1375586807.9843 - val_loss: 4054652529.3881\n",
      "Epoch 9922/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1376829267.6634 - val_loss: 4049998173.3699\n",
      "Epoch 9923/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1375412537.6125 - val_loss: 4054253217.6073\n",
      "Epoch 9924/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1376576428.3366 - val_loss: 4052001621.7717\n",
      "Epoch 9925/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1374037442.8806 - val_loss: 4060505017.4247\n",
      "Epoch 9926/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1377794064.7828 - val_loss: 4050485307.9087\n",
      "Epoch 9927/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1374268538.7397 - val_loss: 4064784637.6621\n",
      "Epoch 9928/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1375396618.0822 - val_loss: 4072525412.5297\n",
      "Epoch 9929/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1376345061.8865 - val_loss: 4047118213.1142\n",
      "Epoch 9930/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1374498992.7202 - val_loss: 4058114718.3927\n",
      "Epoch 9931/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1376002509.4012 - val_loss: 4075009275.4703\n",
      "Epoch 9932/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1373974655.4990 - val_loss: 4056481318.8676\n",
      "Epoch 9933/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1375943879.6399 - val_loss: 4046062666.6667\n",
      "Epoch 9934/10000\n",
      "1022/1022 [==============================] - 0s 56us/step - loss: 1375430897.3464 - val_loss: 4067750209.3151\n",
      "Epoch 9935/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1374727638.4188 - val_loss: 4056754308.0913\n",
      "Epoch 9936/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 42us/step - loss: 1375034951.1389 - val_loss: 4067655713.3151\n",
      "Epoch 9937/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1377779567.9687 - val_loss: 4044070503.7443\n",
      "Epoch 9938/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1374596936.6419 - val_loss: 4055112249.2785\n",
      "Epoch 9939/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1374768887.6086 - val_loss: 4061707525.1142\n",
      "Epoch 9940/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1375303826.1605 - val_loss: 4074862474.0822\n",
      "Epoch 9941/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1374274977.1898 - val_loss: 4056932394.8128\n",
      "Epoch 9942/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1377061953.7534 - val_loss: 4051257005.7352\n",
      "Epoch 9943/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1374661472.9393 - val_loss: 4057386980.0913\n",
      "Epoch 9944/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1374460489.7065 - val_loss: 4059366376.1826\n",
      "Epoch 9945/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1374632992.8141 - val_loss: 4056871815.7443\n",
      "Epoch 9946/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1374590745.0489 - val_loss: 4067031151.7808\n",
      "Epoch 9947/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1374725039.2172 - val_loss: 4058716276.7489\n",
      "Epoch 9948/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1374259215.7808 - val_loss: 4056267875.5068\n",
      "Epoch 9949/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1374718322.7241 - val_loss: 4048724908.2740\n",
      "Epoch 9950/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1374462572.1487 - val_loss: 4065891544.4018\n",
      "Epoch 9951/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1374739141.3855 - val_loss: 4050868123.9087\n",
      "Epoch 9952/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1375392992.6888 - val_loss: 4068054477.1507\n",
      "Epoch 9953/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1374286484.0391 - val_loss: 4054145278.3927\n",
      "Epoch 9954/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1374983231.6243 - val_loss: 4049720452.5297\n",
      "Epoch 9955/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1374964801.8160 - val_loss: 4065184796.9315\n",
      "Epoch 9956/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1375491523.6321 - val_loss: 4046361967.6347\n",
      "Epoch 9957/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1374084157.2446 - val_loss: 4059622616.1096\n",
      "Epoch 9958/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1375240112.3444 - val_loss: 4054648488.7671\n",
      "Epoch 9959/10000\n",
      "1022/1022 [==============================] - 0s 51us/step - loss: 1375031144.5793 - val_loss: 4053664033.3151\n",
      "Epoch 9960/10000\n",
      "1022/1022 [==============================] - 0s 49us/step - loss: 1374510074.4892 - val_loss: 4061002023.0137\n",
      "Epoch 9961/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1374778959.4051 - val_loss: 4049991716.5297\n",
      "Epoch 9962/10000\n",
      "1022/1022 [==============================] - 0s 50us/step - loss: 1375795789.9022 - val_loss: 4049569604.5297\n",
      "Epoch 9963/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1374743061.5421 - val_loss: 4057480401.6804\n",
      "Epoch 9964/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1374115166.1840 - val_loss: 4052176333.0046\n",
      "Epoch 9965/10000\n",
      "1022/1022 [==============================] - 0s 59us/step - loss: 1374237061.7613 - val_loss: 4055486317.8813\n",
      "Epoch 9966/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1376100096.2505 - val_loss: 4067568653.2968\n",
      "Epoch 9967/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1374527377.0333 - val_loss: 4051524626.2648\n",
      "Epoch 9968/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1375943759.4051 - val_loss: 4042036631.2329\n",
      "Epoch 9969/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1374399361.2524 - val_loss: 4058888508.2009\n",
      "Epoch 9970/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1375150343.6399 - val_loss: 4061134100.1644\n",
      "Epoch 9971/10000\n",
      "1022/1022 [==============================] - 0s 42us/step - loss: 1374154553.3620 - val_loss: 4052962765.8813\n",
      "Epoch 9972/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1376900355.2564 - val_loss: 4048005948.9315\n",
      "Epoch 9973/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1373857465.8630 - val_loss: 4059569596.6393\n",
      "Epoch 9974/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1374671394.5675 - val_loss: 4058562175.5616\n",
      "Epoch 9975/10000\n",
      "1022/1022 [==============================] - 0s 41us/step - loss: 1374836210.2231 - val_loss: 4063807425.7534\n",
      "Epoch 9976/10000\n",
      "1022/1022 [==============================] - 0s 52us/step - loss: 1375225160.3914 - val_loss: 4052206249.3516\n",
      "Epoch 9977/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1374714153.0802 - val_loss: 4054008746.2283\n",
      "Epoch 9978/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1375199858.7241 - val_loss: 4064910767.0502\n",
      "Epoch 9979/10000\n",
      "1022/1022 [==============================] - 0s 39us/step - loss: 1374541249.6282 - val_loss: 4056669597.3699\n",
      "Epoch 9980/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1374957301.3542 - val_loss: 4061395814.5753\n",
      "Epoch 9981/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1375503944.8924 - val_loss: 4044685217.7534\n",
      "Epoch 9982/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1375230492.8063 - val_loss: 4059490352.6575\n",
      "Epoch 9983/10000\n",
      "1022/1022 [==============================] - 0s 45us/step - loss: 1376126585.7378 - val_loss: 4049866831.6347\n",
      "Epoch 9984/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1374749674.3327 - val_loss: 4058306912.4384\n",
      "Epoch 9985/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1373734738.5362 - val_loss: 4056141604.8219\n",
      "Epoch 9986/10000\n",
      "1022/1022 [==============================] - 0s 43us/step - loss: 1374814051.1937 - val_loss: 4065147343.4886\n",
      "Epoch 9987/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1374517649.2838 - val_loss: 4050410893.7352\n",
      "Epoch 9988/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1374306365.8708 - val_loss: 4052415014.2831\n",
      "Epoch 9989/10000\n",
      "1022/1022 [==============================] - 0s 54us/step - loss: 1374199613.4951 - val_loss: 4057699118.1735\n",
      "Epoch 9990/10000\n",
      "1022/1022 [==============================] - 0s 38us/step - loss: 1374675834.8650 - val_loss: 4058561633.4612\n",
      "Epoch 9991/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1374990294.6693 - val_loss: 4046724010.3744\n",
      "Epoch 9992/10000\n",
      "1022/1022 [==============================] - 0s 64us/step - loss: 1374884736.2505 - val_loss: 4056565026.7763\n",
      "Epoch 9993/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1375307821.0881 - val_loss: 4074380934.8676\n",
      "Epoch 9994/10000\n",
      "1022/1022 [==============================] - 0s 40us/step - loss: 1373295290.1135 - val_loss: 4050139879.4521\n",
      "Epoch 9995/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1374810505.7691 - val_loss: 4049298604.8584\n",
      "Epoch 9996/10000\n",
      "1022/1022 [==============================] - 0s 44us/step - loss: 1374827577.6751 - val_loss: 4053788557.8813\n",
      "Epoch 9997/10000\n",
      "1022/1022 [==============================] - 0s 47us/step - loss: 1376413248.9393 - val_loss: 4045849451.9817\n",
      "Epoch 9998/10000\n",
      "1022/1022 [==============================] - 0s 46us/step - loss: 1374452271.0920 - val_loss: 4056817566.8311\n",
      "Epoch 9999/10000\n",
      "1022/1022 [==============================] - 0s 48us/step - loss: 1374851801.6751 - val_loss: 4061233412.0913\n",
      "Epoch 10000/10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1022/1022 [==============================] - 0s 54us/step - loss: 1374239515.0528 - val_loss: 4051354415.1963\n",
      "2019-07-29 14:02:48.112387\n"
     ]
    }
   ],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(9, activation='relu', input_shape=(9,)),\n",
    "    Dense(16, activation='relu'),\n",
    "    Dense(9, activation='relu'),\n",
    "    Dense(1, kernel_initializer='normal'),\n",
    "])\n",
    "\n",
    "model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "\n",
    "hist = model.fit(X_train, Y_train,\n",
    "          batch_size=32, epochs=10000,\n",
    "          validation_data=(X_val, Y_val))\n",
    "\n",
    "print(datetime.datetime.now())\n",
    "1.469.793.709"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "219/219 [==============================] - 0s 57us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1172027537.5342467"
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# [1760425580.7123287, 0.0]\n",
    "model.evaluate(X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_resultado = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>projetado</th>\n",
       "      <th>original</th>\n",
       "      <th>diferenca</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>150126.203125</td>\n",
       "      <td>175000</td>\n",
       "      <td>-24873.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>163703.531250</td>\n",
       "      <td>165500</td>\n",
       "      <td>-1796.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>131423.015625</td>\n",
       "      <td>134000</td>\n",
       "      <td>-2576.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>227072.796875</td>\n",
       "      <td>219500</td>\n",
       "      <td>7572.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>226474.562500</td>\n",
       "      <td>184000</td>\n",
       "      <td>42474.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>186783.468750</td>\n",
       "      <td>163990</td>\n",
       "      <td>22793.468750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>175695.078125</td>\n",
       "      <td>202900</td>\n",
       "      <td>-27204.921875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>134346.265625</td>\n",
       "      <td>142000</td>\n",
       "      <td>-7653.734375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>95796.468750</td>\n",
       "      <td>144000</td>\n",
       "      <td>-48203.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>186521.578125</td>\n",
       "      <td>239000</td>\n",
       "      <td>-52478.421875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>127293.359375</td>\n",
       "      <td>64500</td>\n",
       "      <td>62793.359375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>153003.296875</td>\n",
       "      <td>162000</td>\n",
       "      <td>-8996.703125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>146252.296875</td>\n",
       "      <td>145000</td>\n",
       "      <td>1252.296875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>233893.453125</td>\n",
       "      <td>237000</td>\n",
       "      <td>-3106.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>197729.968750</td>\n",
       "      <td>192000</td>\n",
       "      <td>5729.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>243695.546875</td>\n",
       "      <td>230000</td>\n",
       "      <td>13695.546875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>150670.781250</td>\n",
       "      <td>127000</td>\n",
       "      <td>23670.781250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>126477.203125</td>\n",
       "      <td>124900</td>\n",
       "      <td>1577.203125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>52049.937500</td>\n",
       "      <td>61000</td>\n",
       "      <td>-8950.062500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>120836.796875</td>\n",
       "      <td>115000</td>\n",
       "      <td>5836.796875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>170577.375000</td>\n",
       "      <td>175000</td>\n",
       "      <td>-4422.625000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>249104.531250</td>\n",
       "      <td>217000</td>\n",
       "      <td>32104.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>234923.343750</td>\n",
       "      <td>264132</td>\n",
       "      <td>-29208.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>181956.359375</td>\n",
       "      <td>178000</td>\n",
       "      <td>3956.359375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>169239.859375</td>\n",
       "      <td>144152</td>\n",
       "      <td>25087.859375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>276519.468750</td>\n",
       "      <td>324000</td>\n",
       "      <td>-47480.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>135523.828125</td>\n",
       "      <td>130000</td>\n",
       "      <td>5523.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>109724.828125</td>\n",
       "      <td>115000</td>\n",
       "      <td>-5275.171875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>125138.304688</td>\n",
       "      <td>102000</td>\n",
       "      <td>23138.304688</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>134492.171875</td>\n",
       "      <td>127000</td>\n",
       "      <td>7492.171875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>130158.242188</td>\n",
       "      <td>118000</td>\n",
       "      <td>12158.242188</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>167496.453125</td>\n",
       "      <td>167000</td>\n",
       "      <td>496.453125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>162023.218750</td>\n",
       "      <td>110000</td>\n",
       "      <td>52023.218750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>285203.875000</td>\n",
       "      <td>290000</td>\n",
       "      <td>-4796.125000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>378377.843750</td>\n",
       "      <td>250000</td>\n",
       "      <td>128377.843750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>138145.718750</td>\n",
       "      <td>144000</td>\n",
       "      <td>-5854.281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>147573.890625</td>\n",
       "      <td>135000</td>\n",
       "      <td>12573.890625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>251536.968750</td>\n",
       "      <td>200000</td>\n",
       "      <td>51536.968750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>208649.953125</td>\n",
       "      <td>185850</td>\n",
       "      <td>22799.953125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>183747.281250</td>\n",
       "      <td>157000</td>\n",
       "      <td>26747.281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>182946.625000</td>\n",
       "      <td>260000</td>\n",
       "      <td>-77053.375000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>158863.531250</td>\n",
       "      <td>151000</td>\n",
       "      <td>7863.531250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>207559.390625</td>\n",
       "      <td>215000</td>\n",
       "      <td>-7440.609375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>202</th>\n",
       "      <td>350007.656250</td>\n",
       "      <td>325300</td>\n",
       "      <td>24707.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>203</th>\n",
       "      <td>289026.593750</td>\n",
       "      <td>326000</td>\n",
       "      <td>-36973.406250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>204</th>\n",
       "      <td>161035.765625</td>\n",
       "      <td>177500</td>\n",
       "      <td>-16464.234375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>205</th>\n",
       "      <td>241853.171875</td>\n",
       "      <td>244600</td>\n",
       "      <td>-2746.828125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>206</th>\n",
       "      <td>99020.882812</td>\n",
       "      <td>78000</td>\n",
       "      <td>21020.882812</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>207</th>\n",
       "      <td>266174.031250</td>\n",
       "      <td>256300</td>\n",
       "      <td>9874.031250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>213184.015625</td>\n",
       "      <td>225000</td>\n",
       "      <td>-11815.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>132579.046875</td>\n",
       "      <td>132500</td>\n",
       "      <td>79.046875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>141972.984375</td>\n",
       "      <td>154900</td>\n",
       "      <td>-12927.015625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>119296.976562</td>\n",
       "      <td>128950</td>\n",
       "      <td>-9653.023438</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>191806.328125</td>\n",
       "      <td>175500</td>\n",
       "      <td>16306.328125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>316841.281250</td>\n",
       "      <td>315000</td>\n",
       "      <td>1841.281250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>214</th>\n",
       "      <td>141748.234375</td>\n",
       "      <td>139000</td>\n",
       "      <td>2748.234375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>215</th>\n",
       "      <td>345530.656250</td>\n",
       "      <td>305000</td>\n",
       "      <td>40530.656250</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>216</th>\n",
       "      <td>229120.484375</td>\n",
       "      <td>290000</td>\n",
       "      <td>-60879.515625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>217</th>\n",
       "      <td>255280.015625</td>\n",
       "      <td>301000</td>\n",
       "      <td>-45719.984375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>218</th>\n",
       "      <td>184505.546875</td>\n",
       "      <td>160000</td>\n",
       "      <td>24505.546875</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>219 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         projetado  original      diferenca\n",
       "0    150126.203125    175000  -24873.796875\n",
       "1    163703.531250    165500   -1796.468750\n",
       "2    131423.015625    134000   -2576.984375\n",
       "3    227072.796875    219500    7572.796875\n",
       "4    226474.562500    184000   42474.562500\n",
       "5    186783.468750    163990   22793.468750\n",
       "6    175695.078125    202900  -27204.921875\n",
       "7    134346.265625    142000   -7653.734375\n",
       "8     95796.468750    144000  -48203.531250\n",
       "9    186521.578125    239000  -52478.421875\n",
       "10   127293.359375     64500   62793.359375\n",
       "11   153003.296875    162000   -8996.703125\n",
       "12   146252.296875    145000    1252.296875\n",
       "13   233893.453125    237000   -3106.546875\n",
       "14   197729.968750    192000    5729.968750\n",
       "15   243695.546875    230000   13695.546875\n",
       "16   150670.781250    127000   23670.781250\n",
       "17   126477.203125    124900    1577.203125\n",
       "18    52049.937500     61000   -8950.062500\n",
       "19   120836.796875    115000    5836.796875\n",
       "20   170577.375000    175000   -4422.625000\n",
       "21   249104.531250    217000   32104.531250\n",
       "22   234923.343750    264132  -29208.656250\n",
       "23   181956.359375    178000    3956.359375\n",
       "24   169239.859375    144152   25087.859375\n",
       "25   276519.468750    324000  -47480.531250\n",
       "26   135523.828125    130000    5523.828125\n",
       "27   109724.828125    115000   -5275.171875\n",
       "28   125138.304688    102000   23138.304688\n",
       "29   134492.171875    127000    7492.171875\n",
       "..             ...       ...            ...\n",
       "189  130158.242188    118000   12158.242188\n",
       "190  167496.453125    167000     496.453125\n",
       "191  162023.218750    110000   52023.218750\n",
       "192  285203.875000    290000   -4796.125000\n",
       "193  378377.843750    250000  128377.843750\n",
       "194  138145.718750    144000   -5854.281250\n",
       "195  147573.890625    135000   12573.890625\n",
       "196  251536.968750    200000   51536.968750\n",
       "197  208649.953125    185850   22799.953125\n",
       "198  183747.281250    157000   26747.281250\n",
       "199  182946.625000    260000  -77053.375000\n",
       "200  158863.531250    151000    7863.531250\n",
       "201  207559.390625    215000   -7440.609375\n",
       "202  350007.656250    325300   24707.656250\n",
       "203  289026.593750    326000  -36973.406250\n",
       "204  161035.765625    177500  -16464.234375\n",
       "205  241853.171875    244600   -2746.828125\n",
       "206   99020.882812     78000   21020.882812\n",
       "207  266174.031250    256300    9874.031250\n",
       "208  213184.015625    225000  -11815.984375\n",
       "209  132579.046875    132500      79.046875\n",
       "210  141972.984375    154900  -12927.015625\n",
       "211  119296.976562    128950   -9653.023438\n",
       "212  191806.328125    175500   16306.328125\n",
       "213  316841.281250    315000    1841.281250\n",
       "214  141748.234375    139000    2748.234375\n",
       "215  345530.656250    305000   40530.656250\n",
       "216  229120.484375    290000  -60879.515625\n",
       "217  255280.015625    301000  -45719.984375\n",
       "218  184505.546875    160000   24505.546875\n",
       "\n",
       "[219 rows x 3 columns]"
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_Y = pd.DataFrame(Y_resultado)\n",
    "df_Y.columns = [\"projetado\"]\n",
    "\n",
    "df_Y_test = pd.DataFrame(Y_test)\n",
    "df_Y_test.columns = [\"original\"]\n",
    "\n",
    "df_join = df_Y.join(df_Y_test, lsuffix='_caller', rsuffix='_other')\n",
    "df_join[\"diferenca\"] = df_join[\"projetado\"] - df_join[\"original\"]\n",
    "df_join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>208500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>181500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>223500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>140000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>250000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0\n",
       "0  208500\n",
       "1  181500\n",
       "2  223500\n",
       "3  140000\n",
       "4  250000"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(Y).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5375930417680062"
      ]
     },
     "execution_count": 150,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "from math import sqrt\n",
    "# sqrt(mean_squared_error(Y_resultado, Y_test))\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "def rmsle(y, y0):\n",
    "    assert len(y) == len(y0)\n",
    "    return np.sqrt(np.mean(np.power(np.log1p(y)-np.log1p(y0), 2)))\n",
    "\n",
    "df_Y_cheat = df_Y_test[\"original\"] - 7000\n",
    "# df_Y_cheat.columns = [\"cheat\"]\n",
    "# df_Y_cheat\n",
    "# rmsle(Y_test, Y_cheat)\n",
    "\n",
    "# df_join_2 = df_Y_test.join(df_Y_cheat, lsuffix='_caller', rsuffix='_other')\n",
    "# df_join_2[\"diferenca\"] = df_join_2[\"original_caller\"] - df_join_2[\"original_other\"]\n",
    "# df_Y_test[\"original\"].values\n",
    "# df_Y_cheat.values\n",
    "# rmsle(df_Y_test[\"original\"].values, df_Y_cheat.values)\n",
    "\n",
    "rmsle(Y_test, Y_resultado)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.18893243028518214"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "reg = LinearRegression().fit(X_train, Y_train)\n",
    "\n",
    "Y_resultado_2 = reg.predict(X_test)\n",
    "\n",
    "rmsle(Y_test, Y_resultado_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.2956540500521932"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "clf = DecisionTreeClassifier().fit(X_train, Y_train)\n",
    "\n",
    "Y_resultado_3 = clf.predict(X_test)\n",
    "\n",
    "rmsle(Y_test, Y_resultado_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:py3] *",
   "language": "python",
   "name": "conda-env-py3-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
